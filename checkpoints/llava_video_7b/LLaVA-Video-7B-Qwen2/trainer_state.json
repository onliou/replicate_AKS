{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 14382,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 4.197043639821848,
      "learning_rate": 2.3148148148148148e-08,
      "loss": 0.8552,
      "step": 1
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.966297700884303,
      "learning_rate": 4.6296296296296295e-08,
      "loss": 0.8713,
      "step": 2
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.7865329194881148,
      "learning_rate": 6.944444444444444e-08,
      "loss": 0.8455,
      "step": 3
    },
    {
      "epoch": 0.0,
      "grad_norm": 5.744573655715812,
      "learning_rate": 9.259259259259259e-08,
      "loss": 0.8692,
      "step": 4
    },
    {
      "epoch": 0.0,
      "grad_norm": 5.136522019431995,
      "learning_rate": 1.1574074074074074e-07,
      "loss": 0.8741,
      "step": 5
    },
    {
      "epoch": 0.0,
      "grad_norm": 8.669030146464447,
      "learning_rate": 1.3888888888888888e-07,
      "loss": 0.8593,
      "step": 6
    },
    {
      "epoch": 0.0,
      "grad_norm": 4.72998500476174,
      "learning_rate": 1.6203703703703703e-07,
      "loss": 0.9001,
      "step": 7
    },
    {
      "epoch": 0.0,
      "grad_norm": 4.649524345356347,
      "learning_rate": 1.8518518518518518e-07,
      "loss": 0.9104,
      "step": 8
    },
    {
      "epoch": 0.0,
      "grad_norm": 4.122617272193584,
      "learning_rate": 2.0833333333333333e-07,
      "loss": 0.8527,
      "step": 9
    },
    {
      "epoch": 0.0,
      "grad_norm": 4.583809781988919,
      "learning_rate": 2.3148148148148148e-07,
      "loss": 0.9226,
      "step": 10
    },
    {
      "epoch": 0.0,
      "grad_norm": 4.512706129356338,
      "learning_rate": 2.5462962962962963e-07,
      "loss": 0.8966,
      "step": 11
    },
    {
      "epoch": 0.0,
      "grad_norm": 4.056235483994099,
      "learning_rate": 2.7777777777777776e-07,
      "loss": 0.8667,
      "step": 12
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.509217482773418,
      "learning_rate": 3.0092592592592594e-07,
      "loss": 0.8389,
      "step": 13
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.6473254763374935,
      "learning_rate": 3.2407407407407406e-07,
      "loss": 0.3976,
      "step": 14
    },
    {
      "epoch": 0.0,
      "grad_norm": 4.443551796663287,
      "learning_rate": 3.472222222222223e-07,
      "loss": 0.799,
      "step": 15
    },
    {
      "epoch": 0.0,
      "grad_norm": 4.853304885927083,
      "learning_rate": 3.7037037037037036e-07,
      "loss": 0.9066,
      "step": 16
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.881861772186662,
      "learning_rate": 3.9351851851851854e-07,
      "loss": 0.8499,
      "step": 17
    },
    {
      "epoch": 0.0,
      "grad_norm": 4.260577664369995,
      "learning_rate": 4.1666666666666667e-07,
      "loss": 0.8494,
      "step": 18
    },
    {
      "epoch": 0.0,
      "grad_norm": 6.338319013085342,
      "learning_rate": 4.3981481481481484e-07,
      "loss": 0.8441,
      "step": 19
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.9135943670022955,
      "learning_rate": 4.6296296296296297e-07,
      "loss": 0.8949,
      "step": 20
    },
    {
      "epoch": 0.0,
      "grad_norm": 4.608866983504083,
      "learning_rate": 4.861111111111112e-07,
      "loss": 0.8127,
      "step": 21
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.45302875870263,
      "learning_rate": 5.092592592592593e-07,
      "loss": 0.8195,
      "step": 22
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.8548956097201583,
      "learning_rate": 5.324074074074074e-07,
      "loss": 0.7884,
      "step": 23
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.623630161933795,
      "learning_rate": 5.555555555555555e-07,
      "loss": 0.8041,
      "step": 24
    },
    {
      "epoch": 0.0,
      "grad_norm": 7.2159486317662,
      "learning_rate": 5.787037037037038e-07,
      "loss": 0.8262,
      "step": 25
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.846210351498215,
      "learning_rate": 6.018518518518519e-07,
      "loss": 0.8341,
      "step": 26
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.6461191073984014,
      "learning_rate": 6.25e-07,
      "loss": 0.804,
      "step": 27
    },
    {
      "epoch": 0.0,
      "grad_norm": 4.6402251769674905,
      "learning_rate": 6.481481481481481e-07,
      "loss": 0.7784,
      "step": 28
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.663476061060849,
      "learning_rate": 6.712962962962964e-07,
      "loss": 0.7645,
      "step": 29
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.3614388693128094,
      "learning_rate": 6.944444444444446e-07,
      "loss": 0.7437,
      "step": 30
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.1273260077163023,
      "learning_rate": 7.175925925925927e-07,
      "loss": 0.774,
      "step": 31
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.5518907261927892,
      "learning_rate": 7.407407407407407e-07,
      "loss": 0.7471,
      "step": 32
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.8199395428093443,
      "learning_rate": 7.63888888888889e-07,
      "loss": 0.7644,
      "step": 33
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.715524662864493,
      "learning_rate": 7.870370370370371e-07,
      "loss": 0.7155,
      "step": 34
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.7429792953269871,
      "learning_rate": 8.101851851851853e-07,
      "loss": 0.4006,
      "step": 35
    },
    {
      "epoch": 0.0,
      "grad_norm": 10.198237807003807,
      "learning_rate": 8.333333333333333e-07,
      "loss": 0.7222,
      "step": 36
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.5230182436322055,
      "learning_rate": 8.564814814814816e-07,
      "loss": 0.7648,
      "step": 37
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.752203028580122,
      "learning_rate": 8.796296296296297e-07,
      "loss": 0.7622,
      "step": 38
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.5882091104991027,
      "learning_rate": 9.027777777777779e-07,
      "loss": 0.7221,
      "step": 39
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.78128023008227,
      "learning_rate": 9.259259259259259e-07,
      "loss": 0.7188,
      "step": 40
    },
    {
      "epoch": 0.0,
      "grad_norm": 17.84578329389657,
      "learning_rate": 9.490740740740742e-07,
      "loss": 0.6667,
      "step": 41
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.6235966989478325,
      "learning_rate": 9.722222222222224e-07,
      "loss": 0.6687,
      "step": 42
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.4524197387934126,
      "learning_rate": 9.953703703703704e-07,
      "loss": 0.7465,
      "step": 43
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.2330522540279856,
      "learning_rate": 1.0185185185185185e-06,
      "loss": 0.7611,
      "step": 44
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.4669395033869383,
      "learning_rate": 1.0416666666666667e-06,
      "loss": 0.6795,
      "step": 45
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.856023993557037,
      "learning_rate": 1.0648148148148149e-06,
      "loss": 0.7543,
      "step": 46
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.072492172651259,
      "learning_rate": 1.087962962962963e-06,
      "loss": 0.6995,
      "step": 47
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.4478694778322714,
      "learning_rate": 1.111111111111111e-06,
      "loss": 0.7445,
      "step": 48
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.167139561589002,
      "learning_rate": 1.1342592592592594e-06,
      "loss": 0.706,
      "step": 49
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.6008078735368083,
      "learning_rate": 1.1574074074074076e-06,
      "loss": 0.7353,
      "step": 50
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.76173029471043,
      "learning_rate": 1.1805555555555556e-06,
      "loss": 0.693,
      "step": 51
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.314620167731656,
      "learning_rate": 1.2037037037037037e-06,
      "loss": 0.6915,
      "step": 52
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.4622090743253207,
      "learning_rate": 1.226851851851852e-06,
      "loss": 0.7285,
      "step": 53
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.446468510317967,
      "learning_rate": 1.25e-06,
      "loss": 0.7237,
      "step": 54
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.0682240872932396,
      "learning_rate": 1.2731481481481483e-06,
      "loss": 0.7277,
      "step": 55
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.2069103136114023,
      "learning_rate": 1.2962962962962962e-06,
      "loss": 0.6524,
      "step": 56
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.0373168520264944,
      "learning_rate": 1.3194444444444446e-06,
      "loss": 0.6825,
      "step": 57
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.4026085279343548,
      "learning_rate": 1.3425925925925928e-06,
      "loss": 0.7286,
      "step": 58
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.136717538582282,
      "learning_rate": 1.3657407407407408e-06,
      "loss": 0.7219,
      "step": 59
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.712113063544421,
      "learning_rate": 1.3888888888888892e-06,
      "loss": 0.6763,
      "step": 60
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.6817631129345534,
      "learning_rate": 1.4120370370370371e-06,
      "loss": 0.6884,
      "step": 61
    },
    {
      "epoch": 0.0,
      "grad_norm": 6.8246820253519225,
      "learning_rate": 1.4351851851851853e-06,
      "loss": 0.6928,
      "step": 62
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.8950359745547427,
      "learning_rate": 1.4583333333333335e-06,
      "loss": 0.6303,
      "step": 63
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.078290548662997,
      "learning_rate": 1.4814814814814815e-06,
      "loss": 0.7552,
      "step": 64
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.120984565162846,
      "learning_rate": 1.5046296296296298e-06,
      "loss": 0.647,
      "step": 65
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.388711552441574,
      "learning_rate": 1.527777777777778e-06,
      "loss": 0.7123,
      "step": 66
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.3017694571332212,
      "learning_rate": 1.550925925925926e-06,
      "loss": 0.6875,
      "step": 67
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.267199134908115,
      "learning_rate": 1.5740740740740742e-06,
      "loss": 0.6855,
      "step": 68
    },
    {
      "epoch": 0.0,
      "grad_norm": 4.839337382346895,
      "learning_rate": 1.5972222222222221e-06,
      "loss": 0.6536,
      "step": 69
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.411837392926887,
      "learning_rate": 1.6203703703703705e-06,
      "loss": 0.6643,
      "step": 70
    },
    {
      "epoch": 0.0,
      "grad_norm": 3.4582110928856054,
      "learning_rate": 1.6435185185185187e-06,
      "loss": 0.7171,
      "step": 71
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.1349524708120744,
      "learning_rate": 1.6666666666666667e-06,
      "loss": 0.616,
      "step": 72
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.04338921095639,
      "learning_rate": 1.689814814814815e-06,
      "loss": 0.6374,
      "step": 73
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.6732851947403664,
      "learning_rate": 1.7129629629629632e-06,
      "loss": 0.689,
      "step": 74
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.073922838096026,
      "learning_rate": 1.7361111111111112e-06,
      "loss": 0.6833,
      "step": 75
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.705001402006002,
      "learning_rate": 1.7592592592592594e-06,
      "loss": 0.7023,
      "step": 76
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.931090946881886,
      "learning_rate": 1.7824074074074073e-06,
      "loss": 0.6798,
      "step": 77
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.046809069994457,
      "learning_rate": 1.8055555555555557e-06,
      "loss": 0.659,
      "step": 78
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.17050051504363,
      "learning_rate": 1.828703703703704e-06,
      "loss": 0.6306,
      "step": 79
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6290325052458414,
      "learning_rate": 1.8518518518518519e-06,
      "loss": 0.4268,
      "step": 80
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.6590162358555895,
      "learning_rate": 1.8750000000000003e-06,
      "loss": 0.6569,
      "step": 81
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.985712060676535,
      "learning_rate": 1.8981481481481484e-06,
      "loss": 0.6772,
      "step": 82
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.243645409205448,
      "learning_rate": 1.921296296296296e-06,
      "loss": 0.6549,
      "step": 83
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.053323886583903,
      "learning_rate": 1.944444444444445e-06,
      "loss": 0.6404,
      "step": 84
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.208020751174534,
      "learning_rate": 1.967592592592593e-06,
      "loss": 0.6386,
      "step": 85
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.3117994545187317,
      "learning_rate": 1.9907407407407407e-06,
      "loss": 0.6627,
      "step": 86
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.562916023557134,
      "learning_rate": 2.0138888888888893e-06,
      "loss": 0.6716,
      "step": 87
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.178344219403002,
      "learning_rate": 2.037037037037037e-06,
      "loss": 0.6489,
      "step": 88
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.7059696380421743,
      "learning_rate": 2.0601851851851853e-06,
      "loss": 0.6675,
      "step": 89
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.7419179833725624,
      "learning_rate": 2.0833333333333334e-06,
      "loss": 0.6513,
      "step": 90
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.9350301461445816,
      "learning_rate": 2.1064814814814816e-06,
      "loss": 0.5999,
      "step": 91
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.2507180149497046,
      "learning_rate": 2.1296296296296298e-06,
      "loss": 0.6257,
      "step": 92
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.241934542934537,
      "learning_rate": 2.152777777777778e-06,
      "loss": 0.6593,
      "step": 93
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.5049838873028456,
      "learning_rate": 2.175925925925926e-06,
      "loss": 0.5841,
      "step": 94
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.59716963732686,
      "learning_rate": 2.1990740740740743e-06,
      "loss": 0.626,
      "step": 95
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.237851006831317,
      "learning_rate": 2.222222222222222e-06,
      "loss": 0.6704,
      "step": 96
    },
    {
      "epoch": 0.01,
      "grad_norm": 3.3796914681491588,
      "learning_rate": 2.2453703703703707e-06,
      "loss": 0.6674,
      "step": 97
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.011196003989187,
      "learning_rate": 2.268518518518519e-06,
      "loss": 0.6522,
      "step": 98
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.3410786603850893,
      "learning_rate": 2.2916666666666666e-06,
      "loss": 0.6483,
      "step": 99
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.919065956070872,
      "learning_rate": 2.314814814814815e-06,
      "loss": 0.5955,
      "step": 100
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.9828024876214756,
      "learning_rate": 2.3379629629629634e-06,
      "loss": 0.6416,
      "step": 101
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.4350915219831957,
      "learning_rate": 2.361111111111111e-06,
      "loss": 0.6421,
      "step": 102
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.7936289536474916,
      "learning_rate": 2.3842592592592593e-06,
      "loss": 0.6714,
      "step": 103
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.9361657803625534,
      "learning_rate": 2.4074074074074075e-06,
      "loss": 0.6057,
      "step": 104
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.0419559257160556,
      "learning_rate": 2.4305555555555557e-06,
      "loss": 0.6544,
      "step": 105
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.4000147395652482,
      "learning_rate": 2.453703703703704e-06,
      "loss": 0.637,
      "step": 106
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.9613549537711787,
      "learning_rate": 2.476851851851852e-06,
      "loss": 0.6323,
      "step": 107
    },
    {
      "epoch": 0.01,
      "grad_norm": 14.018437447572921,
      "learning_rate": 2.5e-06,
      "loss": 0.6632,
      "step": 108
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.466872071010434,
      "learning_rate": 2.5231481481481484e-06,
      "loss": 0.6572,
      "step": 109
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.2494034128690714,
      "learning_rate": 2.5462962962962966e-06,
      "loss": 0.6585,
      "step": 110
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.208129702771073,
      "learning_rate": 2.5694444444444443e-06,
      "loss": 0.636,
      "step": 111
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.3702248936482193,
      "learning_rate": 2.5925925925925925e-06,
      "loss": 0.6235,
      "step": 112
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.22957751905691,
      "learning_rate": 2.615740740740741e-06,
      "loss": 0.6711,
      "step": 113
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.1856114695290194,
      "learning_rate": 2.6388888888888893e-06,
      "loss": 0.6272,
      "step": 114
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.1291011343060373,
      "learning_rate": 2.6620370370370374e-06,
      "loss": 0.6452,
      "step": 115
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.381933857300962,
      "learning_rate": 2.6851851851851856e-06,
      "loss": 0.5997,
      "step": 116
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.8855626821488622,
      "learning_rate": 2.7083333333333334e-06,
      "loss": 0.657,
      "step": 117
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.9686167722398817,
      "learning_rate": 2.7314814814814816e-06,
      "loss": 0.6815,
      "step": 118
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.326091162098864,
      "learning_rate": 2.7546296296296297e-06,
      "loss": 0.6447,
      "step": 119
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.5262477853941725,
      "learning_rate": 2.7777777777777783e-06,
      "loss": 0.6816,
      "step": 120
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.7348837994793973,
      "learning_rate": 2.8009259259259265e-06,
      "loss": 0.5887,
      "step": 121
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.0154538157454773,
      "learning_rate": 2.8240740740740743e-06,
      "loss": 0.5965,
      "step": 122
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.8362206687395708,
      "learning_rate": 2.8472222222222224e-06,
      "loss": 0.649,
      "step": 123
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.0875860046779926,
      "learning_rate": 2.8703703703703706e-06,
      "loss": 0.5855,
      "step": 124
    },
    {
      "epoch": 0.01,
      "grad_norm": 3.0884065763956463,
      "learning_rate": 2.893518518518519e-06,
      "loss": 0.6058,
      "step": 125
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.758951703645384,
      "learning_rate": 2.916666666666667e-06,
      "loss": 0.6412,
      "step": 126
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.5787108991422194,
      "learning_rate": 2.9398148148148147e-06,
      "loss": 0.5889,
      "step": 127
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.073362707930095,
      "learning_rate": 2.962962962962963e-06,
      "loss": 0.6373,
      "step": 128
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.4005553122351877,
      "learning_rate": 2.986111111111111e-06,
      "loss": 0.632,
      "step": 129
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.350548541686353,
      "learning_rate": 3.0092592592592597e-06,
      "loss": 0.6632,
      "step": 130
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.9579651393806805,
      "learning_rate": 3.032407407407408e-06,
      "loss": 0.5852,
      "step": 131
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.269118043518973,
      "learning_rate": 3.055555555555556e-06,
      "loss": 0.6298,
      "step": 132
    },
    {
      "epoch": 0.01,
      "grad_norm": 3.342948961864737,
      "learning_rate": 3.078703703703704e-06,
      "loss": 0.618,
      "step": 133
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.984437822354501,
      "learning_rate": 3.101851851851852e-06,
      "loss": 0.6277,
      "step": 134
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.1397391435195656,
      "learning_rate": 3.125e-06,
      "loss": 0.6823,
      "step": 135
    },
    {
      "epoch": 0.01,
      "grad_norm": 3.2012525184308216,
      "learning_rate": 3.1481481481481483e-06,
      "loss": 0.6589,
      "step": 136
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.2824118240663838,
      "learning_rate": 3.171296296296297e-06,
      "loss": 0.6063,
      "step": 137
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.9879888348781052,
      "learning_rate": 3.1944444444444443e-06,
      "loss": 0.5727,
      "step": 138
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.35864273899356,
      "learning_rate": 3.217592592592593e-06,
      "loss": 0.5899,
      "step": 139
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.9755246573470147,
      "learning_rate": 3.240740740740741e-06,
      "loss": 0.6242,
      "step": 140
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.371789931906551,
      "learning_rate": 3.2638888888888892e-06,
      "loss": 0.5964,
      "step": 141
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.3778739172092065,
      "learning_rate": 3.2870370370370374e-06,
      "loss": 0.6182,
      "step": 142
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.69374236350335,
      "learning_rate": 3.3101851851851856e-06,
      "loss": 0.5941,
      "step": 143
    },
    {
      "epoch": 0.01,
      "grad_norm": 8.001322185621898,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 0.5801,
      "step": 144
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.1200517367412584,
      "learning_rate": 3.3564814814814815e-06,
      "loss": 0.5859,
      "step": 145
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.950514337407477,
      "learning_rate": 3.37962962962963e-06,
      "loss": 0.6257,
      "step": 146
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.0724038739470214,
      "learning_rate": 3.4027777777777783e-06,
      "loss": 0.6731,
      "step": 147
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.152457171010738,
      "learning_rate": 3.4259259259259265e-06,
      "loss": 0.6567,
      "step": 148
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.262150567218191,
      "learning_rate": 3.449074074074074e-06,
      "loss": 0.6663,
      "step": 149
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.2385297367736507,
      "learning_rate": 3.4722222222222224e-06,
      "loss": 0.5903,
      "step": 150
    },
    {
      "epoch": 0.01,
      "grad_norm": 5.059471881834743,
      "learning_rate": 3.4953703703703706e-06,
      "loss": 0.6326,
      "step": 151
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.222046641931163,
      "learning_rate": 3.5185185185185187e-06,
      "loss": 0.6544,
      "step": 152
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.0740098378568512,
      "learning_rate": 3.5416666666666673e-06,
      "loss": 0.599,
      "step": 153
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.303541992380832,
      "learning_rate": 3.5648148148148147e-06,
      "loss": 0.5708,
      "step": 154
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.060993745808035,
      "learning_rate": 3.5879629629629633e-06,
      "loss": 0.5706,
      "step": 155
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.3296222061504452,
      "learning_rate": 3.6111111111111115e-06,
      "loss": 0.5502,
      "step": 156
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.349935696112314,
      "learning_rate": 3.6342592592592596e-06,
      "loss": 0.641,
      "step": 157
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.9160489669368053,
      "learning_rate": 3.657407407407408e-06,
      "loss": 0.6481,
      "step": 158
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.146482236534526,
      "learning_rate": 3.680555555555556e-06,
      "loss": 0.6645,
      "step": 159
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.3164655231348488,
      "learning_rate": 3.7037037037037037e-06,
      "loss": 0.6015,
      "step": 160
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.2556903724896054,
      "learning_rate": 3.726851851851852e-06,
      "loss": 0.6336,
      "step": 161
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.200047887775062,
      "learning_rate": 3.7500000000000005e-06,
      "loss": 0.6023,
      "step": 162
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.7787473504606554,
      "learning_rate": 3.7731481481481487e-06,
      "loss": 0.3976,
      "step": 163
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.092462238084152,
      "learning_rate": 3.796296296296297e-06,
      "loss": 0.587,
      "step": 164
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.2726947142764153,
      "learning_rate": 3.819444444444444e-06,
      "loss": 0.6435,
      "step": 165
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.0829301420063557,
      "learning_rate": 3.842592592592592e-06,
      "loss": 0.5961,
      "step": 166
    },
    {
      "epoch": 0.01,
      "grad_norm": 3.073110936281767,
      "learning_rate": 3.865740740740741e-06,
      "loss": 0.5684,
      "step": 167
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.6801862179530013,
      "learning_rate": 3.88888888888889e-06,
      "loss": 0.4124,
      "step": 168
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.2229031483671986,
      "learning_rate": 3.912037037037038e-06,
      "loss": 0.6524,
      "step": 169
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.2717899245032327,
      "learning_rate": 3.935185185185186e-06,
      "loss": 0.6431,
      "step": 170
    },
    {
      "epoch": 0.01,
      "grad_norm": 5.463674357917751,
      "learning_rate": 3.958333333333333e-06,
      "loss": 0.6262,
      "step": 171
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.5187407121849548,
      "learning_rate": 3.9814814814814814e-06,
      "loss": 0.5913,
      "step": 172
    },
    {
      "epoch": 0.01,
      "grad_norm": 4.534724072792061,
      "learning_rate": 4.00462962962963e-06,
      "loss": 0.5917,
      "step": 173
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.688672048516144,
      "learning_rate": 4.027777777777779e-06,
      "loss": 0.5817,
      "step": 174
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.4001919724893,
      "learning_rate": 4.050925925925927e-06,
      "loss": 0.6496,
      "step": 175
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.8415882231424228,
      "learning_rate": 4.074074074074074e-06,
      "loss": 0.5343,
      "step": 176
    },
    {
      "epoch": 0.01,
      "grad_norm": 3.1322418046662963,
      "learning_rate": 4.097222222222222e-06,
      "loss": 0.6175,
      "step": 177
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.3303848000164864,
      "learning_rate": 4.1203703703703705e-06,
      "loss": 0.6058,
      "step": 178
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.8927628659794957,
      "learning_rate": 4.143518518518519e-06,
      "loss": 0.5648,
      "step": 179
    },
    {
      "epoch": 0.01,
      "grad_norm": 3.358934242158456,
      "learning_rate": 4.166666666666667e-06,
      "loss": 0.6168,
      "step": 180
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.452056232038823,
      "learning_rate": 4.189814814814815e-06,
      "loss": 0.6212,
      "step": 181
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.1602670616017954,
      "learning_rate": 4.212962962962963e-06,
      "loss": 0.5707,
      "step": 182
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.7019137311215995,
      "learning_rate": 4.236111111111111e-06,
      "loss": 0.6048,
      "step": 183
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.5420777260459926,
      "learning_rate": 4.2592592592592596e-06,
      "loss": 0.6573,
      "step": 184
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.1656125856925326,
      "learning_rate": 4.282407407407408e-06,
      "loss": 0.5759,
      "step": 185
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.105978840395874,
      "learning_rate": 4.305555555555556e-06,
      "loss": 0.5895,
      "step": 186
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.976985773968647,
      "learning_rate": 4.328703703703704e-06,
      "loss": 0.5731,
      "step": 187
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.2325568312306494,
      "learning_rate": 4.351851851851852e-06,
      "loss": 0.6449,
      "step": 188
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.805743575745208,
      "learning_rate": 4.3750000000000005e-06,
      "loss": 0.6417,
      "step": 189
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.1528138407431427,
      "learning_rate": 4.398148148148149e-06,
      "loss": 0.5801,
      "step": 190
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.497960257925467,
      "learning_rate": 4.421296296296297e-06,
      "loss": 0.5796,
      "step": 191
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.6125921740949303,
      "learning_rate": 4.444444444444444e-06,
      "loss": 0.5741,
      "step": 192
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.2034827548088214,
      "learning_rate": 4.467592592592593e-06,
      "loss": 0.5684,
      "step": 193
    },
    {
      "epoch": 0.01,
      "grad_norm": 4.238246054861853,
      "learning_rate": 4.490740740740741e-06,
      "loss": 0.5935,
      "step": 194
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.4116452637366033,
      "learning_rate": 4.5138888888888895e-06,
      "loss": 0.6155,
      "step": 195
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.0642391655328125,
      "learning_rate": 4.537037037037038e-06,
      "loss": 0.6019,
      "step": 196
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.5666746349459575,
      "learning_rate": 4.560185185185186e-06,
      "loss": 0.5458,
      "step": 197
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.4797979947000215,
      "learning_rate": 4.583333333333333e-06,
      "loss": 0.6372,
      "step": 198
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.8222394767710237,
      "learning_rate": 4.606481481481481e-06,
      "loss": 0.3857,
      "step": 199
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.2367511206878716,
      "learning_rate": 4.62962962962963e-06,
      "loss": 0.6266,
      "step": 200
    },
    {
      "epoch": 0.01,
      "grad_norm": 3.595293235177079,
      "learning_rate": 4.652777777777779e-06,
      "loss": 0.6064,
      "step": 201
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.9239581501768308,
      "learning_rate": 4.675925925925927e-06,
      "loss": 0.6017,
      "step": 202
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.7904123636867976,
      "learning_rate": 4.699074074074074e-06,
      "loss": 0.403,
      "step": 203
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.61532112524975,
      "learning_rate": 4.722222222222222e-06,
      "loss": 0.5848,
      "step": 204
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.2378539193430664,
      "learning_rate": 4.7453703703703705e-06,
      "loss": 0.5912,
      "step": 205
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.9008575811723103,
      "learning_rate": 4.768518518518519e-06,
      "loss": 0.5702,
      "step": 206
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.520631395131486,
      "learning_rate": 4.791666666666668e-06,
      "loss": 0.6046,
      "step": 207
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.5341600745414286,
      "learning_rate": 4.814814814814815e-06,
      "loss": 0.5697,
      "step": 208
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.1992751467531235,
      "learning_rate": 4.837962962962963e-06,
      "loss": 0.6103,
      "step": 209
    },
    {
      "epoch": 0.01,
      "grad_norm": 3.2288253020661806,
      "learning_rate": 4.861111111111111e-06,
      "loss": 0.6243,
      "step": 210
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.2248757101863172,
      "learning_rate": 4.8842592592592595e-06,
      "loss": 0.6436,
      "step": 211
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.038126068148268,
      "learning_rate": 4.907407407407408e-06,
      "loss": 0.5966,
      "step": 212
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.198337554340352,
      "learning_rate": 4.930555555555556e-06,
      "loss": 0.5623,
      "step": 213
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.545773053967409,
      "learning_rate": 4.953703703703704e-06,
      "loss": 0.5517,
      "step": 214
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.2428027541209095,
      "learning_rate": 4.976851851851852e-06,
      "loss": 0.6194,
      "step": 215
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.3464254613362705,
      "learning_rate": 5e-06,
      "loss": 0.6285,
      "step": 216
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.117669295060871,
      "learning_rate": 5.023148148148148e-06,
      "loss": 0.6333,
      "step": 217
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.3954332218447423,
      "learning_rate": 5.046296296296297e-06,
      "loss": 0.5694,
      "step": 218
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.4017241294774005,
      "learning_rate": 5.069444444444445e-06,
      "loss": 0.6049,
      "step": 219
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.5197482771034663,
      "learning_rate": 5.092592592592593e-06,
      "loss": 0.6187,
      "step": 220
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.582136659912972,
      "learning_rate": 5.115740740740741e-06,
      "loss": 0.6292,
      "step": 221
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.1170646655188934,
      "learning_rate": 5.138888888888889e-06,
      "loss": 0.5635,
      "step": 222
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.1128224195262404,
      "learning_rate": 5.162037037037038e-06,
      "loss": 0.5919,
      "step": 223
    },
    {
      "epoch": 0.02,
      "grad_norm": 3.0413752272917387,
      "learning_rate": 5.185185185185185e-06,
      "loss": 0.6466,
      "step": 224
    },
    {
      "epoch": 0.02,
      "grad_norm": 9.79988973988075,
      "learning_rate": 5.208333333333334e-06,
      "loss": 0.6311,
      "step": 225
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.2163034502767007,
      "learning_rate": 5.231481481481482e-06,
      "loss": 0.6252,
      "step": 226
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.404548708731894,
      "learning_rate": 5.2546296296296295e-06,
      "loss": 0.6415,
      "step": 227
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.538535342948867,
      "learning_rate": 5.2777777777777785e-06,
      "loss": 0.6,
      "step": 228
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.3036195001772435,
      "learning_rate": 5.300925925925926e-06,
      "loss": 0.6439,
      "step": 229
    },
    {
      "epoch": 0.02,
      "grad_norm": 3.359701994254387,
      "learning_rate": 5.324074074074075e-06,
      "loss": 0.6425,
      "step": 230
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.156402646248771,
      "learning_rate": 5.347222222222222e-06,
      "loss": 0.5998,
      "step": 231
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.3099584000135676,
      "learning_rate": 5.370370370370371e-06,
      "loss": 0.5878,
      "step": 232
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.144857503843885,
      "learning_rate": 5.3935185185185194e-06,
      "loss": 0.5548,
      "step": 233
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.113332853059453,
      "learning_rate": 5.416666666666667e-06,
      "loss": 0.5856,
      "step": 234
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.8708453990046516,
      "learning_rate": 5.439814814814816e-06,
      "loss": 0.5562,
      "step": 235
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.416535926866884,
      "learning_rate": 5.462962962962963e-06,
      "loss": 0.6194,
      "step": 236
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.16949796041407,
      "learning_rate": 5.486111111111112e-06,
      "loss": 0.601,
      "step": 237
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.2255023676219294,
      "learning_rate": 5.5092592592592595e-06,
      "loss": 0.5787,
      "step": 238
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.9599312057519611,
      "learning_rate": 5.532407407407408e-06,
      "loss": 0.5389,
      "step": 239
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.5954863670911887,
      "learning_rate": 5.555555555555557e-06,
      "loss": 0.5898,
      "step": 240
    },
    {
      "epoch": 0.02,
      "grad_norm": 3.0532842369909345,
      "learning_rate": 5.578703703703704e-06,
      "loss": 0.612,
      "step": 241
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.208814435028703,
      "learning_rate": 5.601851851851853e-06,
      "loss": 0.6131,
      "step": 242
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.849581323401412,
      "learning_rate": 5.625e-06,
      "loss": 0.5825,
      "step": 243
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.0870820039904054,
      "learning_rate": 5.6481481481481485e-06,
      "loss": 0.5694,
      "step": 244
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.4410651113704596,
      "learning_rate": 5.671296296296297e-06,
      "loss": 0.6185,
      "step": 245
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.1617282158732674,
      "learning_rate": 5.694444444444445e-06,
      "loss": 0.5965,
      "step": 246
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.1185243511785488,
      "learning_rate": 5.717592592592593e-06,
      "loss": 0.5783,
      "step": 247
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.507298472187166,
      "learning_rate": 5.740740740740741e-06,
      "loss": 0.6021,
      "step": 248
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.2091710179340445,
      "learning_rate": 5.7638888888888886e-06,
      "loss": 0.598,
      "step": 249
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.294679010365696,
      "learning_rate": 5.787037037037038e-06,
      "loss": 0.6269,
      "step": 250
    },
    {
      "epoch": 0.02,
      "grad_norm": 3.1487254734033687,
      "learning_rate": 5.810185185185186e-06,
      "loss": 0.5812,
      "step": 251
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.226332415656323,
      "learning_rate": 5.833333333333334e-06,
      "loss": 0.5987,
      "step": 252
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.8820142704523806,
      "learning_rate": 5.856481481481482e-06,
      "loss": 0.5676,
      "step": 253
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.9772363287531478,
      "learning_rate": 5.8796296296296295e-06,
      "loss": 0.5801,
      "step": 254
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.028123164793493,
      "learning_rate": 5.9027777777777785e-06,
      "loss": 0.4397,
      "step": 255
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.39734289809841,
      "learning_rate": 5.925925925925926e-06,
      "loss": 0.5564,
      "step": 256
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.5105446532278908,
      "learning_rate": 5.949074074074075e-06,
      "loss": 0.5479,
      "step": 257
    },
    {
      "epoch": 0.02,
      "grad_norm": 3.2441812763014353,
      "learning_rate": 5.972222222222222e-06,
      "loss": 0.5623,
      "step": 258
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.5376305724812513,
      "learning_rate": 5.995370370370371e-06,
      "loss": 0.6266,
      "step": 259
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.9393557502953263,
      "learning_rate": 6.018518518518519e-06,
      "loss": 0.5967,
      "step": 260
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.04704169100575,
      "learning_rate": 6.041666666666667e-06,
      "loss": 0.548,
      "step": 261
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.8095832123585935,
      "learning_rate": 6.064814814814816e-06,
      "loss": 0.5759,
      "step": 262
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.1824746667939907,
      "learning_rate": 6.087962962962963e-06,
      "loss": 0.5714,
      "step": 263
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.3308532026028916,
      "learning_rate": 6.111111111111112e-06,
      "loss": 0.6076,
      "step": 264
    },
    {
      "epoch": 0.02,
      "grad_norm": 3.072879106448369,
      "learning_rate": 6.134259259259259e-06,
      "loss": 0.5985,
      "step": 265
    },
    {
      "epoch": 0.02,
      "grad_norm": 4.130066735043933,
      "learning_rate": 6.157407407407408e-06,
      "loss": 0.5995,
      "step": 266
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.2347631636104874,
      "learning_rate": 6.180555555555557e-06,
      "loss": 0.6257,
      "step": 267
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.8232014579577227,
      "learning_rate": 6.203703703703704e-06,
      "loss": 0.6278,
      "step": 268
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.3233986646955076,
      "learning_rate": 6.226851851851853e-06,
      "loss": 0.5911,
      "step": 269
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.1285963608743796,
      "learning_rate": 6.25e-06,
      "loss": 0.5746,
      "step": 270
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.9890930205217217,
      "learning_rate": 6.2731481481481485e-06,
      "loss": 0.5881,
      "step": 271
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.3468150171350772,
      "learning_rate": 6.296296296296297e-06,
      "loss": 0.5906,
      "step": 272
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.9588004640823664,
      "learning_rate": 6.319444444444445e-06,
      "loss": 0.5329,
      "step": 273
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.57544574940646,
      "learning_rate": 6.342592592592594e-06,
      "loss": 0.5808,
      "step": 274
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.14106419035878,
      "learning_rate": 6.365740740740741e-06,
      "loss": 0.5855,
      "step": 275
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.3189529123718393,
      "learning_rate": 6.3888888888888885e-06,
      "loss": 0.594,
      "step": 276
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.670369096268281,
      "learning_rate": 6.4120370370370375e-06,
      "loss": 0.601,
      "step": 277
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.0404838960840945,
      "learning_rate": 6.435185185185186e-06,
      "loss": 0.5819,
      "step": 278
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.579732068516127,
      "learning_rate": 6.458333333333334e-06,
      "loss": 0.6273,
      "step": 279
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.0780932830318506,
      "learning_rate": 6.481481481481482e-06,
      "loss": 0.4372,
      "step": 280
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.033706578160285,
      "learning_rate": 6.504629629629629e-06,
      "loss": 0.5736,
      "step": 281
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.083492599816071,
      "learning_rate": 6.5277777777777784e-06,
      "loss": 0.5753,
      "step": 282
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.8297316617013735,
      "learning_rate": 6.550925925925926e-06,
      "loss": 0.6135,
      "step": 283
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.2160650100645065,
      "learning_rate": 6.574074074074075e-06,
      "loss": 0.6158,
      "step": 284
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.9475076442516712,
      "learning_rate": 6.597222222222223e-06,
      "loss": 0.5714,
      "step": 285
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.5076202249594415,
      "learning_rate": 6.620370370370371e-06,
      "loss": 0.5525,
      "step": 286
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.227651824639651,
      "learning_rate": 6.643518518518519e-06,
      "loss": 0.5777,
      "step": 287
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.159742476698254,
      "learning_rate": 6.666666666666667e-06,
      "loss": 0.6126,
      "step": 288
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.0436232619056294,
      "learning_rate": 6.689814814814816e-06,
      "loss": 0.5778,
      "step": 289
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8835913552111103,
      "learning_rate": 6.712962962962963e-06,
      "loss": 0.4373,
      "step": 290
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.230352413721296,
      "learning_rate": 6.736111111111112e-06,
      "loss": 0.5996,
      "step": 291
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.9198875533647248,
      "learning_rate": 6.75925925925926e-06,
      "loss": 0.5763,
      "step": 292
    },
    {
      "epoch": 0.02,
      "grad_norm": 3.4670625569557925,
      "learning_rate": 6.7824074074074075e-06,
      "loss": 0.6236,
      "step": 293
    },
    {
      "epoch": 0.02,
      "grad_norm": 3.326383268314322,
      "learning_rate": 6.8055555555555566e-06,
      "loss": 0.553,
      "step": 294
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.180516574880617,
      "learning_rate": 6.828703703703704e-06,
      "loss": 0.5616,
      "step": 295
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.8070387208867693,
      "learning_rate": 6.851851851851853e-06,
      "loss": 0.6056,
      "step": 296
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.9580351569012655,
      "learning_rate": 6.875e-06,
      "loss": 0.5549,
      "step": 297
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.2383881792632905,
      "learning_rate": 6.898148148148148e-06,
      "loss": 0.6301,
      "step": 298
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.2921115396547544,
      "learning_rate": 6.9212962962962974e-06,
      "loss": 0.6075,
      "step": 299
    },
    {
      "epoch": 0.02,
      "grad_norm": 3.349348942339094,
      "learning_rate": 6.944444444444445e-06,
      "loss": 0.568,
      "step": 300
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.9849276409869478,
      "learning_rate": 6.967592592592594e-06,
      "loss": 0.5502,
      "step": 301
    },
    {
      "epoch": 0.02,
      "grad_norm": 3.2402747541110997,
      "learning_rate": 6.990740740740741e-06,
      "loss": 0.5705,
      "step": 302
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.975598024016118,
      "learning_rate": 7.013888888888889e-06,
      "loss": 0.5378,
      "step": 303
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.0850994356296213,
      "learning_rate": 7.0370370370370375e-06,
      "loss": 0.596,
      "step": 304
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.8620779582100384,
      "learning_rate": 7.060185185185186e-06,
      "loss": 0.5814,
      "step": 305
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.9678897259166226,
      "learning_rate": 7.083333333333335e-06,
      "loss": 0.5807,
      "step": 306
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.2430948680955467,
      "learning_rate": 7.106481481481482e-06,
      "loss": 0.5781,
      "step": 307
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.301359012503597,
      "learning_rate": 7.129629629629629e-06,
      "loss": 0.6212,
      "step": 308
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.0664419942028325,
      "learning_rate": 7.152777777777778e-06,
      "loss": 0.4103,
      "step": 309
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.7532235991393754,
      "learning_rate": 7.1759259259259266e-06,
      "loss": 0.4435,
      "step": 310
    },
    {
      "epoch": 0.02,
      "grad_norm": 3.227393084366276,
      "learning_rate": 7.199074074074075e-06,
      "loss": 0.5798,
      "step": 311
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.0198506097395774,
      "learning_rate": 7.222222222222223e-06,
      "loss": 0.5923,
      "step": 312
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.3916858350127206,
      "learning_rate": 7.245370370370371e-06,
      "loss": 0.5849,
      "step": 313
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.1632941696219348,
      "learning_rate": 7.268518518518519e-06,
      "loss": 0.5977,
      "step": 314
    },
    {
      "epoch": 0.02,
      "grad_norm": 8.063184794661767,
      "learning_rate": 7.291666666666667e-06,
      "loss": 0.5777,
      "step": 315
    },
    {
      "epoch": 0.02,
      "grad_norm": 3.9202261458798837,
      "learning_rate": 7.314814814814816e-06,
      "loss": 0.5537,
      "step": 316
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.085614111712051,
      "learning_rate": 7.337962962962964e-06,
      "loss": 0.4232,
      "step": 317
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.1303065301839124,
      "learning_rate": 7.361111111111112e-06,
      "loss": 0.6055,
      "step": 318
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.2287618991948657,
      "learning_rate": 7.38425925925926e-06,
      "loss": 0.5569,
      "step": 319
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.1724925951256675,
      "learning_rate": 7.4074074074074075e-06,
      "loss": 0.5953,
      "step": 320
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.177475393024702,
      "learning_rate": 7.4305555555555565e-06,
      "loss": 0.5945,
      "step": 321
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.3660214705984104,
      "learning_rate": 7.453703703703704e-06,
      "loss": 0.5796,
      "step": 322
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.46393256755519,
      "learning_rate": 7.476851851851853e-06,
      "loss": 0.568,
      "step": 323
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.028356491933759,
      "learning_rate": 7.500000000000001e-06,
      "loss": 0.5199,
      "step": 324
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.3621647924108125,
      "learning_rate": 7.523148148148148e-06,
      "loss": 0.5953,
      "step": 325
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.884198822322196,
      "learning_rate": 7.546296296296297e-06,
      "loss": 0.58,
      "step": 326
    },
    {
      "epoch": 0.02,
      "grad_norm": 3.0487068512209534,
      "learning_rate": 7.569444444444445e-06,
      "loss": 0.5459,
      "step": 327
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.4110009785892994,
      "learning_rate": 7.592592592592594e-06,
      "loss": 0.6442,
      "step": 328
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.0555988774533542,
      "learning_rate": 7.615740740740741e-06,
      "loss": 0.5465,
      "step": 329
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.1679862724091867,
      "learning_rate": 7.638888888888888e-06,
      "loss": 0.543,
      "step": 330
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.9603081138779044,
      "learning_rate": 7.662037037037037e-06,
      "loss": 0.5757,
      "step": 331
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.207812057888361,
      "learning_rate": 7.685185185185185e-06,
      "loss": 0.6164,
      "step": 332
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.215780543611807,
      "learning_rate": 7.708333333333334e-06,
      "loss": 0.5463,
      "step": 333
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.14395934393397,
      "learning_rate": 7.731481481481483e-06,
      "loss": 0.6296,
      "step": 334
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.2504027314487813,
      "learning_rate": 7.75462962962963e-06,
      "loss": 0.5911,
      "step": 335
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.0036547676955947,
      "learning_rate": 7.77777777777778e-06,
      "loss": 0.6222,
      "step": 336
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.2462424942903458,
      "learning_rate": 7.800925925925926e-06,
      "loss": 0.4376,
      "step": 337
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.9376527966268893,
      "learning_rate": 7.824074074074076e-06,
      "loss": 0.564,
      "step": 338
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.103477265531025,
      "learning_rate": 7.847222222222223e-06,
      "loss": 0.5988,
      "step": 339
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.7697321236527115,
      "learning_rate": 7.870370370370372e-06,
      "loss": 0.5999,
      "step": 340
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.0473262285618166,
      "learning_rate": 7.89351851851852e-06,
      "loss": 0.5728,
      "step": 341
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.6940262522034872,
      "learning_rate": 7.916666666666667e-06,
      "loss": 0.4132,
      "step": 342
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.388298981673993,
      "learning_rate": 7.939814814814816e-06,
      "loss": 0.532,
      "step": 343
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.6551173879467864,
      "learning_rate": 7.962962962962963e-06,
      "loss": 0.5836,
      "step": 344
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.302429115210385,
      "learning_rate": 7.986111111111112e-06,
      "loss": 0.6,
      "step": 345
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.9758550738734928,
      "learning_rate": 8.00925925925926e-06,
      "loss": 0.571,
      "step": 346
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.0459447918930103,
      "learning_rate": 8.032407407407408e-06,
      "loss": 0.6329,
      "step": 347
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.1857067394150786,
      "learning_rate": 8.055555555555557e-06,
      "loss": 0.552,
      "step": 348
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.9880712047094202,
      "learning_rate": 8.078703703703705e-06,
      "loss": 0.5893,
      "step": 349
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.8450607263927576,
      "learning_rate": 8.101851851851854e-06,
      "loss": 0.5438,
      "step": 350
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.3248744719211274,
      "learning_rate": 8.125000000000001e-06,
      "loss": 0.5714,
      "step": 351
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.1015049584071455,
      "learning_rate": 8.148148148148148e-06,
      "loss": 0.5547,
      "step": 352
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.4748817775140086,
      "learning_rate": 8.171296296296297e-06,
      "loss": 0.6014,
      "step": 353
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.9001293753743215,
      "learning_rate": 8.194444444444445e-06,
      "loss": 0.4298,
      "step": 354
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.8169411919903249,
      "learning_rate": 8.217592592592594e-06,
      "loss": 0.5887,
      "step": 355
    },
    {
      "epoch": 0.02,
      "grad_norm": 3.18935116632167,
      "learning_rate": 8.240740740740741e-06,
      "loss": 0.5902,
      "step": 356
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.898710086016064,
      "learning_rate": 8.263888888888888e-06,
      "loss": 0.5981,
      "step": 357
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.793643061463669,
      "learning_rate": 8.287037037037037e-06,
      "loss": 0.572,
      "step": 358
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8931390401864842,
      "learning_rate": 8.310185185185186e-06,
      "loss": 0.4318,
      "step": 359
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.024955258425725,
      "learning_rate": 8.333333333333334e-06,
      "loss": 0.5781,
      "step": 360
    },
    {
      "epoch": 0.03,
      "grad_norm": 4.080881874540945,
      "learning_rate": 8.356481481481483e-06,
      "loss": 0.5932,
      "step": 361
    },
    {
      "epoch": 0.03,
      "grad_norm": 3.330398478158551,
      "learning_rate": 8.37962962962963e-06,
      "loss": 0.6369,
      "step": 362
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.1834963337558055,
      "learning_rate": 8.402777777777779e-06,
      "loss": 0.5744,
      "step": 363
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.4024924875900022,
      "learning_rate": 8.425925925925926e-06,
      "loss": 0.5852,
      "step": 364
    },
    {
      "epoch": 0.03,
      "grad_norm": 3.163684507853578,
      "learning_rate": 8.449074074074075e-06,
      "loss": 0.5171,
      "step": 365
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.7146743191965927,
      "learning_rate": 8.472222222222223e-06,
      "loss": 0.5664,
      "step": 366
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.3758010625199364,
      "learning_rate": 8.495370370370372e-06,
      "loss": 0.5658,
      "step": 367
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.4902188741679057,
      "learning_rate": 8.518518518518519e-06,
      "loss": 0.629,
      "step": 368
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.8402470430700832,
      "learning_rate": 8.541666666666666e-06,
      "loss": 0.571,
      "step": 369
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.050899938487284,
      "learning_rate": 8.564814814814816e-06,
      "loss": 0.5892,
      "step": 370
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8352736640113179,
      "learning_rate": 8.587962962962963e-06,
      "loss": 0.4561,
      "step": 371
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.639930491915322,
      "learning_rate": 8.611111111111112e-06,
      "loss": 0.5701,
      "step": 372
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.0603780340391116,
      "learning_rate": 8.63425925925926e-06,
      "loss": 0.5913,
      "step": 373
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.8061308914330316,
      "learning_rate": 8.657407407407408e-06,
      "loss": 0.5931,
      "step": 374
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.4408759703981397,
      "learning_rate": 8.680555555555557e-06,
      "loss": 0.5503,
      "step": 375
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.0246430888927827,
      "learning_rate": 8.703703703703705e-06,
      "loss": 0.6048,
      "step": 376
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.782494142043174,
      "learning_rate": 8.726851851851854e-06,
      "loss": 0.5725,
      "step": 377
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.709880208950183,
      "learning_rate": 8.750000000000001e-06,
      "loss": 0.5818,
      "step": 378
    },
    {
      "epoch": 0.03,
      "grad_norm": 3.0778412129654003,
      "learning_rate": 8.773148148148148e-06,
      "loss": 0.5538,
      "step": 379
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.1800447646474246,
      "learning_rate": 8.796296296296297e-06,
      "loss": 0.5096,
      "step": 380
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.2269651753516513,
      "learning_rate": 8.819444444444445e-06,
      "loss": 0.592,
      "step": 381
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.0996363618678457,
      "learning_rate": 8.842592592592594e-06,
      "loss": 0.5777,
      "step": 382
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.9413118813571217,
      "learning_rate": 8.865740740740741e-06,
      "loss": 0.5382,
      "step": 383
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.7795158405992786,
      "learning_rate": 8.888888888888888e-06,
      "loss": 0.5982,
      "step": 384
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.52008611838782,
      "learning_rate": 8.912037037037037e-06,
      "loss": 0.5629,
      "step": 385
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.9757452602960648,
      "learning_rate": 8.935185185185186e-06,
      "loss": 0.5611,
      "step": 386
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.0286851921334,
      "learning_rate": 8.958333333333334e-06,
      "loss": 0.5808,
      "step": 387
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.2618656143243108,
      "learning_rate": 8.981481481481483e-06,
      "loss": 0.5346,
      "step": 388
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.6261813922917647,
      "learning_rate": 9.00462962962963e-06,
      "loss": 0.5932,
      "step": 389
    },
    {
      "epoch": 0.03,
      "grad_norm": 3.446312925242846,
      "learning_rate": 9.027777777777779e-06,
      "loss": 0.5069,
      "step": 390
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.039785208631455,
      "learning_rate": 9.050925925925926e-06,
      "loss": 0.5813,
      "step": 391
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.4592758451751675,
      "learning_rate": 9.074074074074075e-06,
      "loss": 0.5732,
      "step": 392
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.601533127793321,
      "learning_rate": 9.097222222222223e-06,
      "loss": 0.6011,
      "step": 393
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.7315582053983247,
      "learning_rate": 9.120370370370372e-06,
      "loss": 0.5647,
      "step": 394
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.0267904747479832,
      "learning_rate": 9.143518518518519e-06,
      "loss": 0.6385,
      "step": 395
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.549230654420471,
      "learning_rate": 9.166666666666666e-06,
      "loss": 0.5458,
      "step": 396
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.7930429261885183,
      "learning_rate": 9.189814814814815e-06,
      "loss": 0.5449,
      "step": 397
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.378821111766577,
      "learning_rate": 9.212962962962963e-06,
      "loss": 0.559,
      "step": 398
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.9279493794880742,
      "learning_rate": 9.236111111111112e-06,
      "loss": 0.5806,
      "step": 399
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.8428087386788992,
      "learning_rate": 9.25925925925926e-06,
      "loss": 0.5911,
      "step": 400
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.552909298137056,
      "learning_rate": 9.282407407407408e-06,
      "loss": 0.5475,
      "step": 401
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.9146337086131282,
      "learning_rate": 9.305555555555557e-06,
      "loss": 0.5921,
      "step": 402
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.8473982241617688,
      "learning_rate": 9.328703703703705e-06,
      "loss": 0.5707,
      "step": 403
    },
    {
      "epoch": 0.03,
      "grad_norm": 3.0253450088845937,
      "learning_rate": 9.351851851851854e-06,
      "loss": 0.5374,
      "step": 404
    },
    {
      "epoch": 0.03,
      "grad_norm": 3.711712128436851,
      "learning_rate": 9.375000000000001e-06,
      "loss": 0.5724,
      "step": 405
    },
    {
      "epoch": 0.03,
      "grad_norm": 8.311551810150606,
      "learning_rate": 9.398148148148148e-06,
      "loss": 0.5633,
      "step": 406
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.0192309305797798,
      "learning_rate": 9.421296296296297e-06,
      "loss": 0.6214,
      "step": 407
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.0031863181889067,
      "learning_rate": 9.444444444444445e-06,
      "loss": 0.5578,
      "step": 408
    },
    {
      "epoch": 0.03,
      "grad_norm": 4.147396620976379,
      "learning_rate": 9.467592592592594e-06,
      "loss": 0.5978,
      "step": 409
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.165064825161173,
      "learning_rate": 9.490740740740741e-06,
      "loss": 0.566,
      "step": 410
    },
    {
      "epoch": 0.03,
      "grad_norm": 3.9471908620294296,
      "learning_rate": 9.51388888888889e-06,
      "loss": 0.5344,
      "step": 411
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.092763049121973,
      "learning_rate": 9.537037037037037e-06,
      "loss": 0.616,
      "step": 412
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.556747248975912,
      "learning_rate": 9.560185185185186e-06,
      "loss": 0.6222,
      "step": 413
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.6705817886197216,
      "learning_rate": 9.583333333333335e-06,
      "loss": 0.5321,
      "step": 414
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.581249804396518,
      "learning_rate": 9.606481481481483e-06,
      "loss": 0.5573,
      "step": 415
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.8822488493134375,
      "learning_rate": 9.62962962962963e-06,
      "loss": 0.5716,
      "step": 416
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.704990871858173,
      "learning_rate": 9.652777777777779e-06,
      "loss": 0.5522,
      "step": 417
    },
    {
      "epoch": 0.03,
      "grad_norm": 3.432264527917598,
      "learning_rate": 9.675925925925926e-06,
      "loss": 0.5955,
      "step": 418
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.9589197087627008,
      "learning_rate": 9.699074074074075e-06,
      "loss": 0.6358,
      "step": 419
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.837613522028474,
      "learning_rate": 9.722222222222223e-06,
      "loss": 0.5886,
      "step": 420
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.7199560138392729,
      "learning_rate": 9.745370370370372e-06,
      "loss": 0.5638,
      "step": 421
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.728220699839423,
      "learning_rate": 9.768518518518519e-06,
      "loss": 0.5565,
      "step": 422
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.0455934270586495,
      "learning_rate": 9.791666666666666e-06,
      "loss": 0.6432,
      "step": 423
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.90913073673462,
      "learning_rate": 9.814814814814815e-06,
      "loss": 0.5628,
      "step": 424
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.7625259080370563,
      "learning_rate": 9.837962962962964e-06,
      "loss": 0.5778,
      "step": 425
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.142805141866821,
      "learning_rate": 9.861111111111112e-06,
      "loss": 0.5521,
      "step": 426
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.541074492661713,
      "learning_rate": 9.88425925925926e-06,
      "loss": 0.5656,
      "step": 427
    },
    {
      "epoch": 0.03,
      "grad_norm": 5.441425866556802,
      "learning_rate": 9.907407407407408e-06,
      "loss": 0.5572,
      "step": 428
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.8993936556688105,
      "learning_rate": 9.930555555555557e-06,
      "loss": 0.5695,
      "step": 429
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.705359806598062,
      "learning_rate": 9.953703703703704e-06,
      "loss": 0.6277,
      "step": 430
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.002326171218515,
      "learning_rate": 9.976851851851853e-06,
      "loss": 0.5497,
      "step": 431
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.13761916199679,
      "learning_rate": 1e-05,
      "loss": 0.5868,
      "step": 432
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.29333465500792,
      "learning_rate": 9.99999987320815e-06,
      "loss": 0.5505,
      "step": 433
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.1045064878885817,
      "learning_rate": 9.999999492832608e-06,
      "loss": 0.5368,
      "step": 434
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.1004140533800695,
      "learning_rate": 9.999998858873394e-06,
      "loss": 0.5765,
      "step": 435
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.5155695252892456,
      "learning_rate": 9.999997971330537e-06,
      "loss": 0.6082,
      "step": 436
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.676501753759544,
      "learning_rate": 9.999996830204085e-06,
      "loss": 0.5587,
      "step": 437
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.265075791306329,
      "learning_rate": 9.999995435494093e-06,
      "loss": 0.6242,
      "step": 438
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.7139464216225446,
      "learning_rate": 9.999993787200635e-06,
      "loss": 0.5357,
      "step": 439
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.976135655686758,
      "learning_rate": 9.999991885323793e-06,
      "loss": 0.5579,
      "step": 440
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.7444098946030522,
      "learning_rate": 9.999989729863661e-06,
      "loss": 0.5753,
      "step": 441
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.0278320669456518,
      "learning_rate": 9.999987320820353e-06,
      "loss": 0.5913,
      "step": 442
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.293969364224933,
      "learning_rate": 9.99998465819399e-06,
      "loss": 0.5739,
      "step": 443
    },
    {
      "epoch": 0.03,
      "grad_norm": 3.5448707689723244,
      "learning_rate": 9.999981741984703e-06,
      "loss": 0.5953,
      "step": 444
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.151943656302083,
      "learning_rate": 9.999978572192644e-06,
      "loss": 0.5923,
      "step": 445
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.437341976758763,
      "learning_rate": 9.999975148817974e-06,
      "loss": 0.5697,
      "step": 446
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.9141706140965462,
      "learning_rate": 9.999971471860864e-06,
      "loss": 0.5852,
      "step": 447
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.1148556990938463,
      "learning_rate": 9.999967541321503e-06,
      "loss": 0.5617,
      "step": 448
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.0792906009514245,
      "learning_rate": 9.999963357200089e-06,
      "loss": 0.5672,
      "step": 449
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.110186444567592,
      "learning_rate": 9.999958919496832e-06,
      "loss": 0.5943,
      "step": 450
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.9944104155365445,
      "learning_rate": 9.999954228211962e-06,
      "loss": 0.5959,
      "step": 451
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.7421992592500601,
      "learning_rate": 9.999949283345714e-06,
      "loss": 0.5558,
      "step": 452
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.906796320669291,
      "learning_rate": 9.999944084898339e-06,
      "loss": 0.5811,
      "step": 453
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9552630115477119,
      "learning_rate": 9.999938632870099e-06,
      "loss": 0.4441,
      "step": 454
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.6768431481308395,
      "learning_rate": 9.999932927261275e-06,
      "loss": 0.5553,
      "step": 455
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.132059058305716,
      "learning_rate": 9.999926968072151e-06,
      "loss": 0.6207,
      "step": 456
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.7392543613086322,
      "learning_rate": 9.999920755303033e-06,
      "loss": 0.5524,
      "step": 457
    },
    {
      "epoch": 0.03,
      "grad_norm": 3.3126011389973486,
      "learning_rate": 9.999914288954235e-06,
      "loss": 0.5762,
      "step": 458
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.9011498054685985,
      "learning_rate": 9.999907569026086e-06,
      "loss": 0.5643,
      "step": 459
    },
    {
      "epoch": 0.03,
      "grad_norm": 3.996770361585905,
      "learning_rate": 9.999900595518925e-06,
      "loss": 0.6012,
      "step": 460
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.7740578198970427,
      "learning_rate": 9.999893368433106e-06,
      "loss": 0.5666,
      "step": 461
    },
    {
      "epoch": 0.03,
      "grad_norm": 4.1971334740998705,
      "learning_rate": 9.999885887768996e-06,
      "loss": 0.5672,
      "step": 462
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.919402007078843,
      "learning_rate": 9.999878153526974e-06,
      "loss": 0.5789,
      "step": 463
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.520459512547682,
      "learning_rate": 9.999870165707434e-06,
      "loss": 0.5756,
      "step": 464
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.581599443471657,
      "learning_rate": 9.999861924310779e-06,
      "loss": 0.5729,
      "step": 465
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.0001450141045964,
      "learning_rate": 9.999853429337427e-06,
      "loss": 0.4809,
      "step": 466
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.9121635649393243,
      "learning_rate": 9.99984468078781e-06,
      "loss": 0.5626,
      "step": 467
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.967648992729581,
      "learning_rate": 9.999835678662372e-06,
      "loss": 0.5715,
      "step": 468
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.0963414160785128,
      "learning_rate": 9.999826422961567e-06,
      "loss": 0.6052,
      "step": 469
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.142023769560926,
      "learning_rate": 9.999816913685867e-06,
      "loss": 0.5535,
      "step": 470
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.157524517230672,
      "learning_rate": 9.999807150835754e-06,
      "loss": 0.6086,
      "step": 471
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9411339116961396,
      "learning_rate": 9.999797134411724e-06,
      "loss": 0.4393,
      "step": 472
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.4369492709974536,
      "learning_rate": 9.99978686441428e-06,
      "loss": 0.5833,
      "step": 473
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.873292189870392,
      "learning_rate": 9.99977634084395e-06,
      "loss": 0.5803,
      "step": 474
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.1954225452302496,
      "learning_rate": 9.999765563701263e-06,
      "loss": 0.5528,
      "step": 475
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.0182585714563235,
      "learning_rate": 9.999754532986766e-06,
      "loss": 0.5686,
      "step": 476
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.076870496652005,
      "learning_rate": 9.99974324870102e-06,
      "loss": 0.5818,
      "step": 477
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.321951975783257,
      "learning_rate": 9.999731710844596e-06,
      "loss": 0.5821,
      "step": 478
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8527118740262168,
      "learning_rate": 9.999719919418078e-06,
      "loss": 0.467,
      "step": 479
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.7763266557707025,
      "learning_rate": 9.999707874422069e-06,
      "loss": 0.5748,
      "step": 480
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.0910826638576485,
      "learning_rate": 9.999695575857175e-06,
      "loss": 0.5766,
      "step": 481
    },
    {
      "epoch": 0.03,
      "grad_norm": 3.28032073613403,
      "learning_rate": 9.999683023724021e-06,
      "loss": 0.6166,
      "step": 482
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.045222894364988,
      "learning_rate": 9.999670218023245e-06,
      "loss": 0.6081,
      "step": 483
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.82297049749765,
      "learning_rate": 9.999657158755495e-06,
      "loss": 0.5596,
      "step": 484
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.346019290694093,
      "learning_rate": 9.999643845921433e-06,
      "loss": 0.5579,
      "step": 485
    },
    {
      "epoch": 0.03,
      "grad_norm": 3.2474977347594502,
      "learning_rate": 9.999630279521735e-06,
      "loss": 0.575,
      "step": 486
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.4874524178627326,
      "learning_rate": 9.99961645955709e-06,
      "loss": 0.5944,
      "step": 487
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.9837490141044942,
      "learning_rate": 9.999602386028198e-06,
      "loss": 0.5458,
      "step": 488
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.6550673055478347,
      "learning_rate": 9.999588058935772e-06,
      "loss": 0.6003,
      "step": 489
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.0147664486168724,
      "learning_rate": 9.999573478280538e-06,
      "loss": 0.6002,
      "step": 490
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.0793068963279104,
      "learning_rate": 9.999558644063238e-06,
      "loss": 0.5957,
      "step": 491
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.789808780345775,
      "learning_rate": 9.999543556284623e-06,
      "loss": 0.5639,
      "step": 492
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.3286733576991776,
      "learning_rate": 9.999528214945457e-06,
      "loss": 0.6026,
      "step": 493
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.4028589686164388,
      "learning_rate": 9.999512620046523e-06,
      "loss": 0.5199,
      "step": 494
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.4569668005259406,
      "learning_rate": 9.999496771588606e-06,
      "loss": 0.5813,
      "step": 495
    },
    {
      "epoch": 0.03,
      "grad_norm": 3.0739606626574774,
      "learning_rate": 9.99948066957251e-06,
      "loss": 0.562,
      "step": 496
    },
    {
      "epoch": 0.03,
      "grad_norm": 3.451801654552399,
      "learning_rate": 9.999464313999057e-06,
      "loss": 0.5613,
      "step": 497
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.564879117157369,
      "learning_rate": 9.99944770486907e-06,
      "loss": 0.5848,
      "step": 498
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.0738723116020816,
      "learning_rate": 9.999430842183397e-06,
      "loss": 0.5845,
      "step": 499
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.2962586561616543,
      "learning_rate": 9.999413725942891e-06,
      "loss": 0.6122,
      "step": 500
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.5312477403089813,
      "learning_rate": 9.999396356148418e-06,
      "loss": 0.563,
      "step": 501
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.4616758413931215,
      "learning_rate": 9.999378732800862e-06,
      "loss": 0.57,
      "step": 502
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.003930417669165,
      "learning_rate": 9.999360855901115e-06,
      "loss": 0.4544,
      "step": 503
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.486473188727721,
      "learning_rate": 9.999342725450085e-06,
      "loss": 0.6016,
      "step": 504
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.902841486303883,
      "learning_rate": 9.99932434144869e-06,
      "loss": 0.4597,
      "step": 505
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.0037389305931934,
      "learning_rate": 9.999305703897864e-06,
      "loss": 0.5499,
      "step": 506
    },
    {
      "epoch": 0.04,
      "grad_norm": 38.22401546586886,
      "learning_rate": 9.99928681279855e-06,
      "loss": 0.5672,
      "step": 507
    },
    {
      "epoch": 0.04,
      "grad_norm": 3.175734547269327,
      "learning_rate": 9.999267668151709e-06,
      "loss": 0.5381,
      "step": 508
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.896632862221751,
      "learning_rate": 9.999248269958308e-06,
      "loss": 0.4232,
      "step": 509
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.7625092301125815,
      "learning_rate": 9.999228618219337e-06,
      "loss": 0.5834,
      "step": 510
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.8708208374458217,
      "learning_rate": 9.999208712935786e-06,
      "loss": 0.5498,
      "step": 511
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.1651320018318225,
      "learning_rate": 9.999188554108667e-06,
      "loss": 0.6029,
      "step": 512
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.32746820517386,
      "learning_rate": 9.999168141739003e-06,
      "loss": 0.5756,
      "step": 513
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.9458297918080036,
      "learning_rate": 9.999147475827832e-06,
      "loss": 0.5508,
      "step": 514
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.925222337278807,
      "learning_rate": 9.999126556376197e-06,
      "loss": 0.5298,
      "step": 515
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.8721409350929603,
      "learning_rate": 9.999105383385161e-06,
      "loss": 0.5556,
      "step": 516
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.9780162953240426,
      "learning_rate": 9.9990839568558e-06,
      "loss": 0.5149,
      "step": 517
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.9613326721594098,
      "learning_rate": 9.999062276789196e-06,
      "loss": 0.5856,
      "step": 518
    },
    {
      "epoch": 0.04,
      "grad_norm": 6.026022870245804,
      "learning_rate": 9.999040343186452e-06,
      "loss": 0.536,
      "step": 519
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.24506053898808,
      "learning_rate": 9.999018156048681e-06,
      "loss": 0.5816,
      "step": 520
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.5690889801210197,
      "learning_rate": 9.998995715377005e-06,
      "loss": 0.6149,
      "step": 521
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.953690819751824,
      "learning_rate": 9.998973021172564e-06,
      "loss": 0.6066,
      "step": 522
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.010351186073475,
      "learning_rate": 9.998950073436512e-06,
      "loss": 0.5849,
      "step": 523
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.255338827082653,
      "learning_rate": 9.998926872170006e-06,
      "loss": 0.5633,
      "step": 524
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.3249828091003577,
      "learning_rate": 9.998903417374228e-06,
      "loss": 0.5819,
      "step": 525
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.1906302499283705,
      "learning_rate": 9.998879709050366e-06,
      "loss": 0.5764,
      "step": 526
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.3727621999725397,
      "learning_rate": 9.998855747199623e-06,
      "loss": 0.623,
      "step": 527
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.0663457451548997,
      "learning_rate": 9.998831531823212e-06,
      "loss": 0.5978,
      "step": 528
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.1903910427388404,
      "learning_rate": 9.998807062922365e-06,
      "loss": 0.5802,
      "step": 529
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.8091577379638022,
      "learning_rate": 9.99878234049832e-06,
      "loss": 0.5507,
      "step": 530
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.194733027242511,
      "learning_rate": 9.998757364552332e-06,
      "loss": 0.5606,
      "step": 531
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.9815820753647388,
      "learning_rate": 9.998732135085665e-06,
      "loss": 0.5515,
      "step": 532
    },
    {
      "epoch": 0.04,
      "grad_norm": 3.5234749009492523,
      "learning_rate": 9.998706652099603e-06,
      "loss": 0.5689,
      "step": 533
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.371760186393307,
      "learning_rate": 9.998680915595436e-06,
      "loss": 0.5665,
      "step": 534
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.8992594921928894,
      "learning_rate": 9.99865492557447e-06,
      "loss": 0.5479,
      "step": 535
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.1701805581121834,
      "learning_rate": 9.998628682038023e-06,
      "loss": 0.587,
      "step": 536
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.1057218365474575,
      "learning_rate": 9.998602184987425e-06,
      "loss": 0.6161,
      "step": 537
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.5280627700750276,
      "learning_rate": 9.998575434424021e-06,
      "loss": 0.582,
      "step": 538
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.1520333818271444,
      "learning_rate": 9.998548430349167e-06,
      "loss": 0.561,
      "step": 539
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.8684597522314068,
      "learning_rate": 9.998521172764233e-06,
      "loss": 0.5258,
      "step": 540
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.637115457491559,
      "learning_rate": 9.9984936616706e-06,
      "loss": 0.5642,
      "step": 541
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.364396959777023,
      "learning_rate": 9.998465897069665e-06,
      "loss": 0.5705,
      "step": 542
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.451770802859147,
      "learning_rate": 9.998437878962837e-06,
      "loss": 0.5939,
      "step": 543
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.0017709392977088,
      "learning_rate": 9.998409607351534e-06,
      "loss": 0.4603,
      "step": 544
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.0199192755491917,
      "learning_rate": 9.998381082237193e-06,
      "loss": 0.5617,
      "step": 545
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.911977140405017,
      "learning_rate": 9.998352303621258e-06,
      "loss": 0.5432,
      "step": 546
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.9983511744767029,
      "learning_rate": 9.99832327150519e-06,
      "loss": 0.5409,
      "step": 547
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.336741609047343,
      "learning_rate": 9.998293985890461e-06,
      "loss": 0.6062,
      "step": 548
    },
    {
      "epoch": 0.04,
      "grad_norm": 3.7876492957213435,
      "learning_rate": 9.998264446778557e-06,
      "loss": 0.6114,
      "step": 549
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.1745128402070595,
      "learning_rate": 9.998234654170975e-06,
      "loss": 0.5506,
      "step": 550
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.0719529416946627,
      "learning_rate": 9.998204608069226e-06,
      "loss": 0.5543,
      "step": 551
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.688235032512216,
      "learning_rate": 9.998174308474836e-06,
      "loss": 0.5318,
      "step": 552
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.9054635233782082,
      "learning_rate": 9.998143755389338e-06,
      "loss": 0.5192,
      "step": 553
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.3183075186489788,
      "learning_rate": 9.998112948814286e-06,
      "loss": 0.57,
      "step": 554
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.0440447171784313,
      "learning_rate": 9.998081888751239e-06,
      "loss": 0.5571,
      "step": 555
    },
    {
      "epoch": 0.04,
      "grad_norm": 3.3277807414623166,
      "learning_rate": 9.998050575201772e-06,
      "loss": 0.6127,
      "step": 556
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.993767379275625,
      "learning_rate": 9.998019008167476e-06,
      "loss": 0.5928,
      "step": 557
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.107771871581046,
      "learning_rate": 9.99798718764995e-06,
      "loss": 0.5619,
      "step": 558
    },
    {
      "epoch": 0.04,
      "grad_norm": 3.256350111822166,
      "learning_rate": 9.997955113650808e-06,
      "loss": 0.6189,
      "step": 559
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.260410906396471,
      "learning_rate": 9.997922786171677e-06,
      "loss": 0.5696,
      "step": 560
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.454124695844956,
      "learning_rate": 9.997890205214196e-06,
      "loss": 0.5105,
      "step": 561
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.4040936030874915,
      "learning_rate": 9.997857370780018e-06,
      "loss": 0.5664,
      "step": 562
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.859862289022764,
      "learning_rate": 9.99782428287081e-06,
      "loss": 0.5721,
      "step": 563
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.493237813913267,
      "learning_rate": 9.997790941488246e-06,
      "loss": 0.5883,
      "step": 564
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.21110863363673,
      "learning_rate": 9.997757346634019e-06,
      "loss": 0.617,
      "step": 565
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.9972960087621425,
      "learning_rate": 9.997723498309834e-06,
      "loss": 0.5741,
      "step": 566
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.3414386176946618,
      "learning_rate": 9.997689396517408e-06,
      "loss": 0.5597,
      "step": 567
    },
    {
      "epoch": 0.04,
      "grad_norm": 3.0503171713843384,
      "learning_rate": 9.997655041258466e-06,
      "loss": 0.5158,
      "step": 568
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.0024555606195595,
      "learning_rate": 9.997620432534756e-06,
      "loss": 0.5842,
      "step": 569
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.333653461476719,
      "learning_rate": 9.99758557034803e-06,
      "loss": 0.5998,
      "step": 570
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.7650801734612687,
      "learning_rate": 9.997550454700056e-06,
      "loss": 0.576,
      "step": 571
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.268853759429558,
      "learning_rate": 9.997515085592618e-06,
      "loss": 0.585,
      "step": 572
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.0337632807854953,
      "learning_rate": 9.997479463027506e-06,
      "loss": 0.5586,
      "step": 573
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.4948618629204042,
      "learning_rate": 9.99744358700653e-06,
      "loss": 0.579,
      "step": 574
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.979318995244133,
      "learning_rate": 9.997407457531507e-06,
      "loss": 0.5655,
      "step": 575
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.339183834427829,
      "learning_rate": 9.99737107460427e-06,
      "loss": 0.5738,
      "step": 576
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.9327756964059775,
      "learning_rate": 9.997334438226664e-06,
      "loss": 0.6055,
      "step": 577
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.526123575024335,
      "learning_rate": 9.997297548400548e-06,
      "loss": 0.565,
      "step": 578
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.2830502336232756,
      "learning_rate": 9.997260405127792e-06,
      "loss": 0.5499,
      "step": 579
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.221587891844507,
      "learning_rate": 9.997223008410281e-06,
      "loss": 0.6097,
      "step": 580
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.3169955798012043,
      "learning_rate": 9.99718535824991e-06,
      "loss": 0.5467,
      "step": 581
    },
    {
      "epoch": 0.04,
      "grad_norm": 3.0246933189980028,
      "learning_rate": 9.99714745464859e-06,
      "loss": 0.5611,
      "step": 582
    },
    {
      "epoch": 0.04,
      "grad_norm": 3.0084827351037764,
      "learning_rate": 9.997109297608244e-06,
      "loss": 0.5236,
      "step": 583
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.3966019549994986,
      "learning_rate": 9.997070887130803e-06,
      "loss": 0.5918,
      "step": 584
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.578032782856217,
      "learning_rate": 9.997032223218222e-06,
      "loss": 0.5514,
      "step": 585
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.058903218733897,
      "learning_rate": 9.996993305872456e-06,
      "loss": 0.5655,
      "step": 586
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.517784984658178,
      "learning_rate": 9.99695413509548e-06,
      "loss": 0.5998,
      "step": 587
    },
    {
      "epoch": 0.04,
      "grad_norm": 4.399342848174029,
      "learning_rate": 9.99691471088928e-06,
      "loss": 0.521,
      "step": 588
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.648409497111267,
      "learning_rate": 9.99687503325586e-06,
      "loss": 0.5898,
      "step": 589
    },
    {
      "epoch": 0.04,
      "grad_norm": 4.912144686967434,
      "learning_rate": 9.996835102197227e-06,
      "loss": 0.5949,
      "step": 590
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.67703125129002,
      "learning_rate": 9.996794917715408e-06,
      "loss": 0.5918,
      "step": 591
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.230433440832646,
      "learning_rate": 9.996754479812443e-06,
      "loss": 0.5829,
      "step": 592
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.9395561019085485,
      "learning_rate": 9.99671378849038e-06,
      "loss": 0.608,
      "step": 593
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.1453128826314196,
      "learning_rate": 9.996672843751283e-06,
      "loss": 0.5481,
      "step": 594
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.337004526752398,
      "learning_rate": 9.99663164559723e-06,
      "loss": 0.5277,
      "step": 595
    },
    {
      "epoch": 0.04,
      "grad_norm": 4.162914473758052,
      "learning_rate": 9.996590194030311e-06,
      "loss": 0.6145,
      "step": 596
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.029876427952456,
      "learning_rate": 9.996548489052627e-06,
      "loss": 0.5387,
      "step": 597
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.6597684442904808,
      "learning_rate": 9.996506530666292e-06,
      "loss": 0.5424,
      "step": 598
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.240716829468455,
      "learning_rate": 9.996464318873435e-06,
      "loss": 0.5545,
      "step": 599
    },
    {
      "epoch": 0.04,
      "grad_norm": 3.2495086494364394,
      "learning_rate": 9.9964218536762e-06,
      "loss": 0.5716,
      "step": 600
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.7073920675471888,
      "learning_rate": 9.996379135076736e-06,
      "loss": 0.5654,
      "step": 601
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.1797381539052583,
      "learning_rate": 9.996336163077212e-06,
      "loss": 0.5347,
      "step": 602
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.2333164116053912,
      "learning_rate": 9.996292937679805e-06,
      "loss": 0.4791,
      "step": 603
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.0165401465905575,
      "learning_rate": 9.996249458886711e-06,
      "loss": 0.5421,
      "step": 604
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.565568966614241,
      "learning_rate": 9.996205726700133e-06,
      "loss": 0.5715,
      "step": 605
    },
    {
      "epoch": 0.04,
      "grad_norm": 5.802907690380255,
      "learning_rate": 9.996161741122288e-06,
      "loss": 0.6015,
      "step": 606
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.9039692342175507,
      "learning_rate": 9.99611750215541e-06,
      "loss": 0.5584,
      "step": 607
    },
    {
      "epoch": 0.04,
      "grad_norm": 3.7938267631533558,
      "learning_rate": 9.996073009801738e-06,
      "loss": 0.5445,
      "step": 608
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.270328559163921,
      "learning_rate": 9.996028264063531e-06,
      "loss": 0.5152,
      "step": 609
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.4461698022807825,
      "learning_rate": 9.995983264943062e-06,
      "loss": 0.5636,
      "step": 610
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.760444570918936,
      "learning_rate": 9.995938012442605e-06,
      "loss": 0.5558,
      "step": 611
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.9953116201121388,
      "learning_rate": 9.995892506564461e-06,
      "loss": 0.5168,
      "step": 612
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.9343059469618296,
      "learning_rate": 9.99584674731094e-06,
      "loss": 0.5998,
      "step": 613
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.7460965848130414,
      "learning_rate": 9.995800734684356e-06,
      "loss": 0.5314,
      "step": 614
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.103013807960204,
      "learning_rate": 9.995754468687046e-06,
      "loss": 0.5652,
      "step": 615
    },
    {
      "epoch": 0.04,
      "grad_norm": 4.895380209593159,
      "learning_rate": 9.995707949321358e-06,
      "loss": 0.5951,
      "step": 616
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.031064749456186,
      "learning_rate": 9.995661176589649e-06,
      "loss": 0.5676,
      "step": 617
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.0731533626106624,
      "learning_rate": 9.995614150494293e-06,
      "loss": 0.5938,
      "step": 618
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.397522953327107,
      "learning_rate": 9.995566871037671e-06,
      "loss": 0.5481,
      "step": 619
    },
    {
      "epoch": 0.04,
      "grad_norm": 3.628375205671332,
      "learning_rate": 9.995519338222187e-06,
      "loss": 0.5441,
      "step": 620
    },
    {
      "epoch": 0.04,
      "grad_norm": 4.7351456125147315,
      "learning_rate": 9.995471552050247e-06,
      "loss": 0.5936,
      "step": 621
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.1209213792998582,
      "learning_rate": 9.995423512524277e-06,
      "loss": 0.5762,
      "step": 622
    },
    {
      "epoch": 0.04,
      "grad_norm": 3.22672086646402,
      "learning_rate": 9.995375219646711e-06,
      "loss": 0.5775,
      "step": 623
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.0428810877851062,
      "learning_rate": 9.99532667342e-06,
      "loss": 0.5539,
      "step": 624
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.0060935329442677,
      "learning_rate": 9.995277873846606e-06,
      "loss": 0.5789,
      "step": 625
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.842293414669727,
      "learning_rate": 9.995228820929007e-06,
      "loss": 0.5812,
      "step": 626
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.279400411029762,
      "learning_rate": 9.995179514669683e-06,
      "loss": 0.54,
      "step": 627
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.3087618104014656,
      "learning_rate": 9.99512995507114e-06,
      "loss": 0.4783,
      "step": 628
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.6132440405133748,
      "learning_rate": 9.995080142135893e-06,
      "loss": 0.558,
      "step": 629
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.1750698951935954,
      "learning_rate": 9.995030075866465e-06,
      "loss": 0.5558,
      "step": 630
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.9287908939014247,
      "learning_rate": 9.994979756265396e-06,
      "loss": 0.5693,
      "step": 631
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.5029711838352697,
      "learning_rate": 9.994929183335237e-06,
      "loss": 0.5607,
      "step": 632
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.9578287733197506,
      "learning_rate": 9.994878357078556e-06,
      "loss": 0.5856,
      "step": 633
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.0734618942396437,
      "learning_rate": 9.99482727749793e-06,
      "loss": 0.6052,
      "step": 634
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.245974298226667,
      "learning_rate": 9.994775944595947e-06,
      "loss": 0.5914,
      "step": 635
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.3179456049295815,
      "learning_rate": 9.994724358375212e-06,
      "loss": 0.5683,
      "step": 636
    },
    {
      "epoch": 0.04,
      "grad_norm": 3.6187277077455717,
      "learning_rate": 9.99467251883834e-06,
      "loss": 0.5402,
      "step": 637
    },
    {
      "epoch": 0.04,
      "grad_norm": 3.336270384551108,
      "learning_rate": 9.994620425987964e-06,
      "loss": 0.5387,
      "step": 638
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.4661157783018632,
      "learning_rate": 9.994568079826721e-06,
      "loss": 0.6212,
      "step": 639
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.7997910247706275,
      "learning_rate": 9.99451548035727e-06,
      "loss": 0.5964,
      "step": 640
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.8520111453168333,
      "learning_rate": 9.994462627582276e-06,
      "loss": 0.5515,
      "step": 641
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.9209398891640315,
      "learning_rate": 9.99440952150442e-06,
      "loss": 0.5782,
      "step": 642
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.5490168347373765,
      "learning_rate": 9.994356162126397e-06,
      "loss": 0.6053,
      "step": 643
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.018450397845746,
      "learning_rate": 9.994302549450912e-06,
      "loss": 0.553,
      "step": 644
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.1572318217489994,
      "learning_rate": 9.994248683480683e-06,
      "loss": 0.5739,
      "step": 645
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.711650759262239,
      "learning_rate": 9.994194564218445e-06,
      "loss": 0.5641,
      "step": 646
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.8316232141851603,
      "learning_rate": 9.99414019166694e-06,
      "loss": 0.5823,
      "step": 647
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.225383363324197,
      "learning_rate": 9.994085565828924e-06,
      "loss": 0.5345,
      "step": 648
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.6585933159228015,
      "learning_rate": 9.994030686707171e-06,
      "loss": 0.6301,
      "step": 649
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.614200179537769,
      "learning_rate": 9.993975554304462e-06,
      "loss": 0.5354,
      "step": 650
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.8680634257903368,
      "learning_rate": 9.993920168623596e-06,
      "loss": 0.5491,
      "step": 651
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.2821543190389493,
      "learning_rate": 9.99386452966738e-06,
      "loss": 0.4719,
      "step": 652
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.8572711989186366,
      "learning_rate": 9.993808637438635e-06,
      "loss": 0.5589,
      "step": 653
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.541936099793675,
      "learning_rate": 9.993752491940198e-06,
      "loss": 0.5904,
      "step": 654
    },
    {
      "epoch": 0.05,
      "grad_norm": 7.476277514364917,
      "learning_rate": 9.993696093174915e-06,
      "loss": 0.577,
      "step": 655
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.0613537945986997,
      "learning_rate": 9.993639441145645e-06,
      "loss": 0.5752,
      "step": 656
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.823432540660132,
      "learning_rate": 9.993582535855265e-06,
      "loss": 0.5463,
      "step": 657
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.3852578099831696,
      "learning_rate": 9.993525377306657e-06,
      "loss": 0.5649,
      "step": 658
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.279207352365175,
      "learning_rate": 9.993467965502724e-06,
      "loss": 0.5951,
      "step": 659
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.624857682932955,
      "learning_rate": 9.993410300446372e-06,
      "loss": 0.5725,
      "step": 660
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.766639013512368,
      "learning_rate": 9.99335238214053e-06,
      "loss": 0.5762,
      "step": 661
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.430122227138532,
      "learning_rate": 9.993294210588135e-06,
      "loss": 0.5505,
      "step": 662
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.040189995086066,
      "learning_rate": 9.993235785792138e-06,
      "loss": 0.5515,
      "step": 663
    },
    {
      "epoch": 0.05,
      "grad_norm": 3.302921832330914,
      "learning_rate": 9.993177107755501e-06,
      "loss": 0.5519,
      "step": 664
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.330210369018792,
      "learning_rate": 9.993118176481199e-06,
      "loss": 0.5857,
      "step": 665
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.4463604639898895,
      "learning_rate": 9.99305899197222e-06,
      "loss": 0.4907,
      "step": 666
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.1356770036515695,
      "learning_rate": 9.992999554231568e-06,
      "loss": 0.55,
      "step": 667
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.955231627100083,
      "learning_rate": 9.992939863262257e-06,
      "loss": 0.5579,
      "step": 668
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.406081549462802,
      "learning_rate": 9.992879919067314e-06,
      "loss": 0.6097,
      "step": 669
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.943867063346315,
      "learning_rate": 9.99281972164978e-06,
      "loss": 0.553,
      "step": 670
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.5632010028601346,
      "learning_rate": 9.992759271012706e-06,
      "loss": 0.5901,
      "step": 671
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.1526476454274617,
      "learning_rate": 9.99269856715916e-06,
      "loss": 0.5747,
      "step": 672
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.042612131487189,
      "learning_rate": 9.99263761009222e-06,
      "loss": 0.6038,
      "step": 673
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.4114521083056397,
      "learning_rate": 9.992576399814976e-06,
      "loss": 0.5508,
      "step": 674
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.498495319497908,
      "learning_rate": 9.992514936330535e-06,
      "loss": 0.5442,
      "step": 675
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.2055433514203824,
      "learning_rate": 9.992453219642012e-06,
      "loss": 0.4516,
      "step": 676
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.711873010944469,
      "learning_rate": 9.992391249752538e-06,
      "loss": 0.5771,
      "step": 677
    },
    {
      "epoch": 0.05,
      "grad_norm": 3.0400061819071587,
      "learning_rate": 9.992329026665258e-06,
      "loss": 0.5205,
      "step": 678
    },
    {
      "epoch": 0.05,
      "grad_norm": 7.562549285425698,
      "learning_rate": 9.992266550383323e-06,
      "loss": 0.5802,
      "step": 679
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.8788140175968877,
      "learning_rate": 9.992203820909906e-06,
      "loss": 0.5683,
      "step": 680
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.1360899668571913,
      "learning_rate": 9.992140838248185e-06,
      "loss": 0.5921,
      "step": 681
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.0342658110311307,
      "learning_rate": 9.992077602401358e-06,
      "loss": 0.5516,
      "step": 682
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.794217542257663,
      "learning_rate": 9.99201411337263e-06,
      "loss": 0.4656,
      "step": 683
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.040439416677719,
      "learning_rate": 9.99195037116522e-06,
      "loss": 0.5562,
      "step": 684
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.7952120179249595,
      "learning_rate": 9.991886375782362e-06,
      "loss": 0.5505,
      "step": 685
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.1598413443880298,
      "learning_rate": 9.991822127227301e-06,
      "loss": 0.6,
      "step": 686
    },
    {
      "epoch": 0.05,
      "grad_norm": 3.1568709621822895,
      "learning_rate": 9.991757625503298e-06,
      "loss": 0.5566,
      "step": 687
    },
    {
      "epoch": 0.05,
      "grad_norm": 3.2074799762571438,
      "learning_rate": 9.99169287061362e-06,
      "loss": 0.543,
      "step": 688
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.963671706829301,
      "learning_rate": 9.991627862561555e-06,
      "loss": 0.6016,
      "step": 689
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.5694619282093725,
      "learning_rate": 9.9915626013504e-06,
      "loss": 0.5204,
      "step": 690
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.1813961270064697,
      "learning_rate": 9.99149708698346e-06,
      "loss": 0.5886,
      "step": 691
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.96830435868496,
      "learning_rate": 9.991431319464062e-06,
      "loss": 0.5591,
      "step": 692
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.4355597233932778,
      "learning_rate": 9.99136529879554e-06,
      "loss": 0.5933,
      "step": 693
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.0467123431844874,
      "learning_rate": 9.991299024981246e-06,
      "loss": 0.6009,
      "step": 694
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.9464012003759124,
      "learning_rate": 9.991232498024534e-06,
      "loss": 0.5734,
      "step": 695
    },
    {
      "epoch": 0.05,
      "grad_norm": 4.430403601135389,
      "learning_rate": 9.991165717928783e-06,
      "loss": 0.5442,
      "step": 696
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.9563644286728958,
      "learning_rate": 9.99109868469738e-06,
      "loss": 0.5803,
      "step": 697
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.9546268701473661,
      "learning_rate": 9.991031398333725e-06,
      "loss": 0.5604,
      "step": 698
    },
    {
      "epoch": 0.05,
      "grad_norm": 3.2400941843060878,
      "learning_rate": 9.990963858841225e-06,
      "loss": 0.5976,
      "step": 699
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.0849051114911195,
      "learning_rate": 9.990896066223313e-06,
      "loss": 0.5511,
      "step": 700
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.8568980781401014,
      "learning_rate": 9.990828020483423e-06,
      "loss": 0.5587,
      "step": 701
    },
    {
      "epoch": 0.05,
      "grad_norm": 3.443999732037397,
      "learning_rate": 9.990759721625005e-06,
      "loss": 0.5956,
      "step": 702
    },
    {
      "epoch": 0.05,
      "grad_norm": 3.6746639568162784,
      "learning_rate": 9.990691169651527e-06,
      "loss": 0.5396,
      "step": 703
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.479023852046795,
      "learning_rate": 9.990622364566463e-06,
      "loss": 0.5406,
      "step": 704
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.1553359253614885,
      "learning_rate": 9.990553306373303e-06,
      "loss": 0.4877,
      "step": 705
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.01965683386975,
      "learning_rate": 9.990483995075549e-06,
      "loss": 0.566,
      "step": 706
    },
    {
      "epoch": 0.05,
      "grad_norm": 3.2431175256127642,
      "learning_rate": 9.990414430676716e-06,
      "loss": 0.5987,
      "step": 707
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.9707795970749875,
      "learning_rate": 9.990344613180334e-06,
      "loss": 0.516,
      "step": 708
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.892157141799707,
      "learning_rate": 9.990274542589942e-06,
      "loss": 0.4513,
      "step": 709
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.170806346765686,
      "learning_rate": 9.990204218909095e-06,
      "loss": 0.4969,
      "step": 710
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7644950000716663,
      "learning_rate": 9.990133642141359e-06,
      "loss": 0.4497,
      "step": 711
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8830121517604976,
      "learning_rate": 9.990062812290313e-06,
      "loss": 0.4482,
      "step": 712
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.6217257028431353,
      "learning_rate": 9.989991729359549e-06,
      "loss": 0.5589,
      "step": 713
    },
    {
      "epoch": 0.05,
      "grad_norm": 3.7728948350487896,
      "learning_rate": 9.989920393352675e-06,
      "loss": 0.5449,
      "step": 714
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.2305750331196768,
      "learning_rate": 9.989848804273306e-06,
      "loss": 0.6202,
      "step": 715
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.9331186880121352,
      "learning_rate": 9.989776962125072e-06,
      "loss": 0.5908,
      "step": 716
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.307095653972519,
      "learning_rate": 9.989704866911617e-06,
      "loss": 0.5407,
      "step": 717
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.393710868581416,
      "learning_rate": 9.989632518636602e-06,
      "loss": 0.5513,
      "step": 718
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.2537827721990524,
      "learning_rate": 9.989559917303691e-06,
      "loss": 0.5575,
      "step": 719
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.934057346876817,
      "learning_rate": 9.989487062916568e-06,
      "loss": 0.5451,
      "step": 720
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.0061297682182517,
      "learning_rate": 9.989413955478928e-06,
      "loss": 0.5605,
      "step": 721
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.0474828177609021,
      "learning_rate": 9.98934059499448e-06,
      "loss": 0.4636,
      "step": 722
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.1985177420691975,
      "learning_rate": 9.98926698146694e-06,
      "loss": 0.578,
      "step": 723
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.0737843310078365,
      "learning_rate": 9.989193114900048e-06,
      "loss": 0.5661,
      "step": 724
    },
    {
      "epoch": 0.05,
      "grad_norm": 3.0092632000726067,
      "learning_rate": 9.989118995297545e-06,
      "loss": 0.5265,
      "step": 725
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.6344232943211274,
      "learning_rate": 9.989044622663194e-06,
      "loss": 0.5714,
      "step": 726
    },
    {
      "epoch": 0.05,
      "grad_norm": 3.253470972862801,
      "learning_rate": 9.988969997000761e-06,
      "loss": 0.6243,
      "step": 727
    },
    {
      "epoch": 0.05,
      "grad_norm": 3.3689350494743393,
      "learning_rate": 9.988895118314038e-06,
      "loss": 0.5864,
      "step": 728
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.9551282107830251,
      "learning_rate": 9.98881998660682e-06,
      "loss": 0.4569,
      "step": 729
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.781896365692363,
      "learning_rate": 9.988744601882913e-06,
      "loss": 0.575,
      "step": 730
    },
    {
      "epoch": 0.05,
      "grad_norm": 6.726113310868504,
      "learning_rate": 9.988668964146147e-06,
      "loss": 0.5737,
      "step": 731
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8327597752215126,
      "learning_rate": 9.988593073400354e-06,
      "loss": 0.4561,
      "step": 732
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.321968016175508,
      "learning_rate": 9.988516929649386e-06,
      "loss": 0.5608,
      "step": 733
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.7952009107608309,
      "learning_rate": 9.9884405328971e-06,
      "loss": 0.5883,
      "step": 734
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.8378669895318485,
      "learning_rate": 9.988363883147376e-06,
      "loss": 0.6178,
      "step": 735
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7888795982968853,
      "learning_rate": 9.988286980404096e-06,
      "loss": 0.4661,
      "step": 736
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.183000924347447,
      "learning_rate": 9.988209824671164e-06,
      "loss": 0.5792,
      "step": 737
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.8749199126766234,
      "learning_rate": 9.988132415952494e-06,
      "loss": 0.5986,
      "step": 738
    },
    {
      "epoch": 0.05,
      "grad_norm": 3.258819838658967,
      "learning_rate": 9.988054754252009e-06,
      "loss": 0.5624,
      "step": 739
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.5996399809735493,
      "learning_rate": 9.987976839573649e-06,
      "loss": 0.5162,
      "step": 740
    },
    {
      "epoch": 0.05,
      "grad_norm": 5.94210339035484,
      "learning_rate": 9.987898671921365e-06,
      "loss": 0.5648,
      "step": 741
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.7041706346614276,
      "learning_rate": 9.987820251299121e-06,
      "loss": 0.526,
      "step": 742
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.3682319862323036,
      "learning_rate": 9.987741577710897e-06,
      "loss": 0.5641,
      "step": 743
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.680452775228415,
      "learning_rate": 9.987662651160682e-06,
      "loss": 0.5373,
      "step": 744
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.7190831046422919,
      "learning_rate": 9.987583471652476e-06,
      "loss": 0.5648,
      "step": 745
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.05371234946469,
      "learning_rate": 9.987504039190297e-06,
      "loss": 0.5796,
      "step": 746
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.073988171266254,
      "learning_rate": 9.987424353778172e-06,
      "loss": 0.5456,
      "step": 747
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.3359983929111303,
      "learning_rate": 9.987344415420145e-06,
      "loss": 0.6008,
      "step": 748
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.782642572374027,
      "learning_rate": 9.98726422412027e-06,
      "loss": 0.5099,
      "step": 749
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.9604364852327438,
      "learning_rate": 9.987183779882611e-06,
      "loss": 0.5489,
      "step": 750
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.177643854364474,
      "learning_rate": 9.98710308271125e-06,
      "loss": 0.5428,
      "step": 751
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.3040916497917263,
      "learning_rate": 9.987022132610282e-06,
      "loss": 0.542,
      "step": 752
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.486380941996066,
      "learning_rate": 9.986940929583808e-06,
      "loss": 0.5428,
      "step": 753
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.853942657576688,
      "learning_rate": 9.98685947363595e-06,
      "loss": 0.5893,
      "step": 754
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.778429806998479,
      "learning_rate": 9.986777764770836e-06,
      "loss": 0.539,
      "step": 755
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.202164220168128,
      "learning_rate": 9.986695802992613e-06,
      "loss": 0.5981,
      "step": 756
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.6744702184032172,
      "learning_rate": 9.986613588305435e-06,
      "loss": 0.5148,
      "step": 757
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.163047533023289,
      "learning_rate": 9.986531120713474e-06,
      "loss": 0.5737,
      "step": 758
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.2993960354214207,
      "learning_rate": 9.986448400220912e-06,
      "loss": 0.509,
      "step": 759
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.0502362678696144,
      "learning_rate": 9.986365426831943e-06,
      "loss": 0.5725,
      "step": 760
    },
    {
      "epoch": 0.05,
      "grad_norm": 3.065235119437136,
      "learning_rate": 9.986282200550775e-06,
      "loss": 0.5705,
      "step": 761
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.6574852173527868,
      "learning_rate": 9.98619872138163e-06,
      "loss": 0.5158,
      "step": 762
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.3346543908664845,
      "learning_rate": 9.986114989328745e-06,
      "loss": 0.5607,
      "step": 763
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.6079776195704782,
      "learning_rate": 9.986031004396362e-06,
      "loss": 0.5323,
      "step": 764
    },
    {
      "epoch": 0.05,
      "grad_norm": 3.3906578144774335,
      "learning_rate": 9.98594676658874e-06,
      "loss": 0.6039,
      "step": 765
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.3251204950902844,
      "learning_rate": 9.985862275910154e-06,
      "loss": 0.5775,
      "step": 766
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.9881586784263554,
      "learning_rate": 9.985777532364889e-06,
      "loss": 0.527,
      "step": 767
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.1324330932089057,
      "learning_rate": 9.985692535957243e-06,
      "loss": 0.5534,
      "step": 768
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.146970188673765,
      "learning_rate": 9.985607286691524e-06,
      "loss": 0.6045,
      "step": 769
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.1805364754489855,
      "learning_rate": 9.985521784572057e-06,
      "loss": 0.5725,
      "step": 770
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.2900640350751997,
      "learning_rate": 9.985436029603181e-06,
      "loss": 0.5669,
      "step": 771
    },
    {
      "epoch": 0.05,
      "grad_norm": 3.5583081551524143,
      "learning_rate": 9.985350021789242e-06,
      "loss": 0.6297,
      "step": 772
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.8067587508842458,
      "learning_rate": 9.985263761134602e-06,
      "loss": 0.5635,
      "step": 773
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.0332413287287894,
      "learning_rate": 9.985177247643637e-06,
      "loss": 0.5469,
      "step": 774
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.763058683630717,
      "learning_rate": 9.985090481320736e-06,
      "loss": 0.6027,
      "step": 775
    },
    {
      "epoch": 0.05,
      "grad_norm": 5.00014977209575,
      "learning_rate": 9.985003462170297e-06,
      "loss": 0.5826,
      "step": 776
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.234679607877245,
      "learning_rate": 9.984916190196736e-06,
      "loss": 0.5771,
      "step": 777
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.2035751978652875,
      "learning_rate": 9.984828665404477e-06,
      "loss": 0.5902,
      "step": 778
    },
    {
      "epoch": 0.05,
      "grad_norm": 4.184161048441715,
      "learning_rate": 9.984740887797958e-06,
      "loss": 0.5763,
      "step": 779
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.9550589089766335,
      "learning_rate": 9.984652857381633e-06,
      "loss": 0.5496,
      "step": 780
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.09297317529407,
      "learning_rate": 9.984564574159968e-06,
      "loss": 0.5611,
      "step": 781
    },
    {
      "epoch": 0.05,
      "grad_norm": 3.1644812918314105,
      "learning_rate": 9.984476038137437e-06,
      "loss": 0.5876,
      "step": 782
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.7586397477114764,
      "learning_rate": 9.98438724931853e-06,
      "loss": 0.5564,
      "step": 783
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.885306349700664,
      "learning_rate": 9.984298207707754e-06,
      "loss": 0.5301,
      "step": 784
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.2021143788343567,
      "learning_rate": 9.984208913309623e-06,
      "loss": 0.5771,
      "step": 785
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.9320227050320101,
      "learning_rate": 9.984119366128663e-06,
      "loss": 0.4665,
      "step": 786
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.089366341286964,
      "learning_rate": 9.98402956616942e-06,
      "loss": 0.6113,
      "step": 787
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.0391056534127507,
      "learning_rate": 9.983939513436447e-06,
      "loss": 0.5662,
      "step": 788
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.8594231165762696,
      "learning_rate": 9.983849207934308e-06,
      "loss": 0.5545,
      "step": 789
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.9341883425566655,
      "learning_rate": 9.983758649667587e-06,
      "loss": 0.6365,
      "step": 790
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.4215937075995226,
      "learning_rate": 9.983667838640874e-06,
      "loss": 0.5567,
      "step": 791
    },
    {
      "epoch": 0.06,
      "grad_norm": 18.629991802894406,
      "learning_rate": 9.983576774858776e-06,
      "loss": 0.613,
      "step": 792
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.3986543212641624,
      "learning_rate": 9.983485458325913e-06,
      "loss": 0.572,
      "step": 793
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.530142113263372,
      "learning_rate": 9.983393889046914e-06,
      "loss": 0.586,
      "step": 794
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.9496303461447106,
      "learning_rate": 9.983302067026424e-06,
      "loss": 0.5814,
      "step": 795
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.452480678068691,
      "learning_rate": 9.983209992269098e-06,
      "loss": 0.5329,
      "step": 796
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.126841259754625,
      "learning_rate": 9.98311766477961e-06,
      "loss": 0.5869,
      "step": 797
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.9174500061558124,
      "learning_rate": 9.983025084562637e-06,
      "loss": 0.5687,
      "step": 798
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.500366575439157,
      "learning_rate": 9.982932251622878e-06,
      "loss": 0.6305,
      "step": 799
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.2815931399039213,
      "learning_rate": 9.982839165965042e-06,
      "loss": 0.5548,
      "step": 800
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.0410697983222688,
      "learning_rate": 9.982745827593848e-06,
      "loss": 0.4754,
      "step": 801
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.070732145094573,
      "learning_rate": 9.98265223651403e-06,
      "loss": 0.5833,
      "step": 802
    },
    {
      "epoch": 0.06,
      "grad_norm": 4.694786712016096,
      "learning_rate": 9.982558392730334e-06,
      "loss": 0.566,
      "step": 803
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.7952232555290264,
      "learning_rate": 9.982464296247523e-06,
      "loss": 0.6143,
      "step": 804
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.8361847960029107,
      "learning_rate": 9.982369947070365e-06,
      "loss": 0.5159,
      "step": 805
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.2698046459926684,
      "learning_rate": 9.982275345203647e-06,
      "loss": 0.5395,
      "step": 806
    },
    {
      "epoch": 0.06,
      "grad_norm": 3.9324119074229653,
      "learning_rate": 9.982180490652165e-06,
      "loss": 0.5902,
      "step": 807
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.389387609440192,
      "learning_rate": 9.982085383420734e-06,
      "loss": 0.584,
      "step": 808
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.9186957334042578,
      "learning_rate": 9.981990023514173e-06,
      "loss": 0.5128,
      "step": 809
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.9707120585308924,
      "learning_rate": 9.98189441093732e-06,
      "loss": 0.5325,
      "step": 810
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.9805926119261144,
      "learning_rate": 9.981798545695026e-06,
      "loss": 0.4602,
      "step": 811
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.067382552023092,
      "learning_rate": 9.98170242779215e-06,
      "loss": 0.5898,
      "step": 812
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.5081908131927646,
      "learning_rate": 9.98160605723357e-06,
      "loss": 0.5731,
      "step": 813
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.143583328847565,
      "learning_rate": 9.98150943402417e-06,
      "loss": 0.5273,
      "step": 814
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.121303747305892,
      "learning_rate": 9.981412558168853e-06,
      "loss": 0.5488,
      "step": 815
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.5120638455305557,
      "learning_rate": 9.981315429672531e-06,
      "loss": 0.5376,
      "step": 816
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.976569518083638,
      "learning_rate": 9.98121804854013e-06,
      "loss": 0.5894,
      "step": 817
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8457518550103991,
      "learning_rate": 9.981120414776591e-06,
      "loss": 0.468,
      "step": 818
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.0669682938094223,
      "learning_rate": 9.981022528386862e-06,
      "loss": 0.5328,
      "step": 819
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.1710628617478864,
      "learning_rate": 9.98092438937591e-06,
      "loss": 0.5523,
      "step": 820
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.9179449280208356,
      "learning_rate": 9.980825997748712e-06,
      "loss": 0.5815,
      "step": 821
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.146772835032624,
      "learning_rate": 9.980727353510257e-06,
      "loss": 0.5617,
      "step": 822
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.2461777068734246,
      "learning_rate": 9.98062845666555e-06,
      "loss": 0.584,
      "step": 823
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.0018032382868767,
      "learning_rate": 9.980529307219605e-06,
      "loss": 0.5631,
      "step": 824
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.9525451800598137,
      "learning_rate": 9.98042990517745e-06,
      "loss": 0.6466,
      "step": 825
    },
    {
      "epoch": 0.06,
      "grad_norm": 3.1400247674135184,
      "learning_rate": 9.98033025054413e-06,
      "loss": 0.5666,
      "step": 826
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.873315071078197,
      "learning_rate": 9.980230343324695e-06,
      "loss": 0.5758,
      "step": 827
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.956509035358679,
      "learning_rate": 9.980130183524213e-06,
      "loss": 0.5439,
      "step": 828
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.1677313449875246,
      "learning_rate": 9.980029771147764e-06,
      "loss": 0.5986,
      "step": 829
    },
    {
      "epoch": 0.06,
      "grad_norm": 4.080545231754883,
      "learning_rate": 9.97992910620044e-06,
      "loss": 0.588,
      "step": 830
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.3053874566798904,
      "learning_rate": 9.97982818868735e-06,
      "loss": 0.593,
      "step": 831
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.3066184472382596,
      "learning_rate": 9.979727018613607e-06,
      "loss": 0.5933,
      "step": 832
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.9575214965462346,
      "learning_rate": 9.979625595984345e-06,
      "loss": 0.5433,
      "step": 833
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.829804993530123,
      "learning_rate": 9.979523920804709e-06,
      "loss": 0.5466,
      "step": 834
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.9450567070706322,
      "learning_rate": 9.979421993079853e-06,
      "loss": 0.5763,
      "step": 835
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.90689928111399,
      "learning_rate": 9.979319812814947e-06,
      "loss": 0.4378,
      "step": 836
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.811470889593593,
      "learning_rate": 9.979217380015173e-06,
      "loss": 0.5758,
      "step": 837
    },
    {
      "epoch": 0.06,
      "grad_norm": 3.6953793950546063,
      "learning_rate": 9.979114694685727e-06,
      "loss": 0.5487,
      "step": 838
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.323571851907258,
      "learning_rate": 9.979011756831818e-06,
      "loss": 0.5633,
      "step": 839
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.2296643402484686,
      "learning_rate": 9.978908566458663e-06,
      "loss": 0.5195,
      "step": 840
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.059268009427637,
      "learning_rate": 9.9788051235715e-06,
      "loss": 0.6056,
      "step": 841
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.88802727319352,
      "learning_rate": 9.97870142817557e-06,
      "loss": 0.4566,
      "step": 842
    },
    {
      "epoch": 0.06,
      "grad_norm": 3.9529176800079564,
      "learning_rate": 9.978597480276138e-06,
      "loss": 0.5795,
      "step": 843
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.8755298307153538,
      "learning_rate": 9.978493279878472e-06,
      "loss": 0.6251,
      "step": 844
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.8698794278320072,
      "learning_rate": 9.978388826987856e-06,
      "loss": 0.5755,
      "step": 845
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.7885046486324054,
      "learning_rate": 9.978284121609591e-06,
      "loss": 0.5826,
      "step": 846
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.8546342172453616,
      "learning_rate": 9.978179163748985e-06,
      "loss": 0.5618,
      "step": 847
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.204582181895343,
      "learning_rate": 9.978073953411362e-06,
      "loss": 0.5674,
      "step": 848
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.6277746195236995,
      "learning_rate": 9.977968490602056e-06,
      "loss": 0.5461,
      "step": 849
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.8682705175942544,
      "learning_rate": 9.977862775326419e-06,
      "loss": 0.5048,
      "step": 850
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.04145573860538,
      "learning_rate": 9.977756807589812e-06,
      "loss": 0.5683,
      "step": 851
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.763785833479918,
      "learning_rate": 9.977650587397606e-06,
      "loss": 0.5624,
      "step": 852
    },
    {
      "epoch": 0.06,
      "grad_norm": 3.650897103100912,
      "learning_rate": 9.97754411475519e-06,
      "loss": 0.5486,
      "step": 853
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.0866816981469394,
      "learning_rate": 9.977437389667966e-06,
      "loss": 0.589,
      "step": 854
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.2977836891594645,
      "learning_rate": 9.977330412141343e-06,
      "loss": 0.5758,
      "step": 855
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.2751533096937,
      "learning_rate": 9.977223182180749e-06,
      "loss": 0.5944,
      "step": 856
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.7915026885533136,
      "learning_rate": 9.977115699791622e-06,
      "loss": 0.5137,
      "step": 857
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.099058480443349,
      "learning_rate": 9.977007964979414e-06,
      "loss": 0.5592,
      "step": 858
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.5987849500862468,
      "learning_rate": 9.976899977749587e-06,
      "loss": 0.5834,
      "step": 859
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.582186763121356,
      "learning_rate": 9.976791738107618e-06,
      "loss": 0.6004,
      "step": 860
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.25254239933225,
      "learning_rate": 9.976683246059e-06,
      "loss": 0.5618,
      "step": 861
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.736042747114176,
      "learning_rate": 9.976574501609231e-06,
      "loss": 0.535,
      "step": 862
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.574692763598828,
      "learning_rate": 9.976465504763828e-06,
      "loss": 0.5801,
      "step": 863
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.309974743373605,
      "learning_rate": 9.976356255528318e-06,
      "loss": 0.5164,
      "step": 864
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.8873654026455227,
      "learning_rate": 9.976246753908243e-06,
      "loss": 0.5868,
      "step": 865
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.1817097273797135,
      "learning_rate": 9.976136999909156e-06,
      "loss": 0.5939,
      "step": 866
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.8257844661494724,
      "learning_rate": 9.976026993536625e-06,
      "loss": 0.5947,
      "step": 867
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.334198317877179,
      "learning_rate": 9.975916734796226e-06,
      "loss": 0.5159,
      "step": 868
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.631866602220918,
      "learning_rate": 9.975806223693554e-06,
      "loss": 0.5147,
      "step": 869
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.8502758690749797,
      "learning_rate": 9.975695460234211e-06,
      "loss": 0.5661,
      "step": 870
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.7038577839257614,
      "learning_rate": 9.975584444423816e-06,
      "loss": 0.6028,
      "step": 871
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8610084555029561,
      "learning_rate": 9.975473176268001e-06,
      "loss": 0.4448,
      "step": 872
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.9598689006789212,
      "learning_rate": 9.975361655772406e-06,
      "loss": 0.5549,
      "step": 873
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.1075497616962147,
      "learning_rate": 9.975249882942688e-06,
      "loss": 0.5933,
      "step": 874
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.9354794570511846,
      "learning_rate": 9.975137857784518e-06,
      "loss": 0.5897,
      "step": 875
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.236861878208837,
      "learning_rate": 9.975025580303575e-06,
      "loss": 0.5337,
      "step": 876
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.6533697141346573,
      "learning_rate": 9.974913050505553e-06,
      "loss": 0.5786,
      "step": 877
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.9026602673839328,
      "learning_rate": 9.97480026839616e-06,
      "loss": 0.4666,
      "step": 878
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.7735833938647578,
      "learning_rate": 9.97468723398112e-06,
      "loss": 0.5531,
      "step": 879
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.9586107621644773,
      "learning_rate": 9.974573947266158e-06,
      "loss": 0.5921,
      "step": 880
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.3052865663344,
      "learning_rate": 9.974460408257024e-06,
      "loss": 0.568,
      "step": 881
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.7857130052374037,
      "learning_rate": 9.974346616959476e-06,
      "loss": 0.5586,
      "step": 882
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.4736698723090877,
      "learning_rate": 9.974232573379285e-06,
      "loss": 0.5009,
      "step": 883
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.0619240786340507,
      "learning_rate": 9.974118277522235e-06,
      "loss": 0.5552,
      "step": 884
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.9461632108785385,
      "learning_rate": 9.974003729394124e-06,
      "loss": 0.5322,
      "step": 885
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.6848286300980944,
      "learning_rate": 9.973888929000758e-06,
      "loss": 0.5939,
      "step": 886
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.208045226061795,
      "learning_rate": 9.973773876347962e-06,
      "loss": 0.5716,
      "step": 887
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.750522919333993,
      "learning_rate": 9.97365857144157e-06,
      "loss": 0.6029,
      "step": 888
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.8222716548029743,
      "learning_rate": 9.97354301428743e-06,
      "loss": 0.5836,
      "step": 889
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.9574508154698695,
      "learning_rate": 9.973427204891404e-06,
      "loss": 0.4847,
      "step": 890
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.347802992797701,
      "learning_rate": 9.973311143259365e-06,
      "loss": 0.5155,
      "step": 891
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7804540147030457,
      "learning_rate": 9.973194829397198e-06,
      "loss": 0.4418,
      "step": 892
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.6985411564694968,
      "learning_rate": 9.973078263310803e-06,
      "loss": 0.5097,
      "step": 893
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.9770729256220514,
      "learning_rate": 9.97296144500609e-06,
      "loss": 0.5906,
      "step": 894
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.258500630058389,
      "learning_rate": 9.972844374488986e-06,
      "loss": 0.6644,
      "step": 895
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.9058820149148246,
      "learning_rate": 9.97272705176543e-06,
      "loss": 0.5427,
      "step": 896
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.5996925521614136,
      "learning_rate": 9.972609476841368e-06,
      "loss": 0.5563,
      "step": 897
    },
    {
      "epoch": 0.06,
      "grad_norm": 9.2758228820289,
      "learning_rate": 9.972491649722763e-06,
      "loss": 0.5824,
      "step": 898
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.38840327744988,
      "learning_rate": 9.972373570415596e-06,
      "loss": 0.5219,
      "step": 899
    },
    {
      "epoch": 0.06,
      "grad_norm": 7.541034239295777,
      "learning_rate": 9.972255238925853e-06,
      "loss": 0.5068,
      "step": 900
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.126428620549218,
      "learning_rate": 9.972136655259532e-06,
      "loss": 0.5555,
      "step": 901
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.770744558259443,
      "learning_rate": 9.972017819422652e-06,
      "loss": 0.6179,
      "step": 902
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.175859407434709,
      "learning_rate": 9.971898731421237e-06,
      "loss": 0.5453,
      "step": 903
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.052949969301799,
      "learning_rate": 9.971779391261328e-06,
      "loss": 0.5819,
      "step": 904
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.161298556109189,
      "learning_rate": 9.971659798948977e-06,
      "loss": 0.6028,
      "step": 905
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.012340606784275,
      "learning_rate": 9.971539954490248e-06,
      "loss": 0.5016,
      "step": 906
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.9950958094417237,
      "learning_rate": 9.971419857891223e-06,
      "loss": 0.5486,
      "step": 907
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.6677120241568029,
      "learning_rate": 9.97129950915799e-06,
      "loss": 0.5796,
      "step": 908
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.3719112840781533,
      "learning_rate": 9.971178908296652e-06,
      "loss": 0.5219,
      "step": 909
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.8911931953873398,
      "learning_rate": 9.971058055313327e-06,
      "loss": 0.5371,
      "step": 910
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.89573564217718,
      "learning_rate": 9.970936950214145e-06,
      "loss": 0.5177,
      "step": 911
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.4047053475841924,
      "learning_rate": 9.970815593005248e-06,
      "loss": 0.5667,
      "step": 912
    },
    {
      "epoch": 0.06,
      "grad_norm": 3.078922387701072,
      "learning_rate": 9.970693983692787e-06,
      "loss": 0.5759,
      "step": 913
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.8780843407990946,
      "learning_rate": 9.970572122282935e-06,
      "loss": 0.5654,
      "step": 914
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.3959729103132354,
      "learning_rate": 9.970450008781869e-06,
      "loss": 0.5476,
      "step": 915
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.75668139290468,
      "learning_rate": 9.970327643195784e-06,
      "loss": 0.5704,
      "step": 916
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.2862799038824377,
      "learning_rate": 9.970205025530884e-06,
      "loss": 0.5558,
      "step": 917
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.8049533266174465,
      "learning_rate": 9.97008215579339e-06,
      "loss": 0.5661,
      "step": 918
    },
    {
      "epoch": 0.06,
      "grad_norm": 4.692019572667279,
      "learning_rate": 9.969959033989532e-06,
      "loss": 0.5961,
      "step": 919
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.8444378131340864,
      "learning_rate": 9.969835660125554e-06,
      "loss": 0.5351,
      "step": 920
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.351426686274927,
      "learning_rate": 9.969712034207715e-06,
      "loss": 0.5885,
      "step": 921
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.4630736627779517,
      "learning_rate": 9.969588156242282e-06,
      "loss": 0.5704,
      "step": 922
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.869933374965062,
      "learning_rate": 9.969464026235543e-06,
      "loss": 0.5693,
      "step": 923
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.0689674352086858,
      "learning_rate": 9.969339644193787e-06,
      "loss": 0.5638,
      "step": 924
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.2992782509872796,
      "learning_rate": 9.969215010123325e-06,
      "loss": 0.5978,
      "step": 925
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.1037333695784572,
      "learning_rate": 9.96909012403048e-06,
      "loss": 0.5362,
      "step": 926
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.0385719516479837,
      "learning_rate": 9.968964985921584e-06,
      "loss": 0.5295,
      "step": 927
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.185720199644703,
      "learning_rate": 9.968839595802982e-06,
      "loss": 0.6091,
      "step": 928
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.0045714181930765,
      "learning_rate": 9.968713953681037e-06,
      "loss": 0.5862,
      "step": 929
    },
    {
      "epoch": 0.06,
      "grad_norm": 5.679684648778339,
      "learning_rate": 9.968588059562119e-06,
      "loss": 0.5599,
      "step": 930
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.0818199137154796,
      "learning_rate": 9.968461913452612e-06,
      "loss": 0.5251,
      "step": 931
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.0956119370736017,
      "learning_rate": 9.968335515358916e-06,
      "loss": 0.5852,
      "step": 932
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.879241508404355,
      "learning_rate": 9.968208865287438e-06,
      "loss": 0.5735,
      "step": 933
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.509315342523534,
      "learning_rate": 9.968081963244606e-06,
      "loss": 0.5599,
      "step": 934
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.8693012132828766,
      "learning_rate": 9.967954809236852e-06,
      "loss": 0.6196,
      "step": 935
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.225031541611025,
      "learning_rate": 9.96782740327063e-06,
      "loss": 0.5649,
      "step": 936
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.9094732548807012,
      "learning_rate": 9.967699745352395e-06,
      "loss": 0.5504,
      "step": 937
    },
    {
      "epoch": 0.07,
      "grad_norm": 16.03414227728128,
      "learning_rate": 9.967571835488625e-06,
      "loss": 0.5408,
      "step": 938
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.15042609458927,
      "learning_rate": 9.967443673685806e-06,
      "loss": 0.5789,
      "step": 939
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.123450453793311,
      "learning_rate": 9.96731525995044e-06,
      "loss": 0.5736,
      "step": 940
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.9176833465564522,
      "learning_rate": 9.967186594289038e-06,
      "loss": 0.5671,
      "step": 941
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.8181202934151242,
      "learning_rate": 9.967057676708126e-06,
      "loss": 0.571,
      "step": 942
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.3374530061876215,
      "learning_rate": 9.966928507214241e-06,
      "loss": 0.497,
      "step": 943
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.0981015853529543,
      "learning_rate": 9.96679908581394e-06,
      "loss": 0.5315,
      "step": 944
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.9025233644358304,
      "learning_rate": 9.966669412513776e-06,
      "loss": 0.535,
      "step": 945
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.9157581124413023,
      "learning_rate": 9.966539487320335e-06,
      "loss": 0.5188,
      "step": 946
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.3768094131262694,
      "learning_rate": 9.9664093102402e-06,
      "loss": 0.6062,
      "step": 947
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.1877590232509085,
      "learning_rate": 9.96627888127998e-06,
      "loss": 0.5309,
      "step": 948
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.9765399717382979,
      "learning_rate": 9.966148200446284e-06,
      "loss": 0.5547,
      "step": 949
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.8843370884691157,
      "learning_rate": 9.966017267745743e-06,
      "loss": 0.5551,
      "step": 950
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.9421503732612835,
      "learning_rate": 9.965886083184996e-06,
      "loss": 0.557,
      "step": 951
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.8772600680970686,
      "learning_rate": 9.965754646770695e-06,
      "loss": 0.529,
      "step": 952
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.017659612483949,
      "learning_rate": 9.96562295850951e-06,
      "loss": 0.5567,
      "step": 953
    },
    {
      "epoch": 0.07,
      "grad_norm": 3.313325601582755,
      "learning_rate": 9.965491018408115e-06,
      "loss": 0.5257,
      "step": 954
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.2934447748472855,
      "learning_rate": 9.965358826473206e-06,
      "loss": 0.5687,
      "step": 955
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.855555227005227,
      "learning_rate": 9.965226382711485e-06,
      "loss": 0.607,
      "step": 956
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.7004169670154181,
      "learning_rate": 9.965093687129669e-06,
      "loss": 0.5332,
      "step": 957
    },
    {
      "epoch": 0.07,
      "grad_norm": 3.5675367435254373,
      "learning_rate": 9.964960739734489e-06,
      "loss": 0.5555,
      "step": 958
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.0061882991017488,
      "learning_rate": 9.964827540532685e-06,
      "loss": 0.4644,
      "step": 959
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.9259126886225881,
      "learning_rate": 9.964694089531017e-06,
      "loss": 0.5625,
      "step": 960
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.490174422626057,
      "learning_rate": 9.964560386736248e-06,
      "loss": 0.5443,
      "step": 961
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.5041930902032195,
      "learning_rate": 9.964426432155163e-06,
      "loss": 0.5854,
      "step": 962
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.9687702823718176,
      "learning_rate": 9.964292225794556e-06,
      "loss": 0.5514,
      "step": 963
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9048081909325502,
      "learning_rate": 9.96415776766123e-06,
      "loss": 0.4511,
      "step": 964
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.7353104684594358,
      "learning_rate": 9.964023057762005e-06,
      "loss": 0.5802,
      "step": 965
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.202188634741129,
      "learning_rate": 9.963888096103716e-06,
      "loss": 0.609,
      "step": 966
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8491444735867407,
      "learning_rate": 9.963752882693205e-06,
      "loss": 0.4605,
      "step": 967
    },
    {
      "epoch": 0.07,
      "grad_norm": 3.4110734037403994,
      "learning_rate": 9.96361741753733e-06,
      "loss": 0.5499,
      "step": 968
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.816032390292712,
      "learning_rate": 9.963481700642964e-06,
      "loss": 0.5913,
      "step": 969
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.1996972565046082,
      "learning_rate": 9.963345732016988e-06,
      "loss": 0.5309,
      "step": 970
    },
    {
      "epoch": 0.07,
      "grad_norm": 6.780748265464211,
      "learning_rate": 9.963209511666296e-06,
      "loss": 0.602,
      "step": 971
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.660764054672008,
      "learning_rate": 9.963073039597798e-06,
      "loss": 0.5392,
      "step": 972
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.9271997360345154,
      "learning_rate": 9.962936315818417e-06,
      "loss": 0.5275,
      "step": 973
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.3634277861426187,
      "learning_rate": 9.962799340335088e-06,
      "loss": 0.5378,
      "step": 974
    },
    {
      "epoch": 0.07,
      "grad_norm": 3.4988831108504503,
      "learning_rate": 9.962662113154753e-06,
      "loss": 0.5941,
      "step": 975
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.7316022870627548,
      "learning_rate": 9.962524634284377e-06,
      "loss": 0.557,
      "step": 976
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.770387875201469,
      "learning_rate": 9.96238690373093e-06,
      "loss": 0.5687,
      "step": 977
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.952306146547919,
      "learning_rate": 9.962248921501396e-06,
      "loss": 0.6013,
      "step": 978
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.16118119563999,
      "learning_rate": 9.962110687602778e-06,
      "loss": 0.5738,
      "step": 979
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.8443557366597936,
      "learning_rate": 9.96197220204208e-06,
      "loss": 0.5607,
      "step": 980
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.6851569771905208,
      "learning_rate": 9.96183346482633e-06,
      "loss": 0.5794,
      "step": 981
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.8976558647156159,
      "learning_rate": 9.961694475962562e-06,
      "loss": 0.5418,
      "step": 982
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.826784992534557,
      "learning_rate": 9.961555235457829e-06,
      "loss": 0.5497,
      "step": 983
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.771845336177206,
      "learning_rate": 9.961415743319187e-06,
      "loss": 0.593,
      "step": 984
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.9543463049420944,
      "learning_rate": 9.961275999553717e-06,
      "loss": 0.6048,
      "step": 985
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.336241351768847,
      "learning_rate": 9.9611360041685e-06,
      "loss": 0.5258,
      "step": 986
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.5029481694481603,
      "learning_rate": 9.960995757170639e-06,
      "loss": 0.5229,
      "step": 987
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.742000032660184,
      "learning_rate": 9.96085525856725e-06,
      "loss": 0.5748,
      "step": 988
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.9790254233390063,
      "learning_rate": 9.960714508365454e-06,
      "loss": 0.5525,
      "step": 989
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.014135415513823,
      "learning_rate": 9.960573506572391e-06,
      "loss": 0.569,
      "step": 990
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.8775033651568596,
      "learning_rate": 9.960432253195212e-06,
      "loss": 0.5396,
      "step": 991
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.5052540122197597,
      "learning_rate": 9.96029074824108e-06,
      "loss": 0.588,
      "step": 992
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.6484795276015278,
      "learning_rate": 9.960148991717174e-06,
      "loss": 0.5955,
      "step": 993
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.559022545170393,
      "learning_rate": 9.96000698363068e-06,
      "loss": 0.5637,
      "step": 994
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.8266933943676327,
      "learning_rate": 9.959864723988805e-06,
      "loss": 0.5511,
      "step": 995
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9751957452377152,
      "learning_rate": 9.959722212798762e-06,
      "loss": 0.4567,
      "step": 996
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.048495062241685,
      "learning_rate": 9.959579450067776e-06,
      "loss": 0.5929,
      "step": 997
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.8309306156556582,
      "learning_rate": 9.95943643580309e-06,
      "loss": 0.5457,
      "step": 998
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.2917056636029063,
      "learning_rate": 9.959293170011956e-06,
      "loss": 0.558,
      "step": 999
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.9388249152125434,
      "learning_rate": 9.95914965270164e-06,
      "loss": 0.5489,
      "step": 1000
    },
    {
      "epoch": 0.07,
      "grad_norm": 3.3814781014069726,
      "learning_rate": 9.959005883879425e-06,
      "loss": 0.596,
      "step": 1001
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.185784155399169,
      "learning_rate": 9.958861863552596e-06,
      "loss": 0.5776,
      "step": 1002
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.2198530435968102,
      "learning_rate": 9.95871759172846e-06,
      "loss": 0.5742,
      "step": 1003
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.7643989525204975,
      "learning_rate": 9.958573068414334e-06,
      "loss": 0.5187,
      "step": 1004
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.0026161312771507,
      "learning_rate": 9.95842829361755e-06,
      "loss": 0.5521,
      "step": 1005
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.1040310065455907,
      "learning_rate": 9.958283267345446e-06,
      "loss": 0.503,
      "step": 1006
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.6685442554503354,
      "learning_rate": 9.95813798960538e-06,
      "loss": 0.5236,
      "step": 1007
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.7952429909178904,
      "learning_rate": 9.957992460404721e-06,
      "loss": 0.5465,
      "step": 1008
    },
    {
      "epoch": 0.07,
      "grad_norm": 5.733671951212013,
      "learning_rate": 9.957846679750846e-06,
      "loss": 0.5614,
      "step": 1009
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.001965827492936,
      "learning_rate": 9.957700647651154e-06,
      "loss": 0.469,
      "step": 1010
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.9082417349723013,
      "learning_rate": 9.957554364113047e-06,
      "loss": 0.6157,
      "step": 1011
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.7511076495259372,
      "learning_rate": 9.957407829143943e-06,
      "loss": 0.5673,
      "step": 1012
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.0359653464692986,
      "learning_rate": 9.957261042751278e-06,
      "loss": 0.5716,
      "step": 1013
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.9662163409752047,
      "learning_rate": 9.957114004942495e-06,
      "loss": 0.5275,
      "step": 1014
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.707720386105823,
      "learning_rate": 9.95696671572505e-06,
      "loss": 0.5878,
      "step": 1015
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.8227219558190428,
      "learning_rate": 9.956819175106414e-06,
      "loss": 0.5283,
      "step": 1016
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.728584012584327,
      "learning_rate": 9.95667138309407e-06,
      "loss": 0.5674,
      "step": 1017
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.7011551339893063,
      "learning_rate": 9.956523339695513e-06,
      "loss": 0.5126,
      "step": 1018
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.2963640980957067,
      "learning_rate": 9.956375044918249e-06,
      "loss": 0.5531,
      "step": 1019
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.8147957375037103,
      "learning_rate": 9.956226498769805e-06,
      "loss": 0.5641,
      "step": 1020
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.7587551262654157,
      "learning_rate": 9.95607770125771e-06,
      "loss": 0.5503,
      "step": 1021
    },
    {
      "epoch": 0.07,
      "grad_norm": 6.043500156351057,
      "learning_rate": 9.95592865238951e-06,
      "loss": 0.5547,
      "step": 1022
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.110618927404032,
      "learning_rate": 9.955779352172767e-06,
      "loss": 0.5381,
      "step": 1023
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.1138363605941324,
      "learning_rate": 9.955629800615055e-06,
      "loss": 0.5093,
      "step": 1024
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.2041806566474538,
      "learning_rate": 9.955479997723951e-06,
      "loss": 0.5505,
      "step": 1025
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.062695198700824,
      "learning_rate": 9.955329943507061e-06,
      "loss": 0.5058,
      "step": 1026
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.4091650061800554,
      "learning_rate": 9.95517963797199e-06,
      "loss": 0.5293,
      "step": 1027
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.6452322577117153,
      "learning_rate": 9.955029081126362e-06,
      "loss": 0.5495,
      "step": 1028
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.8575665979554035,
      "learning_rate": 9.954878272977814e-06,
      "loss": 0.5646,
      "step": 1029
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.0963949909431814,
      "learning_rate": 9.954727213533994e-06,
      "loss": 0.5718,
      "step": 1030
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.945516239280703,
      "learning_rate": 9.954575902802563e-06,
      "loss": 0.5557,
      "step": 1031
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.7980329542758076,
      "learning_rate": 9.954424340791195e-06,
      "loss": 0.5531,
      "step": 1032
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.8522879323525396,
      "learning_rate": 9.954272527507577e-06,
      "loss": 0.5216,
      "step": 1033
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.9355203438092399,
      "learning_rate": 9.954120462959408e-06,
      "loss": 0.558,
      "step": 1034
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.042727816800905,
      "learning_rate": 9.953968147154401e-06,
      "loss": 0.5433,
      "step": 1035
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.4655873554684486,
      "learning_rate": 9.953815580100279e-06,
      "loss": 0.5541,
      "step": 1036
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.127653979237436,
      "learning_rate": 9.953662761804784e-06,
      "loss": 0.5758,
      "step": 1037
    },
    {
      "epoch": 0.07,
      "grad_norm": 3.059591071285774,
      "learning_rate": 9.95350969227566e-06,
      "loss": 0.5523,
      "step": 1038
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.7329608683342606,
      "learning_rate": 9.953356371520675e-06,
      "loss": 0.5968,
      "step": 1039
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.7875754366083583,
      "learning_rate": 9.953202799547606e-06,
      "loss": 0.5289,
      "step": 1040
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.68473466489213,
      "learning_rate": 9.953048976364237e-06,
      "loss": 0.5093,
      "step": 1041
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.4060615948824307,
      "learning_rate": 9.952894901978371e-06,
      "loss": 0.5489,
      "step": 1042
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.8352365783106523,
      "learning_rate": 9.952740576397826e-06,
      "loss": 0.5463,
      "step": 1043
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.7977291860525502,
      "learning_rate": 9.952585999630423e-06,
      "loss": 0.5655,
      "step": 1044
    },
    {
      "epoch": 0.07,
      "grad_norm": 7.692845847139826,
      "learning_rate": 9.952431171684005e-06,
      "loss": 0.5893,
      "step": 1045
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.1291017497192044,
      "learning_rate": 9.952276092566426e-06,
      "loss": 0.5737,
      "step": 1046
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.8222801837864515,
      "learning_rate": 9.952120762285546e-06,
      "loss": 0.557,
      "step": 1047
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.214358090492579,
      "learning_rate": 9.951965180849247e-06,
      "loss": 0.5416,
      "step": 1048
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.776408794159012,
      "learning_rate": 9.95180934826542e-06,
      "loss": 0.5045,
      "step": 1049
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.635861558495286,
      "learning_rate": 9.951653264541964e-06,
      "loss": 0.5507,
      "step": 1050
    },
    {
      "epoch": 0.07,
      "grad_norm": 3.364658381003825,
      "learning_rate": 9.951496929686799e-06,
      "loss": 0.5344,
      "step": 1051
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.9062806820027745,
      "learning_rate": 9.951340343707852e-06,
      "loss": 0.5794,
      "step": 1052
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.4097274502910953,
      "learning_rate": 9.951183506613066e-06,
      "loss": 0.5661,
      "step": 1053
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.2250195503707313,
      "learning_rate": 9.951026418410394e-06,
      "loss": 0.5478,
      "step": 1054
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.7669373515217546,
      "learning_rate": 9.950869079107804e-06,
      "loss": 0.6007,
      "step": 1055
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.8708977123886252,
      "learning_rate": 9.950711488713273e-06,
      "loss": 0.5821,
      "step": 1056
    },
    {
      "epoch": 0.07,
      "grad_norm": 4.004388357629249,
      "learning_rate": 9.950553647234798e-06,
      "loss": 0.5948,
      "step": 1057
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.0538363373460748,
      "learning_rate": 9.95039555468038e-06,
      "loss": 0.4978,
      "step": 1058
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.982849406688906,
      "learning_rate": 9.950237211058038e-06,
      "loss": 0.4758,
      "step": 1059
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.0261993028493275,
      "learning_rate": 9.950078616375804e-06,
      "loss": 0.5697,
      "step": 1060
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.8429732616258117,
      "learning_rate": 9.949919770641722e-06,
      "loss": 0.5839,
      "step": 1061
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.6731892182688792,
      "learning_rate": 9.949760673863846e-06,
      "loss": 0.5569,
      "step": 1062
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.182475144101246,
      "learning_rate": 9.949601326050247e-06,
      "loss": 0.4867,
      "step": 1063
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.03289171115417,
      "learning_rate": 9.949441727209004e-06,
      "loss": 0.6051,
      "step": 1064
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.215239471935801,
      "learning_rate": 9.949281877348214e-06,
      "loss": 0.5516,
      "step": 1065
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.7270357881165284,
      "learning_rate": 9.94912177647598e-06,
      "loss": 0.5239,
      "step": 1066
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.8749130465310433,
      "learning_rate": 9.948961424600428e-06,
      "loss": 0.5316,
      "step": 1067
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.3589346994950944,
      "learning_rate": 9.948800821729685e-06,
      "loss": 0.5605,
      "step": 1068
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.849415189911575,
      "learning_rate": 9.948639967871897e-06,
      "loss": 0.4875,
      "step": 1069
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.1031496662763014,
      "learning_rate": 9.948478863035227e-06,
      "loss": 0.6085,
      "step": 1070
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.008972567969868,
      "learning_rate": 9.948317507227841e-06,
      "loss": 0.5878,
      "step": 1071
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.5628642911447166,
      "learning_rate": 9.948155900457922e-06,
      "loss": 0.5305,
      "step": 1072
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.6833962528079085,
      "learning_rate": 9.947994042733668e-06,
      "loss": 0.5865,
      "step": 1073
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.6485234245715048,
      "learning_rate": 9.947831934063288e-06,
      "loss": 0.5507,
      "step": 1074
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.2227102244329004,
      "learning_rate": 9.947669574455002e-06,
      "loss": 0.5441,
      "step": 1075
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.0069710194929842,
      "learning_rate": 9.947506963917047e-06,
      "loss": 0.4685,
      "step": 1076
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.6790032470343594,
      "learning_rate": 9.947344102457669e-06,
      "loss": 0.5727,
      "step": 1077
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.2359055573326296,
      "learning_rate": 9.947180990085125e-06,
      "loss": 0.6147,
      "step": 1078
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.09719396072299,
      "learning_rate": 9.94701762680769e-06,
      "loss": 0.5422,
      "step": 1079
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.2556094679295935,
      "learning_rate": 9.946854012633653e-06,
      "loss": 0.5613,
      "step": 1080
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.2240871552781574,
      "learning_rate": 9.946690147571305e-06,
      "loss": 0.5357,
      "step": 1081
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.8477217564368744,
      "learning_rate": 9.94652603162896e-06,
      "loss": 0.5476,
      "step": 1082
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.9943692606736156,
      "learning_rate": 9.946361664814942e-06,
      "loss": 0.5758,
      "step": 1083
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.547505010805301,
      "learning_rate": 9.946197047137587e-06,
      "loss": 0.5597,
      "step": 1084
    },
    {
      "epoch": 0.08,
      "grad_norm": 4.231318039634672,
      "learning_rate": 9.946032178605242e-06,
      "loss": 0.5513,
      "step": 1085
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.9290423467745295,
      "learning_rate": 9.94586705922627e-06,
      "loss": 0.5513,
      "step": 1086
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.835775144145683,
      "learning_rate": 9.945701689009045e-06,
      "loss": 0.5948,
      "step": 1087
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.560004961177216,
      "learning_rate": 9.945536067961956e-06,
      "loss": 0.5547,
      "step": 1088
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.9568560695871118,
      "learning_rate": 9.9453701960934e-06,
      "loss": 0.5824,
      "step": 1089
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.803113696958238,
      "learning_rate": 9.94520407341179e-06,
      "loss": 0.5424,
      "step": 1090
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.242264280349056,
      "learning_rate": 9.945037699925552e-06,
      "loss": 0.5799,
      "step": 1091
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.8459960292954434,
      "learning_rate": 9.944871075643125e-06,
      "loss": 0.5778,
      "step": 1092
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.9739120301737494,
      "learning_rate": 9.944704200572956e-06,
      "loss": 0.5781,
      "step": 1093
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.8662736339106145,
      "learning_rate": 9.944537074723513e-06,
      "loss": 0.5507,
      "step": 1094
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.6697821294726547,
      "learning_rate": 9.944369698103267e-06,
      "loss": 0.515,
      "step": 1095
    },
    {
      "epoch": 0.08,
      "grad_norm": 3.0023158963620875,
      "learning_rate": 9.944202070720711e-06,
      "loss": 0.5378,
      "step": 1096
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.3228338729759264,
      "learning_rate": 9.944034192584345e-06,
      "loss": 0.5396,
      "step": 1097
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.8351768471552314,
      "learning_rate": 9.943866063702683e-06,
      "loss": 0.5903,
      "step": 1098
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.7155360787712222,
      "learning_rate": 9.943697684084253e-06,
      "loss": 0.5181,
      "step": 1099
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.2262439086846486,
      "learning_rate": 9.943529053737593e-06,
      "loss": 0.5669,
      "step": 1100
    },
    {
      "epoch": 0.08,
      "grad_norm": 3.117540749199397,
      "learning_rate": 9.943360172671255e-06,
      "loss": 0.5516,
      "step": 1101
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.7918033844564205,
      "learning_rate": 9.943191040893807e-06,
      "loss": 0.6125,
      "step": 1102
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.3939420699046012,
      "learning_rate": 9.943021658413825e-06,
      "loss": 0.5295,
      "step": 1103
    },
    {
      "epoch": 0.08,
      "grad_norm": 5.594047382734013,
      "learning_rate": 9.9428520252399e-06,
      "loss": 0.5301,
      "step": 1104
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.0513416051605424,
      "learning_rate": 9.942682141380634e-06,
      "loss": 0.4694,
      "step": 1105
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.5545380664230908,
      "learning_rate": 9.942512006844644e-06,
      "loss": 0.5549,
      "step": 1106
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.0161170795000323,
      "learning_rate": 9.942341621640558e-06,
      "loss": 0.5333,
      "step": 1107
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.777191461449979,
      "learning_rate": 9.942170985777018e-06,
      "loss": 0.5628,
      "step": 1108
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.6010506667756768,
      "learning_rate": 9.942000099262679e-06,
      "loss": 0.5282,
      "step": 1109
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.855305451163327,
      "learning_rate": 9.941828962106205e-06,
      "loss": 0.5523,
      "step": 1110
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.1233664392816185,
      "learning_rate": 9.941657574316281e-06,
      "loss": 0.5735,
      "step": 1111
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.6833084708303336,
      "learning_rate": 9.941485935901593e-06,
      "loss": 0.529,
      "step": 1112
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.9219215556607396,
      "learning_rate": 9.941314046870848e-06,
      "loss": 0.5719,
      "step": 1113
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.242534275504336,
      "learning_rate": 9.941141907232766e-06,
      "loss": 0.5606,
      "step": 1114
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.634027787251593,
      "learning_rate": 9.940969516996074e-06,
      "loss": 0.5445,
      "step": 1115
    },
    {
      "epoch": 0.08,
      "grad_norm": 4.196555250010001,
      "learning_rate": 9.940796876169516e-06,
      "loss": 0.5992,
      "step": 1116
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.9786765643417579,
      "learning_rate": 9.94062398476185e-06,
      "loss": 0.56,
      "step": 1117
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.8351760497239602,
      "learning_rate": 9.940450842781842e-06,
      "loss": 0.5176,
      "step": 1118
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.972317093412393,
      "learning_rate": 9.940277450238273e-06,
      "loss": 0.4537,
      "step": 1119
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.9144045462947339,
      "learning_rate": 9.94010380713994e-06,
      "loss": 0.5343,
      "step": 1120
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.611805350754705,
      "learning_rate": 9.939929913495647e-06,
      "loss": 0.5629,
      "step": 1121
    },
    {
      "epoch": 0.08,
      "grad_norm": 3.9378261579916343,
      "learning_rate": 9.939755769314215e-06,
      "loss": 0.5778,
      "step": 1122
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.944885677607741,
      "learning_rate": 9.939581374604472e-06,
      "loss": 0.5369,
      "step": 1123
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.584534927122244,
      "learning_rate": 9.939406729375268e-06,
      "loss": 0.5162,
      "step": 1124
    },
    {
      "epoch": 0.08,
      "grad_norm": 4.322098829068105,
      "learning_rate": 9.939231833635457e-06,
      "loss": 0.5158,
      "step": 1125
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.7694300091046509,
      "learning_rate": 9.93905668739391e-06,
      "loss": 0.5537,
      "step": 1126
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.807221676039088,
      "learning_rate": 9.93888129065951e-06,
      "loss": 0.5559,
      "step": 1127
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.0673944364561865,
      "learning_rate": 9.938705643441154e-06,
      "loss": 0.5558,
      "step": 1128
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.4932127402008635,
      "learning_rate": 9.938529745747748e-06,
      "loss": 0.5354,
      "step": 1129
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.76743111883289,
      "learning_rate": 9.938353597588215e-06,
      "loss": 0.4511,
      "step": 1130
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9661896991371143,
      "learning_rate": 9.938177198971486e-06,
      "loss": 0.4697,
      "step": 1131
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.5296065244747017,
      "learning_rate": 9.938000549906509e-06,
      "loss": 0.5527,
      "step": 1132
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.5861507861337913,
      "learning_rate": 9.937823650402242e-06,
      "loss": 0.5888,
      "step": 1133
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.1917028471384694,
      "learning_rate": 9.93764650046766e-06,
      "loss": 0.5663,
      "step": 1134
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.2162868747232167,
      "learning_rate": 9.937469100111743e-06,
      "loss": 0.5757,
      "step": 1135
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.220189793468373,
      "learning_rate": 9.937291449343492e-06,
      "loss": 0.5873,
      "step": 1136
    },
    {
      "epoch": 0.08,
      "grad_norm": 6.583345469340574,
      "learning_rate": 9.937113548171914e-06,
      "loss": 0.5895,
      "step": 1137
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.7849531182484557,
      "learning_rate": 9.936935396606034e-06,
      "loss": 0.5464,
      "step": 1138
    },
    {
      "epoch": 0.08,
      "grad_norm": 3.2939597716200817,
      "learning_rate": 9.936756994654885e-06,
      "loss": 0.5698,
      "step": 1139
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.2673094213842444,
      "learning_rate": 9.936578342327516e-06,
      "loss": 0.5475,
      "step": 1140
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.9946272715688245,
      "learning_rate": 9.936399439632989e-06,
      "loss": 0.5756,
      "step": 1141
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.5575874277849715,
      "learning_rate": 9.936220286580375e-06,
      "loss": 0.5447,
      "step": 1142
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.2006046352784305,
      "learning_rate": 9.93604088317876e-06,
      "loss": 0.5599,
      "step": 1143
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.7669523953039425,
      "learning_rate": 9.935861229437245e-06,
      "loss": 0.4966,
      "step": 1144
    },
    {
      "epoch": 0.08,
      "grad_norm": 17.169430833858147,
      "learning_rate": 9.93568132536494e-06,
      "loss": 0.5695,
      "step": 1145
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.8474162496925397,
      "learning_rate": 9.935501170970969e-06,
      "loss": 0.5742,
      "step": 1146
    },
    {
      "epoch": 0.08,
      "grad_norm": 3.8007350502458817,
      "learning_rate": 9.93532076626447e-06,
      "loss": 0.538,
      "step": 1147
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.468810842373653,
      "learning_rate": 9.935140111254593e-06,
      "loss": 0.5594,
      "step": 1148
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.4433135539014703,
      "learning_rate": 9.934959205950496e-06,
      "loss": 0.5591,
      "step": 1149
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.2196463670603883,
      "learning_rate": 9.93477805036136e-06,
      "loss": 0.6085,
      "step": 1150
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.48594266480625,
      "learning_rate": 9.934596644496369e-06,
      "loss": 0.6196,
      "step": 1151
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.116392528616146,
      "learning_rate": 9.934414988364722e-06,
      "loss": 0.4681,
      "step": 1152
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.8851497129383497,
      "learning_rate": 9.934233081975634e-06,
      "loss": 0.5447,
      "step": 1153
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.7811336119505854,
      "learning_rate": 9.934050925338333e-06,
      "loss": 0.5838,
      "step": 1154
    },
    {
      "epoch": 0.08,
      "grad_norm": 6.371593474484583,
      "learning_rate": 9.933868518462052e-06,
      "loss": 0.5561,
      "step": 1155
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.2962420979038214,
      "learning_rate": 9.933685861356047e-06,
      "loss": 0.5664,
      "step": 1156
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.9333481626528637,
      "learning_rate": 9.93350295402958e-06,
      "loss": 0.5476,
      "step": 1157
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.8619244040476628,
      "learning_rate": 9.933319796491927e-06,
      "loss": 0.5832,
      "step": 1158
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.027583054449304,
      "learning_rate": 9.933136388752378e-06,
      "loss": 0.5542,
      "step": 1159
    },
    {
      "epoch": 0.08,
      "grad_norm": 21.964705307970842,
      "learning_rate": 9.932952730820234e-06,
      "loss": 0.5744,
      "step": 1160
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.739596017405238,
      "learning_rate": 9.932768822704807e-06,
      "loss": 0.5056,
      "step": 1161
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.79737814770306,
      "learning_rate": 9.93258466441543e-06,
      "loss": 0.5425,
      "step": 1162
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.0708907050534897,
      "learning_rate": 9.93240025596144e-06,
      "loss": 0.5403,
      "step": 1163
    },
    {
      "epoch": 0.08,
      "grad_norm": 5.573027857594619,
      "learning_rate": 9.932215597352189e-06,
      "loss": 0.5364,
      "step": 1164
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.7787330440344016,
      "learning_rate": 9.932030688597043e-06,
      "loss": 0.5211,
      "step": 1165
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.984135028680526,
      "learning_rate": 9.93184552970538e-06,
      "loss": 0.5377,
      "step": 1166
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.8556591173492716,
      "learning_rate": 9.93166012068659e-06,
      "loss": 0.5696,
      "step": 1167
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.518624789622152,
      "learning_rate": 9.931474461550078e-06,
      "loss": 0.5719,
      "step": 1168
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.652443027035311,
      "learning_rate": 9.931288552305256e-06,
      "loss": 0.5132,
      "step": 1169
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.210923787182016,
      "learning_rate": 9.931102392961558e-06,
      "loss": 0.5025,
      "step": 1170
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.049740925597625,
      "learning_rate": 9.930915983528423e-06,
      "loss": 0.5981,
      "step": 1171
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.8567353711148895,
      "learning_rate": 9.930729324015304e-06,
      "loss": 0.5628,
      "step": 1172
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.9910789599617178,
      "learning_rate": 9.93054241443167e-06,
      "loss": 0.515,
      "step": 1173
    },
    {
      "epoch": 0.08,
      "grad_norm": 3.532894599642125,
      "learning_rate": 9.930355254786998e-06,
      "loss": 0.5819,
      "step": 1174
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.7344123012425952,
      "learning_rate": 9.930167845090782e-06,
      "loss": 0.5636,
      "step": 1175
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.075003560339632,
      "learning_rate": 9.929980185352525e-06,
      "loss": 0.5712,
      "step": 1176
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.730965721906093,
      "learning_rate": 9.929792275581747e-06,
      "loss": 0.5385,
      "step": 1177
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.122395046574636,
      "learning_rate": 9.929604115787976e-06,
      "loss": 0.5824,
      "step": 1178
    },
    {
      "epoch": 0.08,
      "grad_norm": 4.45690568072356,
      "learning_rate": 9.929415705980756e-06,
      "loss": 0.5554,
      "step": 1179
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.116559243296377,
      "learning_rate": 9.929227046169644e-06,
      "loss": 0.4824,
      "step": 1180
    },
    {
      "epoch": 0.08,
      "grad_norm": 4.993356806852561,
      "learning_rate": 9.929038136364203e-06,
      "loss": 0.55,
      "step": 1181
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.2345097351185217,
      "learning_rate": 9.92884897657402e-06,
      "loss": 0.5602,
      "step": 1182
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.3211241221738277,
      "learning_rate": 9.928659566808685e-06,
      "loss": 0.541,
      "step": 1183
    },
    {
      "epoch": 0.08,
      "grad_norm": 6.342382750436999,
      "learning_rate": 9.928469907077805e-06,
      "loss": 0.5769,
      "step": 1184
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.7994231170241881,
      "learning_rate": 9.928279997391e-06,
      "loss": 0.5753,
      "step": 1185
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.48829748219242,
      "learning_rate": 9.928089837757898e-06,
      "loss": 0.6143,
      "step": 1186
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.7053181577035645,
      "learning_rate": 9.927899428188148e-06,
      "loss": 0.5599,
      "step": 1187
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.304165382350341,
      "learning_rate": 9.927708768691404e-06,
      "loss": 0.544,
      "step": 1188
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.145411915689672,
      "learning_rate": 9.927517859277338e-06,
      "loss": 0.578,
      "step": 1189
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.1434333587862793,
      "learning_rate": 9.927326699955629e-06,
      "loss": 0.5277,
      "step": 1190
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.902956083185457,
      "learning_rate": 9.927135290735976e-06,
      "loss": 0.5097,
      "step": 1191
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.765177232740717,
      "learning_rate": 9.926943631628084e-06,
      "loss": 0.535,
      "step": 1192
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.9199760672280406,
      "learning_rate": 9.92675172264167e-06,
      "loss": 0.4941,
      "step": 1193
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.713459042041907,
      "learning_rate": 9.926559563786475e-06,
      "loss": 0.5727,
      "step": 1194
    },
    {
      "epoch": 0.08,
      "grad_norm": 5.0483565702232305,
      "learning_rate": 9.926367155072239e-06,
      "loss": 0.5416,
      "step": 1195
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.8442954365131976,
      "learning_rate": 9.926174496508722e-06,
      "loss": 0.5717,
      "step": 1196
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.0089656023703837,
      "learning_rate": 9.925981588105695e-06,
      "loss": 0.5701,
      "step": 1197
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.853967749400768,
      "learning_rate": 9.92578842987294e-06,
      "loss": 0.5656,
      "step": 1198
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.715920487916183,
      "learning_rate": 9.925595021820256e-06,
      "loss": 0.5197,
      "step": 1199
    },
    {
      "epoch": 0.08,
      "grad_norm": 3.5496216399803115,
      "learning_rate": 9.925401363957451e-06,
      "loss": 0.4945,
      "step": 1200
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.8149646356765947,
      "learning_rate": 9.925207456294345e-06,
      "loss": 0.5512,
      "step": 1201
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.686910816733719,
      "learning_rate": 9.925013298840777e-06,
      "loss": 0.5216,
      "step": 1202
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.2109854705109973,
      "learning_rate": 9.924818891606589e-06,
      "loss": 0.5408,
      "step": 1203
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.1812370041787874,
      "learning_rate": 9.924624234601644e-06,
      "loss": 0.6016,
      "step": 1204
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.9007416136660262,
      "learning_rate": 9.92442932783581e-06,
      "loss": 0.5891,
      "step": 1205
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.6224914444809315,
      "learning_rate": 9.924234171318978e-06,
      "loss": 0.5425,
      "step": 1206
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.1812182338430173,
      "learning_rate": 9.924038765061042e-06,
      "loss": 0.5178,
      "step": 1207
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.8524191684982356,
      "learning_rate": 9.923843109071912e-06,
      "loss": 0.5601,
      "step": 1208
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.071648631969781,
      "learning_rate": 9.923647203361512e-06,
      "loss": 0.6458,
      "step": 1209
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.0343741164594493,
      "learning_rate": 9.92345104793978e-06,
      "loss": 0.4754,
      "step": 1210
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.984860128424398,
      "learning_rate": 9.92325464281666e-06,
      "loss": 0.5981,
      "step": 1211
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.2834357658307063,
      "learning_rate": 9.923057988002117e-06,
      "loss": 0.5795,
      "step": 1212
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.7877823621022677,
      "learning_rate": 9.922861083506122e-06,
      "loss": 0.556,
      "step": 1213
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7696141991389177,
      "learning_rate": 9.922663929338662e-06,
      "loss": 0.4909,
      "step": 1214
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.9305488795076,
      "learning_rate": 9.922466525509738e-06,
      "loss": 0.5779,
      "step": 1215
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.5925206791539797,
      "learning_rate": 9.92226887202936e-06,
      "loss": 0.5891,
      "step": 1216
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.7203421926725895,
      "learning_rate": 9.922070968907548e-06,
      "loss": 0.5677,
      "step": 1217
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.613371809143998,
      "learning_rate": 9.921872816154348e-06,
      "loss": 0.5791,
      "step": 1218
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.8671393149842166,
      "learning_rate": 9.921674413779804e-06,
      "loss": 0.5709,
      "step": 1219
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.669766159562155,
      "learning_rate": 9.921475761793978e-06,
      "loss": 0.5485,
      "step": 1220
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.272672342650787,
      "learning_rate": 9.921276860206948e-06,
      "loss": 0.5578,
      "step": 1221
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.973084688333312,
      "learning_rate": 9.9210777090288e-06,
      "loss": 0.5702,
      "step": 1222
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9327660844936388,
      "learning_rate": 9.920878308269632e-06,
      "loss": 0.4745,
      "step": 1223
    },
    {
      "epoch": 0.09,
      "grad_norm": 4.8240761446981955,
      "learning_rate": 9.92067865793956e-06,
      "loss": 0.5339,
      "step": 1224
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.7324925272425409,
      "learning_rate": 9.92047875804871e-06,
      "loss": 0.5128,
      "step": 1225
    },
    {
      "epoch": 0.09,
      "grad_norm": 3.9376889975761338,
      "learning_rate": 9.920278608607218e-06,
      "loss": 0.5155,
      "step": 1226
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.7286689480406736,
      "learning_rate": 9.920078209625235e-06,
      "loss": 0.5965,
      "step": 1227
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.055072944371773,
      "learning_rate": 9.919877561112927e-06,
      "loss": 0.5592,
      "step": 1228
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.016194319530099,
      "learning_rate": 9.91967666308047e-06,
      "loss": 0.5762,
      "step": 1229
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.1486267723657493,
      "learning_rate": 9.91947551553805e-06,
      "loss": 0.5526,
      "step": 1230
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.6722050415323237,
      "learning_rate": 9.919274118495871e-06,
      "loss": 0.5579,
      "step": 1231
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.317392967320329,
      "learning_rate": 9.919072471964146e-06,
      "loss": 0.5397,
      "step": 1232
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.907224825489897,
      "learning_rate": 9.918870575953102e-06,
      "loss": 0.5585,
      "step": 1233
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.7438520711513017,
      "learning_rate": 9.91866843047298e-06,
      "loss": 0.5806,
      "step": 1234
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.7757897121632387,
      "learning_rate": 9.91846603553403e-06,
      "loss": 0.5374,
      "step": 1235
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.8694587608314195,
      "learning_rate": 9.918263391146518e-06,
      "loss": 0.6527,
      "step": 1236
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.2627419067186314,
      "learning_rate": 9.918060497320722e-06,
      "loss": 0.5666,
      "step": 1237
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.7335026845411172,
      "learning_rate": 9.91785735406693e-06,
      "loss": 0.551,
      "step": 1238
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.5321123795955733,
      "learning_rate": 9.917653961395448e-06,
      "loss": 0.5781,
      "step": 1239
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.8033034906093512,
      "learning_rate": 9.917450319316589e-06,
      "loss": 0.5683,
      "step": 1240
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.5945421566160307,
      "learning_rate": 9.91724642784068e-06,
      "loss": 0.5439,
      "step": 1241
    },
    {
      "epoch": 0.09,
      "grad_norm": 4.42180039111654,
      "learning_rate": 9.917042286978064e-06,
      "loss": 0.5879,
      "step": 1242
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.0545268988781453,
      "learning_rate": 9.916837896739095e-06,
      "loss": 0.5859,
      "step": 1243
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.817646163070644,
      "learning_rate": 9.916633257134137e-06,
      "loss": 0.5209,
      "step": 1244
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.493279759030457,
      "learning_rate": 9.916428368173567e-06,
      "loss": 0.5582,
      "step": 1245
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.862946963134797,
      "learning_rate": 9.916223229867782e-06,
      "loss": 0.5912,
      "step": 1246
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8407290671791923,
      "learning_rate": 9.916017842227182e-06,
      "loss": 0.4591,
      "step": 1247
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.835607863638434,
      "learning_rate": 9.915812205262182e-06,
      "loss": 0.5574,
      "step": 1248
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.8689492334613724,
      "learning_rate": 9.915606318983214e-06,
      "loss": 0.5562,
      "step": 1249
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.7112804183842552,
      "learning_rate": 9.915400183400722e-06,
      "loss": 0.5225,
      "step": 1250
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.0131277740160627,
      "learning_rate": 9.915193798525156e-06,
      "loss": 0.5603,
      "step": 1251
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.338614210049428,
      "learning_rate": 9.914987164366984e-06,
      "loss": 0.5628,
      "step": 1252
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.9292500850962013,
      "learning_rate": 9.914780280936689e-06,
      "loss": 0.5505,
      "step": 1253
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.2433111583833347,
      "learning_rate": 9.91457314824476e-06,
      "loss": 0.5492,
      "step": 1254
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7712936001053162,
      "learning_rate": 9.914365766301704e-06,
      "loss": 0.4673,
      "step": 1255
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.015996867165196,
      "learning_rate": 9.914158135118038e-06,
      "loss": 0.5566,
      "step": 1256
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.565168459431114,
      "learning_rate": 9.913950254704291e-06,
      "loss": 0.5627,
      "step": 1257
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.7778764823748325,
      "learning_rate": 9.91374212507101e-06,
      "loss": 0.5269,
      "step": 1258
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7546768430730132,
      "learning_rate": 9.913533746228745e-06,
      "loss": 0.4752,
      "step": 1259
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.719698124896239,
      "learning_rate": 9.913325118188068e-06,
      "loss": 0.5659,
      "step": 1260
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.55576667455733,
      "learning_rate": 9.913116240959561e-06,
      "loss": 0.5113,
      "step": 1261
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.8578330301708932,
      "learning_rate": 9.912907114553815e-06,
      "loss": 0.5702,
      "step": 1262
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6802015149037304,
      "learning_rate": 9.912697738981438e-06,
      "loss": 0.4657,
      "step": 1263
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.039083070496377,
      "learning_rate": 9.912488114253048e-06,
      "loss": 0.6005,
      "step": 1264
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.5273453022032784,
      "learning_rate": 9.912278240379277e-06,
      "loss": 0.5134,
      "step": 1265
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.324573049813836,
      "learning_rate": 9.912068117370766e-06,
      "loss": 0.5566,
      "step": 1266
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.9980188154067444,
      "learning_rate": 9.911857745238176e-06,
      "loss": 0.5303,
      "step": 1267
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.6672451991299133,
      "learning_rate": 9.911647123992175e-06,
      "loss": 0.5377,
      "step": 1268
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.7147056682673836,
      "learning_rate": 9.911436253643445e-06,
      "loss": 0.5128,
      "step": 1269
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.8097736415921584,
      "learning_rate": 9.911225134202678e-06,
      "loss": 0.5327,
      "step": 1270
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.0971996272627145,
      "learning_rate": 9.911013765680585e-06,
      "loss": 0.5499,
      "step": 1271
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.618598086373748,
      "learning_rate": 9.910802148087887e-06,
      "loss": 0.549,
      "step": 1272
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.9070874203401247,
      "learning_rate": 9.910590281435313e-06,
      "loss": 0.5237,
      "step": 1273
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7424062106715805,
      "learning_rate": 9.910378165733608e-06,
      "loss": 0.4655,
      "step": 1274
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.9433392582129967,
      "learning_rate": 9.910165800993532e-06,
      "loss": 0.5438,
      "step": 1275
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.1692267769238662,
      "learning_rate": 9.909953187225853e-06,
      "loss": 0.563,
      "step": 1276
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.5704086027593926,
      "learning_rate": 9.90974032444136e-06,
      "loss": 0.5368,
      "step": 1277
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.2171990902190815,
      "learning_rate": 9.90952721265084e-06,
      "loss": 0.5638,
      "step": 1278
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.3357845436425086,
      "learning_rate": 9.909313851865108e-06,
      "loss": 0.6322,
      "step": 1279
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.7774250329544141,
      "learning_rate": 9.909100242094982e-06,
      "loss": 0.5346,
      "step": 1280
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.7772477474920123,
      "learning_rate": 9.908886383351297e-06,
      "loss": 0.5003,
      "step": 1281
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.2478482983054424,
      "learning_rate": 9.908672275644898e-06,
      "loss": 0.5357,
      "step": 1282
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.6739900194529314,
      "learning_rate": 9.908457918986644e-06,
      "loss": 0.5048,
      "step": 1283
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.6717478610760543,
      "learning_rate": 9.908243313387407e-06,
      "loss": 0.5347,
      "step": 1284
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.8395764486999813,
      "learning_rate": 9.908028458858072e-06,
      "loss": 0.5157,
      "step": 1285
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.112344249428402,
      "learning_rate": 9.907813355409532e-06,
      "loss": 0.5165,
      "step": 1286
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.7276437571014167,
      "learning_rate": 9.907598003052701e-06,
      "loss": 0.5338,
      "step": 1287
    },
    {
      "epoch": 0.09,
      "grad_norm": 3.579208011630157,
      "learning_rate": 9.9073824017985e-06,
      "loss": 0.5683,
      "step": 1288
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.0647172107541847,
      "learning_rate": 9.90716655165786e-06,
      "loss": 0.537,
      "step": 1289
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.7338277483546065,
      "learning_rate": 9.906950452641732e-06,
      "loss": 0.5881,
      "step": 1290
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.2196431461592563,
      "learning_rate": 9.906734104761075e-06,
      "loss": 0.5391,
      "step": 1291
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.2846134932927558,
      "learning_rate": 9.906517508026862e-06,
      "loss": 0.5685,
      "step": 1292
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7795619539211135,
      "learning_rate": 9.906300662450074e-06,
      "loss": 0.4496,
      "step": 1293
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.1887134440227136,
      "learning_rate": 9.906083568041716e-06,
      "loss": 0.5339,
      "step": 1294
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.8148322419096357,
      "learning_rate": 9.905866224812791e-06,
      "loss": 0.5683,
      "step": 1295
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.721432926993276,
      "learning_rate": 9.905648632774327e-06,
      "loss": 0.4739,
      "step": 1296
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.789778959946504,
      "learning_rate": 9.905430791937356e-06,
      "loss": 0.4758,
      "step": 1297
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.873044679380207,
      "learning_rate": 9.905212702312929e-06,
      "loss": 0.5747,
      "step": 1298
    },
    {
      "epoch": 0.09,
      "grad_norm": 3.226653212441916,
      "learning_rate": 9.904994363912106e-06,
      "loss": 0.5451,
      "step": 1299
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.9651307607545903,
      "learning_rate": 9.904775776745959e-06,
      "loss": 0.5697,
      "step": 1300
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.026269702823598,
      "learning_rate": 9.904556940825576e-06,
      "loss": 0.5639,
      "step": 1301
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.2398844385397503,
      "learning_rate": 9.904337856162054e-06,
      "loss": 0.5489,
      "step": 1302
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.8364224657991728,
      "learning_rate": 9.904118522766505e-06,
      "loss": 0.6019,
      "step": 1303
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.5136119163023953,
      "learning_rate": 9.903898940650052e-06,
      "loss": 0.5359,
      "step": 1304
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.6524136377200087,
      "learning_rate": 9.903679109823834e-06,
      "loss": 0.5408,
      "step": 1305
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.8776369024890829,
      "learning_rate": 9.903459030299e-06,
      "loss": 0.5755,
      "step": 1306
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.9043984368862112,
      "learning_rate": 9.903238702086707e-06,
      "loss": 0.5282,
      "step": 1307
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.9452268198857006,
      "learning_rate": 9.903018125198133e-06,
      "loss": 0.566,
      "step": 1308
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.9628637655334304,
      "learning_rate": 9.902797299644464e-06,
      "loss": 0.525,
      "step": 1309
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.2261744811541293,
      "learning_rate": 9.902576225436902e-06,
      "loss": 0.5253,
      "step": 1310
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.713415951901249,
      "learning_rate": 9.902354902586656e-06,
      "loss": 0.5325,
      "step": 1311
    },
    {
      "epoch": 0.09,
      "grad_norm": 6.300704856098714,
      "learning_rate": 9.902133331104952e-06,
      "loss": 0.5265,
      "step": 1312
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.143800709763531,
      "learning_rate": 9.901911511003028e-06,
      "loss": 0.5264,
      "step": 1313
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.7809236783832436,
      "learning_rate": 9.901689442292133e-06,
      "loss": 0.5491,
      "step": 1314
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.822462779740018,
      "learning_rate": 9.90146712498353e-06,
      "loss": 0.5215,
      "step": 1315
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.108833252132229,
      "learning_rate": 9.901244559088493e-06,
      "loss": 0.575,
      "step": 1316
    },
    {
      "epoch": 0.09,
      "grad_norm": 3.7525250510172286,
      "learning_rate": 9.90102174461831e-06,
      "loss": 0.5405,
      "step": 1317
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.5760620352676198,
      "learning_rate": 9.900798681584287e-06,
      "loss": 0.595,
      "step": 1318
    },
    {
      "epoch": 0.09,
      "grad_norm": 3.063509058516689,
      "learning_rate": 9.90057536999773e-06,
      "loss": 0.6364,
      "step": 1319
    },
    {
      "epoch": 0.09,
      "grad_norm": 4.136257401484507,
      "learning_rate": 9.900351809869965e-06,
      "loss": 0.6009,
      "step": 1320
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.7711986783138651,
      "learning_rate": 9.900128001212333e-06,
      "loss": 0.5517,
      "step": 1321
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.1757048989725774,
      "learning_rate": 9.899903944036185e-06,
      "loss": 0.5722,
      "step": 1322
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.223051250594924,
      "learning_rate": 9.899679638352884e-06,
      "loss": 0.5339,
      "step": 1323
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.1517746249284824,
      "learning_rate": 9.899455084173805e-06,
      "loss": 0.5447,
      "step": 1324
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.9828596771281852,
      "learning_rate": 9.899230281510337e-06,
      "loss": 0.5414,
      "step": 1325
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.6436119248175087,
      "learning_rate": 9.899005230373883e-06,
      "loss": 0.5284,
      "step": 1326
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.879958430486084,
      "learning_rate": 9.898779930775854e-06,
      "loss": 0.5352,
      "step": 1327
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.3777763431682426,
      "learning_rate": 9.898554382727678e-06,
      "loss": 0.5531,
      "step": 1328
    },
    {
      "epoch": 0.09,
      "grad_norm": 5.096173141498676,
      "learning_rate": 9.898328586240794e-06,
      "loss": 0.5147,
      "step": 1329
    },
    {
      "epoch": 0.09,
      "grad_norm": 3.2913104574486187,
      "learning_rate": 9.898102541326652e-06,
      "loss": 0.5328,
      "step": 1330
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.6176952677369456,
      "learning_rate": 9.89787624799672e-06,
      "loss": 0.55,
      "step": 1331
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.305079657044032,
      "learning_rate": 9.897649706262474e-06,
      "loss": 0.6153,
      "step": 1332
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.5358488706083766,
      "learning_rate": 9.897422916135399e-06,
      "loss": 0.5906,
      "step": 1333
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.398925586449198,
      "learning_rate": 9.897195877627002e-06,
      "loss": 0.5217,
      "step": 1334
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.9296809987330108,
      "learning_rate": 9.896968590748795e-06,
      "loss": 0.5563,
      "step": 1335
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.7127901144217343,
      "learning_rate": 9.896741055512307e-06,
      "loss": 0.6147,
      "step": 1336
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.8530756960009551,
      "learning_rate": 9.896513271929075e-06,
      "loss": 0.5299,
      "step": 1337
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.220529791096527,
      "learning_rate": 9.896285240010658e-06,
      "loss": 0.5383,
      "step": 1338
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.3925913390834053,
      "learning_rate": 9.896056959768612e-06,
      "loss": 0.5711,
      "step": 1339
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.7239954725857491,
      "learning_rate": 9.89582843121452e-06,
      "loss": 0.4845,
      "step": 1340
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.3354538927598574,
      "learning_rate": 9.895599654359972e-06,
      "loss": 0.5224,
      "step": 1341
    },
    {
      "epoch": 0.09,
      "grad_norm": 8.08204242426632,
      "learning_rate": 9.89537062921657e-06,
      "loss": 0.5645,
      "step": 1342
    },
    {
      "epoch": 0.09,
      "grad_norm": 3.7072361250806978,
      "learning_rate": 9.895141355795929e-06,
      "loss": 0.5488,
      "step": 1343
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.1163495075699537,
      "learning_rate": 9.894911834109677e-06,
      "loss": 0.5805,
      "step": 1344
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9410850916815949,
      "learning_rate": 9.894682064169457e-06,
      "loss": 0.4519,
      "step": 1345
    },
    {
      "epoch": 0.09,
      "grad_norm": 7.474942124655023,
      "learning_rate": 9.894452045986918e-06,
      "loss": 0.5761,
      "step": 1346
    },
    {
      "epoch": 0.09,
      "grad_norm": 4.210650521933725,
      "learning_rate": 9.894221779573729e-06,
      "loss": 0.5173,
      "step": 1347
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.0390394145082813,
      "learning_rate": 9.893991264941568e-06,
      "loss": 0.571,
      "step": 1348
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.2668491981352688,
      "learning_rate": 9.893760502102126e-06,
      "loss": 0.5504,
      "step": 1349
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.267655942317039,
      "learning_rate": 9.893529491067104e-06,
      "loss": 0.5339,
      "step": 1350
    },
    {
      "epoch": 0.09,
      "grad_norm": 4.596585187964407,
      "learning_rate": 9.89329823184822e-06,
      "loss": 0.5681,
      "step": 1351
    },
    {
      "epoch": 0.09,
      "grad_norm": 4.92348466829184,
      "learning_rate": 9.893066724457206e-06,
      "loss": 0.5166,
      "step": 1352
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.3119015181425433,
      "learning_rate": 9.892834968905797e-06,
      "loss": 0.5022,
      "step": 1353
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.0874287408794996,
      "learning_rate": 9.89260296520575e-06,
      "loss": 0.5429,
      "step": 1354
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.0719265353776044,
      "learning_rate": 9.892370713368832e-06,
      "loss": 0.5556,
      "step": 1355
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.103831485047069,
      "learning_rate": 9.892138213406822e-06,
      "loss": 0.4943,
      "step": 1356
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.8642184728710456,
      "learning_rate": 9.89190546533151e-06,
      "loss": 0.5637,
      "step": 1357
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.8006752369616454,
      "learning_rate": 9.891672469154703e-06,
      "loss": 0.5689,
      "step": 1358
    },
    {
      "epoch": 0.09,
      "grad_norm": 3.7045227471760036,
      "learning_rate": 9.891439224888215e-06,
      "loss": 0.5891,
      "step": 1359
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.0052072811419763,
      "learning_rate": 9.891205732543876e-06,
      "loss": 0.512,
      "step": 1360
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8671764201710912,
      "learning_rate": 9.89097199213353e-06,
      "loss": 0.4624,
      "step": 1361
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.8582027913558874,
      "learning_rate": 9.890738003669029e-06,
      "loss": 0.5694,
      "step": 1362
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.7886958552457524,
      "learning_rate": 9.890503767162241e-06,
      "loss": 0.5527,
      "step": 1363
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.9252960475419625,
      "learning_rate": 9.890269282625046e-06,
      "loss": 0.5018,
      "step": 1364
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.386038421114249,
      "learning_rate": 9.890034550069337e-06,
      "loss": 0.5103,
      "step": 1365
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.8609551424948885,
      "learning_rate": 9.889799569507017e-06,
      "loss": 0.5576,
      "step": 1366
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.967029727331019,
      "learning_rate": 9.889564340950005e-06,
      "loss": 0.6049,
      "step": 1367
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.2883089940315364,
      "learning_rate": 9.88932886441023e-06,
      "loss": 0.5921,
      "step": 1368
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.630988090804799,
      "learning_rate": 9.889093139899637e-06,
      "loss": 0.551,
      "step": 1369
    },
    {
      "epoch": 0.1,
      "grad_norm": 6.7938973562571245,
      "learning_rate": 9.888857167430177e-06,
      "loss": 0.5543,
      "step": 1370
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.3033592044718065,
      "learning_rate": 9.888620947013821e-06,
      "loss": 0.5859,
      "step": 1371
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.9036040978169873,
      "learning_rate": 9.88838447866255e-06,
      "loss": 0.5582,
      "step": 1372
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.8252900574444801,
      "learning_rate": 9.888147762388353e-06,
      "loss": 0.5554,
      "step": 1373
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.8217206549059558,
      "learning_rate": 9.887910798203237e-06,
      "loss": 0.4684,
      "step": 1374
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.8195302725665718,
      "learning_rate": 9.887673586119225e-06,
      "loss": 0.5639,
      "step": 1375
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.965580202045482,
      "learning_rate": 9.88743612614834e-06,
      "loss": 0.5493,
      "step": 1376
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.854252380101227,
      "learning_rate": 9.887198418302629e-06,
      "loss": 0.4499,
      "step": 1377
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.8648116179766918,
      "learning_rate": 9.886960462594146e-06,
      "loss": 0.5872,
      "step": 1378
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.8566765706230794,
      "learning_rate": 9.886722259034964e-06,
      "loss": 0.5317,
      "step": 1379
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.7585469642903652,
      "learning_rate": 9.88648380763716e-06,
      "loss": 0.4738,
      "step": 1380
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.1946037625034522,
      "learning_rate": 9.886245108412826e-06,
      "loss": 0.5339,
      "step": 1381
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.836066071474395,
      "learning_rate": 9.88600616137407e-06,
      "loss": 0.5377,
      "step": 1382
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.777539945462161,
      "learning_rate": 9.885766966533014e-06,
      "loss": 0.5537,
      "step": 1383
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.8164194807195633,
      "learning_rate": 9.885527523901783e-06,
      "loss": 0.5658,
      "step": 1384
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.286786929424659,
      "learning_rate": 9.885287833492525e-06,
      "loss": 0.5843,
      "step": 1385
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.09181388691794,
      "learning_rate": 9.885047895317396e-06,
      "loss": 0.5292,
      "step": 1386
    },
    {
      "epoch": 0.1,
      "grad_norm": 3.1282887785149778,
      "learning_rate": 9.884807709388563e-06,
      "loss": 0.5292,
      "step": 1387
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.2041393425365507,
      "learning_rate": 9.88456727571821e-06,
      "loss": 0.5705,
      "step": 1388
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.8557609629505665,
      "learning_rate": 9.884326594318525e-06,
      "loss": 0.5375,
      "step": 1389
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.6115586954492103,
      "learning_rate": 9.884085665201723e-06,
      "loss": 0.5909,
      "step": 1390
    },
    {
      "epoch": 0.1,
      "grad_norm": 3.7464560328748915,
      "learning_rate": 9.883844488380016e-06,
      "loss": 0.542,
      "step": 1391
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.2105135385788164,
      "learning_rate": 9.883603063865642e-06,
      "loss": 0.5395,
      "step": 1392
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.0887797070349308,
      "learning_rate": 9.883361391670841e-06,
      "loss": 0.5611,
      "step": 1393
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.793906098119372,
      "learning_rate": 9.883119471807869e-06,
      "loss": 0.5402,
      "step": 1394
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.006483488635609,
      "learning_rate": 9.882877304289e-06,
      "loss": 0.5143,
      "step": 1395
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.1406208942946545,
      "learning_rate": 9.882634889126513e-06,
      "loss": 0.5826,
      "step": 1396
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.9267990884288684,
      "learning_rate": 9.8823922263327e-06,
      "loss": 0.539,
      "step": 1397
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.105884229030668,
      "learning_rate": 9.882149315919873e-06,
      "loss": 0.5422,
      "step": 1398
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.916217167627262,
      "learning_rate": 9.881906157900349e-06,
      "loss": 0.593,
      "step": 1399
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.087495919948695,
      "learning_rate": 9.88166275228646e-06,
      "loss": 0.5691,
      "step": 1400
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.9783196671435368,
      "learning_rate": 9.881419099090553e-06,
      "loss": 0.6292,
      "step": 1401
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.288663323072212,
      "learning_rate": 9.881175198324982e-06,
      "loss": 0.5652,
      "step": 1402
    },
    {
      "epoch": 0.1,
      "grad_norm": 4.699172797709767,
      "learning_rate": 9.880931050002119e-06,
      "loss": 0.5882,
      "step": 1403
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.235422674825616,
      "learning_rate": 9.880686654134345e-06,
      "loss": 0.5232,
      "step": 1404
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.078073880073831,
      "learning_rate": 9.880442010734057e-06,
      "loss": 0.5723,
      "step": 1405
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.6963347872109957,
      "learning_rate": 9.880197119813662e-06,
      "loss": 0.5159,
      "step": 1406
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.8252128950136373,
      "learning_rate": 9.879951981385577e-06,
      "loss": 0.5761,
      "step": 1407
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.135609902998648,
      "learning_rate": 9.87970659546224e-06,
      "loss": 0.5871,
      "step": 1408
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.8901103302248623,
      "learning_rate": 9.879460962056091e-06,
      "loss": 0.5365,
      "step": 1409
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.282656944910911,
      "learning_rate": 9.87921508117959e-06,
      "loss": 0.5315,
      "step": 1410
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.298343094084343,
      "learning_rate": 9.87896895284521e-06,
      "loss": 0.532,
      "step": 1411
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.441217347191703,
      "learning_rate": 9.878722577065427e-06,
      "loss": 0.5103,
      "step": 1412
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.3901742312626744,
      "learning_rate": 9.878475953852743e-06,
      "loss": 0.5845,
      "step": 1413
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.8591317271542833,
      "learning_rate": 9.878229083219663e-06,
      "loss": 0.5233,
      "step": 1414
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.9231967161537513,
      "learning_rate": 9.877981965178708e-06,
      "loss": 0.5668,
      "step": 1415
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.7302395896270617,
      "learning_rate": 9.87773459974241e-06,
      "loss": 0.569,
      "step": 1416
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.368008775763999,
      "learning_rate": 9.877486986923317e-06,
      "loss": 0.5217,
      "step": 1417
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.39015507999948,
      "learning_rate": 9.877239126733984e-06,
      "loss": 0.5637,
      "step": 1418
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.1089091274972818,
      "learning_rate": 9.876991019186983e-06,
      "loss": 0.5455,
      "step": 1419
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.0567910074179077,
      "learning_rate": 9.876742664294897e-06,
      "loss": 0.5302,
      "step": 1420
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.5924782421854833,
      "learning_rate": 9.876494062070325e-06,
      "loss": 0.499,
      "step": 1421
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.4104522033969187,
      "learning_rate": 9.87624521252587e-06,
      "loss": 0.581,
      "step": 1422
    },
    {
      "epoch": 0.1,
      "grad_norm": 3.283153005120735,
      "learning_rate": 9.875996115674157e-06,
      "loss": 0.571,
      "step": 1423
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.93436354004118,
      "learning_rate": 9.875746771527817e-06,
      "loss": 0.5381,
      "step": 1424
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.295292107798924,
      "learning_rate": 9.875497180099495e-06,
      "loss": 0.5851,
      "step": 1425
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.1523106972869446,
      "learning_rate": 9.875247341401854e-06,
      "loss": 0.5452,
      "step": 1426
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.596990165944362,
      "learning_rate": 9.87499725544756e-06,
      "loss": 0.587,
      "step": 1427
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.1014905224995863,
      "learning_rate": 9.874746922249298e-06,
      "loss": 0.5371,
      "step": 1428
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.5877750204645755,
      "learning_rate": 9.874496341819767e-06,
      "loss": 0.5553,
      "step": 1429
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.17064282955135,
      "learning_rate": 9.874245514171672e-06,
      "loss": 0.5693,
      "step": 1430
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.9778199517872377,
      "learning_rate": 9.873994439317735e-06,
      "loss": 0.5648,
      "step": 1431
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.9396529548431316,
      "learning_rate": 9.873743117270691e-06,
      "loss": 0.512,
      "step": 1432
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.551740193973278,
      "learning_rate": 9.873491548043287e-06,
      "loss": 0.5297,
      "step": 1433
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.8511076056854283,
      "learning_rate": 9.873239731648277e-06,
      "loss": 0.519,
      "step": 1434
    },
    {
      "epoch": 0.1,
      "grad_norm": 4.953494282737956,
      "learning_rate": 9.872987668098438e-06,
      "loss": 0.5521,
      "step": 1435
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.399880480857581,
      "learning_rate": 9.872735357406548e-06,
      "loss": 0.5583,
      "step": 1436
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.6852183753419052,
      "learning_rate": 9.87248279958541e-06,
      "loss": 0.5484,
      "step": 1437
    },
    {
      "epoch": 0.1,
      "grad_norm": 5.863831135541799,
      "learning_rate": 9.872229994647828e-06,
      "loss": 0.5888,
      "step": 1438
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.8117620501156373,
      "learning_rate": 9.871976942606626e-06,
      "loss": 0.5341,
      "step": 1439
    },
    {
      "epoch": 0.1,
      "grad_norm": 3.4142520138291195,
      "learning_rate": 9.871723643474637e-06,
      "loss": 0.5416,
      "step": 1440
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.94671803638781,
      "learning_rate": 9.871470097264705e-06,
      "loss": 0.5688,
      "step": 1441
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.878991905863732,
      "learning_rate": 9.871216303989694e-06,
      "loss": 0.5204,
      "step": 1442
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.184309321664352,
      "learning_rate": 9.870962263662473e-06,
      "loss": 0.5868,
      "step": 1443
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.234705595510431,
      "learning_rate": 9.870707976295927e-06,
      "loss": 0.5209,
      "step": 1444
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.4774202474592797,
      "learning_rate": 9.870453441902951e-06,
      "loss": 0.5773,
      "step": 1445
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.8493429021519692,
      "learning_rate": 9.870198660496455e-06,
      "loss": 0.5386,
      "step": 1446
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.362496403757609,
      "learning_rate": 9.869943632089361e-06,
      "loss": 0.5601,
      "step": 1447
    },
    {
      "epoch": 0.1,
      "grad_norm": 4.011507347384049,
      "learning_rate": 9.869688356694602e-06,
      "loss": 0.5737,
      "step": 1448
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.4679494690587456,
      "learning_rate": 9.869432834325125e-06,
      "loss": 0.5619,
      "step": 1449
    },
    {
      "epoch": 0.1,
      "grad_norm": 5.707884868606985,
      "learning_rate": 9.869177064993892e-06,
      "loss": 0.5369,
      "step": 1450
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.2788762142842036,
      "learning_rate": 9.868921048713872e-06,
      "loss": 0.509,
      "step": 1451
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.9354973100823614,
      "learning_rate": 9.868664785498049e-06,
      "loss": 0.4664,
      "step": 1452
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.4073009510768912,
      "learning_rate": 9.868408275359422e-06,
      "loss": 0.5501,
      "step": 1453
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.855656610501916,
      "learning_rate": 9.868151518311e-06,
      "loss": 0.5903,
      "step": 1454
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.071517206936749,
      "learning_rate": 9.867894514365802e-06,
      "loss": 0.5875,
      "step": 1455
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.1258635967126995,
      "learning_rate": 9.867637263536866e-06,
      "loss": 0.5473,
      "step": 1456
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.007506218699573,
      "learning_rate": 9.867379765837237e-06,
      "loss": 0.5342,
      "step": 1457
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.5419777993025017,
      "learning_rate": 9.867122021279974e-06,
      "loss": 0.4954,
      "step": 1458
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.1029472682358485,
      "learning_rate": 9.86686402987815e-06,
      "loss": 0.5424,
      "step": 1459
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.86336505682535,
      "learning_rate": 9.86660579164485e-06,
      "loss": 0.468,
      "step": 1460
    },
    {
      "epoch": 0.1,
      "grad_norm": 3.027930047008282,
      "learning_rate": 9.86634730659317e-06,
      "loss": 0.5464,
      "step": 1461
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.7528019038704534,
      "learning_rate": 9.86608857473622e-06,
      "loss": 0.5169,
      "step": 1462
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.147819655019357,
      "learning_rate": 9.865829596087121e-06,
      "loss": 0.5066,
      "step": 1463
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.992584821224175,
      "learning_rate": 9.86557037065901e-06,
      "loss": 0.5513,
      "step": 1464
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.605366408470825,
      "learning_rate": 9.865310898465031e-06,
      "loss": 0.5233,
      "step": 1465
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.0745363412282525,
      "learning_rate": 9.865051179518346e-06,
      "loss": 0.5406,
      "step": 1466
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.3001203684365064,
      "learning_rate": 9.864791213832125e-06,
      "loss": 0.5245,
      "step": 1467
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.1073555427953465,
      "learning_rate": 9.864531001419554e-06,
      "loss": 0.5694,
      "step": 1468
    },
    {
      "epoch": 0.1,
      "grad_norm": 7.98373155834165,
      "learning_rate": 9.864270542293833e-06,
      "loss": 0.5559,
      "step": 1469
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.0092344729587532,
      "learning_rate": 9.864009836468165e-06,
      "loss": 0.5195,
      "step": 1470
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.9905462771189526,
      "learning_rate": 9.863748883955776e-06,
      "loss": 0.5502,
      "step": 1471
    },
    {
      "epoch": 0.1,
      "grad_norm": 5.884386623609461,
      "learning_rate": 9.8634876847699e-06,
      "loss": 0.5691,
      "step": 1472
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.470216624097234,
      "learning_rate": 9.863226238923786e-06,
      "loss": 0.5736,
      "step": 1473
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.1584860547078115,
      "learning_rate": 9.862964546430692e-06,
      "loss": 0.597,
      "step": 1474
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.8085356951839682,
      "learning_rate": 9.86270260730389e-06,
      "loss": 0.591,
      "step": 1475
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.8266639254828492,
      "learning_rate": 9.862440421556665e-06,
      "loss": 0.5717,
      "step": 1476
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.9420322662633827,
      "learning_rate": 9.862177989202315e-06,
      "loss": 0.559,
      "step": 1477
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.7386590154264865,
      "learning_rate": 9.861915310254149e-06,
      "loss": 0.5501,
      "step": 1478
    },
    {
      "epoch": 0.1,
      "grad_norm": 9.420515182118066,
      "learning_rate": 9.861652384725488e-06,
      "loss": 0.5264,
      "step": 1479
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.7753075493443932,
      "learning_rate": 9.861389212629668e-06,
      "loss": 0.4512,
      "step": 1480
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.7933143956172966,
      "learning_rate": 9.861125793980038e-06,
      "loss": 0.5275,
      "step": 1481
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.9720255193958782,
      "learning_rate": 9.860862128789954e-06,
      "loss": 0.5899,
      "step": 1482
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.004844817485332,
      "learning_rate": 9.86059821707279e-06,
      "loss": 0.5669,
      "step": 1483
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.7866428762220758,
      "learning_rate": 9.860334058841933e-06,
      "loss": 0.5743,
      "step": 1484
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.891925846910487,
      "learning_rate": 9.860069654110776e-06,
      "loss": 0.6025,
      "step": 1485
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.527264092675327,
      "learning_rate": 9.859805002892733e-06,
      "loss": 0.5365,
      "step": 1486
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.9238608630658869,
      "learning_rate": 9.859540105201221e-06,
      "loss": 0.5207,
      "step": 1487
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.548265407060939,
      "learning_rate": 9.85927496104968e-06,
      "loss": 0.5636,
      "step": 1488
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.211212573820906,
      "learning_rate": 9.859009570451555e-06,
      "loss": 0.5669,
      "step": 1489
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.235294769517532,
      "learning_rate": 9.858743933420306e-06,
      "loss": 0.575,
      "step": 1490
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.9454250420560237,
      "learning_rate": 9.858478049969405e-06,
      "loss": 0.5291,
      "step": 1491
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.3588456292655438,
      "learning_rate": 9.858211920112338e-06,
      "loss": 0.573,
      "step": 1492
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.903038565438714,
      "learning_rate": 9.857945543862599e-06,
      "loss": 0.5266,
      "step": 1493
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.76608990711901,
      "learning_rate": 9.8576789212337e-06,
      "loss": 0.5273,
      "step": 1494
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.1552506275545587,
      "learning_rate": 9.857412052239164e-06,
      "loss": 0.5665,
      "step": 1495
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.7851730680770281,
      "learning_rate": 9.857144936892524e-06,
      "loss": 0.5212,
      "step": 1496
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.4148107531726923,
      "learning_rate": 9.85687757520733e-06,
      "loss": 0.5536,
      "step": 1497
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.080674077295851,
      "learning_rate": 9.856609967197137e-06,
      "loss": 0.5326,
      "step": 1498
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.9882155094760063,
      "learning_rate": 9.856342112875521e-06,
      "loss": 0.5257,
      "step": 1499
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.533417731029216,
      "learning_rate": 9.856074012256065e-06,
      "loss": 0.5627,
      "step": 1500
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.290028052388298,
      "learning_rate": 9.855805665352368e-06,
      "loss": 0.5583,
      "step": 1501
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.071168906451204,
      "learning_rate": 9.85553707217804e-06,
      "loss": 0.5198,
      "step": 1502
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.9429274903315843,
      "learning_rate": 9.855268232746698e-06,
      "loss": 0.5743,
      "step": 1503
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.6858702893263815,
      "learning_rate": 9.854999147071983e-06,
      "loss": 0.498,
      "step": 1504
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.957747236046873,
      "learning_rate": 9.854729815167537e-06,
      "loss": 0.47,
      "step": 1505
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.803771318998113,
      "learning_rate": 9.854460237047023e-06,
      "loss": 0.526,
      "step": 1506
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.2267538923870327,
      "learning_rate": 9.854190412724114e-06,
      "loss": 0.5338,
      "step": 1507
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.1445744391573087,
      "learning_rate": 9.85392034221249e-06,
      "loss": 0.484,
      "step": 1508
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.9618758031348291,
      "learning_rate": 9.853650025525855e-06,
      "loss": 0.5576,
      "step": 1509
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.7379932445674682,
      "learning_rate": 9.85337946267791e-06,
      "loss": 0.5514,
      "step": 1510
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.8714897076987759,
      "learning_rate": 9.853108653682384e-06,
      "loss": 0.4698,
      "step": 1511
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.6681910000621223,
      "learning_rate": 9.85283759855301e-06,
      "loss": 0.5659,
      "step": 1512
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.259037316316373,
      "learning_rate": 9.852566297303531e-06,
      "loss": 0.5717,
      "step": 1513
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.8103173218192996,
      "learning_rate": 9.852294749947712e-06,
      "loss": 0.4723,
      "step": 1514
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.0204921994165166,
      "learning_rate": 9.852022956499323e-06,
      "loss": 0.5261,
      "step": 1515
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7414828931209791,
      "learning_rate": 9.851750916972147e-06,
      "loss": 0.4474,
      "step": 1516
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.143400523072106,
      "learning_rate": 9.851478631379982e-06,
      "loss": 0.5741,
      "step": 1517
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.8386120851006977,
      "learning_rate": 9.851206099736638e-06,
      "loss": 0.5426,
      "step": 1518
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.2554024589113495,
      "learning_rate": 9.850933322055938e-06,
      "loss": 0.5834,
      "step": 1519
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.6644172136495503,
      "learning_rate": 9.850660298351714e-06,
      "loss": 0.5659,
      "step": 1520
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.049683764142065,
      "learning_rate": 9.850387028637812e-06,
      "loss": 0.5654,
      "step": 1521
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.936221353856954,
      "learning_rate": 9.850113512928094e-06,
      "loss": 0.5108,
      "step": 1522
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.2206813907992102,
      "learning_rate": 9.849839751236431e-06,
      "loss": 0.5247,
      "step": 1523
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.776807788621626,
      "learning_rate": 9.849565743576708e-06,
      "loss": 0.5204,
      "step": 1524
    },
    {
      "epoch": 0.11,
      "grad_norm": 5.552317842597892,
      "learning_rate": 9.84929148996282e-06,
      "loss": 0.5355,
      "step": 1525
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.0159054984011164,
      "learning_rate": 9.849016990408678e-06,
      "loss": 0.5689,
      "step": 1526
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.8656446680898373,
      "learning_rate": 9.848742244928202e-06,
      "loss": 0.5828,
      "step": 1527
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.7141516047076033,
      "learning_rate": 9.848467253535327e-06,
      "loss": 0.5493,
      "step": 1528
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.6885004689335246,
      "learning_rate": 9.848192016244001e-06,
      "loss": 0.5062,
      "step": 1529
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.1450698348953794,
      "learning_rate": 9.847916533068183e-06,
      "loss": 0.5059,
      "step": 1530
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.4383317717687567,
      "learning_rate": 9.84764080402184e-06,
      "loss": 0.5216,
      "step": 1531
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.94082349921142,
      "learning_rate": 9.847364829118963e-06,
      "loss": 0.5124,
      "step": 1532
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.7871580419985509,
      "learning_rate": 9.847088608373544e-06,
      "loss": 0.5854,
      "step": 1533
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.8976962843045935,
      "learning_rate": 9.846812141799592e-06,
      "loss": 0.58,
      "step": 1534
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.9464184591601954,
      "learning_rate": 9.84653542941113e-06,
      "loss": 0.5055,
      "step": 1535
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.169361237671338,
      "learning_rate": 9.846258471222194e-06,
      "loss": 0.5632,
      "step": 1536
    },
    {
      "epoch": 0.11,
      "grad_norm": 4.131086809428947,
      "learning_rate": 9.845981267246826e-06,
      "loss": 0.5308,
      "step": 1537
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.796373449780452,
      "learning_rate": 9.845703817499086e-06,
      "loss": 0.5331,
      "step": 1538
    },
    {
      "epoch": 0.11,
      "grad_norm": 4.7326941837571175,
      "learning_rate": 9.84542612199305e-06,
      "loss": 0.5562,
      "step": 1539
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.924904605066489,
      "learning_rate": 9.845148180742794e-06,
      "loss": 0.5441,
      "step": 1540
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.7193510716090175,
      "learning_rate": 9.84486999376242e-06,
      "loss": 0.6155,
      "step": 1541
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.8446757404816743,
      "learning_rate": 9.844591561066035e-06,
      "loss": 0.4509,
      "step": 1542
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.8189145789644394,
      "learning_rate": 9.844312882667762e-06,
      "loss": 0.5352,
      "step": 1543
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.0812364215843524,
      "learning_rate": 9.84403395858173e-06,
      "loss": 0.527,
      "step": 1544
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.7245221757076792,
      "learning_rate": 9.84375478882209e-06,
      "loss": 0.5366,
      "step": 1545
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.9508904909288975,
      "learning_rate": 9.843475373402997e-06,
      "loss": 0.5485,
      "step": 1546
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.754987915489992,
      "learning_rate": 9.843195712338624e-06,
      "loss": 0.5494,
      "step": 1547
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.7297121963144868,
      "learning_rate": 9.842915805643156e-06,
      "loss": 0.5363,
      "step": 1548
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.9547869169166154,
      "learning_rate": 9.842635653330787e-06,
      "loss": 0.5692,
      "step": 1549
    },
    {
      "epoch": 0.11,
      "grad_norm": 3.077515445678803,
      "learning_rate": 9.842355255415724e-06,
      "loss": 0.5675,
      "step": 1550
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.765335934170098,
      "learning_rate": 9.84207461191219e-06,
      "loss": 0.5663,
      "step": 1551
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.441314389912877,
      "learning_rate": 9.84179372283442e-06,
      "loss": 0.5415,
      "step": 1552
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.839093708003101,
      "learning_rate": 9.841512588196653e-06,
      "loss": 0.4507,
      "step": 1553
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.9304402019553266,
      "learning_rate": 9.841231208013155e-06,
      "loss": 0.5617,
      "step": 1554
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.8450608197482685,
      "learning_rate": 9.840949582298193e-06,
      "loss": 0.5395,
      "step": 1555
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.9079534814595835,
      "learning_rate": 9.84066771106605e-06,
      "loss": 0.513,
      "step": 1556
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.7996066580463637,
      "learning_rate": 9.840385594331022e-06,
      "loss": 0.5518,
      "step": 1557
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.11554246709481,
      "learning_rate": 9.840103232107418e-06,
      "loss": 0.5623,
      "step": 1558
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.150666911890544,
      "learning_rate": 9.839820624409558e-06,
      "loss": 0.5195,
      "step": 1559
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.060641747523179,
      "learning_rate": 9.839537771251773e-06,
      "loss": 0.5576,
      "step": 1560
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.1407489429454496,
      "learning_rate": 9.839254672648411e-06,
      "loss": 0.5223,
      "step": 1561
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.8510373635962127,
      "learning_rate": 9.838971328613829e-06,
      "loss": 0.4718,
      "step": 1562
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.2160206461318688,
      "learning_rate": 9.838687739162397e-06,
      "loss": 0.5802,
      "step": 1563
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.495306473056661,
      "learning_rate": 9.838403904308497e-06,
      "loss": 0.5084,
      "step": 1564
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.0178907961607475,
      "learning_rate": 9.838119824066528e-06,
      "loss": 0.5412,
      "step": 1565
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.9277830531667133,
      "learning_rate": 9.837835498450892e-06,
      "loss": 0.5507,
      "step": 1566
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.8317962901928166,
      "learning_rate": 9.837550927476012e-06,
      "loss": 0.5519,
      "step": 1567
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.207723057250158,
      "learning_rate": 9.837266111156322e-06,
      "loss": 0.5634,
      "step": 1568
    },
    {
      "epoch": 0.11,
      "grad_norm": 26.744188552936723,
      "learning_rate": 9.836981049506264e-06,
      "loss": 0.5689,
      "step": 1569
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.185965787678153,
      "learning_rate": 9.836695742540296e-06,
      "loss": 0.5489,
      "step": 1570
    },
    {
      "epoch": 0.11,
      "grad_norm": 3.121879381995159,
      "learning_rate": 9.836410190272889e-06,
      "loss": 0.5285,
      "step": 1571
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.1757014277107154,
      "learning_rate": 9.836124392718526e-06,
      "loss": 0.5675,
      "step": 1572
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.1564073481141994,
      "learning_rate": 9.8358383498917e-06,
      "loss": 0.5564,
      "step": 1573
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.9646974980836016,
      "learning_rate": 9.835552061806917e-06,
      "loss": 0.5476,
      "step": 1574
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.9563979431178633,
      "learning_rate": 9.835265528478699e-06,
      "loss": 0.5669,
      "step": 1575
    },
    {
      "epoch": 0.11,
      "grad_norm": 4.218045060894923,
      "learning_rate": 9.834978749921578e-06,
      "loss": 0.6123,
      "step": 1576
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.2971490459576662,
      "learning_rate": 9.834691726150097e-06,
      "loss": 0.5544,
      "step": 1577
    },
    {
      "epoch": 0.11,
      "grad_norm": 5.2609272874187845,
      "learning_rate": 9.834404457178814e-06,
      "loss": 0.5836,
      "step": 1578
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.992893919666556,
      "learning_rate": 9.834116943022299e-06,
      "loss": 0.5407,
      "step": 1579
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.7679330413807377,
      "learning_rate": 9.83382918369513e-06,
      "loss": 0.5034,
      "step": 1580
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.5290760930726526,
      "learning_rate": 9.833541179211906e-06,
      "loss": 0.5079,
      "step": 1581
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.1075729464040265,
      "learning_rate": 9.833252929587231e-06,
      "loss": 0.5097,
      "step": 1582
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.048064031068914,
      "learning_rate": 9.832964434835726e-06,
      "loss": 0.5369,
      "step": 1583
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.8838643014706675,
      "learning_rate": 9.83267569497202e-06,
      "loss": 0.5816,
      "step": 1584
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.6830593097779634,
      "learning_rate": 9.832386710010758e-06,
      "loss": 0.5239,
      "step": 1585
    },
    {
      "epoch": 0.11,
      "grad_norm": 3.2214999423727217,
      "learning_rate": 9.832097479966599e-06,
      "loss": 0.5395,
      "step": 1586
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.558282649495124,
      "learning_rate": 9.831808004854207e-06,
      "loss": 0.541,
      "step": 1587
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.753881038225815,
      "learning_rate": 9.831518284688265e-06,
      "loss": 0.5407,
      "step": 1588
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.3036418004750576,
      "learning_rate": 9.831228319483469e-06,
      "loss": 0.5297,
      "step": 1589
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.2503347474830746,
      "learning_rate": 9.830938109254523e-06,
      "loss": 0.5459,
      "step": 1590
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.8226959970413061,
      "learning_rate": 9.830647654016143e-06,
      "loss": 0.5094,
      "step": 1591
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.804924298031711,
      "learning_rate": 9.830356953783068e-06,
      "loss": 0.5635,
      "step": 1592
    },
    {
      "epoch": 0.11,
      "grad_norm": 3.0525882958403687,
      "learning_rate": 9.830066008570032e-06,
      "loss": 0.5677,
      "step": 1593
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.02629294574962,
      "learning_rate": 9.829774818391794e-06,
      "loss": 0.5625,
      "step": 1594
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.4075959738424184,
      "learning_rate": 9.829483383263128e-06,
      "loss": 0.5521,
      "step": 1595
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.5824515885202763,
      "learning_rate": 9.829191703198805e-06,
      "loss": 0.5498,
      "step": 1596
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.3473095892466094,
      "learning_rate": 9.828899778213628e-06,
      "loss": 0.5439,
      "step": 1597
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.1157593745900334,
      "learning_rate": 9.828607608322393e-06,
      "loss": 0.5356,
      "step": 1598
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7778841410131981,
      "learning_rate": 9.828315193539925e-06,
      "loss": 0.465,
      "step": 1599
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.0305406081663424,
      "learning_rate": 9.82802253388105e-06,
      "loss": 0.5581,
      "step": 1600
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.8535303280584814,
      "learning_rate": 9.827729629360613e-06,
      "loss": 0.5799,
      "step": 1601
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7911362493190675,
      "learning_rate": 9.827436479993468e-06,
      "loss": 0.4594,
      "step": 1602
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.1176221680280807,
      "learning_rate": 9.827143085794484e-06,
      "loss": 0.5722,
      "step": 1603
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.564577021786373,
      "learning_rate": 9.826849446778539e-06,
      "loss": 0.5448,
      "step": 1604
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.9725407744829733,
      "learning_rate": 9.826555562960526e-06,
      "loss": 0.5756,
      "step": 1605
    },
    {
      "epoch": 0.11,
      "grad_norm": 14.363750120449229,
      "learning_rate": 9.826261434355352e-06,
      "loss": 0.5411,
      "step": 1606
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.418512400431776,
      "learning_rate": 9.825967060977933e-06,
      "loss": 0.5896,
      "step": 1607
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.7367876500778605,
      "learning_rate": 9.825672442843197e-06,
      "loss": 0.5533,
      "step": 1608
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.7748854901677928,
      "learning_rate": 9.825377579966086e-06,
      "loss": 0.5617,
      "step": 1609
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.8004037752925117,
      "learning_rate": 9.825082472361558e-06,
      "loss": 0.5567,
      "step": 1610
    },
    {
      "epoch": 0.11,
      "grad_norm": 3.245307299855084,
      "learning_rate": 9.824787120044576e-06,
      "loss": 0.5091,
      "step": 1611
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.1536586177473684,
      "learning_rate": 9.824491523030123e-06,
      "loss": 0.551,
      "step": 1612
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.8646800773228278,
      "learning_rate": 9.824195681333187e-06,
      "loss": 0.5092,
      "step": 1613
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.8337555395245944,
      "learning_rate": 9.823899594968776e-06,
      "loss": 0.5471,
      "step": 1614
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.0274979624909264,
      "learning_rate": 9.823603263951902e-06,
      "loss": 0.5675,
      "step": 1615
    },
    {
      "epoch": 0.11,
      "grad_norm": 3.636640950089716,
      "learning_rate": 9.823306688297595e-06,
      "loss": 0.5354,
      "step": 1616
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.071622116672287,
      "learning_rate": 9.823009868020901e-06,
      "loss": 0.5316,
      "step": 1617
    },
    {
      "epoch": 0.11,
      "grad_norm": 3.9018243111939332,
      "learning_rate": 9.822712803136869e-06,
      "loss": 0.52,
      "step": 1618
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.1066817739244885,
      "learning_rate": 9.822415493660567e-06,
      "loss": 0.5518,
      "step": 1619
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.1537715046606927,
      "learning_rate": 9.822117939607072e-06,
      "loss": 0.5598,
      "step": 1620
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.161431590184897,
      "learning_rate": 9.821820140991478e-06,
      "loss": 0.5283,
      "step": 1621
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.5678219393670596,
      "learning_rate": 9.821522097828884e-06,
      "loss": 0.5786,
      "step": 1622
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.110883001972284,
      "learning_rate": 9.82122381013441e-06,
      "loss": 0.5283,
      "step": 1623
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.2100154572068234,
      "learning_rate": 9.820925277923183e-06,
      "loss": 0.5296,
      "step": 1624
    },
    {
      "epoch": 0.11,
      "grad_norm": 5.577079351407316,
      "learning_rate": 9.820626501210342e-06,
      "loss": 0.5713,
      "step": 1625
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.2094048131112083,
      "learning_rate": 9.82032748001104e-06,
      "loss": 0.5161,
      "step": 1626
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.8894462702115904,
      "learning_rate": 9.820028214340446e-06,
      "loss": 0.4654,
      "step": 1627
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.2989251404607884,
      "learning_rate": 9.819728704213733e-06,
      "loss": 0.5805,
      "step": 1628
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.948254473137237,
      "learning_rate": 9.819428949646094e-06,
      "loss": 0.5675,
      "step": 1629
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.054548986566069,
      "learning_rate": 9.819128950652733e-06,
      "loss": 0.5568,
      "step": 1630
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.8628027738914971,
      "learning_rate": 9.81882870724886e-06,
      "loss": 0.4864,
      "step": 1631
    },
    {
      "epoch": 0.11,
      "grad_norm": 3.170773543482741,
      "learning_rate": 9.818528219449705e-06,
      "loss": 0.562,
      "step": 1632
    },
    {
      "epoch": 0.11,
      "grad_norm": 3.09724905753145,
      "learning_rate": 9.818227487270508e-06,
      "loss": 0.5366,
      "step": 1633
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.1949566857393865,
      "learning_rate": 9.817926510726522e-06,
      "loss": 0.56,
      "step": 1634
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.9928338227993052,
      "learning_rate": 9.817625289833013e-06,
      "loss": 0.5479,
      "step": 1635
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.220206242919337,
      "learning_rate": 9.817323824605254e-06,
      "loss": 0.5488,
      "step": 1636
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.9524465548466028,
      "learning_rate": 9.817022115058534e-06,
      "loss": 0.5461,
      "step": 1637
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.1145011303471626,
      "learning_rate": 9.81672016120816e-06,
      "loss": 0.5592,
      "step": 1638
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.1752841026157825,
      "learning_rate": 9.81641796306944e-06,
      "loss": 0.5586,
      "step": 1639
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.9314044832787318,
      "learning_rate": 9.816115520657705e-06,
      "loss": 0.5699,
      "step": 1640
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.8256268709650774,
      "learning_rate": 9.815812833988292e-06,
      "loss": 0.4654,
      "step": 1641
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.9309002551970522,
      "learning_rate": 9.815509903076553e-06,
      "loss": 0.5639,
      "step": 1642
    },
    {
      "epoch": 0.11,
      "grad_norm": 4.473156130921279,
      "learning_rate": 9.81520672793785e-06,
      "loss": 0.5502,
      "step": 1643
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.45090208493227,
      "learning_rate": 9.81490330858756e-06,
      "loss": 0.5478,
      "step": 1644
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.8296903778056743,
      "learning_rate": 9.814599645041071e-06,
      "loss": 0.5137,
      "step": 1645
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.9365805790237003,
      "learning_rate": 9.814295737313786e-06,
      "loss": 0.5575,
      "step": 1646
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.9195934085400714,
      "learning_rate": 9.813991585421118e-06,
      "loss": 0.4957,
      "step": 1647
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.82692731260904,
      "learning_rate": 9.81368718937849e-06,
      "loss": 0.5106,
      "step": 1648
    },
    {
      "epoch": 0.11,
      "grad_norm": 3.071785343635811,
      "learning_rate": 9.81338254920134e-06,
      "loss": 0.4953,
      "step": 1649
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.2379036471238396,
      "learning_rate": 9.813077664905122e-06,
      "loss": 0.5366,
      "step": 1650
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.999155434337079,
      "learning_rate": 9.812772536505296e-06,
      "loss": 0.5336,
      "step": 1651
    },
    {
      "epoch": 0.11,
      "grad_norm": 15.127007895960636,
      "learning_rate": 9.812467164017337e-06,
      "loss": 0.5229,
      "step": 1652
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.601994877490434,
      "learning_rate": 9.81216154745673e-06,
      "loss": 0.5771,
      "step": 1653
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.831806462471308,
      "learning_rate": 9.811855686838981e-06,
      "loss": 0.5559,
      "step": 1654
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.8985699019735964,
      "learning_rate": 9.811549582179599e-06,
      "loss": 0.5636,
      "step": 1655
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.8935119888235687,
      "learning_rate": 9.811243233494108e-06,
      "loss": 0.5335,
      "step": 1656
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.318357573806424,
      "learning_rate": 9.810936640798046e-06,
      "loss": 0.5507,
      "step": 1657
    },
    {
      "epoch": 0.12,
      "grad_norm": 3.078168542977125,
      "learning_rate": 9.810629804106964e-06,
      "loss": 0.5204,
      "step": 1658
    },
    {
      "epoch": 0.12,
      "grad_norm": 3.330662805227106,
      "learning_rate": 9.810322723436419e-06,
      "loss": 0.5771,
      "step": 1659
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.7114001017370337,
      "learning_rate": 9.810015398801989e-06,
      "loss": 0.5611,
      "step": 1660
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.3868976924209955,
      "learning_rate": 9.80970783021926e-06,
      "loss": 0.5926,
      "step": 1661
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.65755430960902,
      "learning_rate": 9.80940001770383e-06,
      "loss": 0.5419,
      "step": 1662
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.050518368652045,
      "learning_rate": 9.809091961271311e-06,
      "loss": 0.5479,
      "step": 1663
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.6315605948859337,
      "learning_rate": 9.808783660937325e-06,
      "loss": 0.5824,
      "step": 1664
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.8807730375220786,
      "learning_rate": 9.80847511671751e-06,
      "loss": 0.4637,
      "step": 1665
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.9053418875491195,
      "learning_rate": 9.808166328627515e-06,
      "loss": 0.5679,
      "step": 1666
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.9821734322823938,
      "learning_rate": 9.807857296682999e-06,
      "loss": 0.55,
      "step": 1667
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.9951269556631974,
      "learning_rate": 9.807548020899634e-06,
      "loss": 0.5366,
      "step": 1668
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.510341840006691,
      "learning_rate": 9.807238501293108e-06,
      "loss": 0.4952,
      "step": 1669
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.0083375519245323,
      "learning_rate": 9.806928737879116e-06,
      "loss": 0.5847,
      "step": 1670
    },
    {
      "epoch": 0.12,
      "grad_norm": 4.358521403128807,
      "learning_rate": 9.806618730673371e-06,
      "loss": 0.505,
      "step": 1671
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.4332852330412185,
      "learning_rate": 9.806308479691595e-06,
      "loss": 0.5648,
      "step": 1672
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.8049101061304103,
      "learning_rate": 9.805997984949522e-06,
      "loss": 0.5258,
      "step": 1673
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.7734126065320546,
      "learning_rate": 9.8056872464629e-06,
      "loss": 0.5305,
      "step": 1674
    },
    {
      "epoch": 0.12,
      "grad_norm": 3.460542482703007,
      "learning_rate": 9.805376264247488e-06,
      "loss": 0.553,
      "step": 1675
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.945595679167276,
      "learning_rate": 9.805065038319057e-06,
      "loss": 0.6066,
      "step": 1676
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.9869298984922363,
      "learning_rate": 9.804753568693395e-06,
      "loss": 0.5605,
      "step": 1677
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.4015757544420118,
      "learning_rate": 9.804441855386296e-06,
      "loss": 0.5292,
      "step": 1678
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.0410354579694854,
      "learning_rate": 9.804129898413569e-06,
      "loss": 0.6009,
      "step": 1679
    },
    {
      "epoch": 0.12,
      "grad_norm": 4.364802054195251,
      "learning_rate": 9.803817697791033e-06,
      "loss": 0.4978,
      "step": 1680
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.493877315530362,
      "learning_rate": 9.80350525353453e-06,
      "loss": 0.5287,
      "step": 1681
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.122506475497268,
      "learning_rate": 9.803192565659898e-06,
      "loss": 0.5407,
      "step": 1682
    },
    {
      "epoch": 0.12,
      "grad_norm": 4.5173568053794035,
      "learning_rate": 9.802879634182998e-06,
      "loss": 0.5898,
      "step": 1683
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.1666871269604497,
      "learning_rate": 9.802566459119703e-06,
      "loss": 0.6006,
      "step": 1684
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.9190893624215837,
      "learning_rate": 9.802253040485892e-06,
      "loss": 0.5404,
      "step": 1685
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.9187388455211278,
      "learning_rate": 9.801939378297464e-06,
      "loss": 0.5436,
      "step": 1686
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.6292530757592263,
      "learning_rate": 9.801625472570326e-06,
      "loss": 0.569,
      "step": 1687
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.691454251093335,
      "learning_rate": 9.8013113233204e-06,
      "loss": 0.5438,
      "step": 1688
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.9464378026814698,
      "learning_rate": 9.800996930563615e-06,
      "loss": 0.4773,
      "step": 1689
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7697186525310442,
      "learning_rate": 9.800682294315917e-06,
      "loss": 0.455,
      "step": 1690
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.8454360611500873,
      "learning_rate": 9.800367414593266e-06,
      "loss": 0.4802,
      "step": 1691
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.085137268674787,
      "learning_rate": 9.80005229141163e-06,
      "loss": 0.5443,
      "step": 1692
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.5129254359416326,
      "learning_rate": 9.79973692478699e-06,
      "loss": 0.5245,
      "step": 1693
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.238014341699999,
      "learning_rate": 9.799421314735341e-06,
      "loss": 0.5366,
      "step": 1694
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.9639552418429902,
      "learning_rate": 9.79910546127269e-06,
      "loss": 0.5499,
      "step": 1695
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.162529003426208,
      "learning_rate": 9.798789364415056e-06,
      "loss": 0.5776,
      "step": 1696
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.7076872257227844,
      "learning_rate": 9.798473024178471e-06,
      "loss": 0.4782,
      "step": 1697
    },
    {
      "epoch": 0.12,
      "grad_norm": 4.285652575154081,
      "learning_rate": 9.798156440578977e-06,
      "loss": 0.5269,
      "step": 1698
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.817416751299796,
      "learning_rate": 9.797839613632632e-06,
      "loss": 0.5036,
      "step": 1699
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.094228800285935,
      "learning_rate": 9.797522543355504e-06,
      "loss": 0.5357,
      "step": 1700
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.603703094155023,
      "learning_rate": 9.797205229763674e-06,
      "loss": 0.4873,
      "step": 1701
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.1603681290567707,
      "learning_rate": 9.796887672873233e-06,
      "loss": 0.5469,
      "step": 1702
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.984643939451702,
      "learning_rate": 9.796569872700287e-06,
      "loss": 0.5132,
      "step": 1703
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.2280855316317183,
      "learning_rate": 9.796251829260958e-06,
      "loss": 0.5237,
      "step": 1704
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.5262267265486127,
      "learning_rate": 9.795933542571372e-06,
      "loss": 0.5294,
      "step": 1705
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.8976435088853802,
      "learning_rate": 9.79561501264767e-06,
      "loss": 0.5618,
      "step": 1706
    },
    {
      "epoch": 0.12,
      "grad_norm": 5.435001160899495,
      "learning_rate": 9.795296239506011e-06,
      "loss": 0.5482,
      "step": 1707
    },
    {
      "epoch": 0.12,
      "grad_norm": 3.1715743701205503,
      "learning_rate": 9.79497722316256e-06,
      "loss": 0.5751,
      "step": 1708
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.099215705605699,
      "learning_rate": 9.794657963633497e-06,
      "loss": 0.5456,
      "step": 1709
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.731523195537201,
      "learning_rate": 9.794338460935014e-06,
      "loss": 0.5452,
      "step": 1710
    },
    {
      "epoch": 0.12,
      "grad_norm": 3.80235441612812,
      "learning_rate": 9.794018715083312e-06,
      "loss": 0.497,
      "step": 1711
    },
    {
      "epoch": 0.12,
      "grad_norm": 5.320744317559523,
      "learning_rate": 9.793698726094613e-06,
      "loss": 0.547,
      "step": 1712
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.696032181725322,
      "learning_rate": 9.793378493985144e-06,
      "loss": 0.5487,
      "step": 1713
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.259124159170589,
      "learning_rate": 9.793058018771142e-06,
      "loss": 0.5923,
      "step": 1714
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.6861178752464983,
      "learning_rate": 9.792737300468865e-06,
      "loss": 0.4888,
      "step": 1715
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.5648309242107037,
      "learning_rate": 9.792416339094577e-06,
      "loss": 0.5403,
      "step": 1716
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.3854937355612247,
      "learning_rate": 9.792095134664556e-06,
      "loss": 0.523,
      "step": 1717
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.0964211476223547,
      "learning_rate": 9.791773687195094e-06,
      "loss": 0.543,
      "step": 1718
    },
    {
      "epoch": 0.12,
      "grad_norm": 4.301003739977341,
      "learning_rate": 9.791451996702492e-06,
      "loss": 0.5114,
      "step": 1719
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.864085502009893,
      "learning_rate": 9.791130063203066e-06,
      "loss": 0.5806,
      "step": 1720
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.9954274137262407,
      "learning_rate": 9.790807886713145e-06,
      "loss": 0.5031,
      "step": 1721
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.4051621273204837,
      "learning_rate": 9.790485467249065e-06,
      "loss": 0.4783,
      "step": 1722
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.0005935155809493,
      "learning_rate": 9.790162804827179e-06,
      "loss": 0.4858,
      "step": 1723
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.1346727619677592,
      "learning_rate": 9.789839899463854e-06,
      "loss": 0.5206,
      "step": 1724
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.9525002116524641,
      "learning_rate": 9.789516751175466e-06,
      "loss": 0.5714,
      "step": 1725
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.853624402196436,
      "learning_rate": 9.7891933599784e-06,
      "loss": 0.5532,
      "step": 1726
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.5561187243336176,
      "learning_rate": 9.788869725889062e-06,
      "loss": 0.5681,
      "step": 1727
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.94844009460532,
      "learning_rate": 9.788545848923865e-06,
      "loss": 0.5809,
      "step": 1728
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.703563139405516,
      "learning_rate": 9.788221729099232e-06,
      "loss": 0.5688,
      "step": 1729
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.6914417701520952,
      "learning_rate": 9.787897366431605e-06,
      "loss": 0.5119,
      "step": 1730
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.8675228726707007,
      "learning_rate": 9.787572760937435e-06,
      "loss": 0.54,
      "step": 1731
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.015139241822086,
      "learning_rate": 9.78724791263318e-06,
      "loss": 0.5471,
      "step": 1732
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.372227371760329,
      "learning_rate": 9.786922821535317e-06,
      "loss": 0.5847,
      "step": 1733
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.1455269833838666,
      "learning_rate": 9.786597487660336e-06,
      "loss": 0.5656,
      "step": 1734
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.1059518267133774,
      "learning_rate": 9.786271911024737e-06,
      "loss": 0.5211,
      "step": 1735
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.198801641288087,
      "learning_rate": 9.785946091645031e-06,
      "loss": 0.5293,
      "step": 1736
    },
    {
      "epoch": 0.12,
      "grad_norm": 3.830136827814141,
      "learning_rate": 9.785620029537741e-06,
      "loss": 0.5792,
      "step": 1737
    },
    {
      "epoch": 0.12,
      "grad_norm": 3.177815530837817,
      "learning_rate": 9.785293724719404e-06,
      "loss": 0.5608,
      "step": 1738
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.229503284191083,
      "learning_rate": 9.784967177206572e-06,
      "loss": 0.5223,
      "step": 1739
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.7940107461272063,
      "learning_rate": 9.784640387015805e-06,
      "loss": 0.5148,
      "step": 1740
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.2706002785025112,
      "learning_rate": 9.784313354163677e-06,
      "loss": 0.5539,
      "step": 1741
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.664379857814623,
      "learning_rate": 9.783986078666772e-06,
      "loss": 0.5498,
      "step": 1742
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.396606769063646,
      "learning_rate": 9.783658560541689e-06,
      "loss": 0.5866,
      "step": 1743
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.157572733656871,
      "learning_rate": 9.78333079980504e-06,
      "loss": 0.5092,
      "step": 1744
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.572717182201946,
      "learning_rate": 9.783002796473449e-06,
      "loss": 0.5276,
      "step": 1745
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.741860191900928,
      "learning_rate": 9.782674550563548e-06,
      "loss": 0.496,
      "step": 1746
    },
    {
      "epoch": 0.12,
      "grad_norm": 3.584481458641639,
      "learning_rate": 9.782346062091988e-06,
      "loss": 0.5793,
      "step": 1747
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.144614781021208,
      "learning_rate": 9.782017331075425e-06,
      "loss": 0.5429,
      "step": 1748
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.485988502833608,
      "learning_rate": 9.781688357530534e-06,
      "loss": 0.5145,
      "step": 1749
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.3483914245529687,
      "learning_rate": 9.781359141473998e-06,
      "loss": 0.526,
      "step": 1750
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.7306882093525924,
      "learning_rate": 9.781029682922515e-06,
      "loss": 0.5411,
      "step": 1751
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.1298003267502708,
      "learning_rate": 9.780699981892793e-06,
      "loss": 0.5095,
      "step": 1752
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.9832977161819045,
      "learning_rate": 9.780370038401557e-06,
      "loss": 0.5856,
      "step": 1753
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.8809398101296457,
      "learning_rate": 9.780039852465533e-06,
      "loss": 0.5578,
      "step": 1754
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.003634643654045,
      "learning_rate": 9.779709424101474e-06,
      "loss": 0.5559,
      "step": 1755
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.475032135981332,
      "learning_rate": 9.779378753326136e-06,
      "loss": 0.5745,
      "step": 1756
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.853934173039795,
      "learning_rate": 9.779047840156288e-06,
      "loss": 0.5069,
      "step": 1757
    },
    {
      "epoch": 0.12,
      "grad_norm": 3.0591826446169836,
      "learning_rate": 9.778716684608715e-06,
      "loss": 0.4867,
      "step": 1758
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.8520688791532314,
      "learning_rate": 9.778385286700212e-06,
      "loss": 0.5259,
      "step": 1759
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.342231543833894,
      "learning_rate": 9.778053646447585e-06,
      "loss": 0.5379,
      "step": 1760
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.892689187332239,
      "learning_rate": 9.777721763867653e-06,
      "loss": 0.4846,
      "step": 1761
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.8048714644302816,
      "learning_rate": 9.777389638977251e-06,
      "loss": 0.4693,
      "step": 1762
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.9998882285115558,
      "learning_rate": 9.777057271793222e-06,
      "loss": 0.499,
      "step": 1763
    },
    {
      "epoch": 0.12,
      "grad_norm": 3.444382809725772,
      "learning_rate": 9.776724662332422e-06,
      "loss": 0.5753,
      "step": 1764
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7679789183405689,
      "learning_rate": 9.776391810611719e-06,
      "loss": 0.4433,
      "step": 1765
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.118612529233698,
      "learning_rate": 9.776058716647996e-06,
      "loss": 0.5245,
      "step": 1766
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.514214009942368,
      "learning_rate": 9.775725380458145e-06,
      "loss": 0.5128,
      "step": 1767
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.048683617362661,
      "learning_rate": 9.775391802059074e-06,
      "loss": 0.5315,
      "step": 1768
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.3328852653430707,
      "learning_rate": 9.775057981467699e-06,
      "loss": 0.5794,
      "step": 1769
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.2361489218959307,
      "learning_rate": 9.77472391870095e-06,
      "loss": 0.5673,
      "step": 1770
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.27567327074486,
      "learning_rate": 9.774389613775772e-06,
      "loss": 0.6003,
      "step": 1771
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.9357336633558653,
      "learning_rate": 9.774055066709117e-06,
      "loss": 0.4821,
      "step": 1772
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.3781458823118022,
      "learning_rate": 9.773720277517954e-06,
      "loss": 0.5581,
      "step": 1773
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.8681762476352497,
      "learning_rate": 9.77338524621926e-06,
      "loss": 0.5356,
      "step": 1774
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.3754504451127967,
      "learning_rate": 9.773049972830029e-06,
      "loss": 0.5331,
      "step": 1775
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.7393703489851013,
      "learning_rate": 9.772714457367265e-06,
      "loss": 0.5451,
      "step": 1776
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.8530122185074533,
      "learning_rate": 9.772378699847984e-06,
      "loss": 0.5508,
      "step": 1777
    },
    {
      "epoch": 0.12,
      "grad_norm": 3.070271765683625,
      "learning_rate": 9.772042700289214e-06,
      "loss": 0.5638,
      "step": 1778
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.0541415476016165,
      "learning_rate": 9.771706458707995e-06,
      "loss": 0.5713,
      "step": 1779
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.1805950519332904,
      "learning_rate": 9.771369975121383e-06,
      "loss": 0.5092,
      "step": 1780
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.73571255321594,
      "learning_rate": 9.77103324954644e-06,
      "loss": 0.5514,
      "step": 1781
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.2650492881357907,
      "learning_rate": 9.770696282000245e-06,
      "loss": 0.5605,
      "step": 1782
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.6527801457030824,
      "learning_rate": 9.77035907249989e-06,
      "loss": 0.53,
      "step": 1783
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.911084501272799,
      "learning_rate": 9.77002162106247e-06,
      "loss": 0.5982,
      "step": 1784
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.9417956859185077,
      "learning_rate": 9.76968392770511e-06,
      "loss": 0.5431,
      "step": 1785
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.388344813363377,
      "learning_rate": 9.76934599244493e-06,
      "loss": 0.5619,
      "step": 1786
    },
    {
      "epoch": 0.12,
      "grad_norm": 4.022756666885157,
      "learning_rate": 9.769007815299068e-06,
      "loss": 0.5237,
      "step": 1787
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.1231366899761324,
      "learning_rate": 9.76866939628468e-06,
      "loss": 0.5091,
      "step": 1788
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.026611989566529,
      "learning_rate": 9.768330735418924e-06,
      "loss": 0.5177,
      "step": 1789
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.1523784881479107,
      "learning_rate": 9.767991832718982e-06,
      "loss": 0.5292,
      "step": 1790
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.9005845580096234,
      "learning_rate": 9.767652688202037e-06,
      "loss": 0.5739,
      "step": 1791
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.2053905982425865,
      "learning_rate": 9.767313301885291e-06,
      "loss": 0.5766,
      "step": 1792
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.97983767336722,
      "learning_rate": 9.766973673785957e-06,
      "loss": 0.5324,
      "step": 1793
    },
    {
      "epoch": 0.12,
      "grad_norm": 5.308750620905613,
      "learning_rate": 9.76663380392126e-06,
      "loss": 0.5337,
      "step": 1794
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.362740061661938,
      "learning_rate": 9.766293692308436e-06,
      "loss": 0.513,
      "step": 1795
    },
    {
      "epoch": 0.12,
      "grad_norm": 3.483109418894176,
      "learning_rate": 9.765953338964736e-06,
      "loss": 0.534,
      "step": 1796
    },
    {
      "epoch": 0.12,
      "grad_norm": 3.092828778243436,
      "learning_rate": 9.76561274390742e-06,
      "loss": 0.5012,
      "step": 1797
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.8131887209246327,
      "learning_rate": 9.765271907153762e-06,
      "loss": 0.4691,
      "step": 1798
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.118927522400833,
      "learning_rate": 9.76493082872105e-06,
      "loss": 0.5572,
      "step": 1799
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.5938962607082523,
      "learning_rate": 9.76458950862658e-06,
      "loss": 0.5202,
      "step": 1800
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.053386400615557,
      "learning_rate": 9.764247946887661e-06,
      "loss": 0.5427,
      "step": 1801
    },
    {
      "epoch": 0.13,
      "grad_norm": 3.404847034825489,
      "learning_rate": 9.763906143521621e-06,
      "loss": 0.5781,
      "step": 1802
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.4524812432140166,
      "learning_rate": 9.763564098545792e-06,
      "loss": 0.5137,
      "step": 1803
    },
    {
      "epoch": 0.13,
      "grad_norm": 3.304299986582624,
      "learning_rate": 9.763221811977522e-06,
      "loss": 0.5443,
      "step": 1804
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.848826204864644,
      "learning_rate": 9.762879283834173e-06,
      "loss": 0.5707,
      "step": 1805
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.6244562887861393,
      "learning_rate": 9.762536514133112e-06,
      "loss": 0.5474,
      "step": 1806
    },
    {
      "epoch": 0.13,
      "grad_norm": 3.156689397447551,
      "learning_rate": 9.762193502891726e-06,
      "loss": 0.554,
      "step": 1807
    },
    {
      "epoch": 0.13,
      "grad_norm": 3.7723284802499917,
      "learning_rate": 9.761850250127412e-06,
      "loss": 0.5208,
      "step": 1808
    },
    {
      "epoch": 0.13,
      "grad_norm": 6.982640349884984,
      "learning_rate": 9.761506755857576e-06,
      "loss": 0.6,
      "step": 1809
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.336791053575183,
      "learning_rate": 9.761163020099642e-06,
      "loss": 0.5187,
      "step": 1810
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.8612630874607217,
      "learning_rate": 9.760819042871043e-06,
      "loss": 0.5394,
      "step": 1811
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.176038156174,
      "learning_rate": 9.760474824189222e-06,
      "loss": 0.5207,
      "step": 1812
    },
    {
      "epoch": 0.13,
      "grad_norm": 23.181924352164106,
      "learning_rate": 9.760130364071639e-06,
      "loss": 0.5754,
      "step": 1813
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.3929371709255394,
      "learning_rate": 9.759785662535761e-06,
      "loss": 0.5256,
      "step": 1814
    },
    {
      "epoch": 0.13,
      "grad_norm": 4.939311723776173,
      "learning_rate": 9.759440719599074e-06,
      "loss": 0.537,
      "step": 1815
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.584717022448058,
      "learning_rate": 9.75909553527907e-06,
      "loss": 0.5106,
      "step": 1816
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.3136555153924494,
      "learning_rate": 9.758750109593255e-06,
      "loss": 0.5271,
      "step": 1817
    },
    {
      "epoch": 0.13,
      "grad_norm": 3.1411496659504814,
      "learning_rate": 9.758404442559149e-06,
      "loss": 0.598,
      "step": 1818
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.9260726418147742,
      "learning_rate": 9.758058534194283e-06,
      "loss": 0.5425,
      "step": 1819
    },
    {
      "epoch": 0.13,
      "grad_norm": 6.269982390620439,
      "learning_rate": 9.757712384516201e-06,
      "loss": 0.5146,
      "step": 1820
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.7892421332887511,
      "learning_rate": 9.757365993542457e-06,
      "loss": 0.5199,
      "step": 1821
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.115682374523062,
      "learning_rate": 9.757019361290621e-06,
      "loss": 0.5798,
      "step": 1822
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.0340293462232455,
      "learning_rate": 9.75667248777827e-06,
      "loss": 0.5436,
      "step": 1823
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.322634982072362,
      "learning_rate": 9.756325373023002e-06,
      "loss": 0.5456,
      "step": 1824
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.8536889004172217,
      "learning_rate": 9.755978017042414e-06,
      "loss": 0.5443,
      "step": 1825
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.7132002712412935,
      "learning_rate": 9.755630419854126e-06,
      "loss": 0.5678,
      "step": 1826
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.5666990170222848,
      "learning_rate": 9.755282581475769e-06,
      "loss": 0.5527,
      "step": 1827
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.977100798075492,
      "learning_rate": 9.754934501924982e-06,
      "loss": 0.5307,
      "step": 1828
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.9168260456489669,
      "learning_rate": 9.754586181219419e-06,
      "loss": 0.486,
      "step": 1829
    },
    {
      "epoch": 0.13,
      "grad_norm": 6.882522335253708,
      "learning_rate": 9.754237619376746e-06,
      "loss": 0.5902,
      "step": 1830
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.212497090089515,
      "learning_rate": 9.753888816414641e-06,
      "loss": 0.5717,
      "step": 1831
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.0931846980153743,
      "learning_rate": 9.753539772350792e-06,
      "loss": 0.5179,
      "step": 1832
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.7486788580823505,
      "learning_rate": 9.753190487202903e-06,
      "loss": 0.5703,
      "step": 1833
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.9808471300829649,
      "learning_rate": 9.752840960988693e-06,
      "loss": 0.6097,
      "step": 1834
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.623236055082657,
      "learning_rate": 9.75249119372588e-06,
      "loss": 0.5485,
      "step": 1835
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.9464198008241034,
      "learning_rate": 9.75214118543221e-06,
      "loss": 0.5519,
      "step": 1836
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.952013987386057,
      "learning_rate": 9.751790936125431e-06,
      "loss": 0.5437,
      "step": 1837
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.1556693185748657,
      "learning_rate": 9.751440445823309e-06,
      "loss": 0.5212,
      "step": 1838
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.109802397628861,
      "learning_rate": 9.751089714543615e-06,
      "loss": 0.5684,
      "step": 1839
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.052143487844333,
      "learning_rate": 9.750738742304144e-06,
      "loss": 0.5003,
      "step": 1840
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.120080605333021,
      "learning_rate": 9.750387529122688e-06,
      "loss": 0.5145,
      "step": 1841
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.3365177620750637,
      "learning_rate": 9.750036075017068e-06,
      "loss": 0.546,
      "step": 1842
    },
    {
      "epoch": 0.13,
      "grad_norm": 6.329193977914971,
      "learning_rate": 9.749684380005101e-06,
      "loss": 0.5524,
      "step": 1843
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.992905589641691,
      "learning_rate": 9.749332444104628e-06,
      "loss": 0.557,
      "step": 1844
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.9980973184478767,
      "learning_rate": 9.7489802673335e-06,
      "loss": 0.5377,
      "step": 1845
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.2653726095704916,
      "learning_rate": 9.748627849709572e-06,
      "loss": 0.5222,
      "step": 1846
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.8621662492038042,
      "learning_rate": 9.748275191250722e-06,
      "loss": 0.6086,
      "step": 1847
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.7946307883234904,
      "learning_rate": 9.747922291974834e-06,
      "loss": 0.5371,
      "step": 1848
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.8201401134981987,
      "learning_rate": 9.747569151899807e-06,
      "loss": 0.5471,
      "step": 1849
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.1297234557144513,
      "learning_rate": 9.747215771043551e-06,
      "loss": 0.5369,
      "step": 1850
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.1546141146801476,
      "learning_rate": 9.746862149423989e-06,
      "loss": 0.5703,
      "step": 1851
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.0614024098761083,
      "learning_rate": 9.746508287059052e-06,
      "loss": 0.5466,
      "step": 1852
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.1853875115519705,
      "learning_rate": 9.74615418396669e-06,
      "loss": 0.5756,
      "step": 1853
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.0153257944796072,
      "learning_rate": 9.74579984016486e-06,
      "loss": 0.5383,
      "step": 1854
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.385769849496136,
      "learning_rate": 9.745445255671538e-06,
      "loss": 0.515,
      "step": 1855
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.9401579030916465,
      "learning_rate": 9.7450904305047e-06,
      "loss": 0.5009,
      "step": 1856
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.0864164242567593,
      "learning_rate": 9.744735364682347e-06,
      "loss": 0.5489,
      "step": 1857
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.701581504883273,
      "learning_rate": 9.744380058222483e-06,
      "loss": 0.5738,
      "step": 1858
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.7611171023575025,
      "learning_rate": 9.744024511143132e-06,
      "loss": 0.5229,
      "step": 1859
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.116338035547894,
      "learning_rate": 9.743668723462325e-06,
      "loss": 0.5389,
      "step": 1860
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.1032868210230964,
      "learning_rate": 9.743312695198102e-06,
      "loss": 0.5414,
      "step": 1861
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.210084070311228,
      "learning_rate": 9.742956426368526e-06,
      "loss": 0.506,
      "step": 1862
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.9339868940197766,
      "learning_rate": 9.742599916991663e-06,
      "loss": 0.5707,
      "step": 1863
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.5797320285195215,
      "learning_rate": 9.742243167085593e-06,
      "loss": 0.5696,
      "step": 1864
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.4391140164169376,
      "learning_rate": 9.741886176668412e-06,
      "loss": 0.5248,
      "step": 1865
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.092043108353351,
      "learning_rate": 9.74152894575822e-06,
      "loss": 0.5648,
      "step": 1866
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.059892280393306,
      "learning_rate": 9.741171474373141e-06,
      "loss": 0.602,
      "step": 1867
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.6714937503721041,
      "learning_rate": 9.740813762531301e-06,
      "loss": 0.5352,
      "step": 1868
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.734287406039984,
      "learning_rate": 9.740455810250844e-06,
      "loss": 0.5247,
      "step": 1869
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.9155629706253792,
      "learning_rate": 9.740097617549921e-06,
      "loss": 0.5449,
      "step": 1870
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.1074449215444555,
      "learning_rate": 9.739739184446702e-06,
      "loss": 0.5885,
      "step": 1871
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.6220340855677877,
      "learning_rate": 9.739380510959365e-06,
      "loss": 0.5155,
      "step": 1872
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.0548903946967496,
      "learning_rate": 9.739021597106098e-06,
      "loss": 0.4823,
      "step": 1873
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.914827730852565,
      "learning_rate": 9.738662442905105e-06,
      "loss": 0.4778,
      "step": 1874
    },
    {
      "epoch": 0.13,
      "grad_norm": 4.093582668872411,
      "learning_rate": 9.738303048374605e-06,
      "loss": 0.5747,
      "step": 1875
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.060781561016481,
      "learning_rate": 9.73794341353282e-06,
      "loss": 0.5431,
      "step": 1876
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.73806976331906,
      "learning_rate": 9.73758353839799e-06,
      "loss": 0.5541,
      "step": 1877
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.7056343506991947,
      "learning_rate": 9.73722342298837e-06,
      "loss": 0.4807,
      "step": 1878
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.4674713969251645,
      "learning_rate": 9.736863067322223e-06,
      "loss": 0.5654,
      "step": 1879
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.9467855747173153,
      "learning_rate": 9.736502471417823e-06,
      "loss": 0.53,
      "step": 1880
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.7509229597636515,
      "learning_rate": 9.73614163529346e-06,
      "loss": 0.5662,
      "step": 1881
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.850330918565264,
      "learning_rate": 9.735780558967434e-06,
      "loss": 0.5553,
      "step": 1882
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.075149225413762,
      "learning_rate": 9.735419242458059e-06,
      "loss": 0.506,
      "step": 1883
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.57894761421134,
      "learning_rate": 9.735057685783656e-06,
      "loss": 0.527,
      "step": 1884
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.1479382211521103,
      "learning_rate": 9.734695888962567e-06,
      "loss": 0.5119,
      "step": 1885
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.7625789082376186,
      "learning_rate": 9.734333852013136e-06,
      "loss": 0.5122,
      "step": 1886
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.0488199762922727,
      "learning_rate": 9.733971574953726e-06,
      "loss": 0.5526,
      "step": 1887
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.005003880169423,
      "learning_rate": 9.733609057802715e-06,
      "loss": 0.5558,
      "step": 1888
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.448193016620186,
      "learning_rate": 9.733246300578482e-06,
      "loss": 0.5504,
      "step": 1889
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.0170219705736718,
      "learning_rate": 9.73288330329943e-06,
      "loss": 0.4911,
      "step": 1890
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.8986803704943747,
      "learning_rate": 9.732520065983967e-06,
      "loss": 0.5231,
      "step": 1891
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.381047502938407,
      "learning_rate": 9.732156588650511e-06,
      "loss": 0.5043,
      "step": 1892
    },
    {
      "epoch": 0.13,
      "grad_norm": 5.570993126682041,
      "learning_rate": 9.731792871317504e-06,
      "loss": 0.5349,
      "step": 1893
    },
    {
      "epoch": 0.13,
      "grad_norm": 3.393583170483353,
      "learning_rate": 9.73142891400339e-06,
      "loss": 0.5637,
      "step": 1894
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.7952311626596631,
      "learning_rate": 9.731064716726626e-06,
      "loss": 0.4582,
      "step": 1895
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.7741598498030524,
      "learning_rate": 9.730700279505683e-06,
      "loss": 0.5538,
      "step": 1896
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.9495077031601482,
      "learning_rate": 9.730335602359044e-06,
      "loss": 0.5682,
      "step": 1897
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.7868210746966933,
      "learning_rate": 9.729970685305207e-06,
      "loss": 0.5046,
      "step": 1898
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.731186359524959,
      "learning_rate": 9.729605528362677e-06,
      "loss": 0.4899,
      "step": 1899
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.1896593939202935,
      "learning_rate": 9.729240131549973e-06,
      "loss": 0.5217,
      "step": 1900
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.7121550008112258,
      "learning_rate": 9.72887449488563e-06,
      "loss": 0.501,
      "step": 1901
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.8279405973735516,
      "learning_rate": 9.728508618388186e-06,
      "loss": 0.5619,
      "step": 1902
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.9895045561244717,
      "learning_rate": 9.728142502076204e-06,
      "loss": 0.5429,
      "step": 1903
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.872531051899939,
      "learning_rate": 9.727776145968246e-06,
      "loss": 0.5244,
      "step": 1904
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.6895994124323517,
      "learning_rate": 9.727409550082899e-06,
      "loss": 0.4939,
      "step": 1905
    },
    {
      "epoch": 0.13,
      "grad_norm": 3.8570123878123277,
      "learning_rate": 9.727042714438749e-06,
      "loss": 0.5992,
      "step": 1906
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.001877365116875,
      "learning_rate": 9.726675639054403e-06,
      "loss": 0.5865,
      "step": 1907
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.9054357806150201,
      "learning_rate": 9.726308323948481e-06,
      "loss": 0.4453,
      "step": 1908
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.7637569760162803,
      "learning_rate": 9.725940769139608e-06,
      "loss": 0.5083,
      "step": 1909
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.0529800432525818,
      "learning_rate": 9.725572974646427e-06,
      "loss": 0.5332,
      "step": 1910
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.7641383743063868,
      "learning_rate": 9.725204940487592e-06,
      "loss": 0.4995,
      "step": 1911
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.9350897242677905,
      "learning_rate": 9.724836666681764e-06,
      "loss": 0.53,
      "step": 1912
    },
    {
      "epoch": 0.13,
      "grad_norm": 4.75084633117827,
      "learning_rate": 9.724468153247627e-06,
      "loss": 0.5634,
      "step": 1913
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.7762656983321723,
      "learning_rate": 9.724099400203868e-06,
      "loss": 0.5257,
      "step": 1914
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.7983810316030062,
      "learning_rate": 9.723730407569188e-06,
      "loss": 0.5061,
      "step": 1915
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.6817636446582043,
      "learning_rate": 9.723361175362302e-06,
      "loss": 0.5427,
      "step": 1916
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.8194476338229123,
      "learning_rate": 9.722991703601936e-06,
      "loss": 0.4707,
      "step": 1917
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.3672482451893377,
      "learning_rate": 9.72262199230683e-06,
      "loss": 0.59,
      "step": 1918
    },
    {
      "epoch": 0.13,
      "grad_norm": 4.23996914377455,
      "learning_rate": 9.722252041495733e-06,
      "loss": 0.5563,
      "step": 1919
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.928539973192705,
      "learning_rate": 9.721881851187406e-06,
      "loss": 0.5388,
      "step": 1920
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.7191489626035705,
      "learning_rate": 9.721511421400626e-06,
      "loss": 0.4531,
      "step": 1921
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.9333034554113337,
      "learning_rate": 9.721140752154182e-06,
      "loss": 0.531,
      "step": 1922
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.3445792662933247,
      "learning_rate": 9.720769843466868e-06,
      "loss": 0.5443,
      "step": 1923
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.564708302270321,
      "learning_rate": 9.7203986953575e-06,
      "loss": 0.5716,
      "step": 1924
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.8401639366090816,
      "learning_rate": 9.7200273078449e-06,
      "loss": 0.5888,
      "step": 1925
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.8708034777723461,
      "learning_rate": 9.7196556809479e-06,
      "loss": 0.552,
      "step": 1926
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.3789197903884975,
      "learning_rate": 9.719283814685354e-06,
      "loss": 0.5849,
      "step": 1927
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.7687345522006104,
      "learning_rate": 9.718911709076118e-06,
      "loss": 0.5904,
      "step": 1928
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.798417138020582,
      "learning_rate": 9.718539364139066e-06,
      "loss": 0.5319,
      "step": 1929
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.4300771962746883,
      "learning_rate": 9.718166779893077e-06,
      "loss": 0.5531,
      "step": 1930
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.7413435263268453,
      "learning_rate": 9.717793956357055e-06,
      "loss": 0.5579,
      "step": 1931
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.380597183585833,
      "learning_rate": 9.717420893549902e-06,
      "loss": 0.5534,
      "step": 1932
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.9812199641991677,
      "learning_rate": 9.717047591490541e-06,
      "loss": 0.5283,
      "step": 1933
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.790861939512139,
      "learning_rate": 9.716674050197905e-06,
      "loss": 0.5236,
      "step": 1934
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.847854460812794,
      "learning_rate": 9.716300269690939e-06,
      "loss": 0.5209,
      "step": 1935
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.1791686006852196,
      "learning_rate": 9.715926249988599e-06,
      "loss": 0.5307,
      "step": 1936
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.0711145997265277,
      "learning_rate": 9.715551991109855e-06,
      "loss": 0.5653,
      "step": 1937
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.002696393562356,
      "learning_rate": 9.715177493073686e-06,
      "loss": 0.5976,
      "step": 1938
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.3866723657162834,
      "learning_rate": 9.71480275589909e-06,
      "loss": 0.5622,
      "step": 1939
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.785230207539827,
      "learning_rate": 9.714427779605066e-06,
      "loss": 0.577,
      "step": 1940
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.7325359479719675,
      "learning_rate": 9.714052564210636e-06,
      "loss": 0.5622,
      "step": 1941
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.0567346849832284,
      "learning_rate": 9.71367710973483e-06,
      "loss": 0.5359,
      "step": 1942
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.9664933789275911,
      "learning_rate": 9.713301416196686e-06,
      "loss": 0.5408,
      "step": 1943
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.003003697063451,
      "learning_rate": 9.71292548361526e-06,
      "loss": 0.5492,
      "step": 1944
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.8431653276146818,
      "learning_rate": 9.712549312009622e-06,
      "loss": 0.5907,
      "step": 1945
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.0325416179976314,
      "learning_rate": 9.712172901398844e-06,
      "loss": 0.4991,
      "step": 1946
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.8187962084393317,
      "learning_rate": 9.71179625180202e-06,
      "loss": 0.6141,
      "step": 1947
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.2265826941070923,
      "learning_rate": 9.711419363238252e-06,
      "loss": 0.5209,
      "step": 1948
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.8383751710914105,
      "learning_rate": 9.711042235726652e-06,
      "loss": 0.5317,
      "step": 1949
    },
    {
      "epoch": 0.14,
      "grad_norm": 3.092124623486077,
      "learning_rate": 9.710664869286351e-06,
      "loss": 0.542,
      "step": 1950
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.9552555104448683,
      "learning_rate": 9.710287263936485e-06,
      "loss": 0.5582,
      "step": 1951
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.8349724912274348,
      "learning_rate": 9.709909419696204e-06,
      "loss": 0.5062,
      "step": 1952
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.9208577660288053,
      "learning_rate": 9.709531336584675e-06,
      "loss": 0.5331,
      "step": 1953
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.8197816937505042,
      "learning_rate": 9.709153014621066e-06,
      "loss": 0.5306,
      "step": 1954
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.4550346860864383,
      "learning_rate": 9.708774453824573e-06,
      "loss": 0.5278,
      "step": 1955
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.1499079605788833,
      "learning_rate": 9.70839565421439e-06,
      "loss": 0.5521,
      "step": 1956
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.1352205402365,
      "learning_rate": 9.70801661580973e-06,
      "loss": 0.5513,
      "step": 1957
    },
    {
      "epoch": 0.14,
      "grad_norm": 54.18547637222753,
      "learning_rate": 9.707637338629816e-06,
      "loss": 0.5331,
      "step": 1958
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.4178674381582734,
      "learning_rate": 9.707257822693883e-06,
      "loss": 0.5544,
      "step": 1959
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.8618209022454242,
      "learning_rate": 9.70687806802118e-06,
      "loss": 0.4709,
      "step": 1960
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.9867315916184112,
      "learning_rate": 9.706498074630967e-06,
      "loss": 0.544,
      "step": 1961
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.160407390115068,
      "learning_rate": 9.706117842542517e-06,
      "loss": 0.5463,
      "step": 1962
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.149748171164675,
      "learning_rate": 9.705737371775112e-06,
      "loss": 0.5401,
      "step": 1963
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.1601211718061144,
      "learning_rate": 9.705356662348048e-06,
      "loss": 0.5047,
      "step": 1964
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.6975253842030236,
      "learning_rate": 9.704975714280636e-06,
      "loss": 0.5434,
      "step": 1965
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.052613585331451,
      "learning_rate": 9.704594527592195e-06,
      "loss": 0.4956,
      "step": 1966
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.9270082972044866,
      "learning_rate": 9.704213102302056e-06,
      "loss": 0.5506,
      "step": 1967
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.045769137011829,
      "learning_rate": 9.703831438429564e-06,
      "loss": 0.5233,
      "step": 1968
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.255386583957975,
      "learning_rate": 9.70344953599408e-06,
      "loss": 0.5231,
      "step": 1969
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.9138173184860743,
      "learning_rate": 9.703067395014969e-06,
      "loss": 0.5193,
      "step": 1970
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.228808243701537,
      "learning_rate": 9.702685015511611e-06,
      "loss": 0.5502,
      "step": 1971
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.060470507999331,
      "learning_rate": 9.702302397503401e-06,
      "loss": 0.5104,
      "step": 1972
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.906511622279965,
      "learning_rate": 9.701919541009745e-06,
      "loss": 0.4745,
      "step": 1973
    },
    {
      "epoch": 0.14,
      "grad_norm": 3.158305769304931,
      "learning_rate": 9.701536446050058e-06,
      "loss": 0.5495,
      "step": 1974
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.7705754986170787,
      "learning_rate": 9.70115311264377e-06,
      "loss": 0.5706,
      "step": 1975
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.9130393268278225,
      "learning_rate": 9.700769540810324e-06,
      "loss": 0.5291,
      "step": 1976
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.6454601262091404,
      "learning_rate": 9.700385730569171e-06,
      "loss": 0.5457,
      "step": 1977
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.738427860679822,
      "learning_rate": 9.70000168193978e-06,
      "loss": 0.444,
      "step": 1978
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.936188096211836,
      "learning_rate": 9.699617394941623e-06,
      "loss": 0.4946,
      "step": 1979
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.4716604432988922,
      "learning_rate": 9.699232869594196e-06,
      "loss": 0.547,
      "step": 1980
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.6491170077580766,
      "learning_rate": 9.698848105916998e-06,
      "loss": 0.5368,
      "step": 1981
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.7287481307302028,
      "learning_rate": 9.698463103929542e-06,
      "loss": 0.5188,
      "step": 1982
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.8570876518582793,
      "learning_rate": 9.698077863651356e-06,
      "loss": 0.5216,
      "step": 1983
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.3887213964958294,
      "learning_rate": 9.697692385101978e-06,
      "loss": 0.5603,
      "step": 1984
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.5588378491757,
      "learning_rate": 9.697306668300958e-06,
      "loss": 0.5024,
      "step": 1985
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.8532007328243745,
      "learning_rate": 9.696920713267856e-06,
      "loss": 0.5667,
      "step": 1986
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.121748407683628,
      "learning_rate": 9.69653452002225e-06,
      "loss": 0.5395,
      "step": 1987
    },
    {
      "epoch": 0.14,
      "grad_norm": 3.2174328853034027,
      "learning_rate": 9.696148088583724e-06,
      "loss": 0.5111,
      "step": 1988
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.8745509515534509,
      "learning_rate": 9.695761418971875e-06,
      "loss": 0.5875,
      "step": 1989
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.3905373717298293,
      "learning_rate": 9.69537451120632e-06,
      "loss": 0.5262,
      "step": 1990
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.1196144855135493,
      "learning_rate": 9.694987365306676e-06,
      "loss": 0.552,
      "step": 1991
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.9165396772803351,
      "learning_rate": 9.694599981292578e-06,
      "loss": 0.5232,
      "step": 1992
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.9880131842704825,
      "learning_rate": 9.694212359183676e-06,
      "loss": 0.5518,
      "step": 1993
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.040409189694825,
      "learning_rate": 9.693824498999626e-06,
      "loss": 0.5266,
      "step": 1994
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.2901516968868214,
      "learning_rate": 9.693436400760101e-06,
      "loss": 0.5121,
      "step": 1995
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.9013396841204733,
      "learning_rate": 9.693048064484782e-06,
      "loss": 0.5415,
      "step": 1996
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.457168392435902,
      "learning_rate": 9.692659490193366e-06,
      "loss": 0.5082,
      "step": 1997
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.795594552386776,
      "learning_rate": 9.69227067790556e-06,
      "loss": 0.5542,
      "step": 1998
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.1101909607547937,
      "learning_rate": 9.691881627641083e-06,
      "loss": 0.595,
      "step": 1999
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.4284328684612637,
      "learning_rate": 9.691492339419666e-06,
      "loss": 0.5161,
      "step": 2000
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.4467115744037606,
      "learning_rate": 9.691102813261052e-06,
      "loss": 0.5697,
      "step": 2001
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.5029715638729098,
      "learning_rate": 9.690713049184998e-06,
      "loss": 0.5467,
      "step": 2002
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.9398866837312675,
      "learning_rate": 9.690323047211273e-06,
      "loss": 0.4826,
      "step": 2003
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.1733472186986895,
      "learning_rate": 9.68993280735965e-06,
      "loss": 0.5531,
      "step": 2004
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.621560919181662,
      "learning_rate": 9.689542329649928e-06,
      "loss": 0.5479,
      "step": 2005
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.9059574580374214,
      "learning_rate": 9.689151614101905e-06,
      "loss": 0.5045,
      "step": 2006
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.945343590142604,
      "learning_rate": 9.688760660735403e-06,
      "loss": 0.5733,
      "step": 2007
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.9076975520741186,
      "learning_rate": 9.688369469570245e-06,
      "loss": 0.5276,
      "step": 2008
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.88615280789566,
      "learning_rate": 9.687978040626273e-06,
      "loss": 0.5771,
      "step": 2009
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.7491030500419478,
      "learning_rate": 9.687586373923339e-06,
      "loss": 0.5175,
      "step": 2010
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.136866410031372,
      "learning_rate": 9.687194469481304e-06,
      "loss": 0.5233,
      "step": 2011
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.9271983231191556,
      "learning_rate": 9.686802327320049e-06,
      "loss": 0.5116,
      "step": 2012
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.8075224649906199,
      "learning_rate": 9.68640994745946e-06,
      "loss": 0.4981,
      "step": 2013
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.9968969816116096,
      "learning_rate": 9.686017329919435e-06,
      "loss": 0.5746,
      "step": 2014
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.963509636924207,
      "learning_rate": 9.685624474719888e-06,
      "loss": 0.5268,
      "step": 2015
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.2797473952420746,
      "learning_rate": 9.685231381880747e-06,
      "loss": 0.5409,
      "step": 2016
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.420613090495884,
      "learning_rate": 9.68483805142194e-06,
      "loss": 0.5632,
      "step": 2017
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.2040477333579545,
      "learning_rate": 9.684444483363424e-06,
      "loss": 0.5284,
      "step": 2018
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.8535434985042998,
      "learning_rate": 9.684050677725157e-06,
      "loss": 0.4817,
      "step": 2019
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.6857618481062822,
      "learning_rate": 9.683656634527109e-06,
      "loss": 0.5355,
      "step": 2020
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.8824932488568,
      "learning_rate": 9.683262353789266e-06,
      "loss": 0.5396,
      "step": 2021
    },
    {
      "epoch": 0.14,
      "grad_norm": 3.3154072614972985,
      "learning_rate": 9.682867835531624e-06,
      "loss": 0.5717,
      "step": 2022
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.6594244272043122,
      "learning_rate": 9.682473079774194e-06,
      "loss": 0.5296,
      "step": 2023
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.715782613222258,
      "learning_rate": 9.682078086536994e-06,
      "loss": 0.5062,
      "step": 2024
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.8867728300200595,
      "learning_rate": 9.681682855840057e-06,
      "loss": 0.5268,
      "step": 2025
    },
    {
      "epoch": 0.14,
      "grad_norm": 4.204778529006856,
      "learning_rate": 9.68128738770343e-06,
      "loss": 0.5039,
      "step": 2026
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.8384344722543478,
      "learning_rate": 9.68089168214717e-06,
      "loss": 0.4712,
      "step": 2027
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.5343280425949555,
      "learning_rate": 9.680495739191343e-06,
      "loss": 0.5563,
      "step": 2028
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.1645021717180213,
      "learning_rate": 9.680099558856031e-06,
      "loss": 0.5637,
      "step": 2029
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.3443810892359775,
      "learning_rate": 9.679703141161327e-06,
      "loss": 0.5603,
      "step": 2030
    },
    {
      "epoch": 0.14,
      "grad_norm": 3.2222938536498633,
      "learning_rate": 9.679306486127339e-06,
      "loss": 0.5588,
      "step": 2031
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.305431148453664,
      "learning_rate": 9.67890959377418e-06,
      "loss": 0.5234,
      "step": 2032
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.969816041618507,
      "learning_rate": 9.678512464121978e-06,
      "loss": 0.5289,
      "step": 2033
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.6091713158097587,
      "learning_rate": 9.67811509719088e-06,
      "loss": 0.5578,
      "step": 2034
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.2560291710304567,
      "learning_rate": 9.677717493001035e-06,
      "loss": 0.5452,
      "step": 2035
    },
    {
      "epoch": 0.14,
      "grad_norm": 3.1078333293819433,
      "learning_rate": 9.677319651572607e-06,
      "loss": 0.5508,
      "step": 2036
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.6626666869551143,
      "learning_rate": 9.676921572925777e-06,
      "loss": 0.5623,
      "step": 2037
    },
    {
      "epoch": 0.14,
      "grad_norm": 3.5951840287793897,
      "learning_rate": 9.676523257080733e-06,
      "loss": 0.504,
      "step": 2038
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.8793665285598242,
      "learning_rate": 9.676124704057675e-06,
      "loss": 0.5192,
      "step": 2039
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.753676580230927,
      "learning_rate": 9.675725913876816e-06,
      "loss": 0.4567,
      "step": 2040
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.5915132123810214,
      "learning_rate": 9.675326886558384e-06,
      "loss": 0.5684,
      "step": 2041
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.349693435047009,
      "learning_rate": 9.674927622122615e-06,
      "loss": 0.5133,
      "step": 2042
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.7437947981263109,
      "learning_rate": 9.674528120589757e-06,
      "loss": 0.4692,
      "step": 2043
    },
    {
      "epoch": 0.14,
      "grad_norm": 3.00577309612556,
      "learning_rate": 9.674128381980073e-06,
      "loss": 0.5566,
      "step": 2044
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.766914453415292,
      "learning_rate": 9.673728406313836e-06,
      "loss": 0.5584,
      "step": 2045
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.8922254172108322,
      "learning_rate": 9.673328193611331e-06,
      "loss": 0.5625,
      "step": 2046
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.081551150227096,
      "learning_rate": 9.672927743892856e-06,
      "loss": 0.5662,
      "step": 2047
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.591352411612249,
      "learning_rate": 9.672527057178722e-06,
      "loss": 0.5728,
      "step": 2048
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.6826332559882295,
      "learning_rate": 9.672126133489248e-06,
      "loss": 0.5729,
      "step": 2049
    },
    {
      "epoch": 0.14,
      "grad_norm": 3.921103212958636,
      "learning_rate": 9.671724972844767e-06,
      "loss": 0.5172,
      "step": 2050
    },
    {
      "epoch": 0.14,
      "grad_norm": 3.7093140563591276,
      "learning_rate": 9.671323575265628e-06,
      "loss": 0.5271,
      "step": 2051
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.6688132838772278,
      "learning_rate": 9.670921940772186e-06,
      "loss": 0.4998,
      "step": 2052
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.9540589935152823,
      "learning_rate": 9.67052006938481e-06,
      "loss": 0.5407,
      "step": 2053
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.9175204919774904,
      "learning_rate": 9.670117961123885e-06,
      "loss": 0.5642,
      "step": 2054
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.3411782289911427,
      "learning_rate": 9.6697156160098e-06,
      "loss": 0.4983,
      "step": 2055
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.8032586196140211,
      "learning_rate": 9.669313034062965e-06,
      "loss": 0.4844,
      "step": 2056
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.938642949225432,
      "learning_rate": 9.668910215303797e-06,
      "loss": 0.5298,
      "step": 2057
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.9525270822433547,
      "learning_rate": 9.668507159752723e-06,
      "loss": 0.503,
      "step": 2058
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.9053376802452298,
      "learning_rate": 9.668103867430185e-06,
      "loss": 0.562,
      "step": 2059
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.8521467068006356,
      "learning_rate": 9.667700338356639e-06,
      "loss": 0.5233,
      "step": 2060
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.329627967102577,
      "learning_rate": 9.66729657255255e-06,
      "loss": 0.5541,
      "step": 2061
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.8653352423965306,
      "learning_rate": 9.666892570038393e-06,
      "loss": 0.5042,
      "step": 2062
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.0488903867705575,
      "learning_rate": 9.66648833083466e-06,
      "loss": 0.5285,
      "step": 2063
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.666289277220617,
      "learning_rate": 9.666083854961854e-06,
      "loss": 0.5538,
      "step": 2064
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.265675772221956,
      "learning_rate": 9.665679142440488e-06,
      "loss": 0.5669,
      "step": 2065
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.391706605802923,
      "learning_rate": 9.665274193291085e-06,
      "loss": 0.4982,
      "step": 2066
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.519400592151696,
      "learning_rate": 9.664869007534185e-06,
      "loss": 0.5605,
      "step": 2067
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.9991530913168103,
      "learning_rate": 9.664463585190338e-06,
      "loss": 0.5603,
      "step": 2068
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.565684422759398,
      "learning_rate": 9.664057926280103e-06,
      "loss": 0.5239,
      "step": 2069
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.974384206878022,
      "learning_rate": 9.663652030824058e-06,
      "loss": 0.5414,
      "step": 2070
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.9529137207230818,
      "learning_rate": 9.663245898842785e-06,
      "loss": 0.5468,
      "step": 2071
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.563831686849615,
      "learning_rate": 9.662839530356883e-06,
      "loss": 0.5556,
      "step": 2072
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.7678748581881096,
      "learning_rate": 9.662432925386963e-06,
      "loss": 0.5738,
      "step": 2073
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.459039782213048,
      "learning_rate": 9.662026083953645e-06,
      "loss": 0.5075,
      "step": 2074
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.7370359864440412,
      "learning_rate": 9.661619006077562e-06,
      "loss": 0.5652,
      "step": 2075
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.8966606601304394,
      "learning_rate": 9.661211691779362e-06,
      "loss": 0.51,
      "step": 2076
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.3409616963907776,
      "learning_rate": 9.6608041410797e-06,
      "loss": 0.5316,
      "step": 2077
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.975779856609368,
      "learning_rate": 9.660396353999249e-06,
      "loss": 0.5233,
      "step": 2078
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.9289925590461177,
      "learning_rate": 9.659988330558686e-06,
      "loss": 0.5225,
      "step": 2079
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.7657471149615676,
      "learning_rate": 9.659580070778708e-06,
      "loss": 0.5386,
      "step": 2080
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.055109376851268,
      "learning_rate": 9.659171574680023e-06,
      "loss": 0.5316,
      "step": 2081
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.100097775773642,
      "learning_rate": 9.658762842283343e-06,
      "loss": 0.5056,
      "step": 2082
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.474473154900393,
      "learning_rate": 9.6583538736094e-06,
      "loss": 0.5557,
      "step": 2083
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.224023769601654,
      "learning_rate": 9.657944668678937e-06,
      "loss": 0.5257,
      "step": 2084
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.908109347835223,
      "learning_rate": 9.657535227512705e-06,
      "loss": 0.5257,
      "step": 2085
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7637397622845212,
      "learning_rate": 9.657125550131471e-06,
      "loss": 0.4757,
      "step": 2086
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.137363575493366,
      "learning_rate": 9.656715636556012e-06,
      "loss": 0.5708,
      "step": 2087
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.85096749975204,
      "learning_rate": 9.656305486807119e-06,
      "loss": 0.5197,
      "step": 2088
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.2651587171161114,
      "learning_rate": 9.65589510090559e-06,
      "loss": 0.5129,
      "step": 2089
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.9168392064635007,
      "learning_rate": 9.65548447887224e-06,
      "loss": 0.5338,
      "step": 2090
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.9553397985878134,
      "learning_rate": 9.655073620727898e-06,
      "loss": 0.5858,
      "step": 2091
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.2677772422089513,
      "learning_rate": 9.654662526493397e-06,
      "loss": 0.503,
      "step": 2092
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.0469253405361933,
      "learning_rate": 9.654251196189588e-06,
      "loss": 0.526,
      "step": 2093
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.7642379772278536,
      "learning_rate": 9.653839629837332e-06,
      "loss": 0.5258,
      "step": 2094
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.6376915583727087,
      "learning_rate": 9.653427827457503e-06,
      "loss": 0.5236,
      "step": 2095
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.0933401148579622,
      "learning_rate": 9.653015789070982e-06,
      "loss": 0.5617,
      "step": 2096
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.07655326249994,
      "learning_rate": 9.652603514698674e-06,
      "loss": 0.5369,
      "step": 2097
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.8448284924723604,
      "learning_rate": 9.652191004361482e-06,
      "loss": 0.5398,
      "step": 2098
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.7167327892200792,
      "learning_rate": 9.65177825808033e-06,
      "loss": 0.5091,
      "step": 2099
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.7463669006122513,
      "learning_rate": 9.65136527587615e-06,
      "loss": 0.5253,
      "step": 2100
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.8465876610425523,
      "learning_rate": 9.650952057769888e-06,
      "loss": 0.4437,
      "step": 2101
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.069597808035019,
      "learning_rate": 9.650538603782502e-06,
      "loss": 0.5217,
      "step": 2102
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.91718475782631,
      "learning_rate": 9.650124913934957e-06,
      "loss": 0.5748,
      "step": 2103
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.684502904076278,
      "learning_rate": 9.649710988248238e-06,
      "loss": 0.4999,
      "step": 2104
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7800672113954725,
      "learning_rate": 9.649296826743337e-06,
      "loss": 0.4583,
      "step": 2105
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.4129301966754966,
      "learning_rate": 9.648882429441258e-06,
      "loss": 0.5854,
      "step": 2106
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.062890219714792,
      "learning_rate": 9.648467796363019e-06,
      "loss": 0.5289,
      "step": 2107
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.727782524359102,
      "learning_rate": 9.648052927529648e-06,
      "loss": 0.501,
      "step": 2108
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.9089476174866387,
      "learning_rate": 9.647637822962184e-06,
      "loss": 0.5521,
      "step": 2109
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.8048010056019654,
      "learning_rate": 9.647222482681684e-06,
      "loss": 0.5329,
      "step": 2110
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.730667725194674,
      "learning_rate": 9.646806906709209e-06,
      "loss": 0.5262,
      "step": 2111
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.449279895797764,
      "learning_rate": 9.646391095065838e-06,
      "loss": 0.5628,
      "step": 2112
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.16364030644335,
      "learning_rate": 9.64597504777266e-06,
      "loss": 0.5483,
      "step": 2113
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.4209485095794916,
      "learning_rate": 9.645558764850773e-06,
      "loss": 0.5221,
      "step": 2114
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.1813026660161725,
      "learning_rate": 9.645142246321291e-06,
      "loss": 0.4888,
      "step": 2115
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.0689046498808157,
      "learning_rate": 9.644725492205338e-06,
      "loss": 0.6117,
      "step": 2116
    },
    {
      "epoch": 0.15,
      "grad_norm": 3.838992088990584,
      "learning_rate": 9.644308502524052e-06,
      "loss": 0.5176,
      "step": 2117
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.8559447268968627,
      "learning_rate": 9.643891277298578e-06,
      "loss": 0.5626,
      "step": 2118
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.2170647833002297,
      "learning_rate": 9.64347381655008e-06,
      "loss": 0.5398,
      "step": 2119
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.081960677721436,
      "learning_rate": 9.643056120299728e-06,
      "loss": 0.5451,
      "step": 2120
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.7628252936543982,
      "learning_rate": 9.642638188568706e-06,
      "loss": 0.5286,
      "step": 2121
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.933921183811974,
      "learning_rate": 9.642220021378212e-06,
      "loss": 0.533,
      "step": 2122
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.0447862019430003,
      "learning_rate": 9.641801618749454e-06,
      "loss": 0.547,
      "step": 2123
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.2204343385254113,
      "learning_rate": 9.641382980703648e-06,
      "loss": 0.5794,
      "step": 2124
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.948855395283387,
      "learning_rate": 9.640964107262031e-06,
      "loss": 0.5796,
      "step": 2125
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.0759911610370088,
      "learning_rate": 9.640544998445847e-06,
      "loss": 0.4959,
      "step": 2126
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.9886529752539346,
      "learning_rate": 9.640125654276347e-06,
      "loss": 0.4736,
      "step": 2127
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.6307142432346178,
      "learning_rate": 9.639706074774801e-06,
      "loss": 0.5663,
      "step": 2128
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.872453257033376,
      "learning_rate": 9.63928625996249e-06,
      "loss": 0.4957,
      "step": 2129
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.744046082974892,
      "learning_rate": 9.638866209860706e-06,
      "loss": 0.5349,
      "step": 2130
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.3140416255958263,
      "learning_rate": 9.63844592449075e-06,
      "loss": 0.5167,
      "step": 2131
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.004939456142479,
      "learning_rate": 9.638025403873939e-06,
      "loss": 0.6093,
      "step": 2132
    },
    {
      "epoch": 0.15,
      "grad_norm": 5.985475537734871,
      "learning_rate": 9.637604648031603e-06,
      "loss": 0.5189,
      "step": 2133
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.150949280087567,
      "learning_rate": 9.637183656985075e-06,
      "loss": 0.5293,
      "step": 2134
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.8832738867441075,
      "learning_rate": 9.63676243075571e-06,
      "loss": 0.5451,
      "step": 2135
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.9275872589217105,
      "learning_rate": 9.636340969364875e-06,
      "loss": 0.528,
      "step": 2136
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.937795467266014,
      "learning_rate": 9.635919272833938e-06,
      "loss": 0.5535,
      "step": 2137
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.7543784961426037,
      "learning_rate": 9.63549734118429e-06,
      "loss": 0.5252,
      "step": 2138
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.6673766815560334,
      "learning_rate": 9.63507517443733e-06,
      "loss": 0.53,
      "step": 2139
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.950138453069936,
      "learning_rate": 9.634652772614469e-06,
      "loss": 0.5181,
      "step": 2140
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.8693057082380329,
      "learning_rate": 9.634230135737128e-06,
      "loss": 0.6109,
      "step": 2141
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.189727621062554,
      "learning_rate": 9.633807263826745e-06,
      "loss": 0.5229,
      "step": 2142
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.7404980856440482,
      "learning_rate": 9.633384156904762e-06,
      "loss": 0.4897,
      "step": 2143
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.794078710204928,
      "learning_rate": 9.632960814992642e-06,
      "loss": 0.5394,
      "step": 2144
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.6896441537863183,
      "learning_rate": 9.632537238111852e-06,
      "loss": 0.5255,
      "step": 2145
    },
    {
      "epoch": 0.15,
      "grad_norm": 6.3358997775789625,
      "learning_rate": 9.632113426283877e-06,
      "loss": 0.5908,
      "step": 2146
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.9522547674253865,
      "learning_rate": 9.631689379530211e-06,
      "loss": 0.5261,
      "step": 2147
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.568841561856081,
      "learning_rate": 9.63126509787236e-06,
      "loss": 0.5399,
      "step": 2148
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.1123064387422064,
      "learning_rate": 9.630840581331841e-06,
      "loss": 0.5381,
      "step": 2149
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.6388574874571218,
      "learning_rate": 9.630415829930186e-06,
      "loss": 0.5504,
      "step": 2150
    },
    {
      "epoch": 0.15,
      "grad_norm": 3.7176841481916445,
      "learning_rate": 9.629990843688936e-06,
      "loss": 0.5477,
      "step": 2151
    },
    {
      "epoch": 0.15,
      "grad_norm": 3.3380001398978063,
      "learning_rate": 9.629565622629646e-06,
      "loss": 0.4928,
      "step": 2152
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.9496605788983294,
      "learning_rate": 9.62914016677388e-06,
      "loss": 0.5368,
      "step": 2153
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.4241760991509396,
      "learning_rate": 9.628714476143217e-06,
      "loss": 0.5718,
      "step": 2154
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.609224351485709,
      "learning_rate": 9.628288550759246e-06,
      "loss": 0.555,
      "step": 2155
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.2179023884704505,
      "learning_rate": 9.627862390643568e-06,
      "loss": 0.5661,
      "step": 2156
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.551695403233136,
      "learning_rate": 9.627435995817799e-06,
      "loss": 0.5997,
      "step": 2157
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.8989417516873537,
      "learning_rate": 9.627009366303561e-06,
      "loss": 0.5438,
      "step": 2158
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.9245280060221244,
      "learning_rate": 9.626582502122494e-06,
      "loss": 0.5051,
      "step": 2159
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.6399573615361371,
      "learning_rate": 9.626155403296245e-06,
      "loss": 0.4866,
      "step": 2160
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.7660672915422115,
      "learning_rate": 9.625728069846476e-06,
      "loss": 0.5464,
      "step": 2161
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.841574034591464,
      "learning_rate": 9.625300501794862e-06,
      "loss": 0.5277,
      "step": 2162
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.7351086308615828,
      "learning_rate": 9.624872699163084e-06,
      "loss": 0.5099,
      "step": 2163
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.8117822875484104,
      "learning_rate": 9.624444661972841e-06,
      "loss": 0.5295,
      "step": 2164
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.8018810281903646,
      "learning_rate": 9.624016390245841e-06,
      "loss": 0.5282,
      "step": 2165
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.9985574911895756,
      "learning_rate": 9.623587884003804e-06,
      "loss": 0.5379,
      "step": 2166
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.5125838242004295,
      "learning_rate": 9.623159143268466e-06,
      "loss": 0.4791,
      "step": 2167
    },
    {
      "epoch": 0.15,
      "grad_norm": 4.731032761761242,
      "learning_rate": 9.622730168061568e-06,
      "loss": 0.5381,
      "step": 2168
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.637388933659448,
      "learning_rate": 9.622300958404864e-06,
      "loss": 0.54,
      "step": 2169
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.2517553960709926,
      "learning_rate": 9.621871514320128e-06,
      "loss": 0.5625,
      "step": 2170
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.9686255818311615,
      "learning_rate": 9.621441835829135e-06,
      "loss": 0.5207,
      "step": 2171
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.053117937111344,
      "learning_rate": 9.621011922953681e-06,
      "loss": 0.595,
      "step": 2172
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.2965069297013065,
      "learning_rate": 9.620581775715565e-06,
      "loss": 0.5566,
      "step": 2173
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.3365319330858014,
      "learning_rate": 9.620151394136608e-06,
      "loss": 0.5484,
      "step": 2174
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.8648221532535323,
      "learning_rate": 9.619720778238632e-06,
      "loss": 0.5237,
      "step": 2175
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.07730512821483,
      "learning_rate": 9.619289928043481e-06,
      "loss": 0.5074,
      "step": 2176
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.1844179625710187,
      "learning_rate": 9.618858843573004e-06,
      "loss": 0.5315,
      "step": 2177
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.4534428499695538,
      "learning_rate": 9.618427524849066e-06,
      "loss": 0.5286,
      "step": 2178
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.6647552627122857,
      "learning_rate": 9.61799597189354e-06,
      "loss": 0.5744,
      "step": 2179
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.9967830580531671,
      "learning_rate": 9.617564184728313e-06,
      "loss": 0.5257,
      "step": 2180
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.048378182955458,
      "learning_rate": 9.617132163375287e-06,
      "loss": 0.5758,
      "step": 2181
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.3085661457564055,
      "learning_rate": 9.616699907856368e-06,
      "loss": 0.5748,
      "step": 2182
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.9222108452873545,
      "learning_rate": 9.616267418193483e-06,
      "loss": 0.4706,
      "step": 2183
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.8178321010097522,
      "learning_rate": 9.615834694408564e-06,
      "loss": 0.5117,
      "step": 2184
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.7576831412165566,
      "learning_rate": 9.615401736523556e-06,
      "loss": 0.5064,
      "step": 2185
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.0719240317746968,
      "learning_rate": 9.61496854456042e-06,
      "loss": 0.5154,
      "step": 2186
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.8806204347257827,
      "learning_rate": 9.614535118541126e-06,
      "loss": 0.5326,
      "step": 2187
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.3699970126392613,
      "learning_rate": 9.614101458487653e-06,
      "loss": 0.5067,
      "step": 2188
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.168081987028481,
      "learning_rate": 9.613667564421999e-06,
      "loss": 0.5666,
      "step": 2189
    },
    {
      "epoch": 0.15,
      "grad_norm": 4.473300960269736,
      "learning_rate": 9.613233436366167e-06,
      "loss": 0.5017,
      "step": 2190
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.6306439972659232,
      "learning_rate": 9.612799074342174e-06,
      "loss": 0.5133,
      "step": 2191
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.7733397304707614,
      "learning_rate": 9.612364478372051e-06,
      "loss": 0.559,
      "step": 2192
    },
    {
      "epoch": 0.15,
      "grad_norm": 4.93042634236269,
      "learning_rate": 9.61192964847784e-06,
      "loss": 0.5346,
      "step": 2193
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.596605331717657,
      "learning_rate": 9.611494584681591e-06,
      "loss": 0.535,
      "step": 2194
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.8089716430959255,
      "learning_rate": 9.611059287005374e-06,
      "loss": 0.5536,
      "step": 2195
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.6659301149908226,
      "learning_rate": 9.61062375547126e-06,
      "loss": 0.5544,
      "step": 2196
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.9087319469060058,
      "learning_rate": 9.610187990101341e-06,
      "loss": 0.5826,
      "step": 2197
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.7476371023869974,
      "learning_rate": 9.609751990917719e-06,
      "loss": 0.4883,
      "step": 2198
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.7789626314780296,
      "learning_rate": 9.609315757942504e-06,
      "loss": 0.5882,
      "step": 2199
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.7584954456655315,
      "learning_rate": 9.60887929119782e-06,
      "loss": 0.4968,
      "step": 2200
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.048057200917401,
      "learning_rate": 9.608442590705804e-06,
      "loss": 0.5223,
      "step": 2201
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.712329057968216,
      "learning_rate": 9.608005656488605e-06,
      "loss": 0.5742,
      "step": 2202
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.295517579096646,
      "learning_rate": 9.607568488568382e-06,
      "loss": 0.5579,
      "step": 2203
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.1460786424207647,
      "learning_rate": 9.607131086967307e-06,
      "loss": 0.4993,
      "step": 2204
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.779999746200196,
      "learning_rate": 9.606693451707565e-06,
      "loss": 0.5548,
      "step": 2205
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.7271711501971487,
      "learning_rate": 9.606255582811346e-06,
      "loss": 0.5261,
      "step": 2206
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.717194598550813,
      "learning_rate": 9.605817480300863e-06,
      "loss": 0.535,
      "step": 2207
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.523423958356984,
      "learning_rate": 9.605379144198335e-06,
      "loss": 0.4972,
      "step": 2208
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.0226371875205653,
      "learning_rate": 9.604940574525988e-06,
      "loss": 0.527,
      "step": 2209
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.0860115264481576,
      "learning_rate": 9.60450177130607e-06,
      "loss": 0.559,
      "step": 2210
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.5973395028240822,
      "learning_rate": 9.604062734560832e-06,
      "loss": 0.5131,
      "step": 2211
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.762325984541353,
      "learning_rate": 9.603623464312545e-06,
      "loss": 0.5353,
      "step": 2212
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.5487794619609137,
      "learning_rate": 9.603183960583482e-06,
      "loss": 0.5042,
      "step": 2213
    },
    {
      "epoch": 0.15,
      "grad_norm": 3.1538186236646846,
      "learning_rate": 9.602744223395937e-06,
      "loss": 0.5035,
      "step": 2214
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.4231845895909943,
      "learning_rate": 9.602304252772211e-06,
      "loss": 0.55,
      "step": 2215
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.2272679997419793,
      "learning_rate": 9.601864048734617e-06,
      "loss": 0.4985,
      "step": 2216
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.126874262582758,
      "learning_rate": 9.601423611305481e-06,
      "loss": 0.5371,
      "step": 2217
    },
    {
      "epoch": 0.15,
      "grad_norm": 3.5866210636307994,
      "learning_rate": 9.600982940507142e-06,
      "loss": 0.5493,
      "step": 2218
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.0542677213441514,
      "learning_rate": 9.600542036361948e-06,
      "loss": 0.5509,
      "step": 2219
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.8695810090602338,
      "learning_rate": 9.600100898892261e-06,
      "loss": 0.5537,
      "step": 2220
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.966874333237126,
      "learning_rate": 9.599659528120453e-06,
      "loss": 0.5211,
      "step": 2221
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.7457096762885531,
      "learning_rate": 9.59921792406891e-06,
      "loss": 0.4908,
      "step": 2222
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.010204861671206,
      "learning_rate": 9.598776086760026e-06,
      "loss": 0.5189,
      "step": 2223
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.5339778342253485,
      "learning_rate": 9.598334016216214e-06,
      "loss": 0.5397,
      "step": 2224
    },
    {
      "epoch": 0.15,
      "grad_norm": 4.143251578928957,
      "learning_rate": 9.597891712459892e-06,
      "loss": 0.5152,
      "step": 2225
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.228152161652816,
      "learning_rate": 9.597449175513492e-06,
      "loss": 0.5236,
      "step": 2226
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.5474640424102941,
      "learning_rate": 9.597006405399458e-06,
      "loss": 0.5443,
      "step": 2227
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.373825877102182,
      "learning_rate": 9.596563402140246e-06,
      "loss": 0.5565,
      "step": 2228
    },
    {
      "epoch": 0.15,
      "grad_norm": 4.890377849269165,
      "learning_rate": 9.596120165758325e-06,
      "loss": 0.552,
      "step": 2229
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.1862390938698715,
      "learning_rate": 9.595676696276173e-06,
      "loss": 0.5361,
      "step": 2230
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.8907928516398689,
      "learning_rate": 9.595232993716282e-06,
      "loss": 0.5253,
      "step": 2231
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.4814399659145976,
      "learning_rate": 9.594789058101154e-06,
      "loss": 0.5665,
      "step": 2232
    },
    {
      "epoch": 0.16,
      "grad_norm": 4.467794289332015,
      "learning_rate": 9.594344889453305e-06,
      "loss": 0.5512,
      "step": 2233
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.848016367525046,
      "learning_rate": 9.593900487795263e-06,
      "loss": 0.5335,
      "step": 2234
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.178653885512377,
      "learning_rate": 9.593455853149563e-06,
      "loss": 0.5018,
      "step": 2235
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.092745453979571,
      "learning_rate": 9.59301098553876e-06,
      "loss": 0.483,
      "step": 2236
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.7393117394112592,
      "learning_rate": 9.592565884985412e-06,
      "loss": 0.4955,
      "step": 2237
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.138853059963741,
      "learning_rate": 9.592120551512096e-06,
      "loss": 0.5154,
      "step": 2238
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.5679575425567807,
      "learning_rate": 9.591674985141395e-06,
      "loss": 0.5225,
      "step": 2239
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.902880605931828,
      "learning_rate": 9.59122918589591e-06,
      "loss": 0.5675,
      "step": 2240
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.9160382686597492,
      "learning_rate": 9.59078315379825e-06,
      "loss": 0.5752,
      "step": 2241
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.8767178245700644,
      "learning_rate": 9.590336888871034e-06,
      "loss": 0.5112,
      "step": 2242
    },
    {
      "epoch": 0.16,
      "grad_norm": 4.082055573824177,
      "learning_rate": 9.589890391136896e-06,
      "loss": 0.5077,
      "step": 2243
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.6852913885444527,
      "learning_rate": 9.589443660618483e-06,
      "loss": 0.4983,
      "step": 2244
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.7679694901469309,
      "learning_rate": 9.58899669733845e-06,
      "loss": 0.4529,
      "step": 2245
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.7546002924139952,
      "learning_rate": 9.588549501319462e-06,
      "loss": 0.5421,
      "step": 2246
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.318227850555837,
      "learning_rate": 9.588102072584204e-06,
      "loss": 0.5935,
      "step": 2247
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.9571910197768543,
      "learning_rate": 9.58765441115537e-06,
      "loss": 0.5193,
      "step": 2248
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.1538886782898596,
      "learning_rate": 9.587206517055659e-06,
      "loss": 0.5166,
      "step": 2249
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.7955437367274958,
      "learning_rate": 9.586758390307788e-06,
      "loss": 0.5696,
      "step": 2250
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.8485262395895579,
      "learning_rate": 9.586310030934484e-06,
      "loss": 0.5651,
      "step": 2251
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.7413271046817176,
      "learning_rate": 9.58586143895849e-06,
      "loss": 0.5492,
      "step": 2252
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.129169191341089,
      "learning_rate": 9.585412614402554e-06,
      "loss": 0.5573,
      "step": 2253
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.5852877544355772,
      "learning_rate": 9.58496355728944e-06,
      "loss": 0.5339,
      "step": 2254
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.9577480648348482,
      "learning_rate": 9.58451426764192e-06,
      "loss": 0.5125,
      "step": 2255
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.7470714134096,
      "learning_rate": 9.584064745482784e-06,
      "loss": 0.5189,
      "step": 2256
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.008162382933871,
      "learning_rate": 9.58361499083483e-06,
      "loss": 0.5515,
      "step": 2257
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.813978755921256,
      "learning_rate": 9.583165003720866e-06,
      "loss": 0.5399,
      "step": 2258
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.79441601793755,
      "learning_rate": 9.582714784163715e-06,
      "loss": 0.5207,
      "step": 2259
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.8594332475543278,
      "learning_rate": 9.582264332186211e-06,
      "loss": 0.5023,
      "step": 2260
    },
    {
      "epoch": 0.16,
      "grad_norm": 5.082417432536341,
      "learning_rate": 9.581813647811199e-06,
      "loss": 0.5806,
      "step": 2261
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.459539394573272,
      "learning_rate": 9.581362731061537e-06,
      "loss": 0.5501,
      "step": 2262
    },
    {
      "epoch": 0.16,
      "grad_norm": 3.201073533081489,
      "learning_rate": 9.580911581960092e-06,
      "loss": 0.5566,
      "step": 2263
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.577649524362337,
      "learning_rate": 9.580460200529746e-06,
      "loss": 0.5407,
      "step": 2264
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.6936875597469356,
      "learning_rate": 9.580008586793394e-06,
      "loss": 0.5219,
      "step": 2265
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.8088275238075524,
      "learning_rate": 9.579556740773936e-06,
      "loss": 0.5337,
      "step": 2266
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.016544174362351,
      "learning_rate": 9.579104662494293e-06,
      "loss": 0.5404,
      "step": 2267
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.6237988484368495,
      "learning_rate": 9.578652351977386e-06,
      "loss": 0.5204,
      "step": 2268
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.4577630078077126,
      "learning_rate": 9.578199809246162e-06,
      "loss": 0.5283,
      "step": 2269
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.4180951832396125,
      "learning_rate": 9.577747034323569e-06,
      "loss": 0.5723,
      "step": 2270
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.2887675944546464,
      "learning_rate": 9.577294027232571e-06,
      "loss": 0.5431,
      "step": 2271
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.7504673772409957,
      "learning_rate": 9.576840787996142e-06,
      "loss": 0.4607,
      "step": 2272
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.9823452120838914,
      "learning_rate": 9.57638731663727e-06,
      "loss": 0.5385,
      "step": 2273
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.7025977660485139,
      "learning_rate": 9.575933613178954e-06,
      "loss": 0.5381,
      "step": 2274
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.3624527722301725,
      "learning_rate": 9.575479677644202e-06,
      "loss": 0.5504,
      "step": 2275
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.7648652382130596,
      "learning_rate": 9.575025510056038e-06,
      "loss": 0.5617,
      "step": 2276
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.826206545004478,
      "learning_rate": 9.574571110437496e-06,
      "loss": 0.5428,
      "step": 2277
    },
    {
      "epoch": 0.16,
      "grad_norm": 3.649449866106344,
      "learning_rate": 9.574116478811622e-06,
      "loss": 0.4962,
      "step": 2278
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.8510030970247437,
      "learning_rate": 9.573661615201472e-06,
      "loss": 0.5716,
      "step": 2279
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.041545678025771,
      "learning_rate": 9.573206519630117e-06,
      "loss": 0.5115,
      "step": 2280
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.6769329482064523,
      "learning_rate": 9.572751192120634e-06,
      "loss": 0.5164,
      "step": 2281
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.0599628320722254,
      "learning_rate": 9.57229563269612e-06,
      "loss": 0.5618,
      "step": 2282
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.0175628452884564,
      "learning_rate": 9.571839841379677e-06,
      "loss": 0.5331,
      "step": 2283
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.2646408431212794,
      "learning_rate": 9.571383818194424e-06,
      "loss": 0.5803,
      "step": 2284
    },
    {
      "epoch": 0.16,
      "grad_norm": 4.340819800302945,
      "learning_rate": 9.570927563163488e-06,
      "loss": 0.5394,
      "step": 2285
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.3714244079627944,
      "learning_rate": 9.570471076310006e-06,
      "loss": 0.5629,
      "step": 2286
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.9962234488144461,
      "learning_rate": 9.570014357657133e-06,
      "loss": 0.5124,
      "step": 2287
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.3411214580903392,
      "learning_rate": 9.56955740722803e-06,
      "loss": 0.592,
      "step": 2288
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.6786281082041932,
      "learning_rate": 9.569100225045873e-06,
      "loss": 0.5563,
      "step": 2289
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.324676897615196,
      "learning_rate": 9.56864281113385e-06,
      "loss": 0.5665,
      "step": 2290
    },
    {
      "epoch": 0.16,
      "grad_norm": 4.149628689439517,
      "learning_rate": 9.568185165515156e-06,
      "loss": 0.501,
      "step": 2291
    },
    {
      "epoch": 0.16,
      "grad_norm": 4.065488062643659,
      "learning_rate": 9.567727288213005e-06,
      "loss": 0.5617,
      "step": 2292
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.262259910438871,
      "learning_rate": 9.567269179250618e-06,
      "loss": 0.5886,
      "step": 2293
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.8487272812580479,
      "learning_rate": 9.566810838651228e-06,
      "loss": 0.4617,
      "step": 2294
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.8299848349457004,
      "learning_rate": 9.56635226643808e-06,
      "loss": 0.4743,
      "step": 2295
    },
    {
      "epoch": 0.16,
      "grad_norm": 3.2934173358627925,
      "learning_rate": 9.565893462634432e-06,
      "loss": 0.5294,
      "step": 2296
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.554019994158336,
      "learning_rate": 9.565434427263556e-06,
      "loss": 0.5016,
      "step": 2297
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.6743630688035982,
      "learning_rate": 9.564975160348728e-06,
      "loss": 0.5329,
      "step": 2298
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.1713634129302823,
      "learning_rate": 9.564515661913242e-06,
      "loss": 0.5181,
      "step": 2299
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.242740605971781,
      "learning_rate": 9.564055931980403e-06,
      "loss": 0.5723,
      "step": 2300
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.8779310628542372,
      "learning_rate": 9.563595970573527e-06,
      "loss": 0.5509,
      "step": 2301
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.8960109040293185,
      "learning_rate": 9.563135777715942e-06,
      "loss": 0.5723,
      "step": 2302
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.158164746101086,
      "learning_rate": 9.562675353430988e-06,
      "loss": 0.5123,
      "step": 2303
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.026934323105115,
      "learning_rate": 9.562214697742014e-06,
      "loss": 0.5314,
      "step": 2304
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.8132718132292047,
      "learning_rate": 9.561753810672385e-06,
      "loss": 0.5206,
      "step": 2305
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.738341688449421,
      "learning_rate": 9.561292692245473e-06,
      "loss": 0.4949,
      "step": 2306
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.7778344078732204,
      "learning_rate": 9.560831342484668e-06,
      "loss": 0.5533,
      "step": 2307
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.8832147148073075,
      "learning_rate": 9.560369761413366e-06,
      "loss": 0.5128,
      "step": 2308
    },
    {
      "epoch": 0.16,
      "grad_norm": 3.140561026470972,
      "learning_rate": 9.559907949054978e-06,
      "loss": 0.5456,
      "step": 2309
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.1115491012545435,
      "learning_rate": 9.559445905432923e-06,
      "loss": 0.617,
      "step": 2310
    },
    {
      "epoch": 0.16,
      "grad_norm": 3.283006659523931,
      "learning_rate": 9.558983630570638e-06,
      "loss": 0.5246,
      "step": 2311
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.3389728803943963,
      "learning_rate": 9.558521124491567e-06,
      "loss": 0.5073,
      "step": 2312
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.861702880591161,
      "learning_rate": 9.558058387219165e-06,
      "loss": 0.6298,
      "step": 2313
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.2267630511550593,
      "learning_rate": 9.557595418776902e-06,
      "loss": 0.5283,
      "step": 2314
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.2044989487467888,
      "learning_rate": 9.557132219188257e-06,
      "loss": 0.5247,
      "step": 2315
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.8997533270062263,
      "learning_rate": 9.556668788476725e-06,
      "loss": 0.552,
      "step": 2316
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.8797569734346375,
      "learning_rate": 9.556205126665805e-06,
      "loss": 0.5324,
      "step": 2317
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.8676000677236317,
      "learning_rate": 9.555741233779018e-06,
      "loss": 0.5192,
      "step": 2318
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.7828296506973127,
      "learning_rate": 9.555277109839887e-06,
      "loss": 0.5334,
      "step": 2319
    },
    {
      "epoch": 0.16,
      "grad_norm": 6.080968073928596,
      "learning_rate": 9.55481275487195e-06,
      "loss": 0.5509,
      "step": 2320
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.7631266341910077,
      "learning_rate": 9.554348168898763e-06,
      "loss": 0.516,
      "step": 2321
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.868536189260372,
      "learning_rate": 9.553883351943882e-06,
      "loss": 0.489,
      "step": 2322
    },
    {
      "epoch": 0.16,
      "grad_norm": 7.794678579413322,
      "learning_rate": 9.553418304030886e-06,
      "loss": 0.4982,
      "step": 2323
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.547501794477059,
      "learning_rate": 9.552953025183358e-06,
      "loss": 0.5789,
      "step": 2324
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.6222018179511377,
      "learning_rate": 9.552487515424896e-06,
      "loss": 0.5293,
      "step": 2325
    },
    {
      "epoch": 0.16,
      "grad_norm": 6.693240529964341,
      "learning_rate": 9.552021774779109e-06,
      "loss": 0.5242,
      "step": 2326
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.2029914020907193,
      "learning_rate": 9.551555803269618e-06,
      "loss": 0.5266,
      "step": 2327
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.4776337352714397,
      "learning_rate": 9.551089600920056e-06,
      "loss": 0.5276,
      "step": 2328
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.04074307950793,
      "learning_rate": 9.550623167754068e-06,
      "loss": 0.6246,
      "step": 2329
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.1558177966096763,
      "learning_rate": 9.550156503795307e-06,
      "loss": 0.5536,
      "step": 2330
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.7378633820983087,
      "learning_rate": 9.549689609067443e-06,
      "loss": 0.4503,
      "step": 2331
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.6694014219395499,
      "learning_rate": 9.549222483594154e-06,
      "loss": 0.5685,
      "step": 2332
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.023345256667834,
      "learning_rate": 9.548755127399132e-06,
      "loss": 0.5289,
      "step": 2333
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.8248285076463484,
      "learning_rate": 9.54828754050608e-06,
      "loss": 0.4422,
      "step": 2334
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.3860988954627755,
      "learning_rate": 9.547819722938713e-06,
      "loss": 0.5548,
      "step": 2335
    },
    {
      "epoch": 0.16,
      "grad_norm": 12.340049142564517,
      "learning_rate": 9.547351674720757e-06,
      "loss": 0.5025,
      "step": 2336
    },
    {
      "epoch": 0.16,
      "grad_norm": 3.3777104357915997,
      "learning_rate": 9.546883395875947e-06,
      "loss": 0.5495,
      "step": 2337
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.994369638977376,
      "learning_rate": 9.546414886428037e-06,
      "loss": 0.6152,
      "step": 2338
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.7045960579029966,
      "learning_rate": 9.545946146400787e-06,
      "loss": 0.5535,
      "step": 2339
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.969837965337451,
      "learning_rate": 9.545477175817966e-06,
      "loss": 0.5681,
      "step": 2340
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.363582631551518,
      "learning_rate": 9.545007974703364e-06,
      "loss": 0.5109,
      "step": 2341
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.250673762923318,
      "learning_rate": 9.544538543080773e-06,
      "loss": 0.5247,
      "step": 2342
    },
    {
      "epoch": 0.16,
      "grad_norm": 4.360128821650952,
      "learning_rate": 9.544068880974004e-06,
      "loss": 0.5571,
      "step": 2343
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.076002593239811,
      "learning_rate": 9.543598988406877e-06,
      "loss": 0.5533,
      "step": 2344
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.096115082841536,
      "learning_rate": 9.543128865403222e-06,
      "loss": 0.5623,
      "step": 2345
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.1870050877807814,
      "learning_rate": 9.542658511986882e-06,
      "loss": 0.5528,
      "step": 2346
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.033178482302918,
      "learning_rate": 9.542187928181712e-06,
      "loss": 0.5473,
      "step": 2347
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.352211034621891,
      "learning_rate": 9.541717114011579e-06,
      "loss": 0.5028,
      "step": 2348
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.7372706639517448,
      "learning_rate": 9.541246069500361e-06,
      "loss": 0.5364,
      "step": 2349
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.847000141452299,
      "learning_rate": 9.540774794671946e-06,
      "loss": 0.4833,
      "step": 2350
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.407662987010578,
      "learning_rate": 9.54030328955024e-06,
      "loss": 0.5474,
      "step": 2351
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.1032764704467355,
      "learning_rate": 9.539831554159152e-06,
      "loss": 0.5186,
      "step": 2352
    },
    {
      "epoch": 0.16,
      "grad_norm": 9.182806072940696,
      "learning_rate": 9.539359588522608e-06,
      "loss": 0.5707,
      "step": 2353
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.7289764718375824,
      "learning_rate": 9.538887392664544e-06,
      "loss": 0.4573,
      "step": 2354
    },
    {
      "epoch": 0.16,
      "grad_norm": 3.2200133502741433,
      "learning_rate": 9.53841496660891e-06,
      "loss": 0.5717,
      "step": 2355
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.290887384321387,
      "learning_rate": 9.537942310379666e-06,
      "loss": 0.5222,
      "step": 2356
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.3200600837346577,
      "learning_rate": 9.53746942400078e-06,
      "loss": 0.5448,
      "step": 2357
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.3706391136295344,
      "learning_rate": 9.53699630749624e-06,
      "loss": 0.5287,
      "step": 2358
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.4031754966741734,
      "learning_rate": 9.536522960890038e-06,
      "loss": 0.606,
      "step": 2359
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.261134895340301,
      "learning_rate": 9.536049384206182e-06,
      "loss": 0.5224,
      "step": 2360
    },
    {
      "epoch": 0.16,
      "grad_norm": 3.268008986012278,
      "learning_rate": 9.53557557746869e-06,
      "loss": 0.5352,
      "step": 2361
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.8598016440139875,
      "learning_rate": 9.53510154070159e-06,
      "loss": 0.5378,
      "step": 2362
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.0742796302809294,
      "learning_rate": 9.534627273928924e-06,
      "loss": 0.4976,
      "step": 2363
    },
    {
      "epoch": 0.16,
      "grad_norm": 3.344199039048739,
      "learning_rate": 9.53415277717475e-06,
      "loss": 0.5274,
      "step": 2364
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.283954492434625,
      "learning_rate": 9.533678050463126e-06,
      "loss": 0.5496,
      "step": 2365
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.8021850225741103,
      "learning_rate": 9.533203093818135e-06,
      "loss": 0.532,
      "step": 2366
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.828747768986018,
      "learning_rate": 9.532727907263861e-06,
      "loss": 0.5454,
      "step": 2367
    },
    {
      "epoch": 0.16,
      "grad_norm": 3.029042949820032,
      "learning_rate": 9.532252490824404e-06,
      "loss": 0.5243,
      "step": 2368
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.580524918035292,
      "learning_rate": 9.531776844523877e-06,
      "loss": 0.4836,
      "step": 2369
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.154876138234956,
      "learning_rate": 9.531300968386404e-06,
      "loss": 0.5159,
      "step": 2370
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.7923869084232535,
      "learning_rate": 9.530824862436117e-06,
      "loss": 0.5444,
      "step": 2371
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.574983526260876,
      "learning_rate": 9.530348526697166e-06,
      "loss": 0.5645,
      "step": 2372
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.9261370866065528,
      "learning_rate": 9.529871961193706e-06,
      "loss": 0.4716,
      "step": 2373
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.9550403384302368,
      "learning_rate": 9.529395165949911e-06,
      "loss": 0.5507,
      "step": 2374
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.0514756918707593,
      "learning_rate": 9.528918140989956e-06,
      "loss": 0.5595,
      "step": 2375
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.9682823191560626,
      "learning_rate": 9.528440886338042e-06,
      "loss": 0.5118,
      "step": 2376
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.051031083046076,
      "learning_rate": 9.527963402018367e-06,
      "loss": 0.5476,
      "step": 2377
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.8458703796947213,
      "learning_rate": 9.527485688055152e-06,
      "loss": 0.5361,
      "step": 2378
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.9500198237306328,
      "learning_rate": 9.527007744472622e-06,
      "loss": 0.4625,
      "step": 2379
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.1067686695035506,
      "learning_rate": 9.526529571295017e-06,
      "loss": 0.5784,
      "step": 2380
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.620612905063352,
      "learning_rate": 9.526051168546593e-06,
      "loss": 0.5407,
      "step": 2381
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.2840615094631005,
      "learning_rate": 9.525572536251608e-06,
      "loss": 0.5099,
      "step": 2382
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.0029491071473804,
      "learning_rate": 9.525093674434337e-06,
      "loss": 0.561,
      "step": 2383
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7611009870076975,
      "learning_rate": 9.524614583119067e-06,
      "loss": 0.4614,
      "step": 2384
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.1219969774265,
      "learning_rate": 9.524135262330098e-06,
      "loss": 0.5342,
      "step": 2385
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.8808307790969114,
      "learning_rate": 9.523655712091739e-06,
      "loss": 0.5434,
      "step": 2386
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.2355741962365396,
      "learning_rate": 9.523175932428307e-06,
      "loss": 0.5379,
      "step": 2387
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.79331473270425,
      "learning_rate": 9.522695923364142e-06,
      "loss": 0.5057,
      "step": 2388
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.345311477694168,
      "learning_rate": 9.522215684923582e-06,
      "loss": 0.5368,
      "step": 2389
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.4281974604771674,
      "learning_rate": 9.521735217130987e-06,
      "loss": 0.5375,
      "step": 2390
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.2418140491666705,
      "learning_rate": 9.521254520010722e-06,
      "loss": 0.5087,
      "step": 2391
    },
    {
      "epoch": 0.17,
      "grad_norm": 3.648323375901692,
      "learning_rate": 9.520773593587169e-06,
      "loss": 0.5364,
      "step": 2392
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.037933527872887,
      "learning_rate": 9.520292437884718e-06,
      "loss": 0.5158,
      "step": 2393
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.0004802709811087,
      "learning_rate": 9.51981105292777e-06,
      "loss": 0.5324,
      "step": 2394
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.7312463636683124,
      "learning_rate": 9.519329438740744e-06,
      "loss": 0.5653,
      "step": 2395
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.9080790619171115,
      "learning_rate": 9.51884759534806e-06,
      "loss": 0.5533,
      "step": 2396
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.1084229728673543,
      "learning_rate": 9.518365522774157e-06,
      "loss": 0.5224,
      "step": 2397
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.922105433354704,
      "learning_rate": 9.51788322104349e-06,
      "loss": 0.5145,
      "step": 2398
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.5798076405748904,
      "learning_rate": 9.517400690180512e-06,
      "loss": 0.5229,
      "step": 2399
    },
    {
      "epoch": 0.17,
      "grad_norm": 3.7132574438298565,
      "learning_rate": 9.516917930209699e-06,
      "loss": 0.5094,
      "step": 2400
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.3287042291503526,
      "learning_rate": 9.516434941155535e-06,
      "loss": 0.5083,
      "step": 2401
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.0122383353152933,
      "learning_rate": 9.515951723042514e-06,
      "loss": 0.588,
      "step": 2402
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.911765205155729,
      "learning_rate": 9.515468275895146e-06,
      "loss": 0.5163,
      "step": 2403
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.80666853900993,
      "learning_rate": 9.514984599737947e-06,
      "loss": 0.523,
      "step": 2404
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.831817335266688,
      "learning_rate": 9.51450069459545e-06,
      "loss": 0.5383,
      "step": 2405
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.0741240166258548,
      "learning_rate": 9.514016560492197e-06,
      "loss": 0.5347,
      "step": 2406
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.9108772991742908,
      "learning_rate": 9.513532197452737e-06,
      "loss": 0.562,
      "step": 2407
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6886498624159892,
      "learning_rate": 9.513047605501642e-06,
      "loss": 0.476,
      "step": 2408
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.8971397623182644,
      "learning_rate": 9.512562784663484e-06,
      "loss": 0.5566,
      "step": 2409
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.9813943569104677,
      "learning_rate": 9.512077734962855e-06,
      "loss": 0.5943,
      "step": 2410
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7749936625140027,
      "learning_rate": 9.511592456424353e-06,
      "loss": 0.4357,
      "step": 2411
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.935753171728913,
      "learning_rate": 9.511106949072588e-06,
      "loss": 0.5599,
      "step": 2412
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.2633573492217636,
      "learning_rate": 9.510621212932188e-06,
      "loss": 0.5459,
      "step": 2413
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.935673442317324,
      "learning_rate": 9.510135248027786e-06,
      "loss": 0.5358,
      "step": 2414
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.939858067386727,
      "learning_rate": 9.509649054384027e-06,
      "loss": 0.5002,
      "step": 2415
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7512964581960292,
      "learning_rate": 9.50916263202557e-06,
      "loss": 0.4604,
      "step": 2416
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.108572372470776,
      "learning_rate": 9.508675980977085e-06,
      "loss": 0.5676,
      "step": 2417
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.5004066524664061,
      "learning_rate": 9.508189101263254e-06,
      "loss": 0.483,
      "step": 2418
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.419878634727416,
      "learning_rate": 9.507701992908768e-06,
      "loss": 0.5341,
      "step": 2419
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.1804345114701817,
      "learning_rate": 9.507214655938334e-06,
      "loss": 0.4987,
      "step": 2420
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.8977703666962593,
      "learning_rate": 9.506727090376668e-06,
      "loss": 0.5092,
      "step": 2421
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.3815985371076334,
      "learning_rate": 9.506239296248497e-06,
      "loss": 0.496,
      "step": 2422
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.4400113076308827,
      "learning_rate": 9.505751273578558e-06,
      "loss": 0.5419,
      "step": 2423
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.6959071335452345,
      "learning_rate": 9.505263022391605e-06,
      "loss": 0.5293,
      "step": 2424
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.043678468600472,
      "learning_rate": 9.504774542712398e-06,
      "loss": 0.5609,
      "step": 2425
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.6943891676777239,
      "learning_rate": 9.504285834565714e-06,
      "loss": 0.4916,
      "step": 2426
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7721594395131269,
      "learning_rate": 9.503796897976339e-06,
      "loss": 0.4512,
      "step": 2427
    },
    {
      "epoch": 0.17,
      "grad_norm": 4.613287416916902,
      "learning_rate": 9.503307732969065e-06,
      "loss": 0.5394,
      "step": 2428
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.73395528030888,
      "learning_rate": 9.502818339568706e-06,
      "loss": 0.5269,
      "step": 2429
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.8111689236174613,
      "learning_rate": 9.502328717800082e-06,
      "loss": 0.5749,
      "step": 2430
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.7123757610182087,
      "learning_rate": 9.501838867688022e-06,
      "loss": 0.5776,
      "step": 2431
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.7728449400864297,
      "learning_rate": 9.501348789257373e-06,
      "loss": 0.524,
      "step": 2432
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.830454542584085,
      "learning_rate": 9.500858482532989e-06,
      "loss": 0.4975,
      "step": 2433
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.916672227788548,
      "learning_rate": 9.500367947539735e-06,
      "loss": 0.5285,
      "step": 2434
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.0037955007065906,
      "learning_rate": 9.499877184302491e-06,
      "loss": 0.566,
      "step": 2435
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.223896418388223,
      "learning_rate": 9.499386192846147e-06,
      "loss": 0.5702,
      "step": 2436
    },
    {
      "epoch": 0.17,
      "grad_norm": 10.650947502877736,
      "learning_rate": 9.498894973195603e-06,
      "loss": 0.5448,
      "step": 2437
    },
    {
      "epoch": 0.17,
      "grad_norm": 3.0795097856584497,
      "learning_rate": 9.498403525375774e-06,
      "loss": 0.5412,
      "step": 2438
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.955243734892921,
      "learning_rate": 9.497911849411585e-06,
      "loss": 0.5815,
      "step": 2439
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.8810323350766762,
      "learning_rate": 9.49741994532797e-06,
      "loss": 0.5448,
      "step": 2440
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.477238003496443,
      "learning_rate": 9.496927813149877e-06,
      "loss": 0.5281,
      "step": 2441
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.909542655711139,
      "learning_rate": 9.496435452902268e-06,
      "loss": 0.5355,
      "step": 2442
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7729024002173006,
      "learning_rate": 9.49594286461011e-06,
      "loss": 0.465,
      "step": 2443
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.0913061377200894,
      "learning_rate": 9.495450048298389e-06,
      "loss": 0.5447,
      "step": 2444
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.5226428021778085,
      "learning_rate": 9.494957003992097e-06,
      "loss": 0.5538,
      "step": 2445
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7281070312459871,
      "learning_rate": 9.494463731716241e-06,
      "loss": 0.4774,
      "step": 2446
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.664208899485156,
      "learning_rate": 9.493970231495836e-06,
      "loss": 0.5202,
      "step": 2447
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.146486838376676,
      "learning_rate": 9.493476503355911e-06,
      "loss": 0.5441,
      "step": 2448
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.334121551632877,
      "learning_rate": 9.492982547321509e-06,
      "loss": 0.6162,
      "step": 2449
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.159558487547173,
      "learning_rate": 9.492488363417682e-06,
      "loss": 0.5675,
      "step": 2450
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.689130192673561,
      "learning_rate": 9.49199395166949e-06,
      "loss": 0.4521,
      "step": 2451
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.8212831103988703,
      "learning_rate": 9.491499312102008e-06,
      "loss": 0.5024,
      "step": 2452
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.8909174934165078,
      "learning_rate": 9.491004444740326e-06,
      "loss": 0.5292,
      "step": 2453
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.052250215557212,
      "learning_rate": 9.490509349609538e-06,
      "loss": 0.6331,
      "step": 2454
    },
    {
      "epoch": 0.17,
      "grad_norm": 3.624520706030077,
      "learning_rate": 9.490014026734758e-06,
      "loss": 0.5609,
      "step": 2455
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.006325961504065,
      "learning_rate": 9.489518476141105e-06,
      "loss": 0.5076,
      "step": 2456
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.061494460201576,
      "learning_rate": 9.48902269785371e-06,
      "loss": 0.5103,
      "step": 2457
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.1345731878566307,
      "learning_rate": 9.488526691897718e-06,
      "loss": 0.5632,
      "step": 2458
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.0174733038093433,
      "learning_rate": 9.488030458298288e-06,
      "loss": 0.5188,
      "step": 2459
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.896375939001554,
      "learning_rate": 9.487533997080582e-06,
      "loss": 0.5641,
      "step": 2460
    },
    {
      "epoch": 0.17,
      "grad_norm": 3.3975914071223214,
      "learning_rate": 9.487037308269784e-06,
      "loss": 0.4848,
      "step": 2461
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.5255670206579506,
      "learning_rate": 9.486540391891083e-06,
      "loss": 0.5521,
      "step": 2462
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.8226067596211057,
      "learning_rate": 9.48604324796968e-06,
      "loss": 0.5525,
      "step": 2463
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.9080239642705674,
      "learning_rate": 9.485545876530787e-06,
      "loss": 0.5445,
      "step": 2464
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.7658636894416324,
      "learning_rate": 9.485048277599632e-06,
      "loss": 0.5195,
      "step": 2465
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.233905561446844,
      "learning_rate": 9.484550451201451e-06,
      "loss": 0.522,
      "step": 2466
    },
    {
      "epoch": 0.17,
      "grad_norm": 3.231907847989141,
      "learning_rate": 9.48405239736149e-06,
      "loss": 0.5901,
      "step": 2467
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7606655319716542,
      "learning_rate": 9.483554116105011e-06,
      "loss": 0.4618,
      "step": 2468
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.7869981268862005,
      "learning_rate": 9.483055607457285e-06,
      "loss": 0.5175,
      "step": 2469
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.9303027735827296,
      "learning_rate": 9.482556871443594e-06,
      "loss": 0.5045,
      "step": 2470
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.0015201206480953,
      "learning_rate": 9.482057908089233e-06,
      "loss": 0.5648,
      "step": 2471
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.886004317789523,
      "learning_rate": 9.481558717419506e-06,
      "loss": 0.5098,
      "step": 2472
    },
    {
      "epoch": 0.17,
      "grad_norm": 3.294813825968576,
      "learning_rate": 9.481059299459731e-06,
      "loss": 0.5493,
      "step": 2473
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.9392952590068697,
      "learning_rate": 9.48055965423524e-06,
      "loss": 0.5196,
      "step": 2474
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.181005386943042,
      "learning_rate": 9.48005978177137e-06,
      "loss": 0.5139,
      "step": 2475
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.0524703428229674,
      "learning_rate": 9.479559682093473e-06,
      "loss": 0.5157,
      "step": 2476
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.1481320928483605,
      "learning_rate": 9.479059355226912e-06,
      "loss": 0.5534,
      "step": 2477
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.3697414054182304,
      "learning_rate": 9.478558801197065e-06,
      "loss": 0.4977,
      "step": 2478
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7119373124417893,
      "learning_rate": 9.478058020029316e-06,
      "loss": 0.468,
      "step": 2479
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.7174860130330982,
      "learning_rate": 9.477557011749063e-06,
      "loss": 0.5665,
      "step": 2480
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.237047323759031,
      "learning_rate": 9.477055776381715e-06,
      "loss": 0.5501,
      "step": 2481
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.059460893827842,
      "learning_rate": 9.476554313952697e-06,
      "loss": 0.5275,
      "step": 2482
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.6481043252673717,
      "learning_rate": 9.476052624487437e-06,
      "loss": 0.5222,
      "step": 2483
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.658012211866166,
      "learning_rate": 9.47555070801138e-06,
      "loss": 0.5258,
      "step": 2484
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.0182346218333502,
      "learning_rate": 9.475048564549985e-06,
      "loss": 0.5871,
      "step": 2485
    },
    {
      "epoch": 0.17,
      "grad_norm": 4.446846803086003,
      "learning_rate": 9.474546194128713e-06,
      "loss": 0.5716,
      "step": 2486
    },
    {
      "epoch": 0.17,
      "grad_norm": 7.861625515827177,
      "learning_rate": 9.474043596773048e-06,
      "loss": 0.5663,
      "step": 2487
    },
    {
      "epoch": 0.17,
      "grad_norm": 3.147423731542978,
      "learning_rate": 9.473540772508476e-06,
      "loss": 0.5132,
      "step": 2488
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.9026755604779535,
      "learning_rate": 9.473037721360504e-06,
      "loss": 0.5549,
      "step": 2489
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.568372381936184,
      "learning_rate": 9.472534443354637e-06,
      "loss": 0.5924,
      "step": 2490
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.1376915711482836,
      "learning_rate": 9.472030938516408e-06,
      "loss": 0.5719,
      "step": 2491
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.0058566454070985,
      "learning_rate": 9.471527206871348e-06,
      "loss": 0.5316,
      "step": 2492
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.549693350262801,
      "learning_rate": 9.471023248445007e-06,
      "loss": 0.5199,
      "step": 2493
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.208656779833939,
      "learning_rate": 9.470519063262941e-06,
      "loss": 0.5636,
      "step": 2494
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.330405038234511,
      "learning_rate": 9.470014651350726e-06,
      "loss": 0.519,
      "step": 2495
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.9873178253564683,
      "learning_rate": 9.46951001273394e-06,
      "loss": 0.5655,
      "step": 2496
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.716422705889833,
      "learning_rate": 9.469005147438176e-06,
      "loss": 0.5102,
      "step": 2497
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.6722460671823844,
      "learning_rate": 9.468500055489041e-06,
      "loss": 0.515,
      "step": 2498
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.5064731528743858,
      "learning_rate": 9.467994736912152e-06,
      "loss": 0.5119,
      "step": 2499
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.7584097580845435,
      "learning_rate": 9.467489191733137e-06,
      "loss": 0.5487,
      "step": 2500
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.341934658765881,
      "learning_rate": 9.466983419977634e-06,
      "loss": 0.5678,
      "step": 2501
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.8178883354478166,
      "learning_rate": 9.466477421671296e-06,
      "loss": 0.5428,
      "step": 2502
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.615224791350781,
      "learning_rate": 9.465971196839786e-06,
      "loss": 0.5745,
      "step": 2503
    },
    {
      "epoch": 0.17,
      "grad_norm": 3.072343946828342,
      "learning_rate": 9.465464745508775e-06,
      "loss": 0.5083,
      "step": 2504
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.0701809971848637,
      "learning_rate": 9.464958067703948e-06,
      "loss": 0.5614,
      "step": 2505
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.9713218713961802,
      "learning_rate": 9.464451163451008e-06,
      "loss": 0.5526,
      "step": 2506
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.934902244099076,
      "learning_rate": 9.46394403277566e-06,
      "loss": 0.4762,
      "step": 2507
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.455908267477326,
      "learning_rate": 9.463436675703622e-06,
      "loss": 0.5406,
      "step": 2508
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.8152262443063957,
      "learning_rate": 9.46292909226063e-06,
      "loss": 0.4489,
      "step": 2509
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.0239034498203305,
      "learning_rate": 9.46242128247242e-06,
      "loss": 0.5074,
      "step": 2510
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7414480827655924,
      "learning_rate": 9.461913246364754e-06,
      "loss": 0.4586,
      "step": 2511
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.7815999218028282,
      "learning_rate": 9.461404983963396e-06,
      "loss": 0.5146,
      "step": 2512
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.2580202379980023,
      "learning_rate": 9.46089649529412e-06,
      "loss": 0.5866,
      "step": 2513
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.6775194321527347,
      "learning_rate": 9.460387780382718e-06,
      "loss": 0.5279,
      "step": 2514
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.920112883004713,
      "learning_rate": 9.459878839254988e-06,
      "loss": 0.5323,
      "step": 2515
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.7360162710384949,
      "learning_rate": 9.459369671936744e-06,
      "loss": 0.4683,
      "step": 2516
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.0607771879302423,
      "learning_rate": 9.45886027845381e-06,
      "loss": 0.5593,
      "step": 2517
    },
    {
      "epoch": 0.18,
      "grad_norm": 3.0397627211706046,
      "learning_rate": 9.458350658832019e-06,
      "loss": 0.5347,
      "step": 2518
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.803761487950919,
      "learning_rate": 9.457840813097217e-06,
      "loss": 0.5078,
      "step": 2519
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.3173527144182766,
      "learning_rate": 9.457330741275262e-06,
      "loss": 0.5306,
      "step": 2520
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.8723248338895886,
      "learning_rate": 9.456820443392026e-06,
      "loss": 0.5019,
      "step": 2521
    },
    {
      "epoch": 0.18,
      "grad_norm": 3.028264376914754,
      "learning_rate": 9.456309919473384e-06,
      "loss": 0.5555,
      "step": 2522
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.9649995128466067,
      "learning_rate": 9.455799169545233e-06,
      "loss": 0.5041,
      "step": 2523
    },
    {
      "epoch": 0.18,
      "grad_norm": 3.194656803894076,
      "learning_rate": 9.455288193633475e-06,
      "loss": 0.5196,
      "step": 2524
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.849586067846002,
      "learning_rate": 9.454776991764023e-06,
      "loss": 0.5739,
      "step": 2525
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.9841991014389295,
      "learning_rate": 9.454265563962808e-06,
      "loss": 0.5373,
      "step": 2526
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.473051281340052,
      "learning_rate": 9.453753910255763e-06,
      "loss": 0.5436,
      "step": 2527
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.252595118301949,
      "learning_rate": 9.453242030668842e-06,
      "loss": 0.5686,
      "step": 2528
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.0248382992336458,
      "learning_rate": 9.452729925228001e-06,
      "loss": 0.5235,
      "step": 2529
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.8268573298012212,
      "learning_rate": 9.452217593959217e-06,
      "loss": 0.4937,
      "step": 2530
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.340568682105498,
      "learning_rate": 9.45170503688847e-06,
      "loss": 0.495,
      "step": 2531
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.8500998407367906,
      "learning_rate": 9.451192254041759e-06,
      "loss": 0.5006,
      "step": 2532
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.7541478170512845,
      "learning_rate": 9.450679245445086e-06,
      "loss": 0.5282,
      "step": 2533
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.654017203429688,
      "learning_rate": 9.450166011124475e-06,
      "loss": 0.5682,
      "step": 2534
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.1224035227552407,
      "learning_rate": 9.44965255110595e-06,
      "loss": 0.4988,
      "step": 2535
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.234130456117118,
      "learning_rate": 9.449138865415554e-06,
      "loss": 0.5235,
      "step": 2536
    },
    {
      "epoch": 0.18,
      "grad_norm": 4.609926891745628,
      "learning_rate": 9.448624954079342e-06,
      "loss": 0.5538,
      "step": 2537
    },
    {
      "epoch": 0.18,
      "grad_norm": 3.417990123395476,
      "learning_rate": 9.448110817123375e-06,
      "loss": 0.567,
      "step": 2538
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.7731068171369913,
      "learning_rate": 9.447596454573728e-06,
      "loss": 0.5383,
      "step": 2539
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.581092100240481,
      "learning_rate": 9.44708186645649e-06,
      "loss": 0.5712,
      "step": 2540
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.8593427108317595,
      "learning_rate": 9.446567052797754e-06,
      "loss": 0.5674,
      "step": 2541
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.7751706492046249,
      "learning_rate": 9.446052013623639e-06,
      "loss": 0.5176,
      "step": 2542
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.7917757878217104,
      "learning_rate": 9.445536748960257e-06,
      "loss": 0.5564,
      "step": 2543
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.7375065040941908,
      "learning_rate": 9.445021258833747e-06,
      "loss": 0.4796,
      "step": 2544
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.5287720804617777,
      "learning_rate": 9.44450554327025e-06,
      "loss": 0.5445,
      "step": 2545
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.842254362222788,
      "learning_rate": 9.443989602295923e-06,
      "loss": 0.5592,
      "step": 2546
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.0967774627364864,
      "learning_rate": 9.44347343593693e-06,
      "loss": 0.4946,
      "step": 2547
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.0581839040411807,
      "learning_rate": 9.44295704421945e-06,
      "loss": 0.5074,
      "step": 2548
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.522228748319028,
      "learning_rate": 9.442440427169673e-06,
      "loss": 0.5487,
      "step": 2549
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.9904586691750779,
      "learning_rate": 9.441923584813803e-06,
      "loss": 0.4919,
      "step": 2550
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.8019512273498226,
      "learning_rate": 9.441406517178049e-06,
      "loss": 0.5345,
      "step": 2551
    },
    {
      "epoch": 0.18,
      "grad_norm": 3.212908883467169,
      "learning_rate": 9.440889224288637e-06,
      "loss": 0.5461,
      "step": 2552
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.7023667443734662,
      "learning_rate": 9.440371706171801e-06,
      "loss": 0.5682,
      "step": 2553
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.704324871880273,
      "learning_rate": 9.439853962853789e-06,
      "loss": 0.5276,
      "step": 2554
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.395788303017475,
      "learning_rate": 9.43933599436086e-06,
      "loss": 0.4855,
      "step": 2555
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.6905121144469724,
      "learning_rate": 9.43881780071928e-06,
      "loss": 0.5179,
      "step": 2556
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.1179533018227317,
      "learning_rate": 9.438299381955333e-06,
      "loss": 0.5457,
      "step": 2557
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.9506206283812642,
      "learning_rate": 9.437780738095311e-06,
      "loss": 0.5736,
      "step": 2558
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.6712160861618535,
      "learning_rate": 9.437261869165519e-06,
      "loss": 0.5401,
      "step": 2559
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.8841329706629035,
      "learning_rate": 9.436742775192272e-06,
      "loss": 0.542,
      "step": 2560
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.8950075413781304,
      "learning_rate": 9.436223456201894e-06,
      "loss": 0.5472,
      "step": 2561
    },
    {
      "epoch": 0.18,
      "grad_norm": 4.65089928702813,
      "learning_rate": 9.435703912220727e-06,
      "loss": 0.5577,
      "step": 2562
    },
    {
      "epoch": 0.18,
      "grad_norm": 4.784520560907787,
      "learning_rate": 9.435184143275117e-06,
      "loss": 0.547,
      "step": 2563
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.827377616212774,
      "learning_rate": 9.434664149391427e-06,
      "loss": 0.539,
      "step": 2564
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.243139557792908,
      "learning_rate": 9.43414393059603e-06,
      "loss": 0.5122,
      "step": 2565
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.166960277364582,
      "learning_rate": 9.43362348691531e-06,
      "loss": 0.5598,
      "step": 2566
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.0108406149231057,
      "learning_rate": 9.43310281837566e-06,
      "loss": 0.5731,
      "step": 2567
    },
    {
      "epoch": 0.18,
      "grad_norm": 3.3829621623650667,
      "learning_rate": 9.432581925003489e-06,
      "loss": 0.5482,
      "step": 2568
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.8584161128261474,
      "learning_rate": 9.432060806825211e-06,
      "loss": 0.55,
      "step": 2569
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.0575333187938045,
      "learning_rate": 9.43153946386726e-06,
      "loss": 0.5221,
      "step": 2570
    },
    {
      "epoch": 0.18,
      "grad_norm": 5.690284138551845,
      "learning_rate": 9.431017896156074e-06,
      "loss": 0.5211,
      "step": 2571
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.8282425378685034,
      "learning_rate": 9.430496103718108e-06,
      "loss": 0.548,
      "step": 2572
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.50028342959766,
      "learning_rate": 9.429974086579823e-06,
      "loss": 0.5169,
      "step": 2573
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.626437947673377,
      "learning_rate": 9.429451844767694e-06,
      "loss": 0.4957,
      "step": 2574
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.7854738400225783,
      "learning_rate": 9.428929378308209e-06,
      "loss": 0.5293,
      "step": 2575
    },
    {
      "epoch": 0.18,
      "grad_norm": 3.412014774299328,
      "learning_rate": 9.428406687227865e-06,
      "loss": 0.5546,
      "step": 2576
    },
    {
      "epoch": 0.18,
      "grad_norm": 4.404904904718979,
      "learning_rate": 9.427883771553172e-06,
      "loss": 0.6005,
      "step": 2577
    },
    {
      "epoch": 0.18,
      "grad_norm": 3.161101019918476,
      "learning_rate": 9.42736063131065e-06,
      "loss": 0.5708,
      "step": 2578
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.360663858015375,
      "learning_rate": 9.426837266526829e-06,
      "loss": 0.5238,
      "step": 2579
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.044832874866758,
      "learning_rate": 9.426313677228256e-06,
      "loss": 0.5459,
      "step": 2580
    },
    {
      "epoch": 0.18,
      "grad_norm": 4.656384860216651,
      "learning_rate": 9.425789863441484e-06,
      "loss": 0.5216,
      "step": 2581
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.586923021797912,
      "learning_rate": 9.425265825193077e-06,
      "loss": 0.5637,
      "step": 2582
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.9430002395985995,
      "learning_rate": 9.424741562509617e-06,
      "loss": 0.5154,
      "step": 2583
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.020074038353259,
      "learning_rate": 9.42421707541769e-06,
      "loss": 0.556,
      "step": 2584
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.4111588150980587,
      "learning_rate": 9.423692363943895e-06,
      "loss": 0.5659,
      "step": 2585
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.9941099143990935,
      "learning_rate": 9.423167428114846e-06,
      "loss": 0.5525,
      "step": 2586
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.0968099094979276,
      "learning_rate": 9.422642267957165e-06,
      "loss": 0.5155,
      "step": 2587
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.1144344510892013,
      "learning_rate": 9.422116883497488e-06,
      "loss": 0.524,
      "step": 2588
    },
    {
      "epoch": 0.18,
      "grad_norm": 3.0477787964407317,
      "learning_rate": 9.42159127476246e-06,
      "loss": 0.4883,
      "step": 2589
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.8917517769576848,
      "learning_rate": 9.421065441778736e-06,
      "loss": 0.5268,
      "step": 2590
    },
    {
      "epoch": 0.18,
      "grad_norm": 3.4821029691258127,
      "learning_rate": 9.420539384572988e-06,
      "loss": 0.5532,
      "step": 2591
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.3807583924103413,
      "learning_rate": 9.420013103171893e-06,
      "loss": 0.5656,
      "step": 2592
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.7583891683060567,
      "learning_rate": 9.419486597602143e-06,
      "loss": 0.4687,
      "step": 2593
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.016605882729924,
      "learning_rate": 9.418959867890443e-06,
      "loss": 0.5657,
      "step": 2594
    },
    {
      "epoch": 0.18,
      "grad_norm": 5.346182492379916,
      "learning_rate": 9.418432914063505e-06,
      "loss": 0.525,
      "step": 2595
    },
    {
      "epoch": 0.18,
      "grad_norm": 3.5853398381687254,
      "learning_rate": 9.417905736148053e-06,
      "loss": 0.5678,
      "step": 2596
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.7669508874601487,
      "learning_rate": 9.417378334170826e-06,
      "loss": 0.5253,
      "step": 2597
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.5504515113145843,
      "learning_rate": 9.416850708158571e-06,
      "loss": 0.505,
      "step": 2598
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.650370795175827,
      "learning_rate": 9.416322858138047e-06,
      "loss": 0.5402,
      "step": 2599
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.6383885200084447,
      "learning_rate": 9.415794784136027e-06,
      "loss": 0.5294,
      "step": 2600
    },
    {
      "epoch": 0.18,
      "grad_norm": 4.906840344699837,
      "learning_rate": 9.415266486179293e-06,
      "loss": 0.5374,
      "step": 2601
    },
    {
      "epoch": 0.18,
      "grad_norm": 3.7727445932193313,
      "learning_rate": 9.414737964294636e-06,
      "loss": 0.5217,
      "step": 2602
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.449229995183303,
      "learning_rate": 9.414209218508862e-06,
      "loss": 0.5351,
      "step": 2603
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.5142336333390145,
      "learning_rate": 9.413680248848788e-06,
      "loss": 0.5862,
      "step": 2604
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.9967518674316502,
      "learning_rate": 9.41315105534124e-06,
      "loss": 0.5358,
      "step": 2605
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.3151538512433367,
      "learning_rate": 9.412621638013059e-06,
      "loss": 0.591,
      "step": 2606
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.155642547941955,
      "learning_rate": 9.412091996891097e-06,
      "loss": 0.5551,
      "step": 2607
    },
    {
      "epoch": 0.18,
      "grad_norm": 3.4283958321738313,
      "learning_rate": 9.41156213200221e-06,
      "loss": 0.5186,
      "step": 2608
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.3309423839397057,
      "learning_rate": 9.411032043373275e-06,
      "loss": 0.5683,
      "step": 2609
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.8933283371094207,
      "learning_rate": 9.410501731031177e-06,
      "loss": 0.5071,
      "step": 2610
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.385753384249548,
      "learning_rate": 9.409971195002809e-06,
      "loss": 0.5211,
      "step": 2611
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.8708505224210483,
      "learning_rate": 9.409440435315078e-06,
      "loss": 0.5392,
      "step": 2612
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.9666002288766502,
      "learning_rate": 9.408909451994906e-06,
      "loss": 0.5358,
      "step": 2613
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.0652936681963294,
      "learning_rate": 9.40837824506922e-06,
      "loss": 0.5361,
      "step": 2614
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.9231844227422539,
      "learning_rate": 9.40784681456496e-06,
      "loss": 0.5512,
      "step": 2615
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.1002831355652725,
      "learning_rate": 9.407315160509083e-06,
      "loss": 0.5629,
      "step": 2616
    },
    {
      "epoch": 0.18,
      "grad_norm": 3.3365753596441676,
      "learning_rate": 9.406783282928547e-06,
      "loss": 0.5153,
      "step": 2617
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.933780070750002,
      "learning_rate": 9.40625118185033e-06,
      "loss": 0.5315,
      "step": 2618
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.9127042669759513,
      "learning_rate": 9.405718857301419e-06,
      "loss": 0.5532,
      "step": 2619
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.867538922083093,
      "learning_rate": 9.405186309308812e-06,
      "loss": 0.5292,
      "step": 2620
    },
    {
      "epoch": 0.18,
      "grad_norm": 6.439274722065746,
      "learning_rate": 9.404653537899515e-06,
      "loss": 0.566,
      "step": 2621
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.7482299394833134,
      "learning_rate": 9.404120543100553e-06,
      "loss": 0.528,
      "step": 2622
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.2476454752243944,
      "learning_rate": 9.403587324938952e-06,
      "loss": 0.5533,
      "step": 2623
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.7767632935758353,
      "learning_rate": 9.40305388344176e-06,
      "loss": 0.542,
      "step": 2624
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.7493146687697747,
      "learning_rate": 9.40252021863603e-06,
      "loss": 0.5042,
      "step": 2625
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.1988980780648872,
      "learning_rate": 9.401986330548828e-06,
      "loss": 0.5525,
      "step": 2626
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.317735888732824,
      "learning_rate": 9.40145221920723e-06,
      "loss": 0.4892,
      "step": 2627
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.336601319851672,
      "learning_rate": 9.400917884638325e-06,
      "loss": 0.5662,
      "step": 2628
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.080464173452554,
      "learning_rate": 9.400383326869214e-06,
      "loss": 0.5258,
      "step": 2629
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.0441041417595085,
      "learning_rate": 9.399848545927006e-06,
      "loss": 0.5168,
      "step": 2630
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.9187368063686019,
      "learning_rate": 9.399313541838823e-06,
      "loss": 0.5778,
      "step": 2631
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.7602260546798688,
      "learning_rate": 9.398778314631801e-06,
      "loss": 0.4375,
      "step": 2632
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.1130481622798287,
      "learning_rate": 9.398242864333084e-06,
      "loss": 0.504,
      "step": 2633
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.1646398758060665,
      "learning_rate": 9.397707190969826e-06,
      "loss": 0.4862,
      "step": 2634
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.055149151058997,
      "learning_rate": 9.397171294569198e-06,
      "loss": 0.5104,
      "step": 2635
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.773064855262225,
      "learning_rate": 9.396635175158377e-06,
      "loss": 0.5431,
      "step": 2636
    },
    {
      "epoch": 0.18,
      "grad_norm": 3.1210737968106623,
      "learning_rate": 9.396098832764555e-06,
      "loss": 0.5092,
      "step": 2637
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.8764251680605666,
      "learning_rate": 9.395562267414932e-06,
      "loss": 0.4549,
      "step": 2638
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.4498681990625704,
      "learning_rate": 9.395025479136722e-06,
      "loss": 0.5145,
      "step": 2639
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.151388174161585,
      "learning_rate": 9.394488467957147e-06,
      "loss": 0.5204,
      "step": 2640
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.166796393896852,
      "learning_rate": 9.393951233903442e-06,
      "loss": 0.562,
      "step": 2641
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.592017586886333,
      "learning_rate": 9.393413777002858e-06,
      "loss": 0.5703,
      "step": 2642
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.5581814556995062,
      "learning_rate": 9.39287609728265e-06,
      "loss": 0.5329,
      "step": 2643
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.5243533239127784,
      "learning_rate": 9.392338194770087e-06,
      "loss": 0.5674,
      "step": 2644
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.3701512030321643,
      "learning_rate": 9.391800069492452e-06,
      "loss": 0.5715,
      "step": 2645
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.563763736587412,
      "learning_rate": 9.391261721477034e-06,
      "loss": 0.5618,
      "step": 2646
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.7079282010023054,
      "learning_rate": 9.39072315075114e-06,
      "loss": 0.5179,
      "step": 2647
    },
    {
      "epoch": 0.18,
      "grad_norm": 3.1288401933502,
      "learning_rate": 9.39018435734208e-06,
      "loss": 0.5265,
      "step": 2648
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.9866970630425724,
      "learning_rate": 9.389645341277183e-06,
      "loss": 0.5834,
      "step": 2649
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.4235485693852468,
      "learning_rate": 9.389106102583787e-06,
      "loss": 0.5889,
      "step": 2650
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.7067449295273927,
      "learning_rate": 9.388566641289238e-06,
      "loss": 0.5802,
      "step": 2651
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.047189716066976,
      "learning_rate": 9.388026957420895e-06,
      "loss": 0.5202,
      "step": 2652
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.133172226243011,
      "learning_rate": 9.387487051006133e-06,
      "loss": 0.5527,
      "step": 2653
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.8440339403284545,
      "learning_rate": 9.386946922072329e-06,
      "loss": 0.4914,
      "step": 2654
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.7342775003618547,
      "learning_rate": 9.386406570646881e-06,
      "loss": 0.5503,
      "step": 2655
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.930429486244421,
      "learning_rate": 9.385865996757192e-06,
      "loss": 0.5565,
      "step": 2656
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.8030708439691031,
      "learning_rate": 9.385325200430679e-06,
      "loss": 0.5043,
      "step": 2657
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.132652608320105,
      "learning_rate": 9.384784181694767e-06,
      "loss": 0.5118,
      "step": 2658
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.4048564112734225,
      "learning_rate": 9.384242940576898e-06,
      "loss": 0.5288,
      "step": 2659
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.9026895057600282,
      "learning_rate": 9.38370147710452e-06,
      "loss": 0.5311,
      "step": 2660
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.4260882078001065,
      "learning_rate": 9.383159791305096e-06,
      "loss": 0.4568,
      "step": 2661
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.13879752873166,
      "learning_rate": 9.382617883206096e-06,
      "loss": 0.5301,
      "step": 2662
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.026917211169865,
      "learning_rate": 9.382075752835006e-06,
      "loss": 0.5618,
      "step": 2663
    },
    {
      "epoch": 0.19,
      "grad_norm": 3.0960628657963225,
      "learning_rate": 9.381533400219319e-06,
      "loss": 0.5498,
      "step": 2664
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.3094324084783255,
      "learning_rate": 9.380990825386542e-06,
      "loss": 0.5851,
      "step": 2665
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.7446961021525893,
      "learning_rate": 9.380448028364195e-06,
      "loss": 0.5287,
      "step": 2666
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.7304832663627752,
      "learning_rate": 9.379905009179804e-06,
      "loss": 0.5279,
      "step": 2667
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.392107111253094,
      "learning_rate": 9.379361767860912e-06,
      "loss": 0.5263,
      "step": 2668
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.525782186950409,
      "learning_rate": 9.378818304435066e-06,
      "loss": 0.5084,
      "step": 2669
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.938250110301074,
      "learning_rate": 9.378274618929833e-06,
      "loss": 0.5314,
      "step": 2670
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.8187673919131275,
      "learning_rate": 9.377730711372786e-06,
      "loss": 0.5445,
      "step": 2671
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.2104324863293336,
      "learning_rate": 9.37718658179151e-06,
      "loss": 0.5761,
      "step": 2672
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.3480533988095296,
      "learning_rate": 9.376642230213597e-06,
      "loss": 0.5315,
      "step": 2673
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.16599163059433,
      "learning_rate": 9.376097656666663e-06,
      "loss": 0.5398,
      "step": 2674
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.7842161987548444,
      "learning_rate": 9.37555286117832e-06,
      "loss": 0.5878,
      "step": 2675
    },
    {
      "epoch": 0.19,
      "grad_norm": 4.74860231488474,
      "learning_rate": 9.375007843776202e-06,
      "loss": 0.5116,
      "step": 2676
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.0347582050072783,
      "learning_rate": 9.37446260448795e-06,
      "loss": 0.5244,
      "step": 2677
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.28010729197721,
      "learning_rate": 9.373917143341216e-06,
      "loss": 0.5486,
      "step": 2678
    },
    {
      "epoch": 0.19,
      "grad_norm": 3.3506705964618977,
      "learning_rate": 9.373371460363665e-06,
      "loss": 0.5011,
      "step": 2679
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.090387129401182,
      "learning_rate": 9.372825555582969e-06,
      "loss": 0.5655,
      "step": 2680
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.0792653387274833,
      "learning_rate": 9.37227942902682e-06,
      "loss": 0.5593,
      "step": 2681
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.7275167922246075,
      "learning_rate": 9.371733080722911e-06,
      "loss": 0.5472,
      "step": 2682
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.620115674646058,
      "learning_rate": 9.371186510698954e-06,
      "loss": 0.5396,
      "step": 2683
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.8695401006076997,
      "learning_rate": 9.370639718982668e-06,
      "loss": 0.536,
      "step": 2684
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.417825673715994,
      "learning_rate": 9.370092705601783e-06,
      "loss": 0.5583,
      "step": 2685
    },
    {
      "epoch": 0.19,
      "grad_norm": 3.032766903450933,
      "learning_rate": 9.369545470584045e-06,
      "loss": 0.5118,
      "step": 2686
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.6372139723421486,
      "learning_rate": 9.368998013957205e-06,
      "loss": 0.593,
      "step": 2687
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.336472779509383,
      "learning_rate": 9.36845033574903e-06,
      "loss": 0.5459,
      "step": 2688
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.8186956133522747,
      "learning_rate": 9.367902435987297e-06,
      "loss": 0.5353,
      "step": 2689
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.8319446440846551,
      "learning_rate": 9.367354314699791e-06,
      "loss": 0.4657,
      "step": 2690
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.192304847081578,
      "learning_rate": 9.366805971914313e-06,
      "loss": 0.5748,
      "step": 2691
    },
    {
      "epoch": 0.19,
      "grad_norm": 3.270005296946123,
      "learning_rate": 9.366257407658673e-06,
      "loss": 0.4768,
      "step": 2692
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.9583820781162442,
      "learning_rate": 9.365708621960692e-06,
      "loss": 0.5526,
      "step": 2693
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.895520352001625,
      "learning_rate": 9.365159614848204e-06,
      "loss": 0.5542,
      "step": 2694
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.1093005164169463,
      "learning_rate": 9.364610386349048e-06,
      "loss": 0.5385,
      "step": 2695
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.310542069486252,
      "learning_rate": 9.364060936491086e-06,
      "loss": 0.5278,
      "step": 2696
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.9028431594654989,
      "learning_rate": 9.36351126530218e-06,
      "loss": 0.5454,
      "step": 2697
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.5818691063024946,
      "learning_rate": 9.362961372810208e-06,
      "loss": 0.4858,
      "step": 2698
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.068214117398425,
      "learning_rate": 9.36241125904306e-06,
      "loss": 0.524,
      "step": 2699
    },
    {
      "epoch": 0.19,
      "grad_norm": 4.285278807394754,
      "learning_rate": 9.361860924028635e-06,
      "loss": 0.5027,
      "step": 2700
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.689635327117054,
      "learning_rate": 9.361310367794845e-06,
      "loss": 0.5249,
      "step": 2701
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.9218682892230028,
      "learning_rate": 9.36075959036961e-06,
      "loss": 0.4937,
      "step": 2702
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.9020393657654381,
      "learning_rate": 9.360208591780867e-06,
      "loss": 0.4718,
      "step": 2703
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7352853144145038,
      "learning_rate": 9.35965737205656e-06,
      "loss": 0.4507,
      "step": 2704
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.0883478103376922,
      "learning_rate": 9.359105931224643e-06,
      "loss": 0.5257,
      "step": 2705
    },
    {
      "epoch": 0.19,
      "grad_norm": 6.447051968375037,
      "learning_rate": 9.358554269313085e-06,
      "loss": 0.5188,
      "step": 2706
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.7575345281467676,
      "learning_rate": 9.358002386349862e-06,
      "loss": 0.5101,
      "step": 2707
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.25126694267222,
      "learning_rate": 9.35745028236297e-06,
      "loss": 0.5381,
      "step": 2708
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.09962484997081,
      "learning_rate": 9.356897957380404e-06,
      "loss": 0.521,
      "step": 2709
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.9429789999577824,
      "learning_rate": 9.356345411430176e-06,
      "loss": 0.5468,
      "step": 2710
    },
    {
      "epoch": 0.19,
      "grad_norm": 3.6690742364489273,
      "learning_rate": 9.355792644540313e-06,
      "loss": 0.5218,
      "step": 2711
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.685807938192636,
      "learning_rate": 9.355239656738849e-06,
      "loss": 0.5059,
      "step": 2712
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.00615909970236,
      "learning_rate": 9.354686448053828e-06,
      "loss": 0.5565,
      "step": 2713
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.8981082187476768,
      "learning_rate": 9.354133018513305e-06,
      "loss": 0.5723,
      "step": 2714
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.9191496305819864,
      "learning_rate": 9.353579368145353e-06,
      "loss": 0.5313,
      "step": 2715
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.654361427608457,
      "learning_rate": 9.353025496978047e-06,
      "loss": 0.5178,
      "step": 2716
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.142146780916162,
      "learning_rate": 9.352471405039481e-06,
      "loss": 0.526,
      "step": 2717
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.16104214604812,
      "learning_rate": 9.351917092357754e-06,
      "loss": 0.5324,
      "step": 2718
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.5989001447560778,
      "learning_rate": 9.351362558960982e-06,
      "loss": 0.5204,
      "step": 2719
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.8864281310897013,
      "learning_rate": 9.350807804877286e-06,
      "loss": 0.5604,
      "step": 2720
    },
    {
      "epoch": 0.19,
      "grad_norm": 3.0011456173890227,
      "learning_rate": 9.350252830134802e-06,
      "loss": 0.5347,
      "step": 2721
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.365545569859083,
      "learning_rate": 9.34969763476168e-06,
      "loss": 0.563,
      "step": 2722
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.4032910192318606,
      "learning_rate": 9.34914221878607e-06,
      "loss": 0.5187,
      "step": 2723
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.8081953258199344,
      "learning_rate": 9.34858658223615e-06,
      "loss": 0.5628,
      "step": 2724
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.6909700932955827,
      "learning_rate": 9.348030725140095e-06,
      "loss": 0.5055,
      "step": 2725
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.2351615290594045,
      "learning_rate": 9.347474647526095e-06,
      "loss": 0.5322,
      "step": 2726
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.7377101948702154,
      "learning_rate": 9.346918349422356e-06,
      "loss": 0.5083,
      "step": 2727
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.875516217515371,
      "learning_rate": 9.34636183085709e-06,
      "loss": 0.5599,
      "step": 2728
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.904491008092136,
      "learning_rate": 9.345805091858522e-06,
      "loss": 0.5421,
      "step": 2729
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.7880047917708501,
      "learning_rate": 9.345248132454887e-06,
      "loss": 0.4753,
      "step": 2730
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.7798934028086881,
      "learning_rate": 9.344690952674434e-06,
      "loss": 0.5106,
      "step": 2731
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.2801407344802467,
      "learning_rate": 9.34413355254542e-06,
      "loss": 0.5161,
      "step": 2732
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.4077995117279984,
      "learning_rate": 9.343575932096116e-06,
      "loss": 0.5207,
      "step": 2733
    },
    {
      "epoch": 0.19,
      "grad_norm": 3.4280243230926226,
      "learning_rate": 9.343018091354798e-06,
      "loss": 0.5455,
      "step": 2734
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.0352352886376495,
      "learning_rate": 9.342460030349764e-06,
      "loss": 0.4352,
      "step": 2735
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.2506744395634875,
      "learning_rate": 9.341901749109315e-06,
      "loss": 0.5055,
      "step": 2736
    },
    {
      "epoch": 0.19,
      "grad_norm": 3.9259950892414737,
      "learning_rate": 9.341343247661765e-06,
      "loss": 0.5623,
      "step": 2737
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.164478681207478,
      "learning_rate": 9.340784526035438e-06,
      "loss": 0.5171,
      "step": 2738
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.1001056709036425,
      "learning_rate": 9.34022558425867e-06,
      "loss": 0.5224,
      "step": 2739
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.024208928684956,
      "learning_rate": 9.339666422359815e-06,
      "loss": 0.5347,
      "step": 2740
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.909251764595981,
      "learning_rate": 9.339107040367223e-06,
      "loss": 0.5513,
      "step": 2741
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.049200559978877,
      "learning_rate": 9.33854743830927e-06,
      "loss": 0.4979,
      "step": 2742
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.0040376185649897,
      "learning_rate": 9.337987616214335e-06,
      "loss": 0.5749,
      "step": 2743
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.5772220497292797,
      "learning_rate": 9.33742757411081e-06,
      "loss": 0.5414,
      "step": 2744
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.9864782469462028,
      "learning_rate": 9.3368673120271e-06,
      "loss": 0.5782,
      "step": 2745
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.1374961860192396,
      "learning_rate": 9.336306829991619e-06,
      "loss": 0.5664,
      "step": 2746
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.2842330560379493,
      "learning_rate": 9.335746128032793e-06,
      "loss": 0.5567,
      "step": 2747
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7342844915204731,
      "learning_rate": 9.335185206179058e-06,
      "loss": 0.4749,
      "step": 2748
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.3381002262727946,
      "learning_rate": 9.334624064458864e-06,
      "loss": 0.5489,
      "step": 2749
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6927487362916144,
      "learning_rate": 9.334062702900668e-06,
      "loss": 0.4709,
      "step": 2750
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.2241981363340706,
      "learning_rate": 9.333501121532942e-06,
      "loss": 0.4932,
      "step": 2751
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.9602971161834102,
      "learning_rate": 9.332939320384166e-06,
      "loss": 0.5112,
      "step": 2752
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.1112442873213033,
      "learning_rate": 9.332377299482835e-06,
      "loss": 0.5457,
      "step": 2753
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.296500381897397,
      "learning_rate": 9.331815058857452e-06,
      "loss": 0.5531,
      "step": 2754
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.8804323062935515,
      "learning_rate": 9.33125259853653e-06,
      "loss": 0.5133,
      "step": 2755
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.8498482608282125,
      "learning_rate": 9.3306899185486e-06,
      "loss": 0.5383,
      "step": 2756
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.8828084726782823,
      "learning_rate": 9.330127018922195e-06,
      "loss": 0.5421,
      "step": 2757
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.4294220383049523,
      "learning_rate": 9.329563899685862e-06,
      "loss": 0.5811,
      "step": 2758
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.9950950807524364,
      "learning_rate": 9.329000560868167e-06,
      "loss": 0.5603,
      "step": 2759
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.357627183678642,
      "learning_rate": 9.328437002497675e-06,
      "loss": 0.5907,
      "step": 2760
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.9219423361912158,
      "learning_rate": 9.32787322460297e-06,
      "loss": 0.5338,
      "step": 2761
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.0430250644305317,
      "learning_rate": 9.327309227212644e-06,
      "loss": 0.5325,
      "step": 2762
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.2017734767695276,
      "learning_rate": 9.326745010355303e-06,
      "loss": 0.5373,
      "step": 2763
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.211243123859259,
      "learning_rate": 9.32618057405956e-06,
      "loss": 0.5339,
      "step": 2764
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.0395557170603102,
      "learning_rate": 9.325615918354043e-06,
      "loss": 0.5417,
      "step": 2765
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.3356817325350145,
      "learning_rate": 9.32505104326739e-06,
      "loss": 0.51,
      "step": 2766
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.6806750428098034,
      "learning_rate": 9.324485948828248e-06,
      "loss": 0.5916,
      "step": 2767
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.9363469265831403,
      "learning_rate": 9.323920635065275e-06,
      "loss": 0.5257,
      "step": 2768
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.851681563715032,
      "learning_rate": 9.323355102007146e-06,
      "loss": 0.5075,
      "step": 2769
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.0569728216519483,
      "learning_rate": 9.322789349682541e-06,
      "loss": 0.5522,
      "step": 2770
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.0986776598808348,
      "learning_rate": 9.322223378120154e-06,
      "loss": 0.5636,
      "step": 2771
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.8472088316855664,
      "learning_rate": 9.321657187348689e-06,
      "loss": 0.5497,
      "step": 2772
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.9113683788331133,
      "learning_rate": 9.32109077739686e-06,
      "loss": 0.5637,
      "step": 2773
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.7528758796633612,
      "learning_rate": 9.320524148293393e-06,
      "loss": 0.5355,
      "step": 2774
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.5950917801392857,
      "learning_rate": 9.319957300067029e-06,
      "loss": 0.5866,
      "step": 2775
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.7262787228046728,
      "learning_rate": 9.319390232746514e-06,
      "loss": 0.5374,
      "step": 2776
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.6196031006644747,
      "learning_rate": 9.318822946360608e-06,
      "loss": 0.5276,
      "step": 2777
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.898183455763791,
      "learning_rate": 9.318255440938082e-06,
      "loss": 0.544,
      "step": 2778
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.0486933135024943,
      "learning_rate": 9.31768771650772e-06,
      "loss": 0.5317,
      "step": 2779
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.1214977314139034,
      "learning_rate": 9.31711977309831e-06,
      "loss": 0.5526,
      "step": 2780
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.055119260100235,
      "learning_rate": 9.316551610738664e-06,
      "loss": 0.499,
      "step": 2781
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.453378230386738,
      "learning_rate": 9.31598322945759e-06,
      "loss": 0.5485,
      "step": 2782
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.7330706678241519,
      "learning_rate": 9.315414629283918e-06,
      "loss": 0.5,
      "step": 2783
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.2011838663845786,
      "learning_rate": 9.314845810246487e-06,
      "loss": 0.5412,
      "step": 2784
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.85935545801324,
      "learning_rate": 9.314276772374143e-06,
      "loss": 0.503,
      "step": 2785
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6796465320029379,
      "learning_rate": 9.313707515695745e-06,
      "loss": 0.4682,
      "step": 2786
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.6241640002780797,
      "learning_rate": 9.313138040240167e-06,
      "loss": 0.5876,
      "step": 2787
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7847030391575606,
      "learning_rate": 9.312568346036288e-06,
      "loss": 0.4797,
      "step": 2788
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.18859612061604,
      "learning_rate": 9.311998433113002e-06,
      "loss": 0.5443,
      "step": 2789
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.141053259517826,
      "learning_rate": 9.311428301499215e-06,
      "loss": 0.5627,
      "step": 2790
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.11225697846182,
      "learning_rate": 9.31085795122384e-06,
      "loss": 0.529,
      "step": 2791
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.619112677322311,
      "learning_rate": 9.310287382315804e-06,
      "loss": 0.4772,
      "step": 2792
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.7573251197154287,
      "learning_rate": 9.309716594804044e-06,
      "loss": 0.5174,
      "step": 2793
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.8919612303002722,
      "learning_rate": 9.309145588717507e-06,
      "loss": 0.5114,
      "step": 2794
    },
    {
      "epoch": 0.19,
      "grad_norm": 3.368695569626454,
      "learning_rate": 9.308574364085157e-06,
      "loss": 0.5137,
      "step": 2795
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.9502116438615595,
      "learning_rate": 9.30800292093596e-06,
      "loss": 0.5285,
      "step": 2796
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.2005959942517004,
      "learning_rate": 9.307431259298903e-06,
      "loss": 0.521,
      "step": 2797
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.6594149479840965,
      "learning_rate": 9.306859379202973e-06,
      "loss": 0.5498,
      "step": 2798
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.8888741665880047,
      "learning_rate": 9.306287280677176e-06,
      "loss": 0.5727,
      "step": 2799
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.7890535051183052,
      "learning_rate": 9.305714963750528e-06,
      "loss": 0.5652,
      "step": 2800
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.9946817269815873,
      "learning_rate": 9.305142428452055e-06,
      "loss": 0.5293,
      "step": 2801
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.4106950703130594,
      "learning_rate": 9.304569674810794e-06,
      "loss": 0.5596,
      "step": 2802
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.7660795556288764,
      "learning_rate": 9.303996702855792e-06,
      "loss": 0.5312,
      "step": 2803
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.316452731895389,
      "learning_rate": 9.30342351261611e-06,
      "loss": 0.5434,
      "step": 2804
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.2974322649822128,
      "learning_rate": 9.302850104120815e-06,
      "loss": 0.5435,
      "step": 2805
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.0066869570205412,
      "learning_rate": 9.302276477398992e-06,
      "loss": 0.5633,
      "step": 2806
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.0633838455004008,
      "learning_rate": 9.301702632479734e-06,
      "loss": 0.5038,
      "step": 2807
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.008668572624703,
      "learning_rate": 9.301128569392142e-06,
      "loss": 0.5244,
      "step": 2808
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.312466914167518,
      "learning_rate": 9.300554288165331e-06,
      "loss": 0.5358,
      "step": 2809
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.7463770827032907,
      "learning_rate": 9.299979788828426e-06,
      "loss": 0.5238,
      "step": 2810
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.57681786256349,
      "learning_rate": 9.299405071410568e-06,
      "loss": 0.5056,
      "step": 2811
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.2123494682367952,
      "learning_rate": 9.298830135940899e-06,
      "loss": 0.557,
      "step": 2812
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.9803292093556975,
      "learning_rate": 9.29825498244858e-06,
      "loss": 0.5074,
      "step": 2813
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.8379714757915604,
      "learning_rate": 9.297679610962783e-06,
      "loss": 0.5465,
      "step": 2814
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.856422352394584,
      "learning_rate": 9.297104021512687e-06,
      "loss": 0.5834,
      "step": 2815
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.343296423339463,
      "learning_rate": 9.296528214127484e-06,
      "loss": 0.5258,
      "step": 2816
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.198599046666491,
      "learning_rate": 9.29595218883638e-06,
      "loss": 0.5364,
      "step": 2817
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.429022213119836,
      "learning_rate": 9.295375945668583e-06,
      "loss": 0.579,
      "step": 2818
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.1779677038890135,
      "learning_rate": 9.294799484653323e-06,
      "loss": 0.5772,
      "step": 2819
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.0761593943656846,
      "learning_rate": 9.294222805819834e-06,
      "loss": 0.5317,
      "step": 2820
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.8692449856217872,
      "learning_rate": 9.293645909197366e-06,
      "loss": 0.5429,
      "step": 2821
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.442774151058341,
      "learning_rate": 9.293068794815175e-06,
      "loss": 0.5407,
      "step": 2822
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.0685218180901326,
      "learning_rate": 9.29249146270253e-06,
      "loss": 0.5531,
      "step": 2823
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.841963000007722,
      "learning_rate": 9.291913912888714e-06,
      "loss": 0.5633,
      "step": 2824
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.0288020996571117,
      "learning_rate": 9.291336145403016e-06,
      "loss": 0.5352,
      "step": 2825
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.6968462207970976,
      "learning_rate": 9.29075816027474e-06,
      "loss": 0.5611,
      "step": 2826
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.9286929625333027,
      "learning_rate": 9.290179957533198e-06,
      "loss": 0.5288,
      "step": 2827
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.9351702364118777,
      "learning_rate": 9.289601537207715e-06,
      "loss": 0.541,
      "step": 2828
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.5381468848424436,
      "learning_rate": 9.289022899327627e-06,
      "loss": 0.5336,
      "step": 2829
    },
    {
      "epoch": 0.2,
      "grad_norm": 4.506763689075085,
      "learning_rate": 9.288444043922283e-06,
      "loss": 0.5384,
      "step": 2830
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.976767999379923,
      "learning_rate": 9.287864971021035e-06,
      "loss": 0.5497,
      "step": 2831
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.5843682488860367,
      "learning_rate": 9.287285680653254e-06,
      "loss": 0.5256,
      "step": 2832
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.9128380303363193,
      "learning_rate": 9.286706172848325e-06,
      "loss": 0.5919,
      "step": 2833
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.8891781174650353,
      "learning_rate": 9.286126447635632e-06,
      "loss": 0.5235,
      "step": 2834
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.5044434977765313,
      "learning_rate": 9.285546505044578e-06,
      "loss": 0.551,
      "step": 2835
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.262499654001442,
      "learning_rate": 9.28496634510458e-06,
      "loss": 0.5632,
      "step": 2836
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.5193381099707435,
      "learning_rate": 9.284385967845056e-06,
      "loss": 0.5395,
      "step": 2837
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.218357411532556,
      "learning_rate": 9.283805373295444e-06,
      "loss": 0.4928,
      "step": 2838
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.6466702513666522,
      "learning_rate": 9.283224561485191e-06,
      "loss": 0.5533,
      "step": 2839
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.0347121230930454,
      "learning_rate": 9.282643532443751e-06,
      "loss": 0.5521,
      "step": 2840
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.822294268208579,
      "learning_rate": 9.282062286200595e-06,
      "loss": 0.5762,
      "step": 2841
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.8282101301479665,
      "learning_rate": 9.281480822785197e-06,
      "loss": 0.4332,
      "step": 2842
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.448159454413644,
      "learning_rate": 9.280899142227052e-06,
      "loss": 0.5281,
      "step": 2843
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.4594331027714125,
      "learning_rate": 9.280317244555659e-06,
      "loss": 0.5521,
      "step": 2844
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.531276944272943,
      "learning_rate": 9.279735129800531e-06,
      "loss": 0.5297,
      "step": 2845
    },
    {
      "epoch": 0.2,
      "grad_norm": 5.965793175793186,
      "learning_rate": 9.27915279799119e-06,
      "loss": 0.4919,
      "step": 2846
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6964953046589347,
      "learning_rate": 9.278570249157166e-06,
      "loss": 0.4993,
      "step": 2847
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.02816269263077,
      "learning_rate": 9.277987483328012e-06,
      "loss": 0.5421,
      "step": 2848
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.365207789140195,
      "learning_rate": 9.277404500533278e-06,
      "loss": 0.5889,
      "step": 2849
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.628495056962689,
      "learning_rate": 9.276821300802535e-06,
      "loss": 0.5641,
      "step": 2850
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.3944124795575075,
      "learning_rate": 9.276237884165356e-06,
      "loss": 0.5151,
      "step": 2851
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.313435630150218,
      "learning_rate": 9.275654250651334e-06,
      "loss": 0.5209,
      "step": 2852
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.944270694235351,
      "learning_rate": 9.275070400290068e-06,
      "loss": 0.5414,
      "step": 2853
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.0690648671905425,
      "learning_rate": 9.27448633311117e-06,
      "loss": 0.5629,
      "step": 2854
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.1323473994494653,
      "learning_rate": 9.273902049144259e-06,
      "loss": 0.5618,
      "step": 2855
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.666202796460634,
      "learning_rate": 9.27331754841897e-06,
      "loss": 0.515,
      "step": 2856
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7733058792058761,
      "learning_rate": 9.272732830964948e-06,
      "loss": 0.4509,
      "step": 2857
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.2692647810221134,
      "learning_rate": 9.272147896811844e-06,
      "loss": 0.5477,
      "step": 2858
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.5237476898817994,
      "learning_rate": 9.27156274598933e-06,
      "loss": 0.4974,
      "step": 2859
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.1244289316577687,
      "learning_rate": 9.27097737852708e-06,
      "loss": 0.4945,
      "step": 2860
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.1631523851470864,
      "learning_rate": 9.270391794454779e-06,
      "loss": 0.5948,
      "step": 2861
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.1004071448113737,
      "learning_rate": 9.26980599380213e-06,
      "loss": 0.5245,
      "step": 2862
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.4922708982441315,
      "learning_rate": 9.26921997659884e-06,
      "loss": 0.5525,
      "step": 2863
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.1965943946253375,
      "learning_rate": 9.26863374287463e-06,
      "loss": 0.5647,
      "step": 2864
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.0504266709609102,
      "learning_rate": 9.268047292659236e-06,
      "loss": 0.5381,
      "step": 2865
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.001065168563886,
      "learning_rate": 9.267460625982398e-06,
      "loss": 0.5169,
      "step": 2866
    },
    {
      "epoch": 0.2,
      "grad_norm": 7.145745124496972,
      "learning_rate": 9.266873742873867e-06,
      "loss": 0.5417,
      "step": 2867
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.07556847348365,
      "learning_rate": 9.266286643363414e-06,
      "loss": 0.5391,
      "step": 2868
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.064057214941599,
      "learning_rate": 9.265699327480809e-06,
      "loss": 0.5316,
      "step": 2869
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.4346950562526293,
      "learning_rate": 9.265111795255841e-06,
      "loss": 0.4982,
      "step": 2870
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.447088396402172,
      "learning_rate": 9.264524046718309e-06,
      "loss": 0.54,
      "step": 2871
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.9707685679949427,
      "learning_rate": 9.26393608189802e-06,
      "loss": 0.492,
      "step": 2872
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.4293940150371323,
      "learning_rate": 9.263347900824795e-06,
      "loss": 0.5372,
      "step": 2873
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.9208406309790007,
      "learning_rate": 9.262759503528463e-06,
      "loss": 0.5907,
      "step": 2874
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.3342783633903292,
      "learning_rate": 9.262170890038867e-06,
      "loss": 0.5866,
      "step": 2875
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.683382945801259,
      "learning_rate": 9.261582060385857e-06,
      "loss": 0.5308,
      "step": 2876
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.9026148518931034,
      "learning_rate": 9.2609930145993e-06,
      "loss": 0.5401,
      "step": 2877
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.282630023633445,
      "learning_rate": 9.260403752709068e-06,
      "loss": 0.5308,
      "step": 2878
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.277627006453467,
      "learning_rate": 9.259814274745047e-06,
      "loss": 0.5315,
      "step": 2879
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.906894019792415,
      "learning_rate": 9.259224580737136e-06,
      "loss": 0.5447,
      "step": 2880
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.177482681139777,
      "learning_rate": 9.25863467071524e-06,
      "loss": 0.5341,
      "step": 2881
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.121655466371946,
      "learning_rate": 9.258044544709276e-06,
      "loss": 0.4662,
      "step": 2882
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.6143849948187048,
      "learning_rate": 9.257454202749174e-06,
      "loss": 0.5699,
      "step": 2883
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7912594366721901,
      "learning_rate": 9.256863644864877e-06,
      "loss": 0.4712,
      "step": 2884
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.8537839331334645,
      "learning_rate": 9.256272871086333e-06,
      "loss": 0.5727,
      "step": 2885
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.5290130156008948,
      "learning_rate": 9.255681881443506e-06,
      "loss": 0.5426,
      "step": 2886
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.263614043557521,
      "learning_rate": 9.255090675966368e-06,
      "loss": 0.495,
      "step": 2887
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.7304548439350027,
      "learning_rate": 9.2544992546849e-06,
      "loss": 0.5563,
      "step": 2888
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.217999369738233,
      "learning_rate": 9.253907617629105e-06,
      "loss": 0.5597,
      "step": 2889
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.458813667670128,
      "learning_rate": 9.253315764828984e-06,
      "loss": 0.5752,
      "step": 2890
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7098261968980001,
      "learning_rate": 9.25272369631455e-06,
      "loss": 0.4597,
      "step": 2891
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.8593659133028289,
      "learning_rate": 9.252131412115838e-06,
      "loss": 0.5841,
      "step": 2892
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.9643951947412361,
      "learning_rate": 9.251538912262883e-06,
      "loss": 0.4949,
      "step": 2893
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.6981374612316815,
      "learning_rate": 9.250946196785736e-06,
      "loss": 0.4853,
      "step": 2894
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.7805869564840797,
      "learning_rate": 9.250353265714454e-06,
      "loss": 0.5295,
      "step": 2895
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.5456404302263778,
      "learning_rate": 9.249760119079114e-06,
      "loss": 0.5288,
      "step": 2896
    },
    {
      "epoch": 0.2,
      "grad_norm": 6.803012836175892,
      "learning_rate": 9.249166756909793e-06,
      "loss": 0.538,
      "step": 2897
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.3143549712819653,
      "learning_rate": 9.24857317923659e-06,
      "loss": 0.5326,
      "step": 2898
    },
    {
      "epoch": 0.2,
      "grad_norm": 4.224013357619296,
      "learning_rate": 9.247979386089606e-06,
      "loss": 0.5756,
      "step": 2899
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.0878600767698994,
      "learning_rate": 9.247385377498957e-06,
      "loss": 0.5089,
      "step": 2900
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.8554918247145562,
      "learning_rate": 9.246791153494767e-06,
      "loss": 0.5339,
      "step": 2901
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.5506259466352943,
      "learning_rate": 9.246196714107176e-06,
      "loss": 0.5397,
      "step": 2902
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.297408753073835,
      "learning_rate": 9.24560205936633e-06,
      "loss": 0.5451,
      "step": 2903
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.9161241369694093,
      "learning_rate": 9.245007189302392e-06,
      "loss": 0.5365,
      "step": 2904
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.0941504012479317,
      "learning_rate": 9.244412103945525e-06,
      "loss": 0.5561,
      "step": 2905
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.8486457389003834,
      "learning_rate": 9.243816803325918e-06,
      "loss": 0.4897,
      "step": 2906
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.190958767103423,
      "learning_rate": 9.243221287473755e-06,
      "loss": 0.5632,
      "step": 2907
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.5683991567694067,
      "learning_rate": 9.242625556419243e-06,
      "loss": 0.5238,
      "step": 2908
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.5990022052210162,
      "learning_rate": 9.242029610192596e-06,
      "loss": 0.4886,
      "step": 2909
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.7152215285430246,
      "learning_rate": 9.241433448824036e-06,
      "loss": 0.5672,
      "step": 2910
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.8865763521785082,
      "learning_rate": 9.240837072343797e-06,
      "loss": 0.5171,
      "step": 2911
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.9243955523327354,
      "learning_rate": 9.24024048078213e-06,
      "loss": 0.5116,
      "step": 2912
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.295569209255258,
      "learning_rate": 9.239643674169289e-06,
      "loss": 0.5158,
      "step": 2913
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.8080453899305045,
      "learning_rate": 9.239046652535544e-06,
      "loss": 0.5195,
      "step": 2914
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.9329776965504037,
      "learning_rate": 9.238449415911173e-06,
      "loss": 0.5539,
      "step": 2915
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.2345973144830134,
      "learning_rate": 9.237851964326466e-06,
      "loss": 0.5659,
      "step": 2916
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.1071311938799018,
      "learning_rate": 9.23725429781172e-06,
      "loss": 0.5545,
      "step": 2917
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.42202894179115,
      "learning_rate": 9.236656416397254e-06,
      "loss": 0.5733,
      "step": 2918
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.899460319089203,
      "learning_rate": 9.236058320113386e-06,
      "loss": 0.5069,
      "step": 2919
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.0858792344302715,
      "learning_rate": 9.235460008990449e-06,
      "loss": 0.5383,
      "step": 2920
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.1890930631818657,
      "learning_rate": 9.23486148305879e-06,
      "loss": 0.5355,
      "step": 2921
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.3741553440993313,
      "learning_rate": 9.234262742348764e-06,
      "loss": 0.5297,
      "step": 2922
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7266323710591747,
      "learning_rate": 9.233663786890735e-06,
      "loss": 0.4782,
      "step": 2923
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.6789329980183065,
      "learning_rate": 9.23306461671508e-06,
      "loss": 0.5493,
      "step": 2924
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.9241902689035209,
      "learning_rate": 9.232465231852189e-06,
      "loss": 0.5279,
      "step": 2925
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.0017164026872987,
      "learning_rate": 9.23186563233246e-06,
      "loss": 0.5122,
      "step": 2926
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.448172001096398,
      "learning_rate": 9.231265818186304e-06,
      "loss": 0.5243,
      "step": 2927
    },
    {
      "epoch": 0.2,
      "grad_norm": 4.2757867747723814,
      "learning_rate": 9.23066578944414e-06,
      "loss": 0.5555,
      "step": 2928
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.2906427992308807,
      "learning_rate": 9.2300655461364e-06,
      "loss": 0.5236,
      "step": 2929
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.1795156180768163,
      "learning_rate": 9.229465088293525e-06,
      "loss": 0.5474,
      "step": 2930
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.080909732070262,
      "learning_rate": 9.22886441594597e-06,
      "loss": 0.5739,
      "step": 2931
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.8672921571842904,
      "learning_rate": 9.228263529124199e-06,
      "loss": 0.554,
      "step": 2932
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.0976134822094625,
      "learning_rate": 9.227662427858687e-06,
      "loss": 0.5189,
      "step": 2933
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.9620994472447864,
      "learning_rate": 9.22706111217992e-06,
      "loss": 0.543,
      "step": 2934
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.216274168384271,
      "learning_rate": 9.226459582118394e-06,
      "loss": 0.4963,
      "step": 2935
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.0123086017970255,
      "learning_rate": 9.225857837704617e-06,
      "loss": 0.5494,
      "step": 2936
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.1853671100842154,
      "learning_rate": 9.225255878969108e-06,
      "loss": 0.5668,
      "step": 2937
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.6066489625134532,
      "learning_rate": 9.224653705942396e-06,
      "loss": 0.5644,
      "step": 2938
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.775037766746005,
      "learning_rate": 9.224051318655021e-06,
      "loss": 0.5388,
      "step": 2939
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.7107570562966354,
      "learning_rate": 9.223448717137533e-06,
      "loss": 0.5048,
      "step": 2940
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.2212493250351106,
      "learning_rate": 9.222845901420496e-06,
      "loss": 0.5093,
      "step": 2941
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.193106000583539,
      "learning_rate": 9.222242871534484e-06,
      "loss": 0.5135,
      "step": 2942
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.9133374885896663,
      "learning_rate": 9.221639627510076e-06,
      "loss": 0.5429,
      "step": 2943
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.7309193667503653,
      "learning_rate": 9.22103616937787e-06,
      "loss": 0.5201,
      "step": 2944
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7341856380613395,
      "learning_rate": 9.220432497168472e-06,
      "loss": 0.4643,
      "step": 2945
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.021766499944075,
      "learning_rate": 9.219828610912497e-06,
      "loss": 0.5127,
      "step": 2946
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.206002137393305,
      "learning_rate": 9.219224510640572e-06,
      "loss": 0.4978,
      "step": 2947
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.8441085661551186,
      "learning_rate": 9.218620196383337e-06,
      "loss": 0.5694,
      "step": 2948
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.842309574429751,
      "learning_rate": 9.218015668171435e-06,
      "loss": 0.5707,
      "step": 2949
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.756883799259406,
      "learning_rate": 9.217410926035534e-06,
      "loss": 0.4836,
      "step": 2950
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.783339835953508,
      "learning_rate": 9.216805970006298e-06,
      "loss": 0.5452,
      "step": 2951
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.009581057833983,
      "learning_rate": 9.216200800114412e-06,
      "loss": 0.5434,
      "step": 2952
    },
    {
      "epoch": 0.21,
      "grad_norm": 3.4764776914728532,
      "learning_rate": 9.215595416390567e-06,
      "loss": 0.5403,
      "step": 2953
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.818553419279373,
      "learning_rate": 9.214989818865465e-06,
      "loss": 0.52,
      "step": 2954
    },
    {
      "epoch": 0.21,
      "grad_norm": 3.8852561457172987,
      "learning_rate": 9.21438400756982e-06,
      "loss": 0.5753,
      "step": 2955
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.9727513003366777,
      "learning_rate": 9.213777982534361e-06,
      "loss": 0.5985,
      "step": 2956
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.0228617987217503,
      "learning_rate": 9.21317174378982e-06,
      "loss": 0.5382,
      "step": 2957
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.1492608480884847,
      "learning_rate": 9.212565291366942e-06,
      "loss": 0.5829,
      "step": 2958
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.8985860330307651,
      "learning_rate": 9.211958625296487e-06,
      "loss": 0.5197,
      "step": 2959
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.97492748231079,
      "learning_rate": 9.211351745609221e-06,
      "loss": 0.492,
      "step": 2960
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.837394375029186,
      "learning_rate": 9.210744652335926e-06,
      "loss": 0.5398,
      "step": 2961
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.3159418717402755,
      "learning_rate": 9.21013734550739e-06,
      "loss": 0.4709,
      "step": 2962
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.8207753661672461,
      "learning_rate": 9.209529825154413e-06,
      "loss": 0.5054,
      "step": 2963
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.4351819738030844,
      "learning_rate": 9.208922091307808e-06,
      "loss": 0.5463,
      "step": 2964
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.2457061899904582,
      "learning_rate": 9.208314143998396e-06,
      "loss": 0.5575,
      "step": 2965
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.647960977796312,
      "learning_rate": 9.20770598325701e-06,
      "loss": 0.63,
      "step": 2966
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.452800779892721,
      "learning_rate": 9.207097609114495e-06,
      "loss": 0.5002,
      "step": 2967
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.850086237602427,
      "learning_rate": 9.206489021601704e-06,
      "loss": 0.4516,
      "step": 2968
    },
    {
      "epoch": 0.21,
      "grad_norm": 5.04650131676251,
      "learning_rate": 9.205880220749505e-06,
      "loss": 0.5687,
      "step": 2969
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.1135820916323067,
      "learning_rate": 9.205271206588773e-06,
      "loss": 0.526,
      "step": 2970
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.9215993030585004,
      "learning_rate": 9.204661979150395e-06,
      "loss": 0.5554,
      "step": 2971
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.3526303532061807,
      "learning_rate": 9.20405253846527e-06,
      "loss": 0.5201,
      "step": 2972
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.019928043048244,
      "learning_rate": 9.203442884564305e-06,
      "loss": 0.5084,
      "step": 2973
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.1889688072753946,
      "learning_rate": 9.202833017478421e-06,
      "loss": 0.5064,
      "step": 2974
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.881462095233766,
      "learning_rate": 9.20222293723855e-06,
      "loss": 0.5137,
      "step": 2975
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.520829353875497,
      "learning_rate": 9.20161264387563e-06,
      "loss": 0.5566,
      "step": 2976
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.1859252687874964,
      "learning_rate": 9.201002137420615e-06,
      "loss": 0.5398,
      "step": 2977
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.491334005817437,
      "learning_rate": 9.20039141790447e-06,
      "loss": 0.5142,
      "step": 2978
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.9025590149861824,
      "learning_rate": 9.199780485358164e-06,
      "loss": 0.4912,
      "step": 2979
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.6113156208031865,
      "learning_rate": 9.199169339812685e-06,
      "loss": 0.5093,
      "step": 2980
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.8296039818799388,
      "learning_rate": 9.198557981299026e-06,
      "loss": 0.5502,
      "step": 2981
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.0748064201250425,
      "learning_rate": 9.197946409848196e-06,
      "loss": 0.5526,
      "step": 2982
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.145298462854508,
      "learning_rate": 9.197334625491208e-06,
      "loss": 0.5795,
      "step": 2983
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.318210448837519,
      "learning_rate": 9.196722628259094e-06,
      "loss": 0.5144,
      "step": 2984
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.7934011298900202,
      "learning_rate": 9.196110418182889e-06,
      "loss": 0.4539,
      "step": 2985
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.7136160558719258,
      "learning_rate": 9.195497995293643e-06,
      "loss": 0.4652,
      "step": 2986
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.2546171364985237,
      "learning_rate": 9.194885359622418e-06,
      "loss": 0.5346,
      "step": 2987
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.501884793959311,
      "learning_rate": 9.194272511200284e-06,
      "loss": 0.5551,
      "step": 2988
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.3780719170551525,
      "learning_rate": 9.193659450058321e-06,
      "loss": 0.5306,
      "step": 2989
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.1890274655803053,
      "learning_rate": 9.193046176227625e-06,
      "loss": 0.5449,
      "step": 2990
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.2244804590533502,
      "learning_rate": 9.192432689739294e-06,
      "loss": 0.5576,
      "step": 2991
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.7012060814131387,
      "learning_rate": 9.191818990624447e-06,
      "loss": 0.5005,
      "step": 2992
    },
    {
      "epoch": 0.21,
      "grad_norm": 3.3343139003969253,
      "learning_rate": 9.191205078914207e-06,
      "loss": 0.551,
      "step": 2993
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.9984244751653344,
      "learning_rate": 9.190590954639709e-06,
      "loss": 0.567,
      "step": 2994
    },
    {
      "epoch": 0.21,
      "grad_norm": 14.717545430258406,
      "learning_rate": 9.189976617832101e-06,
      "loss": 0.534,
      "step": 2995
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.376057302077794,
      "learning_rate": 9.189362068522538e-06,
      "loss": 0.4985,
      "step": 2996
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.4713962824404097,
      "learning_rate": 9.18874730674219e-06,
      "loss": 0.5724,
      "step": 2997
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.5965546750752977,
      "learning_rate": 9.188132332522233e-06,
      "loss": 0.5408,
      "step": 2998
    },
    {
      "epoch": 0.21,
      "grad_norm": 3.792468126059908,
      "learning_rate": 9.187517145893859e-06,
      "loss": 0.523,
      "step": 2999
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.169985726430125,
      "learning_rate": 9.186901746888267e-06,
      "loss": 0.5604,
      "step": 3000
    },
    {
      "epoch": 0.21,
      "grad_norm": 3.0908405942681845,
      "learning_rate": 9.186286135536668e-06,
      "loss": 0.5168,
      "step": 3001
    },
    {
      "epoch": 0.21,
      "grad_norm": 13.651967340228394,
      "learning_rate": 9.185670311870286e-06,
      "loss": 0.5351,
      "step": 3002
    },
    {
      "epoch": 0.21,
      "grad_norm": 3.7657485131625714,
      "learning_rate": 9.185054275920351e-06,
      "loss": 0.537,
      "step": 3003
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.899282428180192,
      "learning_rate": 9.184438027718108e-06,
      "loss": 0.566,
      "step": 3004
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.1895054451068774,
      "learning_rate": 9.18382156729481e-06,
      "loss": 0.4884,
      "step": 3005
    },
    {
      "epoch": 0.21,
      "grad_norm": 3.19834402136852,
      "learning_rate": 9.183204894681722e-06,
      "loss": 0.561,
      "step": 3006
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.7284953909349783,
      "learning_rate": 9.182588009910119e-06,
      "loss": 0.52,
      "step": 3007
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.007217302727285,
      "learning_rate": 9.181970913011289e-06,
      "loss": 0.5006,
      "step": 3008
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.3388152460620955,
      "learning_rate": 9.181353604016528e-06,
      "loss": 0.5295,
      "step": 3009
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.0728605671757445,
      "learning_rate": 9.180736082957142e-06,
      "loss": 0.5631,
      "step": 3010
    },
    {
      "epoch": 0.21,
      "grad_norm": 3.3169535132951684,
      "learning_rate": 9.180118349864455e-06,
      "loss": 0.5385,
      "step": 3011
    },
    {
      "epoch": 0.21,
      "grad_norm": 12.92911552513586,
      "learning_rate": 9.179500404769792e-06,
      "loss": 0.5177,
      "step": 3012
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.467803737897323,
      "learning_rate": 9.178882247704494e-06,
      "loss": 0.5604,
      "step": 3013
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.6527262318373521,
      "learning_rate": 9.178263878699913e-06,
      "loss": 0.5027,
      "step": 3014
    },
    {
      "epoch": 0.21,
      "grad_norm": 3.834787375167506,
      "learning_rate": 9.177645297787412e-06,
      "loss": 0.5214,
      "step": 3015
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.724172678966786,
      "learning_rate": 9.177026504998358e-06,
      "loss": 0.5376,
      "step": 3016
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.665299610839437,
      "learning_rate": 9.176407500364139e-06,
      "loss": 0.5103,
      "step": 3017
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.128176544662521,
      "learning_rate": 9.175788283916149e-06,
      "loss": 0.5627,
      "step": 3018
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.51156424468183,
      "learning_rate": 9.17516885568579e-06,
      "loss": 0.5077,
      "step": 3019
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.2415840738289243,
      "learning_rate": 9.174549215704476e-06,
      "loss": 0.5578,
      "step": 3020
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.9929426688921278,
      "learning_rate": 9.173929364003637e-06,
      "loss": 0.4763,
      "step": 3021
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.9102223482968865,
      "learning_rate": 9.17330930061471e-06,
      "loss": 0.5247,
      "step": 3022
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.1301398613005254,
      "learning_rate": 9.17268902556914e-06,
      "loss": 0.5386,
      "step": 3023
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.0744822339841114,
      "learning_rate": 9.172068538898386e-06,
      "loss": 0.526,
      "step": 3024
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.394385431556051,
      "learning_rate": 9.171447840633918e-06,
      "loss": 0.4919,
      "step": 3025
    },
    {
      "epoch": 0.21,
      "grad_norm": 4.70159222240838,
      "learning_rate": 9.170826930807214e-06,
      "loss": 0.5269,
      "step": 3026
    },
    {
      "epoch": 0.21,
      "grad_norm": 8.054010549916505,
      "learning_rate": 9.170205809449768e-06,
      "loss": 0.5698,
      "step": 3027
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.0310362875117947,
      "learning_rate": 9.169584476593078e-06,
      "loss": 0.5192,
      "step": 3028
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.8786969008622505,
      "learning_rate": 9.168962932268657e-06,
      "loss": 0.5485,
      "step": 3029
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.5991807730877245,
      "learning_rate": 9.168341176508028e-06,
      "loss": 0.5245,
      "step": 3030
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.8357991331447963,
      "learning_rate": 9.167719209342723e-06,
      "loss": 0.5486,
      "step": 3031
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.240174877401471,
      "learning_rate": 9.167097030804289e-06,
      "loss": 0.5258,
      "step": 3032
    },
    {
      "epoch": 0.21,
      "grad_norm": 3.711721001134495,
      "learning_rate": 9.166474640924276e-06,
      "loss": 0.5516,
      "step": 3033
    },
    {
      "epoch": 0.21,
      "grad_norm": 5.423627145003715,
      "learning_rate": 9.165852039734255e-06,
      "loss": 0.5855,
      "step": 3034
    },
    {
      "epoch": 0.21,
      "grad_norm": 3.4046427466892064,
      "learning_rate": 9.1652292272658e-06,
      "loss": 0.5054,
      "step": 3035
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.748393563008108,
      "learning_rate": 9.164606203550498e-06,
      "loss": 0.4887,
      "step": 3036
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.7891521992945767,
      "learning_rate": 9.163982968619946e-06,
      "loss": 0.532,
      "step": 3037
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.922216333263107,
      "learning_rate": 9.163359522505755e-06,
      "loss": 0.5446,
      "step": 3038
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.9418100741142337,
      "learning_rate": 9.16273586523954e-06,
      "loss": 0.4985,
      "step": 3039
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.2959000504567606,
      "learning_rate": 9.162111996852933e-06,
      "loss": 0.5276,
      "step": 3040
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.9659371023902465,
      "learning_rate": 9.161487917377578e-06,
      "loss": 0.4629,
      "step": 3041
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.088197100257185,
      "learning_rate": 9.16086362684512e-06,
      "loss": 0.5077,
      "step": 3042
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.7367528609915601,
      "learning_rate": 9.160239125287224e-06,
      "loss": 0.454,
      "step": 3043
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.8476838256873527,
      "learning_rate": 9.159614412735566e-06,
      "loss": 0.49,
      "step": 3044
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.9571541724271064,
      "learning_rate": 9.158989489221824e-06,
      "loss": 0.5351,
      "step": 3045
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.5286578348298683,
      "learning_rate": 9.158364354777693e-06,
      "loss": 0.5122,
      "step": 3046
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.1528883897428583,
      "learning_rate": 9.15773900943488e-06,
      "loss": 0.5794,
      "step": 3047
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.365754742043168,
      "learning_rate": 9.157113453225099e-06,
      "loss": 0.5283,
      "step": 3048
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.5963339556747194,
      "learning_rate": 9.156487686180078e-06,
      "loss": 0.5191,
      "step": 3049
    },
    {
      "epoch": 0.21,
      "grad_norm": 3.6581136014038735,
      "learning_rate": 9.155861708331553e-06,
      "loss": 0.5755,
      "step": 3050
    },
    {
      "epoch": 0.21,
      "grad_norm": 6.359226459505235,
      "learning_rate": 9.155235519711269e-06,
      "loss": 0.5532,
      "step": 3051
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.950852385221523,
      "learning_rate": 9.154609120350986e-06,
      "loss": 0.5404,
      "step": 3052
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.1071578632260644,
      "learning_rate": 9.153982510282475e-06,
      "loss": 0.5289,
      "step": 3053
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.0325833552211963,
      "learning_rate": 9.153355689537513e-06,
      "loss": 0.5418,
      "step": 3054
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.0580740907111914,
      "learning_rate": 9.152728658147891e-06,
      "loss": 0.5347,
      "step": 3055
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.5888058637223388,
      "learning_rate": 9.152101416145411e-06,
      "loss": 0.5093,
      "step": 3056
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.0475296639752356,
      "learning_rate": 9.151473963561884e-06,
      "loss": 0.5607,
      "step": 3057
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.6146001485589414,
      "learning_rate": 9.15084630042913e-06,
      "loss": 0.5357,
      "step": 3058
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.9831014070534214,
      "learning_rate": 9.150218426778985e-06,
      "loss": 0.5281,
      "step": 3059
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.8130412352806147,
      "learning_rate": 9.149590342643293e-06,
      "loss": 0.5624,
      "step": 3060
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.056783204452251,
      "learning_rate": 9.148962048053906e-06,
      "loss": 0.5176,
      "step": 3061
    },
    {
      "epoch": 0.21,
      "grad_norm": 11.770359017769534,
      "learning_rate": 9.14833354304269e-06,
      "loss": 0.5579,
      "step": 3062
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.1752610316966177,
      "learning_rate": 9.147704827641524e-06,
      "loss": 0.5181,
      "step": 3063
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.0749093867953037,
      "learning_rate": 9.147075901882289e-06,
      "loss": 0.5079,
      "step": 3064
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.450709431897131,
      "learning_rate": 9.146446765796884e-06,
      "loss": 0.4561,
      "step": 3065
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.3193958270338157,
      "learning_rate": 9.145817419417218e-06,
      "loss": 0.6069,
      "step": 3066
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.3847057604615471,
      "learning_rate": 9.145187862775208e-06,
      "loss": 0.5355,
      "step": 3067
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.091116936592703,
      "learning_rate": 9.144558095902785e-06,
      "loss": 0.5491,
      "step": 3068
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.9137044254904203,
      "learning_rate": 9.143928118831888e-06,
      "loss": 0.4712,
      "step": 3069
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.8295486392655498,
      "learning_rate": 9.143297931594465e-06,
      "loss": 0.5267,
      "step": 3070
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.5108506429197126,
      "learning_rate": 9.14266753422248e-06,
      "loss": 0.5265,
      "step": 3071
    },
    {
      "epoch": 0.21,
      "grad_norm": 3.264909331037275,
      "learning_rate": 9.142036926747904e-06,
      "loss": 0.4659,
      "step": 3072
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.3519003844189705,
      "learning_rate": 9.141406109202718e-06,
      "loss": 0.5884,
      "step": 3073
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.2756264992390807,
      "learning_rate": 9.140775081618915e-06,
      "loss": 0.5777,
      "step": 3074
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.2041958106263775,
      "learning_rate": 9.1401438440285e-06,
      "loss": 0.4969,
      "step": 3075
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.511181607579774,
      "learning_rate": 9.139512396463487e-06,
      "loss": 0.556,
      "step": 3076
    },
    {
      "epoch": 0.21,
      "grad_norm": 4.988984099062096,
      "learning_rate": 9.138880738955902e-06,
      "loss": 0.5434,
      "step": 3077
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.213184607127239,
      "learning_rate": 9.138248871537778e-06,
      "loss": 0.5444,
      "step": 3078
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.8428661885014053,
      "learning_rate": 9.137616794241162e-06,
      "loss": 0.5016,
      "step": 3079
    },
    {
      "epoch": 0.21,
      "grad_norm": 3.7337754600394764,
      "learning_rate": 9.136984507098114e-06,
      "loss": 0.5166,
      "step": 3080
    },
    {
      "epoch": 0.21,
      "grad_norm": 3.678341231805817,
      "learning_rate": 9.136352010140697e-06,
      "loss": 0.5143,
      "step": 3081
    },
    {
      "epoch": 0.21,
      "grad_norm": 3.416314183976969,
      "learning_rate": 9.135719303400995e-06,
      "loss": 0.5074,
      "step": 3082
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.4278247233583206,
      "learning_rate": 9.13508638691109e-06,
      "loss": 0.4855,
      "step": 3083
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.6218647905487122,
      "learning_rate": 9.134453260703084e-06,
      "loss": 0.5224,
      "step": 3084
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.4565514644328603,
      "learning_rate": 9.133819924809089e-06,
      "loss": 0.5558,
      "step": 3085
    },
    {
      "epoch": 0.21,
      "grad_norm": 4.057894305426421,
      "learning_rate": 9.133186379261224e-06,
      "loss": 0.5209,
      "step": 3086
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.3090735178815573,
      "learning_rate": 9.13255262409162e-06,
      "loss": 0.4968,
      "step": 3087
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.5810024268005107,
      "learning_rate": 9.131918659332422e-06,
      "loss": 0.4953,
      "step": 3088
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.5668645939600272,
      "learning_rate": 9.131284485015778e-06,
      "loss": 0.5188,
      "step": 3089
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.1344833584619503,
      "learning_rate": 9.130650101173856e-06,
      "loss": 0.5092,
      "step": 3090
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.6851854893156957,
      "learning_rate": 9.130015507838827e-06,
      "loss": 0.5492,
      "step": 3091
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.565158233212656,
      "learning_rate": 9.129380705042874e-06,
      "loss": 0.5458,
      "step": 3092
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.393632425385858,
      "learning_rate": 9.128745692818198e-06,
      "loss": 0.5817,
      "step": 3093
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.9509733786237486,
      "learning_rate": 9.128110471196997e-06,
      "loss": 0.4793,
      "step": 3094
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.1594419710100885,
      "learning_rate": 9.127475040211493e-06,
      "loss": 0.5193,
      "step": 3095
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.2850772535923127,
      "learning_rate": 9.126839399893913e-06,
      "loss": 0.5143,
      "step": 3096
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.913293414975452,
      "learning_rate": 9.12620355027649e-06,
      "loss": 0.5188,
      "step": 3097
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.8230168575403582,
      "learning_rate": 9.125567491391476e-06,
      "loss": 0.5483,
      "step": 3098
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.850527995344107,
      "learning_rate": 9.12493122327113e-06,
      "loss": 0.5148,
      "step": 3099
    },
    {
      "epoch": 0.22,
      "grad_norm": 3.10847795551992,
      "learning_rate": 9.124294745947719e-06,
      "loss": 0.5562,
      "step": 3100
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.892071925084636,
      "learning_rate": 9.123658059453526e-06,
      "loss": 0.5436,
      "step": 3101
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.1926926580964348,
      "learning_rate": 9.123021163820839e-06,
      "loss": 0.5334,
      "step": 3102
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.1393087725890365,
      "learning_rate": 9.122384059081961e-06,
      "loss": 0.5186,
      "step": 3103
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.8404326854930917,
      "learning_rate": 9.121746745269201e-06,
      "loss": 0.5758,
      "step": 3104
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.5619632519388884,
      "learning_rate": 9.121109222414888e-06,
      "loss": 0.5096,
      "step": 3105
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.7848906185134741,
      "learning_rate": 9.120471490551348e-06,
      "loss": 0.4678,
      "step": 3106
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.9995580931884533,
      "learning_rate": 9.119833549710927e-06,
      "loss": 0.5768,
      "step": 3107
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.1644803196371805,
      "learning_rate": 9.119195399925981e-06,
      "loss": 0.5201,
      "step": 3108
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.2417461019285856,
      "learning_rate": 9.118557041228875e-06,
      "loss": 0.4946,
      "step": 3109
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.9770202776404928,
      "learning_rate": 9.117918473651982e-06,
      "loss": 0.5149,
      "step": 3110
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.1241902926451224,
      "learning_rate": 9.117279697227687e-06,
      "loss": 0.5888,
      "step": 3111
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.9752010164927924,
      "learning_rate": 9.116640711988392e-06,
      "loss": 0.5192,
      "step": 3112
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.4151179984166458,
      "learning_rate": 9.1160015179665e-06,
      "loss": 0.5373,
      "step": 3113
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.7245374919967561,
      "learning_rate": 9.11536211519443e-06,
      "loss": 0.4646,
      "step": 3114
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.121183165197359,
      "learning_rate": 9.11472250370461e-06,
      "loss": 0.5595,
      "step": 3115
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.5229341157555707,
      "learning_rate": 9.11408268352948e-06,
      "loss": 0.5262,
      "step": 3116
    },
    {
      "epoch": 0.22,
      "grad_norm": 5.504643218361446,
      "learning_rate": 9.113442654701487e-06,
      "loss": 0.5443,
      "step": 3117
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.0329608925775293,
      "learning_rate": 9.112802417253094e-06,
      "loss": 0.5293,
      "step": 3118
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.2307617793808863,
      "learning_rate": 9.112161971216774e-06,
      "loss": 0.57,
      "step": 3119
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.380253961172946,
      "learning_rate": 9.111521316625002e-06,
      "loss": 0.6063,
      "step": 3120
    },
    {
      "epoch": 0.22,
      "grad_norm": 3.315202934593163,
      "learning_rate": 9.110880453510274e-06,
      "loss": 0.539,
      "step": 3121
    },
    {
      "epoch": 0.22,
      "grad_norm": 9.582525135344424,
      "learning_rate": 9.11023938190509e-06,
      "loss": 0.5401,
      "step": 3122
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.8404179317080724,
      "learning_rate": 9.109598101841967e-06,
      "loss": 0.5145,
      "step": 3123
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.473768892848045,
      "learning_rate": 9.108956613353425e-06,
      "loss": 0.5586,
      "step": 3124
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.1269909644612146,
      "learning_rate": 9.108314916472e-06,
      "loss": 0.4978,
      "step": 3125
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.9580623780020536,
      "learning_rate": 9.107673011230238e-06,
      "loss": 0.4951,
      "step": 3126
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.0872909278381804,
      "learning_rate": 9.10703089766069e-06,
      "loss": 0.5707,
      "step": 3127
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.7675827611797792,
      "learning_rate": 9.106388575795925e-06,
      "loss": 0.5214,
      "step": 3128
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.0153776963084997,
      "learning_rate": 9.10574604566852e-06,
      "loss": 0.5313,
      "step": 3129
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.054913782118899,
      "learning_rate": 9.105103307311062e-06,
      "loss": 0.5926,
      "step": 3130
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.80309476913075,
      "learning_rate": 9.104460360756146e-06,
      "loss": 0.5265,
      "step": 3131
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.7034773504182239,
      "learning_rate": 9.103817206036383e-06,
      "loss": 0.4749,
      "step": 3132
    },
    {
      "epoch": 0.22,
      "grad_norm": 6.787604791711632,
      "learning_rate": 9.10317384318439e-06,
      "loss": 0.5193,
      "step": 3133
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.5335274067225653,
      "learning_rate": 9.102530272232796e-06,
      "loss": 0.5064,
      "step": 3134
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.1460819949836987,
      "learning_rate": 9.101886493214243e-06,
      "loss": 0.5362,
      "step": 3135
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.7887361160248454,
      "learning_rate": 9.101242506161378e-06,
      "loss": 0.5268,
      "step": 3136
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.981767800552069,
      "learning_rate": 9.100598311106865e-06,
      "loss": 0.524,
      "step": 3137
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.382788780189984,
      "learning_rate": 9.099953908083375e-06,
      "loss": 0.5942,
      "step": 3138
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.9976443681001617,
      "learning_rate": 9.099309297123588e-06,
      "loss": 0.5351,
      "step": 3139
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.8549645517390634,
      "learning_rate": 9.098664478260199e-06,
      "loss": 0.542,
      "step": 3140
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.458646607828953,
      "learning_rate": 9.09801945152591e-06,
      "loss": 0.5227,
      "step": 3141
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.781228838366784,
      "learning_rate": 9.097374216953435e-06,
      "loss": 0.5463,
      "step": 3142
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6710596381102523,
      "learning_rate": 9.096728774575498e-06,
      "loss": 0.4679,
      "step": 3143
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.990889933022726,
      "learning_rate": 9.096083124424833e-06,
      "loss": 0.5282,
      "step": 3144
    },
    {
      "epoch": 0.22,
      "grad_norm": 3.479892474733491,
      "learning_rate": 9.095437266534186e-06,
      "loss": 0.5594,
      "step": 3145
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.099331697720281,
      "learning_rate": 9.094791200936312e-06,
      "loss": 0.5274,
      "step": 3146
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.3379947751401104,
      "learning_rate": 9.094144927663979e-06,
      "loss": 0.5909,
      "step": 3147
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.29028796676006,
      "learning_rate": 9.093498446749964e-06,
      "loss": 0.5176,
      "step": 3148
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.724454108126892,
      "learning_rate": 9.092851758227052e-06,
      "loss": 0.564,
      "step": 3149
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.9850334586023886,
      "learning_rate": 9.092204862128042e-06,
      "loss": 0.5649,
      "step": 3150
    },
    {
      "epoch": 0.22,
      "grad_norm": 4.501987048914701,
      "learning_rate": 9.091557758485743e-06,
      "loss": 0.5013,
      "step": 3151
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.8276535777534892,
      "learning_rate": 9.090910447332975e-06,
      "loss": 0.5188,
      "step": 3152
    },
    {
      "epoch": 0.22,
      "grad_norm": 3.4239831499973947,
      "learning_rate": 9.090262928702564e-06,
      "loss": 0.5179,
      "step": 3153
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.7998005775577317,
      "learning_rate": 9.089615202627353e-06,
      "loss": 0.5487,
      "step": 3154
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.4771053833411747,
      "learning_rate": 9.088967269140193e-06,
      "loss": 0.539,
      "step": 3155
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.2427431331817935,
      "learning_rate": 9.088319128273944e-06,
      "loss": 0.5398,
      "step": 3156
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.6172518708937815,
      "learning_rate": 9.087670780061477e-06,
      "loss": 0.5347,
      "step": 3157
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.418419926229957,
      "learning_rate": 9.087022224535673e-06,
      "loss": 0.5767,
      "step": 3158
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.7961095230930494,
      "learning_rate": 9.086373461729428e-06,
      "loss": 0.4715,
      "step": 3159
    },
    {
      "epoch": 0.22,
      "grad_norm": 3.042752102442738,
      "learning_rate": 9.085724491675642e-06,
      "loss": 0.5387,
      "step": 3160
    },
    {
      "epoch": 0.22,
      "grad_norm": 3.6822044011712176,
      "learning_rate": 9.085075314407233e-06,
      "loss": 0.5278,
      "step": 3161
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.807214513259878,
      "learning_rate": 9.08442592995712e-06,
      "loss": 0.5203,
      "step": 3162
    },
    {
      "epoch": 0.22,
      "grad_norm": 3.3108262687785897,
      "learning_rate": 9.08377633835824e-06,
      "loss": 0.5689,
      "step": 3163
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.127619454842086,
      "learning_rate": 9.083126539643538e-06,
      "loss": 0.5601,
      "step": 3164
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.2236599762940994,
      "learning_rate": 9.082476533845968e-06,
      "loss": 0.5436,
      "step": 3165
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6346772976390846,
      "learning_rate": 9.081826320998502e-06,
      "loss": 0.4532,
      "step": 3166
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.9422221809085773,
      "learning_rate": 9.081175901134107e-06,
      "loss": 0.5154,
      "step": 3167
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.38554674867134,
      "learning_rate": 9.080525274285781e-06,
      "loss": 0.5284,
      "step": 3168
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.9834922392482455,
      "learning_rate": 9.079874440486514e-06,
      "loss": 0.5111,
      "step": 3169
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.523942640438443,
      "learning_rate": 9.079223399769316e-06,
      "loss": 0.5266,
      "step": 3170
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.719229088559115,
      "learning_rate": 9.078572152167207e-06,
      "loss": 0.5649,
      "step": 3171
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.006417087795945,
      "learning_rate": 9.077920697713215e-06,
      "loss": 0.5476,
      "step": 3172
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.3859929905580604,
      "learning_rate": 9.07726903644038e-06,
      "loss": 0.5359,
      "step": 3173
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.950400239572102,
      "learning_rate": 9.076617168381751e-06,
      "loss": 0.5043,
      "step": 3174
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.0269938154173723,
      "learning_rate": 9.075965093570391e-06,
      "loss": 0.4862,
      "step": 3175
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.8997547204552787,
      "learning_rate": 9.07531281203937e-06,
      "loss": 0.5553,
      "step": 3176
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.7498265184473416,
      "learning_rate": 9.074660323821772e-06,
      "loss": 0.5025,
      "step": 3177
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.3562173887558964,
      "learning_rate": 9.074007628950684e-06,
      "loss": 0.5438,
      "step": 3178
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.7084954926392735,
      "learning_rate": 9.07335472745921e-06,
      "loss": 0.508,
      "step": 3179
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.1071001829786002,
      "learning_rate": 9.072701619380464e-06,
      "loss": 0.5555,
      "step": 3180
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.140628244048615,
      "learning_rate": 9.072048304747572e-06,
      "loss": 0.4759,
      "step": 3181
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.4299436771918583,
      "learning_rate": 9.071394783593664e-06,
      "loss": 0.5126,
      "step": 3182
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.9544448702934214,
      "learning_rate": 9.070741055951886e-06,
      "loss": 0.4982,
      "step": 3183
    },
    {
      "epoch": 0.22,
      "grad_norm": 3.4791845174602902,
      "learning_rate": 9.070087121855394e-06,
      "loss": 0.4884,
      "step": 3184
    },
    {
      "epoch": 0.22,
      "grad_norm": 10.75066789112008,
      "learning_rate": 9.069432981337352e-06,
      "loss": 0.4824,
      "step": 3185
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.52761936751602,
      "learning_rate": 9.068778634430935e-06,
      "loss": 0.5439,
      "step": 3186
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.7916903797124544,
      "learning_rate": 9.068124081169332e-06,
      "loss": 0.5066,
      "step": 3187
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.158972531740938,
      "learning_rate": 9.067469321585738e-06,
      "loss": 0.5583,
      "step": 3188
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.5213383918276233,
      "learning_rate": 9.06681435571336e-06,
      "loss": 0.5257,
      "step": 3189
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.055362093429336,
      "learning_rate": 9.066159183585419e-06,
      "loss": 0.5474,
      "step": 3190
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.2531418595842756,
      "learning_rate": 9.065503805235139e-06,
      "loss": 0.5193,
      "step": 3191
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.420751916177846,
      "learning_rate": 9.06484822069576e-06,
      "loss": 0.5407,
      "step": 3192
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.0895795365857293,
      "learning_rate": 9.064192430000533e-06,
      "loss": 0.5379,
      "step": 3193
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.012979966389308,
      "learning_rate": 9.063536433182714e-06,
      "loss": 0.5257,
      "step": 3194
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.7946565938539414,
      "learning_rate": 9.062880230275576e-06,
      "loss": 0.5018,
      "step": 3195
    },
    {
      "epoch": 0.22,
      "grad_norm": 3.0179433749561007,
      "learning_rate": 9.062223821312398e-06,
      "loss": 0.4806,
      "step": 3196
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6898299998457711,
      "learning_rate": 9.061567206326472e-06,
      "loss": 0.4675,
      "step": 3197
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.0271339847483176,
      "learning_rate": 9.060910385351098e-06,
      "loss": 0.4829,
      "step": 3198
    },
    {
      "epoch": 0.22,
      "grad_norm": 7.979203051253202,
      "learning_rate": 9.060253358419588e-06,
      "loss": 0.5391,
      "step": 3199
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.894724672637066,
      "learning_rate": 9.059596125565266e-06,
      "loss": 0.5478,
      "step": 3200
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.889575198016344,
      "learning_rate": 9.058938686821464e-06,
      "loss": 0.5685,
      "step": 3201
    },
    {
      "epoch": 0.22,
      "grad_norm": 3.1650270635964652,
      "learning_rate": 9.058281042221523e-06,
      "loss": 0.5144,
      "step": 3202
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.673779286086223,
      "learning_rate": 9.0576231917988e-06,
      "loss": 0.4923,
      "step": 3203
    },
    {
      "epoch": 0.22,
      "grad_norm": 3.0506411124580652,
      "learning_rate": 9.056965135586657e-06,
      "loss": 0.5239,
      "step": 3204
    },
    {
      "epoch": 0.22,
      "grad_norm": 3.1797024949066666,
      "learning_rate": 9.056306873618469e-06,
      "loss": 0.5338,
      "step": 3205
    },
    {
      "epoch": 0.22,
      "grad_norm": 3.194401488640837,
      "learning_rate": 9.05564840592762e-06,
      "loss": 0.5723,
      "step": 3206
    },
    {
      "epoch": 0.22,
      "grad_norm": 3.762053126281273,
      "learning_rate": 9.054989732547507e-06,
      "loss": 0.5029,
      "step": 3207
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.9069475682895374,
      "learning_rate": 9.054330853511534e-06,
      "loss": 0.5173,
      "step": 3208
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.3513390612912044,
      "learning_rate": 9.05367176885312e-06,
      "loss": 0.4793,
      "step": 3209
    },
    {
      "epoch": 0.22,
      "grad_norm": 3.2908721758602733,
      "learning_rate": 9.053012478605685e-06,
      "loss": 0.5648,
      "step": 3210
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.652728128951956,
      "learning_rate": 9.052352982802675e-06,
      "loss": 0.5086,
      "step": 3211
    },
    {
      "epoch": 0.22,
      "grad_norm": 3.2066531506695175,
      "learning_rate": 9.05169328147753e-06,
      "loss": 0.5631,
      "step": 3212
    },
    {
      "epoch": 0.22,
      "grad_norm": 3.146137555314019,
      "learning_rate": 9.051033374663713e-06,
      "loss": 0.5404,
      "step": 3213
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.7724601948347116,
      "learning_rate": 9.05037326239469e-06,
      "loss": 0.5455,
      "step": 3214
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.196631580899808,
      "learning_rate": 9.049712944703939e-06,
      "loss": 0.4904,
      "step": 3215
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.1349835169088807,
      "learning_rate": 9.04905242162495e-06,
      "loss": 0.4883,
      "step": 3216
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.6927383172887946,
      "learning_rate": 9.048391693191225e-06,
      "loss": 0.5144,
      "step": 3217
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.2227904193827395,
      "learning_rate": 9.047730759436271e-06,
      "loss": 0.541,
      "step": 3218
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.299000947900234,
      "learning_rate": 9.047069620393609e-06,
      "loss": 0.5509,
      "step": 3219
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.6120209539810806,
      "learning_rate": 9.046408276096771e-06,
      "loss": 0.5453,
      "step": 3220
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.092119447125785,
      "learning_rate": 9.045746726579297e-06,
      "loss": 0.5588,
      "step": 3221
    },
    {
      "epoch": 0.22,
      "grad_norm": 3.1820879071898096,
      "learning_rate": 9.045084971874738e-06,
      "loss": 0.4937,
      "step": 3222
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.006355776010789,
      "learning_rate": 9.044423012016657e-06,
      "loss": 0.5628,
      "step": 3223
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.1095493671072556,
      "learning_rate": 9.043760847038628e-06,
      "loss": 0.5677,
      "step": 3224
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.756918024271773,
      "learning_rate": 9.04309847697423e-06,
      "loss": 0.552,
      "step": 3225
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.394116798130808,
      "learning_rate": 9.042435901857059e-06,
      "loss": 0.5208,
      "step": 3226
    },
    {
      "epoch": 0.22,
      "grad_norm": 3.496901307806425,
      "learning_rate": 9.04177312172072e-06,
      "loss": 0.4847,
      "step": 3227
    },
    {
      "epoch": 0.22,
      "grad_norm": 3.263828526846937,
      "learning_rate": 9.041110136598823e-06,
      "loss": 0.5605,
      "step": 3228
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.6567333304518655,
      "learning_rate": 9.040446946524995e-06,
      "loss": 0.469,
      "step": 3229
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.8100190740554134,
      "learning_rate": 9.039783551532872e-06,
      "loss": 0.5391,
      "step": 3230
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.688732512952767,
      "learning_rate": 9.039119951656097e-06,
      "loss": 0.5354,
      "step": 3231
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.3219552217684676,
      "learning_rate": 9.038456146928325e-06,
      "loss": 0.5281,
      "step": 3232
    },
    {
      "epoch": 0.22,
      "grad_norm": 4.417139391080855,
      "learning_rate": 9.037792137383226e-06,
      "loss": 0.4852,
      "step": 3233
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.781457356444079,
      "learning_rate": 9.037127923054472e-06,
      "loss": 0.5452,
      "step": 3234
    },
    {
      "epoch": 0.22,
      "grad_norm": 3.8084861207953438,
      "learning_rate": 9.036463503975752e-06,
      "loss": 0.5196,
      "step": 3235
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.3481837854915693,
      "learning_rate": 9.035798880180762e-06,
      "loss": 0.5833,
      "step": 3236
    },
    {
      "epoch": 0.23,
      "grad_norm": 3.0634516241926297,
      "learning_rate": 9.03513405170321e-06,
      "loss": 0.4884,
      "step": 3237
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.3344847862185407,
      "learning_rate": 9.034469018576815e-06,
      "loss": 0.5228,
      "step": 3238
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.1834059055780903,
      "learning_rate": 9.033803780835304e-06,
      "loss": 0.5457,
      "step": 3239
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.206610892506715,
      "learning_rate": 9.033138338512417e-06,
      "loss": 0.5578,
      "step": 3240
    },
    {
      "epoch": 0.23,
      "grad_norm": 3.1492824637343144,
      "learning_rate": 9.032472691641902e-06,
      "loss": 0.4968,
      "step": 3241
    },
    {
      "epoch": 0.23,
      "grad_norm": 10.771822514483889,
      "learning_rate": 9.031806840257519e-06,
      "loss": 0.5395,
      "step": 3242
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.7030480905472314,
      "learning_rate": 9.031140784393036e-06,
      "loss": 0.5049,
      "step": 3243
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.8988264156917456,
      "learning_rate": 9.030474524082237e-06,
      "loss": 0.5377,
      "step": 3244
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7629225721110902,
      "learning_rate": 9.029808059358908e-06,
      "loss": 0.4681,
      "step": 3245
    },
    {
      "epoch": 0.23,
      "grad_norm": 4.916750542303115,
      "learning_rate": 9.029141390256854e-06,
      "loss": 0.5222,
      "step": 3246
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.031457272200131,
      "learning_rate": 9.028474516809882e-06,
      "loss": 0.5142,
      "step": 3247
    },
    {
      "epoch": 0.23,
      "grad_norm": 4.346098512878762,
      "learning_rate": 9.02780743905182e-06,
      "loss": 0.5669,
      "step": 3248
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.1555157863879617,
      "learning_rate": 9.027140157016491e-06,
      "loss": 0.534,
      "step": 3249
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.01963720674623,
      "learning_rate": 9.026472670737746e-06,
      "loss": 0.5249,
      "step": 3250
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6793092200843325,
      "learning_rate": 9.025804980249434e-06,
      "loss": 0.4379,
      "step": 3251
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.440397793369153,
      "learning_rate": 9.025137085585417e-06,
      "loss": 0.5101,
      "step": 3252
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.203596911839043,
      "learning_rate": 9.02446898677957e-06,
      "loss": 0.5802,
      "step": 3253
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.7285819163171197,
      "learning_rate": 9.023800683865777e-06,
      "loss": 0.5469,
      "step": 3254
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.17239734546309,
      "learning_rate": 9.023132176877933e-06,
      "loss": 0.5598,
      "step": 3255
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.3140760174624826,
      "learning_rate": 9.02246346584994e-06,
      "loss": 0.54,
      "step": 3256
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.19031815499943,
      "learning_rate": 9.021794550815713e-06,
      "loss": 0.5551,
      "step": 3257
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.0639121871004242,
      "learning_rate": 9.02112543180918e-06,
      "loss": 0.5681,
      "step": 3258
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.152363878321764,
      "learning_rate": 9.020456108864273e-06,
      "loss": 0.5194,
      "step": 3259
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.120017595301851,
      "learning_rate": 9.01978658201494e-06,
      "loss": 0.5137,
      "step": 3260
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.108570486078546,
      "learning_rate": 9.019116851295138e-06,
      "loss": 0.5734,
      "step": 3261
    },
    {
      "epoch": 0.23,
      "grad_norm": 3.0158996400624183,
      "learning_rate": 9.018446916738832e-06,
      "loss": 0.524,
      "step": 3262
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.3518387650473622,
      "learning_rate": 9.017776778379998e-06,
      "loss": 0.5162,
      "step": 3263
    },
    {
      "epoch": 0.23,
      "grad_norm": 3.0719761932803045,
      "learning_rate": 9.017106436252626e-06,
      "loss": 0.5449,
      "step": 3264
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.9493923237796715,
      "learning_rate": 9.01643589039071e-06,
      "loss": 0.5236,
      "step": 3265
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.3003585306258567,
      "learning_rate": 9.01576514082826e-06,
      "loss": 0.5119,
      "step": 3266
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.1765322578509174,
      "learning_rate": 9.015094187599297e-06,
      "loss": 0.5343,
      "step": 3267
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.508027124693378,
      "learning_rate": 9.014423030737846e-06,
      "loss": 0.5416,
      "step": 3268
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.774504584439167,
      "learning_rate": 9.013751670277946e-06,
      "loss": 0.53,
      "step": 3269
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.6091536449033588,
      "learning_rate": 9.013080106253646e-06,
      "loss": 0.5464,
      "step": 3270
    },
    {
      "epoch": 0.23,
      "grad_norm": 4.176401325224124,
      "learning_rate": 9.012408338699006e-06,
      "loss": 0.501,
      "step": 3271
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.822433288306551,
      "learning_rate": 9.011736367648099e-06,
      "loss": 0.4896,
      "step": 3272
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.9185489084154637,
      "learning_rate": 9.011064193135e-06,
      "loss": 0.533,
      "step": 3273
    },
    {
      "epoch": 0.23,
      "grad_norm": 3.5800126120942504,
      "learning_rate": 9.010391815193803e-06,
      "loss": 0.5366,
      "step": 3274
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.497259364186641,
      "learning_rate": 9.009719233858609e-06,
      "loss": 0.535,
      "step": 3275
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.8665098048146564,
      "learning_rate": 9.009046449163526e-06,
      "loss": 0.5008,
      "step": 3276
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.9813133352663463,
      "learning_rate": 9.008373461142676e-06,
      "loss": 0.5318,
      "step": 3277
    },
    {
      "epoch": 0.23,
      "grad_norm": 3.2107415187130677,
      "learning_rate": 9.007700269830196e-06,
      "loss": 0.4782,
      "step": 3278
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.118285418744826,
      "learning_rate": 9.00702687526022e-06,
      "loss": 0.5718,
      "step": 3279
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.5155943490403203,
      "learning_rate": 9.006353277466908e-06,
      "loss": 0.4625,
      "step": 3280
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7962048615243801,
      "learning_rate": 9.005679476484417e-06,
      "loss": 0.4604,
      "step": 3281
    },
    {
      "epoch": 0.23,
      "grad_norm": 3.0204194227478007,
      "learning_rate": 9.005005472346923e-06,
      "loss": 0.5035,
      "step": 3282
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.540597901802147,
      "learning_rate": 9.00433126508861e-06,
      "loss": 0.5999,
      "step": 3283
    },
    {
      "epoch": 0.23,
      "grad_norm": 3.041305285686049,
      "learning_rate": 9.003656854743667e-06,
      "loss": 0.5271,
      "step": 3284
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.207431838030621,
      "learning_rate": 9.002982241346303e-06,
      "loss": 0.4719,
      "step": 3285
    },
    {
      "epoch": 0.23,
      "grad_norm": 3.798894067208264,
      "learning_rate": 9.00230742493073e-06,
      "loss": 0.4664,
      "step": 3286
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.3978382157736893,
      "learning_rate": 9.001632405531174e-06,
      "loss": 0.522,
      "step": 3287
    },
    {
      "epoch": 0.23,
      "grad_norm": 3.6302212970861083,
      "learning_rate": 9.000957183181866e-06,
      "loss": 0.5025,
      "step": 3288
    },
    {
      "epoch": 0.23,
      "grad_norm": 3.4297076020613257,
      "learning_rate": 9.000281757917055e-06,
      "loss": 0.5344,
      "step": 3289
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.5557206000471777,
      "learning_rate": 8.999606129770995e-06,
      "loss": 0.5369,
      "step": 3290
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.308222784435193,
      "learning_rate": 8.99893029877795e-06,
      "loss": 0.5627,
      "step": 3291
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.2877326195069503,
      "learning_rate": 8.9982542649722e-06,
      "loss": 0.5178,
      "step": 3292
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.1692526082637453,
      "learning_rate": 8.997578028388026e-06,
      "loss": 0.5294,
      "step": 3293
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.2949348718099474,
      "learning_rate": 8.996901589059728e-06,
      "loss": 0.5292,
      "step": 3294
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.15789300537692,
      "learning_rate": 8.996224947021613e-06,
      "loss": 0.5029,
      "step": 3295
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.9856265027206133,
      "learning_rate": 8.995548102307997e-06,
      "loss": 0.503,
      "step": 3296
    },
    {
      "epoch": 0.23,
      "grad_norm": 3.325684163712244,
      "learning_rate": 8.994871054953207e-06,
      "loss": 0.5803,
      "step": 3297
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.0863070381097377,
      "learning_rate": 8.994193804991582e-06,
      "loss": 0.4844,
      "step": 3298
    },
    {
      "epoch": 0.23,
      "grad_norm": 3.232287580365505,
      "learning_rate": 8.993516352457467e-06,
      "loss": 0.551,
      "step": 3299
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.3593410693519203,
      "learning_rate": 8.992838697385224e-06,
      "loss": 0.5253,
      "step": 3300
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7487835501484031,
      "learning_rate": 8.99216083980922e-06,
      "loss": 0.4662,
      "step": 3301
    },
    {
      "epoch": 0.23,
      "grad_norm": 3.0914834494019527,
      "learning_rate": 8.991482779763833e-06,
      "loss": 0.4983,
      "step": 3302
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.2561754860071424,
      "learning_rate": 8.99080451728345e-06,
      "loss": 0.5016,
      "step": 3303
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.2575245524398997,
      "learning_rate": 8.990126052402478e-06,
      "loss": 0.5656,
      "step": 3304
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.1629460789086106,
      "learning_rate": 8.989447385155316e-06,
      "loss": 0.5502,
      "step": 3305
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.0113478760834163,
      "learning_rate": 8.988768515576392e-06,
      "loss": 0.5284,
      "step": 3306
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.2590273960745733,
      "learning_rate": 8.988089443700131e-06,
      "loss": 0.5233,
      "step": 3307
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6506657854461175,
      "learning_rate": 8.987410169560977e-06,
      "loss": 0.4774,
      "step": 3308
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.7377617568148278,
      "learning_rate": 8.986730693193377e-06,
      "loss": 0.4991,
      "step": 3309
    },
    {
      "epoch": 0.23,
      "grad_norm": 7.661760598882945,
      "learning_rate": 8.986051014631796e-06,
      "loss": 0.5357,
      "step": 3310
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.8526746497077007,
      "learning_rate": 8.9853711339107e-06,
      "loss": 0.5561,
      "step": 3311
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.114047862458588,
      "learning_rate": 8.984691051064576e-06,
      "loss": 0.5143,
      "step": 3312
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.8942971383611473,
      "learning_rate": 8.98401076612791e-06,
      "loss": 0.5259,
      "step": 3313
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.796620218993623,
      "learning_rate": 8.98333027913521e-06,
      "loss": 0.5552,
      "step": 3314
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.079302294497145,
      "learning_rate": 8.982649590120982e-06,
      "loss": 0.5861,
      "step": 3315
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.895159605163961,
      "learning_rate": 8.981968699119752e-06,
      "loss": 0.4752,
      "step": 3316
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.0343383670385173,
      "learning_rate": 8.981287606166052e-06,
      "loss": 0.4939,
      "step": 3317
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.8406360123863292,
      "learning_rate": 8.980606311294423e-06,
      "loss": 0.5544,
      "step": 3318
    },
    {
      "epoch": 0.23,
      "grad_norm": 4.444678039511263,
      "learning_rate": 8.979924814539421e-06,
      "loss": 0.5438,
      "step": 3319
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.8760460984906178,
      "learning_rate": 8.979243115935605e-06,
      "loss": 0.5585,
      "step": 3320
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.383659934046545,
      "learning_rate": 8.978561215517554e-06,
      "loss": 0.511,
      "step": 3321
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.1819638231839664,
      "learning_rate": 8.977879113319847e-06,
      "loss": 0.564,
      "step": 3322
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.1989251979780953,
      "learning_rate": 8.977196809377083e-06,
      "loss": 0.5058,
      "step": 3323
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.4805073890919838,
      "learning_rate": 8.97651430372386e-06,
      "loss": 0.5024,
      "step": 3324
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.1166719427695657,
      "learning_rate": 8.975831596394796e-06,
      "loss": 0.5363,
      "step": 3325
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.2668087154539562,
      "learning_rate": 8.975148687424518e-06,
      "loss": 0.5338,
      "step": 3326
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.003558582474014,
      "learning_rate": 8.974465576847655e-06,
      "loss": 0.539,
      "step": 3327
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.443045199928373,
      "learning_rate": 8.973782264698858e-06,
      "loss": 0.5254,
      "step": 3328
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.0637011166338506,
      "learning_rate": 8.973098751012779e-06,
      "loss": 0.5368,
      "step": 3329
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.9419609425171576,
      "learning_rate": 8.972415035824085e-06,
      "loss": 0.5462,
      "step": 3330
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.571342976952878,
      "learning_rate": 8.97173111916745e-06,
      "loss": 0.5286,
      "step": 3331
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.013469276682794,
      "learning_rate": 8.971047001077561e-06,
      "loss": 0.5601,
      "step": 3332
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.095802833121677,
      "learning_rate": 8.970362681589116e-06,
      "loss": 0.4935,
      "step": 3333
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.169544658895118,
      "learning_rate": 8.969678160736819e-06,
      "loss": 0.5183,
      "step": 3334
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.9646090088857349,
      "learning_rate": 8.968993438555387e-06,
      "loss": 0.5249,
      "step": 3335
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.046704794505105,
      "learning_rate": 8.968308515079548e-06,
      "loss": 0.4946,
      "step": 3336
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.4328272107298723,
      "learning_rate": 8.967623390344038e-06,
      "loss": 0.4977,
      "step": 3337
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.5920990234653343,
      "learning_rate": 8.966938064383606e-06,
      "loss": 0.5251,
      "step": 3338
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.1943589675803286,
      "learning_rate": 8.96625253723301e-06,
      "loss": 0.508,
      "step": 3339
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.801291464807949,
      "learning_rate": 8.965566808927012e-06,
      "loss": 0.4414,
      "step": 3340
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.5503949110163218,
      "learning_rate": 8.964880879500394e-06,
      "loss": 0.5359,
      "step": 3341
    },
    {
      "epoch": 0.23,
      "grad_norm": 4.224540015587777,
      "learning_rate": 8.964194748987948e-06,
      "loss": 0.4779,
      "step": 3342
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.9921635051349103,
      "learning_rate": 8.963508417424465e-06,
      "loss": 0.4574,
      "step": 3343
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.914101880017548,
      "learning_rate": 8.96282188484476e-06,
      "loss": 0.5088,
      "step": 3344
    },
    {
      "epoch": 0.23,
      "grad_norm": 3.3460483875113334,
      "learning_rate": 8.962135151283644e-06,
      "loss": 0.5364,
      "step": 3345
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.7180707632192307,
      "learning_rate": 8.961448216775955e-06,
      "loss": 0.48,
      "step": 3346
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.412755529254299,
      "learning_rate": 8.960761081356524e-06,
      "loss": 0.4852,
      "step": 3347
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.76090920871386,
      "learning_rate": 8.960073745060206e-06,
      "loss": 0.4762,
      "step": 3348
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.0974223071643863,
      "learning_rate": 8.959386207921858e-06,
      "loss": 0.5073,
      "step": 3349
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.0792782250582396,
      "learning_rate": 8.958698469976348e-06,
      "loss": 0.5077,
      "step": 3350
    },
    {
      "epoch": 0.23,
      "grad_norm": 3.2431473575559973,
      "learning_rate": 8.95801053125856e-06,
      "loss": 0.5175,
      "step": 3351
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.105898172320032,
      "learning_rate": 8.95732239180338e-06,
      "loss": 0.5371,
      "step": 3352
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.3977152999095703,
      "learning_rate": 8.956634051645713e-06,
      "loss": 0.5119,
      "step": 3353
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.298845710717415,
      "learning_rate": 8.955945510820463e-06,
      "loss": 0.5455,
      "step": 3354
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.540195680743299,
      "learning_rate": 8.955256769362555e-06,
      "loss": 0.5294,
      "step": 3355
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.9420531355708204,
      "learning_rate": 8.954567827306917e-06,
      "loss": 0.4949,
      "step": 3356
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.9723875197931964,
      "learning_rate": 8.953878684688492e-06,
      "loss": 0.5177,
      "step": 3357
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.7953812432775873,
      "learning_rate": 8.953189341542232e-06,
      "loss": 0.5524,
      "step": 3358
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.8719020125096613,
      "learning_rate": 8.952499797903097e-06,
      "loss": 0.527,
      "step": 3359
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.5426888056249368,
      "learning_rate": 8.951810053806057e-06,
      "loss": 0.491,
      "step": 3360
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.1365186252525126,
      "learning_rate": 8.951120109286096e-06,
      "loss": 0.5581,
      "step": 3361
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.2436810918368355,
      "learning_rate": 8.950429964378202e-06,
      "loss": 0.5468,
      "step": 3362
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.1810942632267287,
      "learning_rate": 8.949739619117381e-06,
      "loss": 0.5047,
      "step": 3363
    },
    {
      "epoch": 0.23,
      "grad_norm": 3.9464757181600816,
      "learning_rate": 8.949049073538642e-06,
      "loss": 0.5346,
      "step": 3364
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.0885356509447828,
      "learning_rate": 8.948358327677012e-06,
      "loss": 0.5157,
      "step": 3365
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.765080810957733,
      "learning_rate": 8.947667381567518e-06,
      "loss": 0.542,
      "step": 3366
    },
    {
      "epoch": 0.23,
      "grad_norm": 3.6365582184933585,
      "learning_rate": 8.946976235245202e-06,
      "loss": 0.5389,
      "step": 3367
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7099838944938477,
      "learning_rate": 8.946284888745123e-06,
      "loss": 0.4571,
      "step": 3368
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.8930124169463527,
      "learning_rate": 8.945593342102337e-06,
      "loss": 0.5566,
      "step": 3369
    },
    {
      "epoch": 0.23,
      "grad_norm": 3.7101543739228546,
      "learning_rate": 8.944901595351922e-06,
      "loss": 0.5494,
      "step": 3370
    },
    {
      "epoch": 0.23,
      "grad_norm": 3.1450639210516735,
      "learning_rate": 8.94420964852896e-06,
      "loss": 0.5071,
      "step": 3371
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.3582085067300906,
      "learning_rate": 8.943517501668541e-06,
      "loss": 0.5169,
      "step": 3372
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.8538535940974137,
      "learning_rate": 8.942825154805773e-06,
      "loss": 0.4897,
      "step": 3373
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.999292117088519,
      "learning_rate": 8.942132607975766e-06,
      "loss": 0.5627,
      "step": 3374
    },
    {
      "epoch": 0.23,
      "grad_norm": 5.152379083876261,
      "learning_rate": 8.941439861213646e-06,
      "loss": 0.5222,
      "step": 3375
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.8837620141758231,
      "learning_rate": 8.940746914554546e-06,
      "loss": 0.5801,
      "step": 3376
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.7002903930993344,
      "learning_rate": 8.94005376803361e-06,
      "loss": 0.4524,
      "step": 3377
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.4571575718811167,
      "learning_rate": 8.939360421685993e-06,
      "loss": 0.577,
      "step": 3378
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.9696465562752083,
      "learning_rate": 8.938666875546858e-06,
      "loss": 0.5073,
      "step": 3379
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.1184521758697086,
      "learning_rate": 8.93797312965138e-06,
      "loss": 0.5333,
      "step": 3380
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.393567170377083,
      "learning_rate": 8.937279184034741e-06,
      "loss": 0.5378,
      "step": 3381
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.5008680104699037,
      "learning_rate": 8.936585038732143e-06,
      "loss": 0.5252,
      "step": 3382
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.926971469289648,
      "learning_rate": 8.935890693778781e-06,
      "loss": 0.5308,
      "step": 3383
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.9974876440070681,
      "learning_rate": 8.935196149209878e-06,
      "loss": 0.4958,
      "step": 3384
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.2473195636686776,
      "learning_rate": 8.934501405060654e-06,
      "loss": 0.5119,
      "step": 3385
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.979655997298799,
      "learning_rate": 8.933806461366346e-06,
      "loss": 0.5225,
      "step": 3386
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.6302322917814553,
      "learning_rate": 8.9331113181622e-06,
      "loss": 0.5507,
      "step": 3387
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.040737721455353,
      "learning_rate": 8.93241597548347e-06,
      "loss": 0.503,
      "step": 3388
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.0054552785103033,
      "learning_rate": 8.931720433365423e-06,
      "loss": 0.5183,
      "step": 3389
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.7849391721151906,
      "learning_rate": 8.931024691843334e-06,
      "loss": 0.5543,
      "step": 3390
    },
    {
      "epoch": 0.24,
      "grad_norm": 3.3468309220719004,
      "learning_rate": 8.930328750952485e-06,
      "loss": 0.5346,
      "step": 3391
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.6312170280414757,
      "learning_rate": 8.929632610728178e-06,
      "loss": 0.496,
      "step": 3392
    },
    {
      "epoch": 0.24,
      "grad_norm": 3.079702884695401,
      "learning_rate": 8.928936271205716e-06,
      "loss": 0.5123,
      "step": 3393
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.275294617224804,
      "learning_rate": 8.928239732420416e-06,
      "loss": 0.5018,
      "step": 3394
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.8073004384776726,
      "learning_rate": 8.927542994407604e-06,
      "loss": 0.4641,
      "step": 3395
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.4617552686830395,
      "learning_rate": 8.926846057202617e-06,
      "loss": 0.5252,
      "step": 3396
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.9240149505302622,
      "learning_rate": 8.926148920840797e-06,
      "loss": 0.4832,
      "step": 3397
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.03097430352596,
      "learning_rate": 8.925451585357506e-06,
      "loss": 0.5471,
      "step": 3398
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.3154551985803065,
      "learning_rate": 8.924754050788106e-06,
      "loss": 0.4992,
      "step": 3399
    },
    {
      "epoch": 0.24,
      "grad_norm": 3.432629867503997,
      "learning_rate": 8.924056317167976e-06,
      "loss": 0.5186,
      "step": 3400
    },
    {
      "epoch": 0.24,
      "grad_norm": 3.8129533566121814,
      "learning_rate": 8.923358384532506e-06,
      "loss": 0.528,
      "step": 3401
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.226513285993814,
      "learning_rate": 8.922660252917088e-06,
      "loss": 0.5543,
      "step": 3402
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.1669499033361617,
      "learning_rate": 8.92196192235713e-06,
      "loss": 0.5691,
      "step": 3403
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.6488001286233205,
      "learning_rate": 8.92126339288805e-06,
      "loss": 0.5211,
      "step": 3404
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.1522054466237877,
      "learning_rate": 8.920564664545274e-06,
      "loss": 0.5557,
      "step": 3405
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.7199177754658093,
      "learning_rate": 8.919865737364242e-06,
      "loss": 0.4613,
      "step": 3406
    },
    {
      "epoch": 0.24,
      "grad_norm": 5.034164202248318,
      "learning_rate": 8.919166611380397e-06,
      "loss": 0.5231,
      "step": 3407
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.320281992256027,
      "learning_rate": 8.9184672866292e-06,
      "loss": 0.5396,
      "step": 3408
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.3360224679604484,
      "learning_rate": 8.917767763146117e-06,
      "loss": 0.4945,
      "step": 3409
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.0651860906586608,
      "learning_rate": 8.917068040966625e-06,
      "loss": 0.5314,
      "step": 3410
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6792354476283059,
      "learning_rate": 8.916368120126213e-06,
      "loss": 0.4452,
      "step": 3411
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.1947613210523658,
      "learning_rate": 8.915668000660378e-06,
      "loss": 0.5352,
      "step": 3412
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.0203486671968944,
      "learning_rate": 8.914967682604628e-06,
      "loss": 0.5583,
      "step": 3413
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.516248435219546,
      "learning_rate": 8.91426716599448e-06,
      "loss": 0.4801,
      "step": 3414
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.5809532421686283,
      "learning_rate": 8.913566450865462e-06,
      "loss": 0.517,
      "step": 3415
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.0572167875789433,
      "learning_rate": 8.912865537253115e-06,
      "loss": 0.5405,
      "step": 3416
    },
    {
      "epoch": 0.24,
      "grad_norm": 4.153451023501468,
      "learning_rate": 8.912164425192983e-06,
      "loss": 0.4818,
      "step": 3417
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.6919920066667986,
      "learning_rate": 8.911463114720626e-06,
      "loss": 0.5085,
      "step": 3418
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.149258253158724,
      "learning_rate": 8.910761605871611e-06,
      "loss": 0.503,
      "step": 3419
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.2257811542525827,
      "learning_rate": 8.910059898681519e-06,
      "loss": 0.4872,
      "step": 3420
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.1338832097110383,
      "learning_rate": 8.909357993185935e-06,
      "loss": 0.583,
      "step": 3421
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.201925610058252,
      "learning_rate": 8.90865588942046e-06,
      "loss": 0.5329,
      "step": 3422
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.798028541861809,
      "learning_rate": 8.9079535874207e-06,
      "loss": 0.5081,
      "step": 3423
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.504540270329134,
      "learning_rate": 8.907251087222275e-06,
      "loss": 0.5295,
      "step": 3424
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.169557864005875,
      "learning_rate": 8.906548388860813e-06,
      "loss": 0.5311,
      "step": 3425
    },
    {
      "epoch": 0.24,
      "grad_norm": 7.586955907561627,
      "learning_rate": 8.905845492371953e-06,
      "loss": 0.5297,
      "step": 3426
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.078463648833057,
      "learning_rate": 8.905142397791345e-06,
      "loss": 0.5608,
      "step": 3427
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.454186324607823,
      "learning_rate": 8.904439105154645e-06,
      "loss": 0.5665,
      "step": 3428
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.9866396931865642,
      "learning_rate": 8.903735614497522e-06,
      "loss": 0.4958,
      "step": 3429
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.1292602598368173,
      "learning_rate": 8.903031925855656e-06,
      "loss": 0.5123,
      "step": 3430
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.0815576898633124,
      "learning_rate": 8.902328039264737e-06,
      "loss": 0.545,
      "step": 3431
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.4158800404655274,
      "learning_rate": 8.90162395476046e-06,
      "loss": 0.5522,
      "step": 3432
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.2569601133590074,
      "learning_rate": 8.900919672378536e-06,
      "loss": 0.579,
      "step": 3433
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.2015513006100758,
      "learning_rate": 8.900215192154685e-06,
      "loss": 0.5473,
      "step": 3434
    },
    {
      "epoch": 0.24,
      "grad_norm": 3.468681542458726,
      "learning_rate": 8.899510514124634e-06,
      "loss": 0.5542,
      "step": 3435
    },
    {
      "epoch": 0.24,
      "grad_norm": 3.404765076404761,
      "learning_rate": 8.898805638324125e-06,
      "loss": 0.5282,
      "step": 3436
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.219208109973685,
      "learning_rate": 8.898100564788903e-06,
      "loss": 0.5344,
      "step": 3437
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.0909861784778494,
      "learning_rate": 8.897395293554728e-06,
      "loss": 0.5436,
      "step": 3438
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.0615427359597795,
      "learning_rate": 8.896689824657371e-06,
      "loss": 0.5301,
      "step": 3439
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.9539091636515917,
      "learning_rate": 8.895984158132612e-06,
      "loss": 0.5426,
      "step": 3440
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.9663438551650432,
      "learning_rate": 8.895278294016235e-06,
      "loss": 0.4955,
      "step": 3441
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.6288238876682777,
      "learning_rate": 8.894572232344042e-06,
      "loss": 0.6006,
      "step": 3442
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.9282461302597351,
      "learning_rate": 8.893865973151846e-06,
      "loss": 0.5566,
      "step": 3443
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.031182680168258,
      "learning_rate": 8.89315951647546e-06,
      "loss": 0.5208,
      "step": 3444
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.1118209264560464,
      "learning_rate": 8.892452862350715e-06,
      "loss": 0.5406,
      "step": 3445
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.9247605741242662,
      "learning_rate": 8.891746010813454e-06,
      "loss": 0.5423,
      "step": 3446
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.246427851064234,
      "learning_rate": 8.891038961899521e-06,
      "loss": 0.5421,
      "step": 3447
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.7816259962989678,
      "learning_rate": 8.890331715644778e-06,
      "loss": 0.4782,
      "step": 3448
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.160494006263958,
      "learning_rate": 8.889624272085092e-06,
      "loss": 0.5154,
      "step": 3449
    },
    {
      "epoch": 0.24,
      "grad_norm": 7.11720789257807,
      "learning_rate": 8.888916631256346e-06,
      "loss": 0.4946,
      "step": 3450
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.402258610353867,
      "learning_rate": 8.888208793194426e-06,
      "loss": 0.5473,
      "step": 3451
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.4446682893838285,
      "learning_rate": 8.887500757935233e-06,
      "loss": 0.5006,
      "step": 3452
    },
    {
      "epoch": 0.24,
      "grad_norm": 4.4160402174948725,
      "learning_rate": 8.886792525514674e-06,
      "loss": 0.5649,
      "step": 3453
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.0515899536504545,
      "learning_rate": 8.886084095968671e-06,
      "loss": 0.5398,
      "step": 3454
    },
    {
      "epoch": 0.24,
      "grad_norm": 3.14266981896469,
      "learning_rate": 8.885375469333151e-06,
      "loss": 0.4814,
      "step": 3455
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.069745535109038,
      "learning_rate": 8.884666645644056e-06,
      "loss": 0.5846,
      "step": 3456
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.880362508013471,
      "learning_rate": 8.883957624937333e-06,
      "loss": 0.5286,
      "step": 3457
    },
    {
      "epoch": 0.24,
      "grad_norm": 7.029357520850137,
      "learning_rate": 8.883248407248941e-06,
      "loss": 0.5668,
      "step": 3458
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.320704918005354,
      "learning_rate": 8.88253899261485e-06,
      "loss": 0.4599,
      "step": 3459
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.345743357466084,
      "learning_rate": 8.881829381071039e-06,
      "loss": 0.5046,
      "step": 3460
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.018601423169997,
      "learning_rate": 8.881119572653498e-06,
      "loss": 0.5104,
      "step": 3461
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.9561077393950257,
      "learning_rate": 8.880409567398225e-06,
      "loss": 0.5236,
      "step": 3462
    },
    {
      "epoch": 0.24,
      "grad_norm": 3.374706068191224,
      "learning_rate": 8.87969936534123e-06,
      "loss": 0.5612,
      "step": 3463
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.9869273367542497,
      "learning_rate": 8.878988966518532e-06,
      "loss": 0.5247,
      "step": 3464
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.382416661905289,
      "learning_rate": 8.878278370966157e-06,
      "loss": 0.5774,
      "step": 3465
    },
    {
      "epoch": 0.24,
      "grad_norm": 6.683363165175041,
      "learning_rate": 8.87756757872015e-06,
      "loss": 0.5099,
      "step": 3466
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.801355994601372,
      "learning_rate": 8.876856589816555e-06,
      "loss": 0.4834,
      "step": 3467
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.2995148248584445,
      "learning_rate": 8.876145404291436e-06,
      "loss": 0.5552,
      "step": 3468
    },
    {
      "epoch": 0.24,
      "grad_norm": 3.0265954475206307,
      "learning_rate": 8.875434022180857e-06,
      "loss": 0.5297,
      "step": 3469
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6793771106179652,
      "learning_rate": 8.874722443520898e-06,
      "loss": 0.4768,
      "step": 3470
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.6843189499884035,
      "learning_rate": 8.874010668347651e-06,
      "loss": 0.4714,
      "step": 3471
    },
    {
      "epoch": 0.24,
      "grad_norm": 4.40261728904739,
      "learning_rate": 8.873298696697213e-06,
      "loss": 0.5515,
      "step": 3472
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6931480197393499,
      "learning_rate": 8.872586528605692e-06,
      "loss": 0.4712,
      "step": 3473
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.2103793083811856,
      "learning_rate": 8.871874164109206e-06,
      "loss": 0.5194,
      "step": 3474
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.4385707316428142,
      "learning_rate": 8.871161603243887e-06,
      "loss": 0.5102,
      "step": 3475
    },
    {
      "epoch": 0.24,
      "grad_norm": 3.0288122052020334,
      "learning_rate": 8.870448846045873e-06,
      "loss": 0.5463,
      "step": 3476
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.2981627081380194,
      "learning_rate": 8.869735892551312e-06,
      "loss": 0.5021,
      "step": 3477
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.1688271173146845,
      "learning_rate": 8.86902274279636e-06,
      "loss": 0.5434,
      "step": 3478
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.826261469438203,
      "learning_rate": 8.86830939681719e-06,
      "loss": 0.4983,
      "step": 3479
    },
    {
      "epoch": 0.24,
      "grad_norm": 3.1139518638727717,
      "learning_rate": 8.86759585464998e-06,
      "loss": 0.5237,
      "step": 3480
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.812220873917266,
      "learning_rate": 8.866882116330914e-06,
      "loss": 0.5188,
      "step": 3481
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.308666700716183,
      "learning_rate": 8.866168181896198e-06,
      "loss": 0.533,
      "step": 3482
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.3431936247148037,
      "learning_rate": 8.865454051382033e-06,
      "loss": 0.5389,
      "step": 3483
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.006167253350874,
      "learning_rate": 8.864739724824643e-06,
      "loss": 0.4976,
      "step": 3484
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.2399454128693597,
      "learning_rate": 8.864025202260252e-06,
      "loss": 0.5235,
      "step": 3485
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.55778933278602,
      "learning_rate": 8.863310483725101e-06,
      "loss": 0.5355,
      "step": 3486
    },
    {
      "epoch": 0.24,
      "grad_norm": 7.917704942886216,
      "learning_rate": 8.862595569255436e-06,
      "loss": 0.5518,
      "step": 3487
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.7654546495214061,
      "learning_rate": 8.861880458887518e-06,
      "loss": 0.4507,
      "step": 3488
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6592479455846697,
      "learning_rate": 8.861165152657614e-06,
      "loss": 0.4641,
      "step": 3489
    },
    {
      "epoch": 0.24,
      "grad_norm": 3.097535747445806,
      "learning_rate": 8.860449650602002e-06,
      "loss": 0.5231,
      "step": 3490
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.4172017489617694,
      "learning_rate": 8.859733952756967e-06,
      "loss": 0.5103,
      "step": 3491
    },
    {
      "epoch": 0.24,
      "grad_norm": 5.024690469280838,
      "learning_rate": 8.85901805915881e-06,
      "loss": 0.5641,
      "step": 3492
    },
    {
      "epoch": 0.24,
      "grad_norm": 3.0653638920985027,
      "learning_rate": 8.85830196984384e-06,
      "loss": 0.5013,
      "step": 3493
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.0017399127437048,
      "learning_rate": 8.857585684848373e-06,
      "loss": 0.5272,
      "step": 3494
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.4681347271353395,
      "learning_rate": 8.856869204208734e-06,
      "loss": 0.556,
      "step": 3495
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.593746348315001,
      "learning_rate": 8.856152527961264e-06,
      "loss": 0.5625,
      "step": 3496
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.148901541890999,
      "learning_rate": 8.85543565614231e-06,
      "loss": 0.5189,
      "step": 3497
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.9215515482920806,
      "learning_rate": 8.854718588788229e-06,
      "loss": 0.5447,
      "step": 3498
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.9718121480927275,
      "learning_rate": 8.854001325935388e-06,
      "loss": 0.4957,
      "step": 3499
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.3166040325196007,
      "learning_rate": 8.853283867620167e-06,
      "loss": 0.4999,
      "step": 3500
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.444245161176126,
      "learning_rate": 8.852566213878947e-06,
      "loss": 0.5486,
      "step": 3501
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.1011798595536466,
      "learning_rate": 8.85184836474813e-06,
      "loss": 0.4613,
      "step": 3502
    },
    {
      "epoch": 0.24,
      "grad_norm": 3.2200575297380785,
      "learning_rate": 8.851130320264122e-06,
      "loss": 0.5574,
      "step": 3503
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.3948919966723863,
      "learning_rate": 8.85041208046334e-06,
      "loss": 0.4961,
      "step": 3504
    },
    {
      "epoch": 0.24,
      "grad_norm": 5.206075119592007,
      "learning_rate": 8.849693645382209e-06,
      "loss": 0.5421,
      "step": 3505
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.1776556951612625,
      "learning_rate": 8.848975015057169e-06,
      "loss": 0.5857,
      "step": 3506
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.3751700184273514,
      "learning_rate": 8.848256189524661e-06,
      "loss": 0.5475,
      "step": 3507
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.6883555590616113,
      "learning_rate": 8.847537168821148e-06,
      "loss": 0.5544,
      "step": 3508
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.4692667970291047,
      "learning_rate": 8.846817952983094e-06,
      "loss": 0.5313,
      "step": 3509
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.0615325607739057,
      "learning_rate": 8.846098542046972e-06,
      "loss": 0.4834,
      "step": 3510
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.2568809105527494,
      "learning_rate": 8.845378936049274e-06,
      "loss": 0.4779,
      "step": 3511
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.6362359126116393,
      "learning_rate": 8.844659135026493e-06,
      "loss": 0.5271,
      "step": 3512
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.1944824448979294,
      "learning_rate": 8.843939139015132e-06,
      "loss": 0.5187,
      "step": 3513
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.1835943654996095,
      "learning_rate": 8.843218948051712e-06,
      "loss": 0.538,
      "step": 3514
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.055822164378642,
      "learning_rate": 8.842498562172757e-06,
      "loss": 0.539,
      "step": 3515
    },
    {
      "epoch": 0.24,
      "grad_norm": 6.6504683521367935,
      "learning_rate": 8.841777981414802e-06,
      "loss": 0.5031,
      "step": 3516
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.0799134975525684,
      "learning_rate": 8.841057205814391e-06,
      "loss": 0.5705,
      "step": 3517
    },
    {
      "epoch": 0.24,
      "grad_norm": 4.526682841187489,
      "learning_rate": 8.840336235408082e-06,
      "loss": 0.5573,
      "step": 3518
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.1686495256797835,
      "learning_rate": 8.839615070232438e-06,
      "loss": 0.5083,
      "step": 3519
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.1936578179432935,
      "learning_rate": 8.838893710324037e-06,
      "loss": 0.5495,
      "step": 3520
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.578540011881545,
      "learning_rate": 8.838172155719463e-06,
      "loss": 0.5467,
      "step": 3521
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.314899206325523,
      "learning_rate": 8.83745040645531e-06,
      "loss": 0.5526,
      "step": 3522
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.424085186517841,
      "learning_rate": 8.836728462568182e-06,
      "loss": 0.5592,
      "step": 3523
    },
    {
      "epoch": 0.25,
      "grad_norm": 3.080256368597767,
      "learning_rate": 8.836006324094697e-06,
      "loss": 0.5683,
      "step": 3524
    },
    {
      "epoch": 0.25,
      "grad_norm": 3.167850577573296,
      "learning_rate": 8.835283991071478e-06,
      "loss": 0.5536,
      "step": 3525
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.8879987035638799,
      "learning_rate": 8.834561463535155e-06,
      "loss": 0.488,
      "step": 3526
    },
    {
      "epoch": 0.25,
      "grad_norm": 5.3752416204203035,
      "learning_rate": 8.833838741522379e-06,
      "loss": 0.5641,
      "step": 3527
    },
    {
      "epoch": 0.25,
      "grad_norm": 7.010152564709642,
      "learning_rate": 8.833115825069801e-06,
      "loss": 0.5317,
      "step": 3528
    },
    {
      "epoch": 0.25,
      "grad_norm": 8.476531193341417,
      "learning_rate": 8.832392714214082e-06,
      "loss": 0.5316,
      "step": 3529
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.1153663816804036,
      "learning_rate": 8.8316694089919e-06,
      "loss": 0.5371,
      "step": 3530
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.0671321694132803,
      "learning_rate": 8.83094590943994e-06,
      "loss": 0.5278,
      "step": 3531
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.246201459790284,
      "learning_rate": 8.83022221559489e-06,
      "loss": 0.5712,
      "step": 3532
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.3562549190333395,
      "learning_rate": 8.829498327493458e-06,
      "loss": 0.5277,
      "step": 3533
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.0966328414405653,
      "learning_rate": 8.828774245172357e-06,
      "loss": 0.5178,
      "step": 3534
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.3890880285236635,
      "learning_rate": 8.828049968668308e-06,
      "loss": 0.5076,
      "step": 3535
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.8036769943350277,
      "learning_rate": 8.827325498018042e-06,
      "loss": 0.5683,
      "step": 3536
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.0950429223090263,
      "learning_rate": 8.826600833258307e-06,
      "loss": 0.5496,
      "step": 3537
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.2213642239779525,
      "learning_rate": 8.825875974425853e-06,
      "loss": 0.5254,
      "step": 3538
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.9684158928391329,
      "learning_rate": 8.825150921557443e-06,
      "loss": 0.5459,
      "step": 3539
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.669510516085636,
      "learning_rate": 8.824425674689849e-06,
      "loss": 0.5119,
      "step": 3540
    },
    {
      "epoch": 0.25,
      "grad_norm": 3.7418747086390627,
      "learning_rate": 8.823700233859854e-06,
      "loss": 0.5002,
      "step": 3541
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.7696547418279543,
      "learning_rate": 8.822974599104246e-06,
      "loss": 0.457,
      "step": 3542
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.5584329083622315,
      "learning_rate": 8.822248770459832e-06,
      "loss": 0.576,
      "step": 3543
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.197462495018592,
      "learning_rate": 8.821522747963422e-06,
      "loss": 0.4757,
      "step": 3544
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.7490042825833987,
      "learning_rate": 8.820796531651836e-06,
      "loss": 0.5007,
      "step": 3545
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.938341338693162,
      "learning_rate": 8.820070121561906e-06,
      "loss": 0.5268,
      "step": 3546
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.7905955861165859,
      "learning_rate": 8.819343517730476e-06,
      "loss": 0.5006,
      "step": 3547
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.46228775346739,
      "learning_rate": 8.818616720194393e-06,
      "loss": 0.4933,
      "step": 3548
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.2137725720283954,
      "learning_rate": 8.81788972899052e-06,
      "loss": 0.5237,
      "step": 3549
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.426951684858742,
      "learning_rate": 8.817162544155726e-06,
      "loss": 0.546,
      "step": 3550
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.9237237674207133,
      "learning_rate": 8.816435165726892e-06,
      "loss": 0.437,
      "step": 3551
    },
    {
      "epoch": 0.25,
      "grad_norm": 3.0352575811883953,
      "learning_rate": 8.815707593740909e-06,
      "loss": 0.5834,
      "step": 3552
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.2850008304201124,
      "learning_rate": 8.814979828234678e-06,
      "loss": 0.5258,
      "step": 3553
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.150065993218745,
      "learning_rate": 8.814251869245106e-06,
      "loss": 0.5462,
      "step": 3554
    },
    {
      "epoch": 0.25,
      "grad_norm": 5.952873836105846,
      "learning_rate": 8.813523716809115e-06,
      "loss": 0.5355,
      "step": 3555
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.0507200960369083,
      "learning_rate": 8.812795370963635e-06,
      "loss": 0.4579,
      "step": 3556
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.2740184438165953,
      "learning_rate": 8.812066831745602e-06,
      "loss": 0.5508,
      "step": 3557
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.0458538691427766,
      "learning_rate": 8.81133809919197e-06,
      "loss": 0.536,
      "step": 3558
    },
    {
      "epoch": 0.25,
      "grad_norm": 10.91465145528408,
      "learning_rate": 8.810609173339693e-06,
      "loss": 0.5064,
      "step": 3559
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.0373380706212902,
      "learning_rate": 8.809880054225744e-06,
      "loss": 0.5314,
      "step": 3560
    },
    {
      "epoch": 0.25,
      "grad_norm": 3.4606831097364266,
      "learning_rate": 8.809150741887099e-06,
      "loss": 0.4952,
      "step": 3561
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.0737758592130273,
      "learning_rate": 8.808421236360745e-06,
      "loss": 0.5274,
      "step": 3562
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.0859974810197977,
      "learning_rate": 8.807691537683685e-06,
      "loss": 0.507,
      "step": 3563
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.607406987296528,
      "learning_rate": 8.806961645892921e-06,
      "loss": 0.548,
      "step": 3564
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.7784331004656302,
      "learning_rate": 8.806231561025476e-06,
      "loss": 0.4767,
      "step": 3565
    },
    {
      "epoch": 0.25,
      "grad_norm": 3.6857808735368556,
      "learning_rate": 8.805501283118374e-06,
      "loss": 0.5011,
      "step": 3566
    },
    {
      "epoch": 0.25,
      "grad_norm": 3.9748808792216335,
      "learning_rate": 8.804770812208655e-06,
      "loss": 0.5517,
      "step": 3567
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.365973037836517,
      "learning_rate": 8.804040148333364e-06,
      "loss": 0.4954,
      "step": 3568
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.197900875638051,
      "learning_rate": 8.803309291529557e-06,
      "loss": 0.4863,
      "step": 3569
    },
    {
      "epoch": 0.25,
      "grad_norm": 3.8254979659935535,
      "learning_rate": 8.802578241834306e-06,
      "loss": 0.5387,
      "step": 3570
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.2664547661404244,
      "learning_rate": 8.80184699928468e-06,
      "loss": 0.5233,
      "step": 3571
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.9331748943949845,
      "learning_rate": 8.80111556391777e-06,
      "loss": 0.5399,
      "step": 3572
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.6162940876336656,
      "learning_rate": 8.800383935770672e-06,
      "loss": 0.5273,
      "step": 3573
    },
    {
      "epoch": 0.25,
      "grad_norm": 3.286402921299235,
      "learning_rate": 8.799652114880489e-06,
      "loss": 0.5642,
      "step": 3574
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.9482542292893064,
      "learning_rate": 8.79892010128434e-06,
      "loss": 0.5761,
      "step": 3575
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.0396625902051584,
      "learning_rate": 8.798187895019348e-06,
      "loss": 0.5172,
      "step": 3576
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.1823995254702218,
      "learning_rate": 8.797455496122647e-06,
      "loss": 0.4953,
      "step": 3577
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.734315864237198,
      "learning_rate": 8.796722904631386e-06,
      "loss": 0.4997,
      "step": 3578
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.0388837199042533,
      "learning_rate": 8.795990120582717e-06,
      "loss": 0.5735,
      "step": 3579
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.133321322764405,
      "learning_rate": 8.795257144013805e-06,
      "loss": 0.5037,
      "step": 3580
    },
    {
      "epoch": 0.25,
      "grad_norm": 3.38655266567961,
      "learning_rate": 8.794523974961822e-06,
      "loss": 0.5101,
      "step": 3581
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.3701641307513204,
      "learning_rate": 8.793790613463956e-06,
      "loss": 0.5816,
      "step": 3582
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.730880541929398,
      "learning_rate": 8.793057059557397e-06,
      "loss": 0.5614,
      "step": 3583
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.116921152368919,
      "learning_rate": 8.79232331327935e-06,
      "loss": 0.5362,
      "step": 3584
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.388202438648935,
      "learning_rate": 8.791589374667029e-06,
      "loss": 0.5009,
      "step": 3585
    },
    {
      "epoch": 0.25,
      "grad_norm": 5.2628564656936065,
      "learning_rate": 8.790855243757657e-06,
      "loss": 0.5142,
      "step": 3586
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.5637252223936113,
      "learning_rate": 8.790120920588466e-06,
      "loss": 0.5368,
      "step": 3587
    },
    {
      "epoch": 0.25,
      "grad_norm": 4.434648292464123,
      "learning_rate": 8.789386405196695e-06,
      "loss": 0.5335,
      "step": 3588
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.0017399960281796,
      "learning_rate": 8.788651697619604e-06,
      "loss": 0.5203,
      "step": 3589
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.063650342505411,
      "learning_rate": 8.787916797894448e-06,
      "loss": 0.5095,
      "step": 3590
    },
    {
      "epoch": 0.25,
      "grad_norm": 3.2453971937295503,
      "learning_rate": 8.787181706058502e-06,
      "loss": 0.4856,
      "step": 3591
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.7618644539497748,
      "learning_rate": 8.786446422149046e-06,
      "loss": 0.537,
      "step": 3592
    },
    {
      "epoch": 0.25,
      "grad_norm": 3.2764874286409693,
      "learning_rate": 8.785710946203374e-06,
      "loss": 0.5512,
      "step": 3593
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.818090665795369,
      "learning_rate": 8.784975278258783e-06,
      "loss": 0.5508,
      "step": 3594
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.958906879074597,
      "learning_rate": 8.784239418352588e-06,
      "loss": 0.529,
      "step": 3595
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.974766069267539,
      "learning_rate": 8.783503366522103e-06,
      "loss": 0.489,
      "step": 3596
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.371033371535326,
      "learning_rate": 8.782767122804664e-06,
      "loss": 0.5485,
      "step": 3597
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.488837700404961,
      "learning_rate": 8.78203068723761e-06,
      "loss": 0.5027,
      "step": 3598
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.5169250352602073,
      "learning_rate": 8.781294059858289e-06,
      "loss": 0.5191,
      "step": 3599
    },
    {
      "epoch": 0.25,
      "grad_norm": 4.286484157891911,
      "learning_rate": 8.780557240704062e-06,
      "loss": 0.4931,
      "step": 3600
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.0847502126034705,
      "learning_rate": 8.779820229812297e-06,
      "loss": 0.5467,
      "step": 3601
    },
    {
      "epoch": 0.25,
      "grad_norm": 3.0679885537214315,
      "learning_rate": 8.779083027220372e-06,
      "loss": 0.5609,
      "step": 3602
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.7284437724411834,
      "learning_rate": 8.778345632965677e-06,
      "loss": 0.5689,
      "step": 3603
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.586195520574123,
      "learning_rate": 8.777608047085608e-06,
      "loss": 0.4737,
      "step": 3604
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.240956966094431,
      "learning_rate": 8.776870269617577e-06,
      "loss": 0.5476,
      "step": 3605
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.9261264994086615,
      "learning_rate": 8.776132300598998e-06,
      "loss": 0.5497,
      "step": 3606
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.9733840113783736,
      "learning_rate": 8.775394140067299e-06,
      "loss": 0.5404,
      "step": 3607
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.265291879782088,
      "learning_rate": 8.774655788059918e-06,
      "loss": 0.5789,
      "step": 3608
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.0226775342686403,
      "learning_rate": 8.773917244614303e-06,
      "loss": 0.536,
      "step": 3609
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.240528507008594,
      "learning_rate": 8.773178509767907e-06,
      "loss": 0.5072,
      "step": 3610
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.3439932915827693,
      "learning_rate": 8.772439583558198e-06,
      "loss": 0.5321,
      "step": 3611
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.962545448507023,
      "learning_rate": 8.771700466022655e-06,
      "loss": 0.5462,
      "step": 3612
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.190658100563807,
      "learning_rate": 8.770961157198759e-06,
      "loss": 0.5669,
      "step": 3613
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.5641920969107517,
      "learning_rate": 8.770221657124007e-06,
      "loss": 0.5561,
      "step": 3614
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.2797767420402377,
      "learning_rate": 8.769481965835904e-06,
      "loss": 0.5355,
      "step": 3615
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.01903403762126,
      "learning_rate": 8.768742083371967e-06,
      "loss": 0.4982,
      "step": 3616
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.7305752729945287,
      "learning_rate": 8.768002009769716e-06,
      "loss": 0.4637,
      "step": 3617
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.4484529602468807,
      "learning_rate": 8.767261745066689e-06,
      "loss": 0.5276,
      "step": 3618
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.35600157710465,
      "learning_rate": 8.766521289300428e-06,
      "loss": 0.5765,
      "step": 3619
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.6716659109367304,
      "learning_rate": 8.765780642508484e-06,
      "loss": 0.562,
      "step": 3620
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.061793620236172,
      "learning_rate": 8.765039804728425e-06,
      "loss": 0.5242,
      "step": 3621
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.2758456846946857,
      "learning_rate": 8.764298775997823e-06,
      "loss": 0.4954,
      "step": 3622
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.168601815222705,
      "learning_rate": 8.763557556354258e-06,
      "loss": 0.4962,
      "step": 3623
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.3827069900103455,
      "learning_rate": 8.762816145835325e-06,
      "loss": 0.5253,
      "step": 3624
    },
    {
      "epoch": 0.25,
      "grad_norm": 4.145450496220491,
      "learning_rate": 8.762074544478622e-06,
      "loss": 0.5588,
      "step": 3625
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.929539178008797,
      "learning_rate": 8.761332752321765e-06,
      "loss": 0.537,
      "step": 3626
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.3078696142065183,
      "learning_rate": 8.760590769402372e-06,
      "loss": 0.5427,
      "step": 3627
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.3784513272404455,
      "learning_rate": 8.759848595758077e-06,
      "loss": 0.4775,
      "step": 3628
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.8416828936457617,
      "learning_rate": 8.75910623142652e-06,
      "loss": 0.4879,
      "step": 3629
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.641367052270432,
      "learning_rate": 8.75836367644535e-06,
      "loss": 0.4976,
      "step": 3630
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.2513759224138825,
      "learning_rate": 8.757620930852225e-06,
      "loss": 0.4997,
      "step": 3631
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.9772578329271504,
      "learning_rate": 8.756877994684818e-06,
      "loss": 0.5133,
      "step": 3632
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.2811736036415273,
      "learning_rate": 8.756134867980808e-06,
      "loss": 0.528,
      "step": 3633
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.183171797349614,
      "learning_rate": 8.755391550777883e-06,
      "loss": 0.5197,
      "step": 3634
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.1386541352431556,
      "learning_rate": 8.754648043113742e-06,
      "loss": 0.5302,
      "step": 3635
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.8492990750546148,
      "learning_rate": 8.753904345026091e-06,
      "loss": 0.5046,
      "step": 3636
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.8894972262357885,
      "learning_rate": 8.753160456552653e-06,
      "loss": 0.5116,
      "step": 3637
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.4620036294563734,
      "learning_rate": 8.752416377731151e-06,
      "loss": 0.4968,
      "step": 3638
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.764332892182987,
      "learning_rate": 8.751672108599325e-06,
      "loss": 0.4907,
      "step": 3639
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.2222114619727513,
      "learning_rate": 8.75092764919492e-06,
      "loss": 0.5563,
      "step": 3640
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.187597264806784,
      "learning_rate": 8.750182999555692e-06,
      "loss": 0.5165,
      "step": 3641
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.896944586699426,
      "learning_rate": 8.74943815971941e-06,
      "loss": 0.5295,
      "step": 3642
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.1648520546745504,
      "learning_rate": 8.748693129723849e-06,
      "loss": 0.5305,
      "step": 3643
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.0167313227878036,
      "learning_rate": 8.747947909606793e-06,
      "loss": 0.5489,
      "step": 3644
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.8936340530028692,
      "learning_rate": 8.747202499406039e-06,
      "loss": 0.5359,
      "step": 3645
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.6483317282519425,
      "learning_rate": 8.74645689915939e-06,
      "loss": 0.501,
      "step": 3646
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.996482866588451,
      "learning_rate": 8.745711108904661e-06,
      "loss": 0.5032,
      "step": 3647
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.4890635900501805,
      "learning_rate": 8.744965128679676e-06,
      "loss": 0.5623,
      "step": 3648
    },
    {
      "epoch": 0.25,
      "grad_norm": 45.64398501153853,
      "learning_rate": 8.74421895852227e-06,
      "loss": 0.5626,
      "step": 3649
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.2524226428062426,
      "learning_rate": 8.743472598470286e-06,
      "loss": 0.5338,
      "step": 3650
    },
    {
      "epoch": 0.25,
      "grad_norm": 3.612848034541288,
      "learning_rate": 8.742726048561574e-06,
      "loss": 0.565,
      "step": 3651
    },
    {
      "epoch": 0.25,
      "grad_norm": 3.6933408776146877,
      "learning_rate": 8.741979308834e-06,
      "loss": 0.522,
      "step": 3652
    },
    {
      "epoch": 0.25,
      "grad_norm": 3.534166795169759,
      "learning_rate": 8.741232379325434e-06,
      "loss": 0.5437,
      "step": 3653
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.0214628379406245,
      "learning_rate": 8.740485260073761e-06,
      "loss": 0.5112,
      "step": 3654
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.127175886858643,
      "learning_rate": 8.739737951116869e-06,
      "loss": 0.528,
      "step": 3655
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.7952162307763766,
      "learning_rate": 8.73899045249266e-06,
      "loss": 0.5374,
      "step": 3656
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.0620272041838184,
      "learning_rate": 8.738242764239046e-06,
      "loss": 0.5386,
      "step": 3657
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.5254013842220124,
      "learning_rate": 8.737494886393946e-06,
      "loss": 0.5701,
      "step": 3658
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.397792966014641,
      "learning_rate": 8.736746818995289e-06,
      "loss": 0.5373,
      "step": 3659
    },
    {
      "epoch": 0.25,
      "grad_norm": 4.853352454853895,
      "learning_rate": 8.735998562081018e-06,
      "loss": 0.5811,
      "step": 3660
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.1915674137017698,
      "learning_rate": 8.735250115689079e-06,
      "loss": 0.515,
      "step": 3661
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.715330907315891,
      "learning_rate": 8.734501479857431e-06,
      "loss": 0.5592,
      "step": 3662
    },
    {
      "epoch": 0.25,
      "grad_norm": 3.5276087436581975,
      "learning_rate": 8.733752654624044e-06,
      "loss": 0.5136,
      "step": 3663
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.385669304350616,
      "learning_rate": 8.733003640026895e-06,
      "loss": 0.4905,
      "step": 3664
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.0950049324149966,
      "learning_rate": 8.732254436103971e-06,
      "loss": 0.4849,
      "step": 3665
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.2148245382459115,
      "learning_rate": 8.731505042893272e-06,
      "loss": 0.5619,
      "step": 3666
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.4315853870344157,
      "learning_rate": 8.7307554604328e-06,
      "loss": 0.543,
      "step": 3667
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.499976749091393,
      "learning_rate": 8.730005688760575e-06,
      "loss": 0.5201,
      "step": 3668
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.818680666396874,
      "learning_rate": 8.729255727914622e-06,
      "loss": 0.5321,
      "step": 3669
    },
    {
      "epoch": 0.26,
      "grad_norm": 3.1433471922497516,
      "learning_rate": 8.728505577932977e-06,
      "loss": 0.5381,
      "step": 3670
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.6648581201744825,
      "learning_rate": 8.727755238853684e-06,
      "loss": 0.5236,
      "step": 3671
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.319931683287913,
      "learning_rate": 8.7270047107148e-06,
      "loss": 0.4806,
      "step": 3672
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.1297690942261673,
      "learning_rate": 8.726253993554385e-06,
      "loss": 0.5358,
      "step": 3673
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.0694521538849178,
      "learning_rate": 8.725503087410518e-06,
      "loss": 0.5404,
      "step": 3674
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.899699962858237,
      "learning_rate": 8.724751992321279e-06,
      "loss": 0.5505,
      "step": 3675
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.789060708358528,
      "learning_rate": 8.724000708324763e-06,
      "loss": 0.5351,
      "step": 3676
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.7784905110467528,
      "learning_rate": 8.723249235459073e-06,
      "loss": 0.4855,
      "step": 3677
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.789852834573784,
      "learning_rate": 8.722497573762319e-06,
      "loss": 0.5292,
      "step": 3678
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.262480115053966,
      "learning_rate": 8.721745723272622e-06,
      "loss": 0.533,
      "step": 3679
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.7652745304518086,
      "learning_rate": 8.72099368402812e-06,
      "loss": 0.4715,
      "step": 3680
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.067974519864034,
      "learning_rate": 8.720241456066947e-06,
      "loss": 0.5026,
      "step": 3681
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.9555804346120305,
      "learning_rate": 8.719489039427256e-06,
      "loss": 0.5748,
      "step": 3682
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.036915733959882,
      "learning_rate": 8.718736434147208e-06,
      "loss": 0.503,
      "step": 3683
    },
    {
      "epoch": 0.26,
      "grad_norm": 6.667833134336921,
      "learning_rate": 8.717983640264972e-06,
      "loss": 0.5483,
      "step": 3684
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.1580489483530734,
      "learning_rate": 8.717230657818725e-06,
      "loss": 0.5399,
      "step": 3685
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.537676391043027,
      "learning_rate": 8.71647748684666e-06,
      "loss": 0.4479,
      "step": 3686
    },
    {
      "epoch": 0.26,
      "grad_norm": 4.317457391098491,
      "learning_rate": 8.715724127386971e-06,
      "loss": 0.5169,
      "step": 3687
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.8709784269676903,
      "learning_rate": 8.71497057947787e-06,
      "loss": 0.5079,
      "step": 3688
    },
    {
      "epoch": 0.26,
      "grad_norm": 3.370455399942849,
      "learning_rate": 8.714216843157574e-06,
      "loss": 0.5403,
      "step": 3689
    },
    {
      "epoch": 0.26,
      "grad_norm": 3.7115546406365345,
      "learning_rate": 8.713462918464306e-06,
      "loss": 0.5977,
      "step": 3690
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.4431459277282688,
      "learning_rate": 8.712708805436307e-06,
      "loss": 0.5074,
      "step": 3691
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.509966884804185,
      "learning_rate": 8.711954504111821e-06,
      "loss": 0.5429,
      "step": 3692
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.00103721890184,
      "learning_rate": 8.711200014529104e-06,
      "loss": 0.5316,
      "step": 3693
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.1325099174167703,
      "learning_rate": 8.710445336726424e-06,
      "loss": 0.567,
      "step": 3694
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.8477972997926755,
      "learning_rate": 8.70969047074205e-06,
      "loss": 0.5038,
      "step": 3695
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.7718906272442285,
      "learning_rate": 8.708935416614271e-06,
      "loss": 0.4887,
      "step": 3696
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.9428410199421344,
      "learning_rate": 8.708180174381378e-06,
      "loss": 0.4858,
      "step": 3697
    },
    {
      "epoch": 0.26,
      "grad_norm": 3.9382321259407904,
      "learning_rate": 8.707424744081678e-06,
      "loss": 0.5185,
      "step": 3698
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.084467480186099,
      "learning_rate": 8.70666912575348e-06,
      "loss": 0.517,
      "step": 3699
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.8233062172295484,
      "learning_rate": 8.705913319435111e-06,
      "loss": 0.4536,
      "step": 3700
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.7458790410640406,
      "learning_rate": 8.705157325164898e-06,
      "loss": 0.5168,
      "step": 3701
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.978836535351864,
      "learning_rate": 8.704401142981184e-06,
      "loss": 0.5831,
      "step": 3702
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.1972410527908086,
      "learning_rate": 8.703644772922324e-06,
      "loss": 0.5065,
      "step": 3703
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.5640127633021765,
      "learning_rate": 8.702888215026674e-06,
      "loss": 0.5357,
      "step": 3704
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.0706295476450216,
      "learning_rate": 8.702131469332607e-06,
      "loss": 0.5799,
      "step": 3705
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.1907060612696294,
      "learning_rate": 8.701374535878501e-06,
      "loss": 0.5648,
      "step": 3706
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.607746172548098,
      "learning_rate": 8.700617414702746e-06,
      "loss": 0.5218,
      "step": 3707
    },
    {
      "epoch": 0.26,
      "grad_norm": 8.03652316729857,
      "learning_rate": 8.69986010584374e-06,
      "loss": 0.5488,
      "step": 3708
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.4810567741607357,
      "learning_rate": 8.699102609339891e-06,
      "loss": 0.5006,
      "step": 3709
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.194403362338275,
      "learning_rate": 8.698344925229618e-06,
      "loss": 0.5116,
      "step": 3710
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.9443146440222583,
      "learning_rate": 8.697587053551348e-06,
      "loss": 0.5295,
      "step": 3711
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.63240832975306,
      "learning_rate": 8.696828994343518e-06,
      "loss": 0.5553,
      "step": 3712
    },
    {
      "epoch": 0.26,
      "grad_norm": 3.2953456533450582,
      "learning_rate": 8.696070747644572e-06,
      "loss": 0.5472,
      "step": 3713
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.0804099879995617,
      "learning_rate": 8.69531231349297e-06,
      "loss": 0.545,
      "step": 3714
    },
    {
      "epoch": 0.26,
      "grad_norm": 3.2831855424660765,
      "learning_rate": 8.694553691927172e-06,
      "loss": 0.5395,
      "step": 3715
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.5576155974010093,
      "learning_rate": 8.693794882985657e-06,
      "loss": 0.527,
      "step": 3716
    },
    {
      "epoch": 0.26,
      "grad_norm": 3.01635407043485,
      "learning_rate": 8.693035886706909e-06,
      "loss": 0.5047,
      "step": 3717
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.1779968299530275,
      "learning_rate": 8.692276703129421e-06,
      "loss": 0.5461,
      "step": 3718
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.4352683433005997,
      "learning_rate": 8.691517332291694e-06,
      "loss": 0.5543,
      "step": 3719
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.8833804945185557,
      "learning_rate": 8.690757774232243e-06,
      "loss": 0.4776,
      "step": 3720
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.061716263742032,
      "learning_rate": 8.689998028989592e-06,
      "loss": 0.5005,
      "step": 3721
    },
    {
      "epoch": 0.26,
      "grad_norm": 4.23981879862806,
      "learning_rate": 8.68923809660227e-06,
      "loss": 0.5099,
      "step": 3722
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.9584407422389223,
      "learning_rate": 8.68847797710882e-06,
      "loss": 0.5465,
      "step": 3723
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.022314003911285,
      "learning_rate": 8.687717670547793e-06,
      "loss": 0.4977,
      "step": 3724
    },
    {
      "epoch": 0.26,
      "grad_norm": 3.915683346643599,
      "learning_rate": 8.686957176957747e-06,
      "loss": 0.4963,
      "step": 3725
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.036512898362579,
      "learning_rate": 8.686196496377252e-06,
      "loss": 0.5174,
      "step": 3726
    },
    {
      "epoch": 0.26,
      "grad_norm": 4.502824227572773,
      "learning_rate": 8.68543562884489e-06,
      "loss": 0.5519,
      "step": 3727
    },
    {
      "epoch": 0.26,
      "grad_norm": 3.3740159241614447,
      "learning_rate": 8.684674574399248e-06,
      "loss": 0.4997,
      "step": 3728
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.8899140949407354,
      "learning_rate": 8.683913333078924e-06,
      "loss": 0.5628,
      "step": 3729
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.2737525492489183,
      "learning_rate": 8.683151904922526e-06,
      "loss": 0.5879,
      "step": 3730
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.7759950716954971,
      "learning_rate": 8.682390289968671e-06,
      "loss": 0.444,
      "step": 3731
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.752302625152706,
      "learning_rate": 8.681628488255986e-06,
      "loss": 0.4413,
      "step": 3732
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.1568794828612785,
      "learning_rate": 8.68086649982311e-06,
      "loss": 0.5802,
      "step": 3733
    },
    {
      "epoch": 0.26,
      "grad_norm": 8.818619332790844,
      "learning_rate": 8.68010432470868e-06,
      "loss": 0.4984,
      "step": 3734
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.0529722863882847,
      "learning_rate": 8.67934196295136e-06,
      "loss": 0.5314,
      "step": 3735
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.375832855231668,
      "learning_rate": 8.67857941458981e-06,
      "loss": 0.5478,
      "step": 3736
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.204081493577573,
      "learning_rate": 8.677816679662705e-06,
      "loss": 0.5421,
      "step": 3737
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.9331392681697934,
      "learning_rate": 8.677053758208727e-06,
      "loss": 0.5076,
      "step": 3738
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.910194432384829,
      "learning_rate": 8.676290650266571e-06,
      "loss": 0.4988,
      "step": 3739
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.4284945665126694,
      "learning_rate": 8.67552735587494e-06,
      "loss": 0.5466,
      "step": 3740
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.1266504362215506,
      "learning_rate": 8.674763875072544e-06,
      "loss": 0.5354,
      "step": 3741
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.93407824189815,
      "learning_rate": 8.674000207898103e-06,
      "loss": 0.5409,
      "step": 3742
    },
    {
      "epoch": 0.26,
      "grad_norm": 3.5394687437692225,
      "learning_rate": 8.67323635439035e-06,
      "loss": 0.5253,
      "step": 3743
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.1918764345448807,
      "learning_rate": 8.672472314588027e-06,
      "loss": 0.5603,
      "step": 3744
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.4092846430502406,
      "learning_rate": 8.67170808852988e-06,
      "loss": 0.5739,
      "step": 3745
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.2315024724942014,
      "learning_rate": 8.670943676254669e-06,
      "loss": 0.4685,
      "step": 3746
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.0383030448194774,
      "learning_rate": 8.67017907780116e-06,
      "loss": 0.5109,
      "step": 3747
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.095690873780799,
      "learning_rate": 8.669414293208136e-06,
      "loss": 0.5283,
      "step": 3748
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.723653938225429,
      "learning_rate": 8.668649322514382e-06,
      "loss": 0.5496,
      "step": 3749
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.304282857086934,
      "learning_rate": 8.667884165758695e-06,
      "loss": 0.5157,
      "step": 3750
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.1608852151984186,
      "learning_rate": 8.667118822979881e-06,
      "loss": 0.4896,
      "step": 3751
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.3840052168133745,
      "learning_rate": 8.666353294216756e-06,
      "loss": 0.5338,
      "step": 3752
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.6518843821258775,
      "learning_rate": 8.665587579508145e-06,
      "loss": 0.5065,
      "step": 3753
    },
    {
      "epoch": 0.26,
      "grad_norm": 3.045830472153495,
      "learning_rate": 8.66482167889288e-06,
      "loss": 0.5167,
      "step": 3754
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.9423587142630603,
      "learning_rate": 8.66405559240981e-06,
      "loss": 0.5193,
      "step": 3755
    },
    {
      "epoch": 0.26,
      "grad_norm": 3.7676723468159317,
      "learning_rate": 8.663289320097786e-06,
      "loss": 0.5757,
      "step": 3756
    },
    {
      "epoch": 0.26,
      "grad_norm": 3.1610600708536403,
      "learning_rate": 8.66252286199567e-06,
      "loss": 0.5255,
      "step": 3757
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.2922990399861622,
      "learning_rate": 8.661756218142335e-06,
      "loss": 0.4952,
      "step": 3758
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6701716636488854,
      "learning_rate": 8.660989388576663e-06,
      "loss": 0.494,
      "step": 3759
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.20011838240872,
      "learning_rate": 8.660222373337543e-06,
      "loss": 0.5192,
      "step": 3760
    },
    {
      "epoch": 0.26,
      "grad_norm": 4.195243035521683,
      "learning_rate": 8.65945517246388e-06,
      "loss": 0.5332,
      "step": 3761
    },
    {
      "epoch": 0.26,
      "grad_norm": 3.0141771716881274,
      "learning_rate": 8.658687785994579e-06,
      "loss": 0.4882,
      "step": 3762
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.8826292292127271,
      "learning_rate": 8.657920213968563e-06,
      "loss": 0.5434,
      "step": 3763
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.9853940390241533,
      "learning_rate": 8.657152456424758e-06,
      "loss": 0.5366,
      "step": 3764
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.7255638333165826,
      "learning_rate": 8.656384513402104e-06,
      "loss": 0.4794,
      "step": 3765
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.206947905752786,
      "learning_rate": 8.655616384939547e-06,
      "loss": 0.5359,
      "step": 3766
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.2443471733441736,
      "learning_rate": 8.654848071076048e-06,
      "loss": 0.5097,
      "step": 3767
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.5445760842911995,
      "learning_rate": 8.654079571850567e-06,
      "loss": 0.4991,
      "step": 3768
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.114488426095849,
      "learning_rate": 8.653310887302084e-06,
      "loss": 0.5269,
      "step": 3769
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.703736968451234,
      "learning_rate": 8.652542017469582e-06,
      "loss": 0.583,
      "step": 3770
    },
    {
      "epoch": 0.26,
      "grad_norm": 4.746644658044353,
      "learning_rate": 8.65177296239206e-06,
      "loss": 0.5413,
      "step": 3771
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.513407937389252,
      "learning_rate": 8.651003722108517e-06,
      "loss": 0.5431,
      "step": 3772
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.3690948347175227,
      "learning_rate": 8.650234296657969e-06,
      "loss": 0.5238,
      "step": 3773
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.318573765035713,
      "learning_rate": 8.649464686079436e-06,
      "loss": 0.533,
      "step": 3774
    },
    {
      "epoch": 0.26,
      "grad_norm": 8.90998469916259,
      "learning_rate": 8.648694890411953e-06,
      "loss": 0.4713,
      "step": 3775
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.160156744861095,
      "learning_rate": 8.647924909694562e-06,
      "loss": 0.5423,
      "step": 3776
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.8407278051157028,
      "learning_rate": 8.64715474396631e-06,
      "loss": 0.5065,
      "step": 3777
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.521058309730091,
      "learning_rate": 8.646384393266263e-06,
      "loss": 0.5065,
      "step": 3778
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.8549105272480033,
      "learning_rate": 8.645613857633486e-06,
      "loss": 0.4816,
      "step": 3779
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.487566725797757,
      "learning_rate": 8.644843137107058e-06,
      "loss": 0.4811,
      "step": 3780
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.640707030207746,
      "learning_rate": 8.64407223172607e-06,
      "loss": 0.4976,
      "step": 3781
    },
    {
      "epoch": 0.26,
      "grad_norm": 5.522236458224338,
      "learning_rate": 8.643301141529619e-06,
      "loss": 0.564,
      "step": 3782
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.156780805060411,
      "learning_rate": 8.642529866556813e-06,
      "loss": 0.5219,
      "step": 3783
    },
    {
      "epoch": 0.26,
      "grad_norm": 8.427162026285805,
      "learning_rate": 8.641758406846765e-06,
      "loss": 0.5488,
      "step": 3784
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.3442412195671687,
      "learning_rate": 8.640986762438606e-06,
      "loss": 0.5183,
      "step": 3785
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.626527512474173,
      "learning_rate": 8.640214933371467e-06,
      "loss": 0.5532,
      "step": 3786
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.0707949769589855,
      "learning_rate": 8.639442919684495e-06,
      "loss": 0.4738,
      "step": 3787
    },
    {
      "epoch": 0.26,
      "grad_norm": 3.7882958979056642,
      "learning_rate": 8.638670721416844e-06,
      "loss": 0.5492,
      "step": 3788
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.2510535274432235,
      "learning_rate": 8.637898338607675e-06,
      "loss": 0.4669,
      "step": 3789
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.1436351180858173,
      "learning_rate": 8.637125771296164e-06,
      "loss": 0.4895,
      "step": 3790
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.9978905870079702,
      "learning_rate": 8.636353019521491e-06,
      "loss": 0.5302,
      "step": 3791
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.0868886989734716,
      "learning_rate": 8.635580083322847e-06,
      "loss": 0.5782,
      "step": 3792
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.16403604039235,
      "learning_rate": 8.634806962739436e-06,
      "loss": 0.5466,
      "step": 3793
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.0862101170941902,
      "learning_rate": 8.634033657810465e-06,
      "loss": 0.5209,
      "step": 3794
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.7034507313266277,
      "learning_rate": 8.633260168575155e-06,
      "loss": 0.4762,
      "step": 3795
    },
    {
      "epoch": 0.26,
      "grad_norm": 4.122183173138723,
      "learning_rate": 8.632486495072734e-06,
      "loss": 0.4621,
      "step": 3796
    },
    {
      "epoch": 0.26,
      "grad_norm": 3.2165038577466345,
      "learning_rate": 8.63171263734244e-06,
      "loss": 0.5595,
      "step": 3797
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.836384706769621,
      "learning_rate": 8.630938595423521e-06,
      "loss": 0.5443,
      "step": 3798
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.2783048323824278,
      "learning_rate": 8.630164369355234e-06,
      "loss": 0.4809,
      "step": 3799
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.9674132192117815,
      "learning_rate": 8.629389959176846e-06,
      "loss": 0.4791,
      "step": 3800
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.68692696708168,
      "learning_rate": 8.628615364927632e-06,
      "loss": 0.5418,
      "step": 3801
    },
    {
      "epoch": 0.26,
      "grad_norm": 3.0151270401158183,
      "learning_rate": 8.627840586646876e-06,
      "loss": 0.5206,
      "step": 3802
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.0737547507579706,
      "learning_rate": 8.627065624373872e-06,
      "loss": 0.4478,
      "step": 3803
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.909457151736851,
      "learning_rate": 8.626290478147925e-06,
      "loss": 0.5127,
      "step": 3804
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.323887539684951,
      "learning_rate": 8.625515148008349e-06,
      "loss": 0.561,
      "step": 3805
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.4875361348688894,
      "learning_rate": 8.624739633994463e-06,
      "loss": 0.5027,
      "step": 3806
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.357588449542588,
      "learning_rate": 8.6239639361456e-06,
      "loss": 0.523,
      "step": 3807
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.7395458244122026,
      "learning_rate": 8.623188054501101e-06,
      "loss": 0.5102,
      "step": 3808
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.1816855007473217,
      "learning_rate": 8.622411989100316e-06,
      "loss": 0.5019,
      "step": 3809
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.8234003003843603,
      "learning_rate": 8.621635739982607e-06,
      "loss": 0.4539,
      "step": 3810
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.48267509116787,
      "learning_rate": 8.620859307187339e-06,
      "loss": 0.5211,
      "step": 3811
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.009672659301427,
      "learning_rate": 8.620082690753891e-06,
      "loss": 0.536,
      "step": 3812
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.2958375383675778,
      "learning_rate": 8.61930589072165e-06,
      "loss": 0.5072,
      "step": 3813
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.3328122781194516,
      "learning_rate": 8.618528907130017e-06,
      "loss": 0.4772,
      "step": 3814
    },
    {
      "epoch": 0.27,
      "grad_norm": 3.182504638939967,
      "learning_rate": 8.617751740018391e-06,
      "loss": 0.5399,
      "step": 3815
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.2562980125990237,
      "learning_rate": 8.616974389426194e-06,
      "loss": 0.5184,
      "step": 3816
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.2894444540652747,
      "learning_rate": 8.616196855392849e-06,
      "loss": 0.4974,
      "step": 3817
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.473927140023618,
      "learning_rate": 8.615419137957785e-06,
      "loss": 0.5273,
      "step": 3818
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.2659877571781735,
      "learning_rate": 8.614641237160453e-06,
      "loss": 0.5136,
      "step": 3819
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.921489580565488,
      "learning_rate": 8.613863153040301e-06,
      "loss": 0.5153,
      "step": 3820
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.345072968049024,
      "learning_rate": 8.61308488563679e-06,
      "loss": 0.5184,
      "step": 3821
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.3932926321790657,
      "learning_rate": 8.612306434989395e-06,
      "loss": 0.522,
      "step": 3822
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.3924935602609643,
      "learning_rate": 8.611527801137593e-06,
      "loss": 0.5294,
      "step": 3823
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7033924387799331,
      "learning_rate": 8.610748984120876e-06,
      "loss": 0.4585,
      "step": 3824
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.5330930734405603,
      "learning_rate": 8.609969983978741e-06,
      "loss": 0.5714,
      "step": 3825
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.4416984543694955,
      "learning_rate": 8.6091908007507e-06,
      "loss": 0.5847,
      "step": 3826
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.155927427154589,
      "learning_rate": 8.608411434476267e-06,
      "loss": 0.5113,
      "step": 3827
    },
    {
      "epoch": 0.27,
      "grad_norm": 3.320147512861697,
      "learning_rate": 8.60763188519497e-06,
      "loss": 0.5042,
      "step": 3828
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6727721269129312,
      "learning_rate": 8.606852152946345e-06,
      "loss": 0.4669,
      "step": 3829
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.93915292268244,
      "learning_rate": 8.606072237769938e-06,
      "loss": 0.5507,
      "step": 3830
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.6547762397502757,
      "learning_rate": 8.605292139705303e-06,
      "loss": 0.4633,
      "step": 3831
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.6991342756358447,
      "learning_rate": 8.604511858792006e-06,
      "loss": 0.5442,
      "step": 3832
    },
    {
      "epoch": 0.27,
      "grad_norm": 3.059399098652851,
      "learning_rate": 8.603731395069618e-06,
      "loss": 0.5326,
      "step": 3833
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.3443255537764447,
      "learning_rate": 8.602950748577722e-06,
      "loss": 0.53,
      "step": 3834
    },
    {
      "epoch": 0.27,
      "grad_norm": 3.7452799716645306,
      "learning_rate": 8.60216991935591e-06,
      "loss": 0.5566,
      "step": 3835
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.9913900076512963,
      "learning_rate": 8.601388907443787e-06,
      "loss": 0.5388,
      "step": 3836
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.3390791914494464,
      "learning_rate": 8.600607712880956e-06,
      "loss": 0.5366,
      "step": 3837
    },
    {
      "epoch": 0.27,
      "grad_norm": 3.0813896350800154,
      "learning_rate": 8.599826335707043e-06,
      "loss": 0.4935,
      "step": 3838
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.9416584679154225,
      "learning_rate": 8.599044775961671e-06,
      "loss": 0.5504,
      "step": 3839
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.2728484857309796,
      "learning_rate": 8.598263033684485e-06,
      "loss": 0.5101,
      "step": 3840
    },
    {
      "epoch": 0.27,
      "grad_norm": 5.57323362116715,
      "learning_rate": 8.597481108915127e-06,
      "loss": 0.5173,
      "step": 3841
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.9579371695269654,
      "learning_rate": 8.596699001693257e-06,
      "loss": 0.5476,
      "step": 3842
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.12693643169581,
      "learning_rate": 8.595916712058539e-06,
      "loss": 0.5272,
      "step": 3843
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.728703803788036,
      "learning_rate": 8.595134240050648e-06,
      "loss": 0.4692,
      "step": 3844
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.6175873258399,
      "learning_rate": 8.59435158570927e-06,
      "loss": 0.5346,
      "step": 3845
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.9817833425291844,
      "learning_rate": 8.593568749074098e-06,
      "loss": 0.5189,
      "step": 3846
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.9152970335669623,
      "learning_rate": 8.592785730184833e-06,
      "loss": 0.5379,
      "step": 3847
    },
    {
      "epoch": 0.27,
      "grad_norm": 9.456216059243967,
      "learning_rate": 8.59200252908119e-06,
      "loss": 0.4778,
      "step": 3848
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.9589768122980193,
      "learning_rate": 8.591219145802888e-06,
      "loss": 0.553,
      "step": 3849
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.4780725162645116,
      "learning_rate": 8.590435580389663e-06,
      "loss": 0.5345,
      "step": 3850
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.20879442582938,
      "learning_rate": 8.589651832881247e-06,
      "loss": 0.5444,
      "step": 3851
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.885798266334496,
      "learning_rate": 8.588867903317395e-06,
      "loss": 0.5111,
      "step": 3852
    },
    {
      "epoch": 0.27,
      "grad_norm": 3.4091467397910913,
      "learning_rate": 8.588083791737862e-06,
      "loss": 0.5317,
      "step": 3853
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.538932113641809,
      "learning_rate": 8.587299498182418e-06,
      "loss": 0.5176,
      "step": 3854
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.792660220361907,
      "learning_rate": 8.586515022690838e-06,
      "loss": 0.4488,
      "step": 3855
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7169219037776585,
      "learning_rate": 8.58573036530291e-06,
      "loss": 0.4626,
      "step": 3856
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.047344626020278,
      "learning_rate": 8.584945526058426e-06,
      "loss": 0.5385,
      "step": 3857
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.495239458848464,
      "learning_rate": 8.584160504997191e-06,
      "loss": 0.5555,
      "step": 3858
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.8704947306463922,
      "learning_rate": 8.583375302159026e-06,
      "loss": 0.5253,
      "step": 3859
    },
    {
      "epoch": 0.27,
      "grad_norm": 3.6150398122715375,
      "learning_rate": 8.582589917583744e-06,
      "loss": 0.5218,
      "step": 3860
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7138219057010432,
      "learning_rate": 8.581804351311181e-06,
      "loss": 0.4675,
      "step": 3861
    },
    {
      "epoch": 0.27,
      "grad_norm": 3.2568345912440355,
      "learning_rate": 8.581018603381181e-06,
      "loss": 0.5136,
      "step": 3862
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.8916228623251317,
      "learning_rate": 8.58023267383359e-06,
      "loss": 0.5116,
      "step": 3863
    },
    {
      "epoch": 0.27,
      "grad_norm": 3.382235785927807,
      "learning_rate": 8.579446562708272e-06,
      "loss": 0.5385,
      "step": 3864
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.26846457465917,
      "learning_rate": 8.578660270045092e-06,
      "loss": 0.4694,
      "step": 3865
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.9969419121993957,
      "learning_rate": 8.57787379588393e-06,
      "loss": 0.4957,
      "step": 3866
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.5101370773988068,
      "learning_rate": 8.577087140264677e-06,
      "loss": 0.4812,
      "step": 3867
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.4095469792223914,
      "learning_rate": 8.576300303227224e-06,
      "loss": 0.5543,
      "step": 3868
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.309657257614999,
      "learning_rate": 8.57551328481148e-06,
      "loss": 0.5185,
      "step": 3869
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.559708199131768,
      "learning_rate": 8.574726085057357e-06,
      "loss": 0.5335,
      "step": 3870
    },
    {
      "epoch": 0.27,
      "grad_norm": 3.8646776421176234,
      "learning_rate": 8.573938704004783e-06,
      "loss": 0.5576,
      "step": 3871
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.337348952284365,
      "learning_rate": 8.573151141693688e-06,
      "loss": 0.506,
      "step": 3872
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.078156882897043,
      "learning_rate": 8.572363398164017e-06,
      "loss": 0.5291,
      "step": 3873
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.5799794347136706,
      "learning_rate": 8.571575473455723e-06,
      "loss": 0.5239,
      "step": 3874
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.2349694129898636,
      "learning_rate": 8.570787367608762e-06,
      "loss": 0.5198,
      "step": 3875
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.2709513229049625,
      "learning_rate": 8.569999080663108e-06,
      "loss": 0.5289,
      "step": 3876
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.981084939659423,
      "learning_rate": 8.569210612658741e-06,
      "loss": 0.5434,
      "step": 3877
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.5163051337446567,
      "learning_rate": 8.568421963635647e-06,
      "loss": 0.5333,
      "step": 3878
    },
    {
      "epoch": 0.27,
      "grad_norm": 3.2767739093044397,
      "learning_rate": 8.567633133633824e-06,
      "loss": 0.5238,
      "step": 3879
    },
    {
      "epoch": 0.27,
      "grad_norm": 3.713043343328141,
      "learning_rate": 8.56684412269328e-06,
      "loss": 0.5447,
      "step": 3880
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.780100379386781,
      "learning_rate": 8.56605493085403e-06,
      "loss": 0.5718,
      "step": 3881
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.8983410645576781,
      "learning_rate": 8.565265558156101e-06,
      "loss": 0.5074,
      "step": 3882
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.4478983390917395,
      "learning_rate": 8.564476004639528e-06,
      "loss": 0.5271,
      "step": 3883
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.432007868592813,
      "learning_rate": 8.56368627034435e-06,
      "loss": 0.5367,
      "step": 3884
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.2361028577343727,
      "learning_rate": 8.562896355310624e-06,
      "loss": 0.5135,
      "step": 3885
    },
    {
      "epoch": 0.27,
      "grad_norm": 3.081119582195075,
      "learning_rate": 8.56210625957841e-06,
      "loss": 0.5637,
      "step": 3886
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.517905189942309,
      "learning_rate": 8.561315983187781e-06,
      "loss": 0.523,
      "step": 3887
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.8468471984333221,
      "learning_rate": 8.560525526178814e-06,
      "loss": 0.5022,
      "step": 3888
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.7125630759147246,
      "learning_rate": 8.559734888591602e-06,
      "loss": 0.5359,
      "step": 3889
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.5005362257963664,
      "learning_rate": 8.558944070466242e-06,
      "loss": 0.4984,
      "step": 3890
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.7074190199257937,
      "learning_rate": 8.55815307184284e-06,
      "loss": 0.5068,
      "step": 3891
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.9365891103699613,
      "learning_rate": 8.557361892761514e-06,
      "loss": 0.5255,
      "step": 3892
    },
    {
      "epoch": 0.27,
      "grad_norm": 4.939374452852201,
      "learning_rate": 8.556570533262392e-06,
      "loss": 0.5655,
      "step": 3893
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.2779838969111377,
      "learning_rate": 8.555778993385607e-06,
      "loss": 0.5397,
      "step": 3894
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.436571204727681,
      "learning_rate": 8.554987273171305e-06,
      "loss": 0.519,
      "step": 3895
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.204689380758165,
      "learning_rate": 8.554195372659638e-06,
      "loss": 0.5078,
      "step": 3896
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.0704957224764704,
      "learning_rate": 8.553403291890767e-06,
      "loss": 0.5199,
      "step": 3897
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.7674174697629814,
      "learning_rate": 8.552611030904866e-06,
      "loss": 0.5084,
      "step": 3898
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.6013874881735783,
      "learning_rate": 8.551818589742118e-06,
      "loss": 0.5903,
      "step": 3899
    },
    {
      "epoch": 0.27,
      "grad_norm": 5.9916872660610885,
      "learning_rate": 8.55102596844271e-06,
      "loss": 0.5353,
      "step": 3900
    },
    {
      "epoch": 0.27,
      "grad_norm": 3.1708239974253605,
      "learning_rate": 8.550233167046842e-06,
      "loss": 0.5265,
      "step": 3901
    },
    {
      "epoch": 0.27,
      "grad_norm": 3.0389450886363716,
      "learning_rate": 8.549440185594722e-06,
      "loss": 0.5237,
      "step": 3902
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.305394017314473,
      "learning_rate": 8.548647024126568e-06,
      "loss": 0.5654,
      "step": 3903
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.005901389011338,
      "learning_rate": 8.547853682682605e-06,
      "loss": 0.53,
      "step": 3904
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.1805773198843807,
      "learning_rate": 8.547060161303071e-06,
      "loss": 0.5517,
      "step": 3905
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.5197563918873582,
      "learning_rate": 8.54626646002821e-06,
      "loss": 0.5243,
      "step": 3906
    },
    {
      "epoch": 0.27,
      "grad_norm": 4.792662311495654,
      "learning_rate": 8.545472578898276e-06,
      "loss": 0.5163,
      "step": 3907
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.9162427605919063,
      "learning_rate": 8.544678517953528e-06,
      "loss": 0.5263,
      "step": 3908
    },
    {
      "epoch": 0.27,
      "grad_norm": 8.009549121198845,
      "learning_rate": 8.543884277234245e-06,
      "loss": 0.4633,
      "step": 3909
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.141581675140968,
      "learning_rate": 8.543089856780704e-06,
      "loss": 0.5038,
      "step": 3910
    },
    {
      "epoch": 0.27,
      "grad_norm": 3.2949703747815864,
      "learning_rate": 8.542295256633198e-06,
      "loss": 0.5721,
      "step": 3911
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.0010473649464857,
      "learning_rate": 8.541500476832025e-06,
      "loss": 0.5079,
      "step": 3912
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.177774432013743,
      "learning_rate": 8.540705517417494e-06,
      "loss": 0.5187,
      "step": 3913
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.9754554289077668,
      "learning_rate": 8.539910378429921e-06,
      "loss": 0.5526,
      "step": 3914
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.975992633481006,
      "learning_rate": 8.539115059909634e-06,
      "loss": 0.5353,
      "step": 3915
    },
    {
      "epoch": 0.27,
      "grad_norm": 4.5966658553064565,
      "learning_rate": 8.53831956189697e-06,
      "loss": 0.5492,
      "step": 3916
    },
    {
      "epoch": 0.27,
      "grad_norm": 3.1642766812236887,
      "learning_rate": 8.537523884432275e-06,
      "loss": 0.5034,
      "step": 3917
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.5938930009499526,
      "learning_rate": 8.5367280275559e-06,
      "loss": 0.5184,
      "step": 3918
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.2014244472697135,
      "learning_rate": 8.53593199130821e-06,
      "loss": 0.4923,
      "step": 3919
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.1934637776169703,
      "learning_rate": 8.535135775729578e-06,
      "loss": 0.5152,
      "step": 3920
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.7920887801680898,
      "learning_rate": 8.534339380860383e-06,
      "loss": 0.4937,
      "step": 3921
    },
    {
      "epoch": 0.27,
      "grad_norm": 3.05391662332352,
      "learning_rate": 8.53354280674102e-06,
      "loss": 0.5451,
      "step": 3922
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.6893158005871265,
      "learning_rate": 8.532746053411883e-06,
      "loss": 0.5122,
      "step": 3923
    },
    {
      "epoch": 0.27,
      "grad_norm": 3.012361101562062,
      "learning_rate": 8.531949120913385e-06,
      "loss": 0.5179,
      "step": 3924
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.2662987805592594,
      "learning_rate": 8.531152009285942e-06,
      "loss": 0.5268,
      "step": 3925
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.126261140678252,
      "learning_rate": 8.530354718569982e-06,
      "loss": 0.4794,
      "step": 3926
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.0064552778837,
      "learning_rate": 8.52955724880594e-06,
      "loss": 0.5149,
      "step": 3927
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.967522967652453,
      "learning_rate": 8.52875960003426e-06,
      "loss": 0.571,
      "step": 3928
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.5490314850213265,
      "learning_rate": 8.527961772295399e-06,
      "loss": 0.5136,
      "step": 3929
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.263267219588836,
      "learning_rate": 8.527163765629819e-06,
      "loss": 0.5131,
      "step": 3930
    },
    {
      "epoch": 0.27,
      "grad_norm": 3.3588859745666095,
      "learning_rate": 8.526365580077991e-06,
      "loss": 0.5156,
      "step": 3931
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.3862278323703583,
      "learning_rate": 8.525567215680397e-06,
      "loss": 0.5678,
      "step": 3932
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.7042199583419304,
      "learning_rate": 8.524768672477528e-06,
      "loss": 0.4579,
      "step": 3933
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.3558458968179696,
      "learning_rate": 8.523969950509886e-06,
      "loss": 0.4849,
      "step": 3934
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.7922686752981152,
      "learning_rate": 8.523171049817974e-06,
      "loss": 0.5386,
      "step": 3935
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.2972834093276355,
      "learning_rate": 8.522371970442314e-06,
      "loss": 0.538,
      "step": 3936
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.0140777328750055,
      "learning_rate": 8.52157271242343e-06,
      "loss": 0.5087,
      "step": 3937
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.128123540193942,
      "learning_rate": 8.52077327580186e-06,
      "loss": 0.5333,
      "step": 3938
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.362728806687714,
      "learning_rate": 8.519973660618149e-06,
      "loss": 0.4915,
      "step": 3939
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.6200349391478728,
      "learning_rate": 8.519173866912847e-06,
      "loss": 0.5201,
      "step": 3940
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.064491583778276,
      "learning_rate": 8.51837389472652e-06,
      "loss": 0.5422,
      "step": 3941
    },
    {
      "epoch": 0.27,
      "grad_norm": 4.103565689503897,
      "learning_rate": 8.51757374409974e-06,
      "loss": 0.5361,
      "step": 3942
    },
    {
      "epoch": 0.27,
      "grad_norm": 4.492800349262188,
      "learning_rate": 8.516773415073089e-06,
      "loss": 0.474,
      "step": 3943
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.9319231426781598,
      "learning_rate": 8.515972907687155e-06,
      "loss": 0.5192,
      "step": 3944
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.658646272423889,
      "learning_rate": 8.515172221982537e-06,
      "loss": 0.511,
      "step": 3945
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.8704526553717877,
      "learning_rate": 8.514371357999846e-06,
      "loss": 0.5367,
      "step": 3946
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.89640651973324,
      "learning_rate": 8.513570315779696e-06,
      "loss": 0.5396,
      "step": 3947
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.615202101796226,
      "learning_rate": 8.512769095362714e-06,
      "loss": 0.5228,
      "step": 3948
    },
    {
      "epoch": 0.27,
      "grad_norm": 13.835011859376063,
      "learning_rate": 8.511967696789535e-06,
      "loss": 0.5578,
      "step": 3949
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.715050427962862,
      "learning_rate": 8.511166120100806e-06,
      "loss": 0.5596,
      "step": 3950
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.32948111629035,
      "learning_rate": 8.510364365337178e-06,
      "loss": 0.5456,
      "step": 3951
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.8816515431921532,
      "learning_rate": 8.509562432539313e-06,
      "loss": 0.5073,
      "step": 3952
    },
    {
      "epoch": 0.27,
      "grad_norm": 4.627380188562036,
      "learning_rate": 8.508760321747884e-06,
      "loss": 0.5391,
      "step": 3953
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.019658849012253,
      "learning_rate": 8.507958033003569e-06,
      "loss": 0.5439,
      "step": 3954
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.946414341605947,
      "learning_rate": 8.507155566347063e-06,
      "loss": 0.5154,
      "step": 3955
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.425169333612445,
      "learning_rate": 8.506352921819057e-06,
      "loss": 0.4743,
      "step": 3956
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.3452847229199567,
      "learning_rate": 8.505550099460264e-06,
      "loss": 0.5397,
      "step": 3957
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.214689703951406,
      "learning_rate": 8.504747099311398e-06,
      "loss": 0.5159,
      "step": 3958
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.4409326206994484,
      "learning_rate": 8.503943921413186e-06,
      "loss": 0.4945,
      "step": 3959
    },
    {
      "epoch": 0.28,
      "grad_norm": 3.901201898021694,
      "learning_rate": 8.50314056580636e-06,
      "loss": 0.5134,
      "step": 3960
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.8856308671437025,
      "learning_rate": 8.502337032531667e-06,
      "loss": 0.506,
      "step": 3961
    },
    {
      "epoch": 0.28,
      "grad_norm": 3.811407991398703,
      "learning_rate": 8.501533321629859e-06,
      "loss": 0.5501,
      "step": 3962
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.27104039682797,
      "learning_rate": 8.500729433141694e-06,
      "loss": 0.5692,
      "step": 3963
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.9319149264647877,
      "learning_rate": 8.499925367107947e-06,
      "loss": 0.5246,
      "step": 3964
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.658804321373391,
      "learning_rate": 8.499121123569395e-06,
      "loss": 0.5203,
      "step": 3965
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.6347300003939185,
      "learning_rate": 8.498316702566828e-06,
      "loss": 0.5401,
      "step": 3966
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.7414853333047765,
      "learning_rate": 8.497512104141043e-06,
      "loss": 0.4775,
      "step": 3967
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.7278031795812341,
      "learning_rate": 8.496707328332846e-06,
      "loss": 0.47,
      "step": 3968
    },
    {
      "epoch": 0.28,
      "grad_norm": 6.555462055331702,
      "learning_rate": 8.495902375183054e-06,
      "loss": 0.5617,
      "step": 3969
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.0228025299139065,
      "learning_rate": 8.495097244732489e-06,
      "loss": 0.543,
      "step": 3970
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.7523506394083403,
      "learning_rate": 8.494291937021988e-06,
      "loss": 0.5421,
      "step": 3971
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.8899034653563367,
      "learning_rate": 8.493486452092391e-06,
      "loss": 0.5266,
      "step": 3972
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.2161014656406604,
      "learning_rate": 8.492680789984553e-06,
      "loss": 0.5052,
      "step": 3973
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.092425516827532,
      "learning_rate": 8.49187495073933e-06,
      "loss": 0.5304,
      "step": 3974
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.950674472493286,
      "learning_rate": 8.491068934397596e-06,
      "loss": 0.5403,
      "step": 3975
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.43267763341215,
      "learning_rate": 8.490262741000223e-06,
      "loss": 0.5047,
      "step": 3976
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.0992183860562927,
      "learning_rate": 8.489456370588106e-06,
      "loss": 0.4995,
      "step": 3977
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.4911475479208787,
      "learning_rate": 8.488649823202137e-06,
      "loss": 0.5369,
      "step": 3978
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.7295581389482907,
      "learning_rate": 8.487843098883222e-06,
      "loss": 0.4396,
      "step": 3979
    },
    {
      "epoch": 0.28,
      "grad_norm": 7.53727930498743,
      "learning_rate": 8.487036197672277e-06,
      "loss": 0.5215,
      "step": 3980
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6488378053161912,
      "learning_rate": 8.486229119610225e-06,
      "loss": 0.4377,
      "step": 3981
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.6516584146551154,
      "learning_rate": 8.485421864737997e-06,
      "loss": 0.529,
      "step": 3982
    },
    {
      "epoch": 0.28,
      "grad_norm": 3.8991905215637,
      "learning_rate": 8.484614433096535e-06,
      "loss": 0.5355,
      "step": 3983
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.3692965496950817,
      "learning_rate": 8.483806824726788e-06,
      "loss": 0.5844,
      "step": 3984
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.9723291026270124,
      "learning_rate": 8.48299903966972e-06,
      "loss": 0.5447,
      "step": 3985
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.980279476972843,
      "learning_rate": 8.482191077966293e-06,
      "loss": 0.502,
      "step": 3986
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.80666992162666,
      "learning_rate": 8.48138293965749e-06,
      "loss": 0.4701,
      "step": 3987
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.7390032165472182,
      "learning_rate": 8.480574624784292e-06,
      "loss": 0.5666,
      "step": 3988
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.2012364748456235,
      "learning_rate": 8.479766133387698e-06,
      "loss": 0.4984,
      "step": 3989
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.6392681544488936,
      "learning_rate": 8.478957465508708e-06,
      "loss": 0.5187,
      "step": 3990
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.7101899947041405,
      "learning_rate": 8.47814862118834e-06,
      "loss": 0.4559,
      "step": 3991
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.0965833913336347,
      "learning_rate": 8.477339600467612e-06,
      "loss": 0.5218,
      "step": 3992
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.79666791675014,
      "learning_rate": 8.476530403387557e-06,
      "loss": 0.4968,
      "step": 3993
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.1886169067858012,
      "learning_rate": 8.475721029989212e-06,
      "loss": 0.5334,
      "step": 3994
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.4675989694148877,
      "learning_rate": 8.47491148031363e-06,
      "loss": 0.5388,
      "step": 3995
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.760925854647543,
      "learning_rate": 8.474101754401866e-06,
      "loss": 0.4587,
      "step": 3996
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.3194394609269806,
      "learning_rate": 8.473291852294986e-06,
      "loss": 0.5338,
      "step": 3997
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.6029132487420035,
      "learning_rate": 8.47248177403407e-06,
      "loss": 0.5066,
      "step": 3998
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.202560426595829,
      "learning_rate": 8.471671519660196e-06,
      "loss": 0.5119,
      "step": 3999
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.7128997388005063,
      "learning_rate": 8.470861089214464e-06,
      "loss": 0.5367,
      "step": 4000
    },
    {
      "epoch": 0.28,
      "grad_norm": 4.592939032541322,
      "learning_rate": 8.47005048273797e-06,
      "loss": 0.5375,
      "step": 4001
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.3977189737705045,
      "learning_rate": 8.46923970027183e-06,
      "loss": 0.5141,
      "step": 4002
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.975764545193673,
      "learning_rate": 8.468428741857164e-06,
      "loss": 0.5606,
      "step": 4003
    },
    {
      "epoch": 0.28,
      "grad_norm": 3.238374686859336,
      "learning_rate": 8.467617607535096e-06,
      "loss": 0.5456,
      "step": 4004
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.01549090457518,
      "learning_rate": 8.466806297346772e-06,
      "loss": 0.5521,
      "step": 4005
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.934493667216449,
      "learning_rate": 8.465994811333334e-06,
      "loss": 0.5396,
      "step": 4006
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.9806302590992433,
      "learning_rate": 8.465183149535939e-06,
      "loss": 0.4761,
      "step": 4007
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.6171484592058287,
      "learning_rate": 8.464371311995752e-06,
      "loss": 0.5533,
      "step": 4008
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.400425499376261,
      "learning_rate": 8.463559298753946e-06,
      "loss": 0.5026,
      "step": 4009
    },
    {
      "epoch": 0.28,
      "grad_norm": 3.4614404440483044,
      "learning_rate": 8.462747109851703e-06,
      "loss": 0.5332,
      "step": 4010
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.8856457143233136,
      "learning_rate": 8.461934745330219e-06,
      "loss": 0.4881,
      "step": 4011
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.8477960313235178,
      "learning_rate": 8.461122205230689e-06,
      "loss": 0.5231,
      "step": 4012
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.41622346917578,
      "learning_rate": 8.460309489594324e-06,
      "loss": 0.5509,
      "step": 4013
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.24851458269517,
      "learning_rate": 8.459496598462345e-06,
      "loss": 0.4959,
      "step": 4014
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.152533978842766,
      "learning_rate": 8.458683531875975e-06,
      "loss": 0.5221,
      "step": 4015
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.5223879246103857,
      "learning_rate": 8.457870289876454e-06,
      "loss": 0.5081,
      "step": 4016
    },
    {
      "epoch": 0.28,
      "grad_norm": 4.049176887944281,
      "learning_rate": 8.457056872505024e-06,
      "loss": 0.5038,
      "step": 4017
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.970909827951694,
      "learning_rate": 8.456243279802941e-06,
      "loss": 0.5025,
      "step": 4018
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.9215361412142609,
      "learning_rate": 8.455429511811466e-06,
      "loss": 0.4734,
      "step": 4019
    },
    {
      "epoch": 0.28,
      "grad_norm": 4.020482025679888,
      "learning_rate": 8.454615568571872e-06,
      "loss": 0.5296,
      "step": 4020
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.6740130887629814,
      "learning_rate": 8.453801450125439e-06,
      "loss": 0.509,
      "step": 4021
    },
    {
      "epoch": 0.28,
      "grad_norm": 3.0827616708625247,
      "learning_rate": 8.452987156513457e-06,
      "loss": 0.5066,
      "step": 4022
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.7236539369300523,
      "learning_rate": 8.452172687777223e-06,
      "loss": 0.4573,
      "step": 4023
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.134403977570078,
      "learning_rate": 8.451358043958046e-06,
      "loss": 0.5157,
      "step": 4024
    },
    {
      "epoch": 0.28,
      "grad_norm": 3.1340322082277035,
      "learning_rate": 8.45054322509724e-06,
      "loss": 0.5241,
      "step": 4025
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.9547538317684348,
      "learning_rate": 8.449728231236132e-06,
      "loss": 0.5423,
      "step": 4026
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.488293330615144,
      "learning_rate": 8.448913062416054e-06,
      "loss": 0.5118,
      "step": 4027
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.285482238572763,
      "learning_rate": 8.44809771867835e-06,
      "loss": 0.5269,
      "step": 4028
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.41315541869908,
      "learning_rate": 8.447282200064371e-06,
      "loss": 0.5158,
      "step": 4029
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.237541837833695,
      "learning_rate": 8.446466506615478e-06,
      "loss": 0.5456,
      "step": 4030
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.193455397659149,
      "learning_rate": 8.445650638373038e-06,
      "loss": 0.5213,
      "step": 4031
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.4240813671526573,
      "learning_rate": 8.444834595378434e-06,
      "loss": 0.5549,
      "step": 4032
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.5584987974119184,
      "learning_rate": 8.444018377673048e-06,
      "loss": 0.5566,
      "step": 4033
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.7275627939500775,
      "learning_rate": 8.443201985298279e-06,
      "loss": 0.4947,
      "step": 4034
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.257541312615433,
      "learning_rate": 8.442385418295532e-06,
      "loss": 0.5292,
      "step": 4035
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.8349122798905455,
      "learning_rate": 8.441568676706217e-06,
      "loss": 0.5215,
      "step": 4036
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.995976589895054,
      "learning_rate": 8.44075176057176e-06,
      "loss": 0.489,
      "step": 4037
    },
    {
      "epoch": 0.28,
      "grad_norm": 4.7711384933865855,
      "learning_rate": 8.439934669933591e-06,
      "loss": 0.521,
      "step": 4038
    },
    {
      "epoch": 0.28,
      "grad_norm": 4.1341501436678065,
      "learning_rate": 8.439117404833151e-06,
      "loss": 0.5531,
      "step": 4039
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.602437333466879,
      "learning_rate": 8.438299965311887e-06,
      "loss": 0.5039,
      "step": 4040
    },
    {
      "epoch": 0.28,
      "grad_norm": 8.3011003976083,
      "learning_rate": 8.437482351411258e-06,
      "loss": 0.4987,
      "step": 4041
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6957414520701312,
      "learning_rate": 8.436664563172733e-06,
      "loss": 0.4694,
      "step": 4042
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.1541145638513464,
      "learning_rate": 8.435846600637786e-06,
      "loss": 0.5023,
      "step": 4043
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.8671173254386555,
      "learning_rate": 8.435028463847898e-06,
      "loss": 0.4837,
      "step": 4044
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.061346856679508,
      "learning_rate": 8.434210152844566e-06,
      "loss": 0.5654,
      "step": 4045
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.127790880758026,
      "learning_rate": 8.433391667669292e-06,
      "loss": 0.5838,
      "step": 4046
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.4099969778519332,
      "learning_rate": 8.432573008363587e-06,
      "loss": 0.5282,
      "step": 4047
    },
    {
      "epoch": 0.28,
      "grad_norm": 3.0301703001491136,
      "learning_rate": 8.431754174968969e-06,
      "loss": 0.4812,
      "step": 4048
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.720854533794223,
      "learning_rate": 8.430935167526967e-06,
      "loss": 0.5155,
      "step": 4049
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.165314815617279,
      "learning_rate": 8.43011598607912e-06,
      "loss": 0.5369,
      "step": 4050
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.8530977547617935,
      "learning_rate": 8.429296630666971e-06,
      "loss": 0.5587,
      "step": 4051
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.642408998636408,
      "learning_rate": 8.428477101332079e-06,
      "loss": 0.555,
      "step": 4052
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.8859588166040502,
      "learning_rate": 8.427657398116005e-06,
      "loss": 0.5125,
      "step": 4053
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.9289466887969864,
      "learning_rate": 8.426837521060322e-06,
      "loss": 0.5279,
      "step": 4054
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.4896717712590095,
      "learning_rate": 8.426017470206612e-06,
      "loss": 0.4692,
      "step": 4055
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.144711274129273,
      "learning_rate": 8.425197245596467e-06,
      "loss": 0.511,
      "step": 4056
    },
    {
      "epoch": 0.28,
      "grad_norm": 6.792446108384517,
      "learning_rate": 8.424376847271483e-06,
      "loss": 0.5196,
      "step": 4057
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.654414883742684,
      "learning_rate": 8.42355627527327e-06,
      "loss": 0.5128,
      "step": 4058
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.3071610634538158,
      "learning_rate": 8.422735529643445e-06,
      "loss": 0.5285,
      "step": 4059
    },
    {
      "epoch": 0.28,
      "grad_norm": 3.1755708415841943,
      "learning_rate": 8.421914610423631e-06,
      "loss": 0.4721,
      "step": 4060
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.947698978298332,
      "learning_rate": 8.421093517655465e-06,
      "loss": 0.5486,
      "step": 4061
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.5957885783630434,
      "learning_rate": 8.42027225138059e-06,
      "loss": 0.5347,
      "step": 4062
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.610706277254822,
      "learning_rate": 8.419450811640654e-06,
      "loss": 0.5564,
      "step": 4063
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.4124203771616477,
      "learning_rate": 8.418629198477325e-06,
      "loss": 0.5233,
      "step": 4064
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.886693589443562,
      "learning_rate": 8.417807411932265e-06,
      "loss": 0.4991,
      "step": 4065
    },
    {
      "epoch": 0.28,
      "grad_norm": 3.7182771050089674,
      "learning_rate": 8.416985452047157e-06,
      "loss": 0.5441,
      "step": 4066
    },
    {
      "epoch": 0.28,
      "grad_norm": 3.172602098037414,
      "learning_rate": 8.416163318863687e-06,
      "loss": 0.5624,
      "step": 4067
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.8867333495004384,
      "learning_rate": 8.415341012423552e-06,
      "loss": 0.5168,
      "step": 4068
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.29634922453354,
      "learning_rate": 8.414518532768455e-06,
      "loss": 0.5694,
      "step": 4069
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.0708720671273166,
      "learning_rate": 8.41369587994011e-06,
      "loss": 0.518,
      "step": 4070
    },
    {
      "epoch": 0.28,
      "grad_norm": 4.9457559792100545,
      "learning_rate": 8.412873053980237e-06,
      "loss": 0.4978,
      "step": 4071
    },
    {
      "epoch": 0.28,
      "grad_norm": 4.2724252523790645,
      "learning_rate": 8.412050054930571e-06,
      "loss": 0.518,
      "step": 4072
    },
    {
      "epoch": 0.28,
      "grad_norm": 3.1059594184219117,
      "learning_rate": 8.41122688283285e-06,
      "loss": 0.5297,
      "step": 4073
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.077672965413576,
      "learning_rate": 8.410403537728824e-06,
      "loss": 0.5309,
      "step": 4074
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.079529945411876,
      "learning_rate": 8.409580019660246e-06,
      "loss": 0.5311,
      "step": 4075
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.8123579868337685,
      "learning_rate": 8.408756328668888e-06,
      "loss": 0.5674,
      "step": 4076
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.043218313627377,
      "learning_rate": 8.407932464796521e-06,
      "loss": 0.5254,
      "step": 4077
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.615990335855449,
      "learning_rate": 8.407108428084932e-06,
      "loss": 0.5469,
      "step": 4078
    },
    {
      "epoch": 0.28,
      "grad_norm": 3.2742748918810776,
      "learning_rate": 8.40628421857591e-06,
      "loss": 0.5559,
      "step": 4079
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.188453832407426,
      "learning_rate": 8.405459836311256e-06,
      "loss": 0.5026,
      "step": 4080
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.259746458538575,
      "learning_rate": 8.404635281332783e-06,
      "loss": 0.5173,
      "step": 4081
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.8423894738582398,
      "learning_rate": 8.403810553682307e-06,
      "loss": 0.5038,
      "step": 4082
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.4026103567578927,
      "learning_rate": 8.402985653401659e-06,
      "loss": 0.5569,
      "step": 4083
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.4997861147826588,
      "learning_rate": 8.40216058053267e-06,
      "loss": 0.5462,
      "step": 4084
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.759003498541017,
      "learning_rate": 8.40133533511719e-06,
      "loss": 0.514,
      "step": 4085
    },
    {
      "epoch": 0.28,
      "grad_norm": 3.528801209188115,
      "learning_rate": 8.40050991719707e-06,
      "loss": 0.4971,
      "step": 4086
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.3658571462269578,
      "learning_rate": 8.399684326814174e-06,
      "loss": 0.5545,
      "step": 4087
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.135510204010901,
      "learning_rate": 8.398858564010373e-06,
      "loss": 0.5064,
      "step": 4088
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.856522823134108,
      "learning_rate": 8.398032628827547e-06,
      "loss": 0.6053,
      "step": 4089
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.297872571863127,
      "learning_rate": 8.397206521307584e-06,
      "loss": 0.5333,
      "step": 4090
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.7214680111833767,
      "learning_rate": 8.396380241492382e-06,
      "loss": 0.5104,
      "step": 4091
    },
    {
      "epoch": 0.28,
      "grad_norm": 3.3243659612122793,
      "learning_rate": 8.395553789423844e-06,
      "loss": 0.5483,
      "step": 4092
    },
    {
      "epoch": 0.28,
      "grad_norm": 3.215812753898239,
      "learning_rate": 8.39472716514389e-06,
      "loss": 0.5155,
      "step": 4093
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.0018589853238145,
      "learning_rate": 8.393900368694442e-06,
      "loss": 0.5273,
      "step": 4094
    },
    {
      "epoch": 0.28,
      "grad_norm": 4.5348768126082515,
      "learning_rate": 8.393073400117433e-06,
      "loss": 0.5432,
      "step": 4095
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.186272722426418,
      "learning_rate": 8.392246259454801e-06,
      "loss": 0.5056,
      "step": 4096
    },
    {
      "epoch": 0.28,
      "grad_norm": 3.4980353202775287,
      "learning_rate": 8.3914189467485e-06,
      "loss": 0.5147,
      "step": 4097
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.9389938064950036,
      "learning_rate": 8.390591462040485e-06,
      "loss": 0.4972,
      "step": 4098
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.5877989659716762,
      "learning_rate": 8.389763805372725e-06,
      "loss": 0.5041,
      "step": 4099
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.2939237334696316,
      "learning_rate": 8.388935976787196e-06,
      "loss": 0.5373,
      "step": 4100
    },
    {
      "epoch": 0.29,
      "grad_norm": 3.372836047112025,
      "learning_rate": 8.388107976325885e-06,
      "loss": 0.5844,
      "step": 4101
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.1578761398759334,
      "learning_rate": 8.387279804030781e-06,
      "loss": 0.5433,
      "step": 4102
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.356034461367926,
      "learning_rate": 8.386451459943889e-06,
      "loss": 0.5252,
      "step": 4103
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.4356776656904366,
      "learning_rate": 8.385622944107221e-06,
      "loss": 0.5387,
      "step": 4104
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.020937064606239,
      "learning_rate": 8.384794256562793e-06,
      "loss": 0.4959,
      "step": 4105
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.1022107823934784,
      "learning_rate": 8.383965397352636e-06,
      "loss": 0.5372,
      "step": 4106
    },
    {
      "epoch": 0.29,
      "grad_norm": 4.062724196026394,
      "learning_rate": 8.383136366518788e-06,
      "loss": 0.4897,
      "step": 4107
    },
    {
      "epoch": 0.29,
      "grad_norm": 3.0517827158237387,
      "learning_rate": 8.382307164103291e-06,
      "loss": 0.5102,
      "step": 4108
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.3110082275553294,
      "learning_rate": 8.381477790148203e-06,
      "loss": 0.5171,
      "step": 4109
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.3192524886057306,
      "learning_rate": 8.380648244695584e-06,
      "loss": 0.5201,
      "step": 4110
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.179766364512027,
      "learning_rate": 8.379818527787508e-06,
      "loss": 0.5551,
      "step": 4111
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.449534074056117,
      "learning_rate": 8.378988639466058e-06,
      "loss": 0.5705,
      "step": 4112
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.2762201808789406,
      "learning_rate": 8.378158579773318e-06,
      "loss": 0.5334,
      "step": 4113
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.7784640889058614,
      "learning_rate": 8.377328348751388e-06,
      "loss": 0.4628,
      "step": 4114
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.4883205424409938,
      "learning_rate": 8.376497946442374e-06,
      "loss": 0.5263,
      "step": 4115
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.902650682811987,
      "learning_rate": 8.375667372888394e-06,
      "loss": 0.5492,
      "step": 4116
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.5791268241841157,
      "learning_rate": 8.374836628131571e-06,
      "loss": 0.5353,
      "step": 4117
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.4150412328116895,
      "learning_rate": 8.374005712214035e-06,
      "loss": 0.4737,
      "step": 4118
    },
    {
      "epoch": 0.29,
      "grad_norm": 3.0971596903158605,
      "learning_rate": 8.373174625177929e-06,
      "loss": 0.5353,
      "step": 4119
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.6543354844809977,
      "learning_rate": 8.372343367065404e-06,
      "loss": 0.5242,
      "step": 4120
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.8681554380339396,
      "learning_rate": 8.371511937918616e-06,
      "loss": 0.5469,
      "step": 4121
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.339643299410237,
      "learning_rate": 8.370680337779737e-06,
      "loss": 0.5052,
      "step": 4122
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.027840684702795,
      "learning_rate": 8.369848566690941e-06,
      "loss": 0.5452,
      "step": 4123
    },
    {
      "epoch": 0.29,
      "grad_norm": 4.15167586647881,
      "learning_rate": 8.36901662469441e-06,
      "loss": 0.4973,
      "step": 4124
    },
    {
      "epoch": 0.29,
      "grad_norm": 3.4837308297309133,
      "learning_rate": 8.36818451183234e-06,
      "loss": 0.5699,
      "step": 4125
    },
    {
      "epoch": 0.29,
      "grad_norm": 5.089464795301506,
      "learning_rate": 8.367352228146931e-06,
      "loss": 0.5904,
      "step": 4126
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.3239671180434764,
      "learning_rate": 8.366519773680398e-06,
      "loss": 0.5484,
      "step": 4127
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.759358682090633,
      "learning_rate": 8.365687148474955e-06,
      "loss": 0.5675,
      "step": 4128
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.220547045109724,
      "learning_rate": 8.364854352572834e-06,
      "loss": 0.4927,
      "step": 4129
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.4275337818055216,
      "learning_rate": 8.364021386016269e-06,
      "loss": 0.4904,
      "step": 4130
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.7424844495988603,
      "learning_rate": 8.363188248847508e-06,
      "loss": 0.4569,
      "step": 4131
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.6962316586524935,
      "learning_rate": 8.362354941108803e-06,
      "loss": 0.4837,
      "step": 4132
    },
    {
      "epoch": 0.29,
      "grad_norm": 3.6457699826359318,
      "learning_rate": 8.361521462842416e-06,
      "loss": 0.5192,
      "step": 4133
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.5844863123951924,
      "learning_rate": 8.360687814090622e-06,
      "loss": 0.5251,
      "step": 4134
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.8888215574007954,
      "learning_rate": 8.359853994895698e-06,
      "loss": 0.5903,
      "step": 4135
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.6695857142209496,
      "learning_rate": 8.359020005299931e-06,
      "loss": 0.5284,
      "step": 4136
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.9229064922948222,
      "learning_rate": 8.358185845345623e-06,
      "loss": 0.4958,
      "step": 4137
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.1881135779231258,
      "learning_rate": 8.357351515075077e-06,
      "loss": 0.5131,
      "step": 4138
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.980586879367603,
      "learning_rate": 8.356517014530608e-06,
      "loss": 0.5355,
      "step": 4139
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.867930156555114,
      "learning_rate": 8.355682343754536e-06,
      "loss": 0.5253,
      "step": 4140
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.53964749177765,
      "learning_rate": 8.354847502789198e-06,
      "loss": 0.5077,
      "step": 4141
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.278128811770959,
      "learning_rate": 8.354012491676933e-06,
      "loss": 0.503,
      "step": 4142
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.7328997812763213,
      "learning_rate": 8.353177310460088e-06,
      "loss": 0.476,
      "step": 4143
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.7550742858907832,
      "learning_rate": 8.352341959181021e-06,
      "loss": 0.454,
      "step": 4144
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.4718956967730117,
      "learning_rate": 8.3515064378821e-06,
      "loss": 0.4836,
      "step": 4145
    },
    {
      "epoch": 0.29,
      "grad_norm": 3.0851444910646917,
      "learning_rate": 8.350670746605698e-06,
      "loss": 0.5493,
      "step": 4146
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.660303801721061,
      "learning_rate": 8.3498348853942e-06,
      "loss": 0.4469,
      "step": 4147
    },
    {
      "epoch": 0.29,
      "grad_norm": 3.7805705075153098,
      "learning_rate": 8.348998854289997e-06,
      "loss": 0.5307,
      "step": 4148
    },
    {
      "epoch": 0.29,
      "grad_norm": 3.737765244680508,
      "learning_rate": 8.348162653335493e-06,
      "loss": 0.5073,
      "step": 4149
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.4168272462456084,
      "learning_rate": 8.347326282573093e-06,
      "loss": 0.4958,
      "step": 4150
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.7693221440823863,
      "learning_rate": 8.346489742045216e-06,
      "loss": 0.5756,
      "step": 4151
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.5063121323914173,
      "learning_rate": 8.345653031794292e-06,
      "loss": 0.5254,
      "step": 4152
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.559720822930078,
      "learning_rate": 8.34481615186275e-06,
      "loss": 0.5578,
      "step": 4153
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.20641393568291,
      "learning_rate": 8.343979102293043e-06,
      "loss": 0.5094,
      "step": 4154
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.290534525212069,
      "learning_rate": 8.343141883127615e-06,
      "loss": 0.4633,
      "step": 4155
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.3125911521030256,
      "learning_rate": 8.342304494408929e-06,
      "loss": 0.5461,
      "step": 4156
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.9036817496355802,
      "learning_rate": 8.341466936179457e-06,
      "loss": 0.534,
      "step": 4157
    },
    {
      "epoch": 0.29,
      "grad_norm": 3.4219466537982997,
      "learning_rate": 8.340629208481675e-06,
      "loss": 0.542,
      "step": 4158
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.8134598306287075,
      "learning_rate": 8.33979131135807e-06,
      "loss": 0.5441,
      "step": 4159
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.645277593698078,
      "learning_rate": 8.338953244851137e-06,
      "loss": 0.5786,
      "step": 4160
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.249048184122533,
      "learning_rate": 8.338115009003384e-06,
      "loss": 0.5009,
      "step": 4161
    },
    {
      "epoch": 0.29,
      "grad_norm": 3.168687054786112,
      "learning_rate": 8.33727660385732e-06,
      "loss": 0.4862,
      "step": 4162
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.8882037424095137,
      "learning_rate": 8.336438029455467e-06,
      "loss": 0.4971,
      "step": 4163
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.548811521255299,
      "learning_rate": 8.335599285840353e-06,
      "loss": 0.5492,
      "step": 4164
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.8814831493169673,
      "learning_rate": 8.334760373054517e-06,
      "loss": 0.5204,
      "step": 4165
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.5817725909712252,
      "learning_rate": 8.33392129114051e-06,
      "loss": 0.5052,
      "step": 4166
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.209081473058045,
      "learning_rate": 8.333082040140884e-06,
      "loss": 0.4884,
      "step": 4167
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.086736886913224,
      "learning_rate": 8.3322426200982e-06,
      "loss": 0.5219,
      "step": 4168
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.148844508327227,
      "learning_rate": 8.331403031055036e-06,
      "loss": 0.5317,
      "step": 4169
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.3260881141893246,
      "learning_rate": 8.330563273053973e-06,
      "loss": 0.4941,
      "step": 4170
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.0711642690733765,
      "learning_rate": 8.329723346137597e-06,
      "loss": 0.4965,
      "step": 4171
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.1365470249673626,
      "learning_rate": 8.32888325034851e-06,
      "loss": 0.5308,
      "step": 4172
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.3647209036132346,
      "learning_rate": 8.328042985729316e-06,
      "loss": 0.5359,
      "step": 4173
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.0035593214563736,
      "learning_rate": 8.327202552322634e-06,
      "loss": 0.4838,
      "step": 4174
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.111121273574749,
      "learning_rate": 8.326361950171083e-06,
      "loss": 0.5214,
      "step": 4175
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.5476938779919602,
      "learning_rate": 8.325521179317298e-06,
      "loss": 0.579,
      "step": 4176
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.3093910471398993,
      "learning_rate": 8.324680239803922e-06,
      "loss": 0.468,
      "step": 4177
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.9766703960361998,
      "learning_rate": 8.323839131673603e-06,
      "loss": 0.5085,
      "step": 4178
    },
    {
      "epoch": 0.29,
      "grad_norm": 4.557364291890512,
      "learning_rate": 8.322997854969e-06,
      "loss": 0.5282,
      "step": 4179
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.6707794710293349,
      "learning_rate": 8.32215640973278e-06,
      "loss": 0.4744,
      "step": 4180
    },
    {
      "epoch": 0.29,
      "grad_norm": 3.4614039179640352,
      "learning_rate": 8.321314796007618e-06,
      "loss": 0.5343,
      "step": 4181
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.699427203234691,
      "learning_rate": 8.320473013836197e-06,
      "loss": 0.5172,
      "step": 4182
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.644331125732769,
      "learning_rate": 8.319631063261209e-06,
      "loss": 0.5415,
      "step": 4183
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.4777808895331064,
      "learning_rate": 8.318788944325357e-06,
      "loss": 0.4998,
      "step": 4184
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.300436813750277,
      "learning_rate": 8.31794665707135e-06,
      "loss": 0.542,
      "step": 4185
    },
    {
      "epoch": 0.29,
      "grad_norm": 3.026818473190027,
      "learning_rate": 8.317104201541904e-06,
      "loss": 0.5693,
      "step": 4186
    },
    {
      "epoch": 0.29,
      "grad_norm": 3.1443495415826335,
      "learning_rate": 8.316261577779749e-06,
      "loss": 0.4746,
      "step": 4187
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.4172827062141287,
      "learning_rate": 8.315418785827618e-06,
      "loss": 0.4848,
      "step": 4188
    },
    {
      "epoch": 0.29,
      "grad_norm": 10.083029065500831,
      "learning_rate": 8.314575825728254e-06,
      "loss": 0.5189,
      "step": 4189
    },
    {
      "epoch": 0.29,
      "grad_norm": 3.370103974677032,
      "learning_rate": 8.313732697524413e-06,
      "loss": 0.5454,
      "step": 4190
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.3399698641566635,
      "learning_rate": 8.31288940125885e-06,
      "loss": 0.5179,
      "step": 4191
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.030467731157077,
      "learning_rate": 8.312045936974339e-06,
      "loss": 0.5199,
      "step": 4192
    },
    {
      "epoch": 0.29,
      "grad_norm": 3.7271125643871112,
      "learning_rate": 8.311202304713655e-06,
      "loss": 0.5349,
      "step": 4193
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.921537216795132,
      "learning_rate": 8.310358504519587e-06,
      "loss": 0.5342,
      "step": 4194
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.4462504787176185,
      "learning_rate": 8.309514536434926e-06,
      "loss": 0.4939,
      "step": 4195
    },
    {
      "epoch": 0.29,
      "grad_norm": 3.7865741058487226,
      "learning_rate": 8.308670400502479e-06,
      "loss": 0.5497,
      "step": 4196
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.424101970061872,
      "learning_rate": 8.307826096765054e-06,
      "loss": 0.5071,
      "step": 4197
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.072712133646513,
      "learning_rate": 8.306981625265476e-06,
      "loss": 0.56,
      "step": 4198
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.235046927954524,
      "learning_rate": 8.306136986046568e-06,
      "loss": 0.5601,
      "step": 4199
    },
    {
      "epoch": 0.29,
      "grad_norm": 3.401967920022823,
      "learning_rate": 8.305292179151175e-06,
      "loss": 0.5263,
      "step": 4200
    },
    {
      "epoch": 0.29,
      "grad_norm": 3.0172951655751725,
      "learning_rate": 8.304447204622135e-06,
      "loss": 0.5126,
      "step": 4201
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.712513403861314,
      "learning_rate": 8.303602062502307e-06,
      "loss": 0.5541,
      "step": 4202
    },
    {
      "epoch": 0.29,
      "grad_norm": 3.691074291279032,
      "learning_rate": 8.302756752834553e-06,
      "loss": 0.4993,
      "step": 4203
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.6121638455888623,
      "learning_rate": 8.301911275661744e-06,
      "loss": 0.4982,
      "step": 4204
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.7740501730237663,
      "learning_rate": 8.301065631026759e-06,
      "loss": 0.5197,
      "step": 4205
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.4938667514089774,
      "learning_rate": 8.30021981897249e-06,
      "loss": 0.4998,
      "step": 4206
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.7979724992253714,
      "learning_rate": 8.299373839541829e-06,
      "loss": 0.4972,
      "step": 4207
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.340640743311268,
      "learning_rate": 8.298527692777682e-06,
      "loss": 0.5063,
      "step": 4208
    },
    {
      "epoch": 0.29,
      "grad_norm": 5.592836350433659,
      "learning_rate": 8.297681378722967e-06,
      "loss": 0.5372,
      "step": 4209
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.921455739076113,
      "learning_rate": 8.296834897420602e-06,
      "loss": 0.5771,
      "step": 4210
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.635308575166915,
      "learning_rate": 8.29598824891352e-06,
      "loss": 0.5161,
      "step": 4211
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.2099473099741953,
      "learning_rate": 8.29514143324466e-06,
      "loss": 0.5167,
      "step": 4212
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.314839770741851,
      "learning_rate": 8.29429445045697e-06,
      "loss": 0.5509,
      "step": 4213
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.665163823318094,
      "learning_rate": 8.293447300593402e-06,
      "loss": 0.5204,
      "step": 4214
    },
    {
      "epoch": 0.29,
      "grad_norm": 3.6639341177303177,
      "learning_rate": 8.292599983696927e-06,
      "loss": 0.4753,
      "step": 4215
    },
    {
      "epoch": 0.29,
      "grad_norm": 3.3836100527141926,
      "learning_rate": 8.291752499810515e-06,
      "loss": 0.6018,
      "step": 4216
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.3888972583133126,
      "learning_rate": 8.290904848977149e-06,
      "loss": 0.5657,
      "step": 4217
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.976039366226251,
      "learning_rate": 8.290057031239815e-06,
      "loss": 0.4933,
      "step": 4218
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.2259945378788064,
      "learning_rate": 8.289209046641518e-06,
      "loss": 0.5448,
      "step": 4219
    },
    {
      "epoch": 0.29,
      "grad_norm": 4.087682341580172,
      "learning_rate": 8.288360895225259e-06,
      "loss": 0.5524,
      "step": 4220
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.253870001134351,
      "learning_rate": 8.287512577034058e-06,
      "loss": 0.4915,
      "step": 4221
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.980298846875799,
      "learning_rate": 8.286664092110935e-06,
      "loss": 0.5248,
      "step": 4222
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.613188119555488,
      "learning_rate": 8.285815440498926e-06,
      "loss": 0.5005,
      "step": 4223
    },
    {
      "epoch": 0.29,
      "grad_norm": 5.280473267931873,
      "learning_rate": 8.284966622241069e-06,
      "loss": 0.5098,
      "step": 4224
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.7621964208785941,
      "learning_rate": 8.284117637380415e-06,
      "loss": 0.4423,
      "step": 4225
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.416161703083722,
      "learning_rate": 8.28326848596002e-06,
      "loss": 0.4953,
      "step": 4226
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.1119969914434766,
      "learning_rate": 8.282419168022953e-06,
      "loss": 0.5245,
      "step": 4227
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.757899035160197,
      "learning_rate": 8.281569683612288e-06,
      "loss": 0.5658,
      "step": 4228
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.200606534934271,
      "learning_rate": 8.280720032771105e-06,
      "loss": 0.5302,
      "step": 4229
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.318547527319647,
      "learning_rate": 8.279870215542499e-06,
      "loss": 0.5056,
      "step": 4230
    },
    {
      "epoch": 0.29,
      "grad_norm": 10.65323857998497,
      "learning_rate": 8.27902023196957e-06,
      "loss": 0.49,
      "step": 4231
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.4882270949911565,
      "learning_rate": 8.278170082095422e-06,
      "loss": 0.5452,
      "step": 4232
    },
    {
      "epoch": 0.29,
      "grad_norm": 3.581047473274916,
      "learning_rate": 8.277319765963176e-06,
      "loss": 0.6051,
      "step": 4233
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.3116497916369014,
      "learning_rate": 8.276469283615958e-06,
      "loss": 0.5238,
      "step": 4234
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.1924109016498567,
      "learning_rate": 8.275618635096898e-06,
      "loss": 0.5324,
      "step": 4235
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.3102733945870746,
      "learning_rate": 8.27476782044914e-06,
      "loss": 0.5135,
      "step": 4236
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.743925176153246,
      "learning_rate": 8.273916839715835e-06,
      "loss": 0.5016,
      "step": 4237
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.4010439364852436,
      "learning_rate": 8.27306569294014e-06,
      "loss": 0.5353,
      "step": 4238
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.281836461251618,
      "learning_rate": 8.272214380165226e-06,
      "loss": 0.5146,
      "step": 4239
    },
    {
      "epoch": 0.29,
      "grad_norm": 3.2384791080294644,
      "learning_rate": 8.271362901434266e-06,
      "loss": 0.5037,
      "step": 4240
    },
    {
      "epoch": 0.29,
      "grad_norm": 7.186863194502782,
      "learning_rate": 8.270511256790445e-06,
      "loss": 0.515,
      "step": 4241
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.404268914210172,
      "learning_rate": 8.269659446276955e-06,
      "loss": 0.4538,
      "step": 4242
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.7423334112443448,
      "learning_rate": 8.268807469937e-06,
      "loss": 0.4399,
      "step": 4243
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.7711244375507547,
      "learning_rate": 8.267955327813783e-06,
      "loss": 0.5288,
      "step": 4244
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.7097660572094737,
      "learning_rate": 8.267103019950529e-06,
      "loss": 0.5042,
      "step": 4245
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.5192145695874757,
      "learning_rate": 8.26625054639046e-06,
      "loss": 0.4848,
      "step": 4246
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.170909619346426,
      "learning_rate": 8.26539790717681e-06,
      "loss": 0.5043,
      "step": 4247
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.8434975894476864,
      "learning_rate": 8.264545102352827e-06,
      "loss": 0.4957,
      "step": 4248
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.5334101674910414,
      "learning_rate": 8.263692131961758e-06,
      "loss": 0.5014,
      "step": 4249
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.203731343323635,
      "learning_rate": 8.262838996046865e-06,
      "loss": 0.5623,
      "step": 4250
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.850589000840901,
      "learning_rate": 8.261985694651416e-06,
      "loss": 0.5289,
      "step": 4251
    },
    {
      "epoch": 0.3,
      "grad_norm": 3.207038594745736,
      "learning_rate": 8.261132227818685e-06,
      "loss": 0.4907,
      "step": 4252
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.236987077513189,
      "learning_rate": 8.260278595591962e-06,
      "loss": 0.5306,
      "step": 4253
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.370612938752225,
      "learning_rate": 8.259424798014536e-06,
      "loss": 0.5084,
      "step": 4254
    },
    {
      "epoch": 0.3,
      "grad_norm": 55.31175066144977,
      "learning_rate": 8.25857083512971e-06,
      "loss": 0.5293,
      "step": 4255
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.1832749596313765,
      "learning_rate": 8.257716706980796e-06,
      "loss": 0.5098,
      "step": 4256
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.1298704867429237,
      "learning_rate": 8.256862413611113e-06,
      "loss": 0.4946,
      "step": 4257
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.192628722413569,
      "learning_rate": 8.256007955063983e-06,
      "loss": 0.5102,
      "step": 4258
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.383814548304035,
      "learning_rate": 8.255153331382747e-06,
      "loss": 0.5514,
      "step": 4259
    },
    {
      "epoch": 0.3,
      "grad_norm": 3.488327632417455,
      "learning_rate": 8.254298542610745e-06,
      "loss": 0.5068,
      "step": 4260
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.367378304443912,
      "learning_rate": 8.253443588791332e-06,
      "loss": 0.5372,
      "step": 4261
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.7330506442620779,
      "learning_rate": 8.252588469967866e-06,
      "loss": 0.4552,
      "step": 4262
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.8249676823489973,
      "learning_rate": 8.251733186183718e-06,
      "loss": 0.5213,
      "step": 4263
    },
    {
      "epoch": 0.3,
      "grad_norm": 3.7569729556865696,
      "learning_rate": 8.250877737482264e-06,
      "loss": 0.5263,
      "step": 4264
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.2169558702516485,
      "learning_rate": 8.250022123906887e-06,
      "loss": 0.4761,
      "step": 4265
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.0777328263755934,
      "learning_rate": 8.249166345500984e-06,
      "loss": 0.5101,
      "step": 4266
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.2610036608820843,
      "learning_rate": 8.24831040230796e-06,
      "loss": 0.5445,
      "step": 4267
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.485134314474418,
      "learning_rate": 8.247454294371221e-06,
      "loss": 0.4834,
      "step": 4268
    },
    {
      "epoch": 0.3,
      "grad_norm": 3.9196285773836,
      "learning_rate": 8.246598021734187e-06,
      "loss": 0.5231,
      "step": 4269
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6727262056873663,
      "learning_rate": 8.245741584440286e-06,
      "loss": 0.4598,
      "step": 4270
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.7950793533211176,
      "learning_rate": 8.244884982532954e-06,
      "loss": 0.5562,
      "step": 4271
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.9226582753425703,
      "learning_rate": 8.244028216055636e-06,
      "loss": 0.5178,
      "step": 4272
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.9255628822634185,
      "learning_rate": 8.24317128505178e-06,
      "loss": 0.5369,
      "step": 4273
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.78247918867183,
      "learning_rate": 8.242314189564851e-06,
      "loss": 0.5331,
      "step": 4274
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.6566901957386944,
      "learning_rate": 8.241456929638316e-06,
      "loss": 0.5395,
      "step": 4275
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.040339102819933,
      "learning_rate": 8.240599505315656e-06,
      "loss": 0.5543,
      "step": 4276
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.371560068489783,
      "learning_rate": 8.239741916640352e-06,
      "loss": 0.5411,
      "step": 4277
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.8405249250441025,
      "learning_rate": 8.238884163655901e-06,
      "loss": 0.4919,
      "step": 4278
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.8549504132405847,
      "learning_rate": 8.238026246405804e-06,
      "loss": 0.5099,
      "step": 4279
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.011295923502456,
      "learning_rate": 8.237168164933572e-06,
      "loss": 0.5532,
      "step": 4280
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.075963205792806,
      "learning_rate": 8.236309919282724e-06,
      "loss": 0.5686,
      "step": 4281
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.3323024571147863,
      "learning_rate": 8.23545150949679e-06,
      "loss": 0.5535,
      "step": 4282
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.734553511742279,
      "learning_rate": 8.2345929356193e-06,
      "loss": 0.5275,
      "step": 4283
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.374213128560485,
      "learning_rate": 8.233734197693805e-06,
      "loss": 0.4943,
      "step": 4284
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.6497792016441655,
      "learning_rate": 8.232875295763853e-06,
      "loss": 0.5219,
      "step": 4285
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.134396211746325,
      "learning_rate": 8.232016229873006e-06,
      "loss": 0.5526,
      "step": 4286
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.564828459897395,
      "learning_rate": 8.231157000064833e-06,
      "loss": 0.532,
      "step": 4287
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.1544518304033566,
      "learning_rate": 8.230297606382911e-06,
      "loss": 0.5384,
      "step": 4288
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.517893102804214,
      "learning_rate": 8.229438048870826e-06,
      "loss": 0.5518,
      "step": 4289
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.9621855090609497,
      "learning_rate": 8.228578327572172e-06,
      "loss": 0.5501,
      "step": 4290
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.2543691046211927,
      "learning_rate": 8.227718442530549e-06,
      "loss": 0.4859,
      "step": 4291
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.9802157205385256,
      "learning_rate": 8.226858393789572e-06,
      "loss": 0.5336,
      "step": 4292
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.7348090066861672,
      "learning_rate": 8.225998181392854e-06,
      "loss": 0.4664,
      "step": 4293
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.3734916101208956,
      "learning_rate": 8.225137805384029e-06,
      "loss": 0.5235,
      "step": 4294
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.262736374399556,
      "learning_rate": 8.224277265806729e-06,
      "loss": 0.5068,
      "step": 4295
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.9996194684562196,
      "learning_rate": 8.223416562704596e-06,
      "loss": 0.5411,
      "step": 4296
    },
    {
      "epoch": 0.3,
      "grad_norm": 3.9904173501648574,
      "learning_rate": 8.222555696121283e-06,
      "loss": 0.5126,
      "step": 4297
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.9168493591721592,
      "learning_rate": 8.221694666100455e-06,
      "loss": 0.5224,
      "step": 4298
    },
    {
      "epoch": 0.3,
      "grad_norm": 3.774077111174975,
      "learning_rate": 8.220833472685774e-06,
      "loss": 0.5451,
      "step": 4299
    },
    {
      "epoch": 0.3,
      "grad_norm": 3.1096047729881255,
      "learning_rate": 8.21997211592092e-06,
      "loss": 0.5432,
      "step": 4300
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.6683419293313415,
      "learning_rate": 8.21911059584958e-06,
      "loss": 0.5276,
      "step": 4301
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.709956734319518,
      "learning_rate": 8.218248912515443e-06,
      "loss": 0.5391,
      "step": 4302
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6992997611509558,
      "learning_rate": 8.217387065962214e-06,
      "loss": 0.4568,
      "step": 4303
    },
    {
      "epoch": 0.3,
      "grad_norm": 3.309350938290334,
      "learning_rate": 8.216525056233604e-06,
      "loss": 0.531,
      "step": 4304
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.1251688363888785,
      "learning_rate": 8.215662883373328e-06,
      "loss": 0.5281,
      "step": 4305
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.9168208790939882,
      "learning_rate": 8.214800547425115e-06,
      "loss": 0.509,
      "step": 4306
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6100064315675645,
      "learning_rate": 8.213938048432697e-06,
      "loss": 0.4547,
      "step": 4307
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.9040727476114228,
      "learning_rate": 8.213075386439821e-06,
      "loss": 0.5356,
      "step": 4308
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.029077415508731,
      "learning_rate": 8.212212561490236e-06,
      "loss": 0.464,
      "step": 4309
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6521504031113022,
      "learning_rate": 8.211349573627703e-06,
      "loss": 0.4385,
      "step": 4310
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6284331887478715,
      "learning_rate": 8.210486422895989e-06,
      "loss": 0.4489,
      "step": 4311
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.031296754187591,
      "learning_rate": 8.209623109338872e-06,
      "loss": 0.5487,
      "step": 4312
    },
    {
      "epoch": 0.3,
      "grad_norm": 4.218416038108262,
      "learning_rate": 8.208759633000132e-06,
      "loss": 0.5162,
      "step": 4313
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.0117479566102863,
      "learning_rate": 8.207895993923566e-06,
      "loss": 0.5214,
      "step": 4314
    },
    {
      "epoch": 0.3,
      "grad_norm": 7.985935149330244,
      "learning_rate": 8.207032192152974e-06,
      "loss": 0.5228,
      "step": 4315
    },
    {
      "epoch": 0.3,
      "grad_norm": 6.318672908660357,
      "learning_rate": 8.206168227732164e-06,
      "loss": 0.511,
      "step": 4316
    },
    {
      "epoch": 0.3,
      "grad_norm": 4.2401193988896555,
      "learning_rate": 8.205304100704953e-06,
      "loss": 0.4879,
      "step": 4317
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.7445044100406301,
      "learning_rate": 8.20443981111517e-06,
      "loss": 0.4532,
      "step": 4318
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.2910467334217186,
      "learning_rate": 8.203575359006645e-06,
      "loss": 0.4692,
      "step": 4319
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.287594457169831,
      "learning_rate": 8.202710744423223e-06,
      "loss": 0.5732,
      "step": 4320
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.6320370088895912,
      "learning_rate": 8.201845967408753e-06,
      "loss": 0.5131,
      "step": 4321
    },
    {
      "epoch": 0.3,
      "grad_norm": 8.778384597324782,
      "learning_rate": 8.200981028007095e-06,
      "loss": 0.5075,
      "step": 4322
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.281114364693002,
      "learning_rate": 8.200115926262116e-06,
      "loss": 0.559,
      "step": 4323
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.7895249960542436,
      "learning_rate": 8.199250662217688e-06,
      "loss": 0.5374,
      "step": 4324
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.6639767972005055,
      "learning_rate": 8.198385235917697e-06,
      "loss": 0.4831,
      "step": 4325
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.3184864301574324,
      "learning_rate": 8.197519647406036e-06,
      "loss": 0.5361,
      "step": 4326
    },
    {
      "epoch": 0.3,
      "grad_norm": 4.853507202014266,
      "learning_rate": 8.1966538967266e-06,
      "loss": 0.5786,
      "step": 4327
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.5621968741420598,
      "learning_rate": 8.195787983923302e-06,
      "loss": 0.5172,
      "step": 4328
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.1125806703256527,
      "learning_rate": 8.194921909040056e-06,
      "loss": 0.5364,
      "step": 4329
    },
    {
      "epoch": 0.3,
      "grad_norm": 3.100199892266563,
      "learning_rate": 8.194055672120788e-06,
      "loss": 0.5203,
      "step": 4330
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.4302441828434973,
      "learning_rate": 8.193189273209428e-06,
      "loss": 0.5121,
      "step": 4331
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.2012613468942503,
      "learning_rate": 8.192322712349917e-06,
      "loss": 0.5231,
      "step": 4332
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.4852946360492005,
      "learning_rate": 8.191455989586208e-06,
      "loss": 0.5075,
      "step": 4333
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.941247250076081,
      "learning_rate": 8.190589104962257e-06,
      "loss": 0.5083,
      "step": 4334
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.3472450000526583,
      "learning_rate": 8.189722058522025e-06,
      "loss": 0.5021,
      "step": 4335
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.699686316213107,
      "learning_rate": 8.18885485030949e-06,
      "loss": 0.5652,
      "step": 4336
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.9379238043131184,
      "learning_rate": 8.187987480368637e-06,
      "loss": 0.5036,
      "step": 4337
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.0834688897204527,
      "learning_rate": 8.18711994874345e-06,
      "loss": 0.5495,
      "step": 4338
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.19662091253378,
      "learning_rate": 8.186252255477929e-06,
      "loss": 0.5053,
      "step": 4339
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.6684033509143696,
      "learning_rate": 8.185384400616082e-06,
      "loss": 0.5603,
      "step": 4340
    },
    {
      "epoch": 0.3,
      "grad_norm": 8.968957716458721,
      "learning_rate": 8.184516384201924e-06,
      "loss": 0.5638,
      "step": 4341
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.1346381481267644,
      "learning_rate": 8.183648206279476e-06,
      "loss": 0.4713,
      "step": 4342
    },
    {
      "epoch": 0.3,
      "grad_norm": 3.4608681943097066,
      "learning_rate": 8.18277986689277e-06,
      "loss": 0.5059,
      "step": 4343
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.6204720710472342,
      "learning_rate": 8.181911366085846e-06,
      "loss": 0.5488,
      "step": 4344
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.9372163861994292,
      "learning_rate": 8.181042703902751e-06,
      "loss": 0.5151,
      "step": 4345
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.5571356710605637,
      "learning_rate": 8.180173880387542e-06,
      "loss": 0.5064,
      "step": 4346
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.7305434406776845,
      "learning_rate": 8.179304895584282e-06,
      "loss": 0.5513,
      "step": 4347
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.1066318801506263,
      "learning_rate": 8.17843574953704e-06,
      "loss": 0.5295,
      "step": 4348
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.6715190357654626,
      "learning_rate": 8.177566442289902e-06,
      "loss": 0.4941,
      "step": 4349
    },
    {
      "epoch": 0.3,
      "grad_norm": 4.334779730561428,
      "learning_rate": 8.176696973886951e-06,
      "loss": 0.5139,
      "step": 4350
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.900925421707714,
      "learning_rate": 8.17582734437229e-06,
      "loss": 0.5047,
      "step": 4351
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.267512338024383,
      "learning_rate": 8.174957553790015e-06,
      "loss": 0.557,
      "step": 4352
    },
    {
      "epoch": 0.3,
      "grad_norm": 8.272855005385756,
      "learning_rate": 8.174087602184247e-06,
      "loss": 0.4914,
      "step": 4353
    },
    {
      "epoch": 0.3,
      "grad_norm": 3.0285219867325766,
      "learning_rate": 8.173217489599102e-06,
      "loss": 0.4764,
      "step": 4354
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.2187207301058565,
      "learning_rate": 8.172347216078713e-06,
      "loss": 0.5128,
      "step": 4355
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.5530558921781514,
      "learning_rate": 8.171476781667215e-06,
      "loss": 0.5474,
      "step": 4356
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.1385994130864847,
      "learning_rate": 8.170606186408756e-06,
      "loss": 0.5358,
      "step": 4357
    },
    {
      "epoch": 0.3,
      "grad_norm": 6.230571281735116,
      "learning_rate": 8.169735430347486e-06,
      "loss": 0.5689,
      "step": 4358
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.0717709240336433,
      "learning_rate": 8.168864513527569e-06,
      "loss": 0.5106,
      "step": 4359
    },
    {
      "epoch": 0.3,
      "grad_norm": 4.34872886801,
      "learning_rate": 8.167993435993174e-06,
      "loss": 0.5206,
      "step": 4360
    },
    {
      "epoch": 0.3,
      "grad_norm": 3.0585511886918857,
      "learning_rate": 8.167122197788482e-06,
      "loss": 0.5295,
      "step": 4361
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.173152403816651,
      "learning_rate": 8.166250798957676e-06,
      "loss": 0.5431,
      "step": 4362
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.7486243702563715,
      "learning_rate": 8.165379239544953e-06,
      "loss": 0.4355,
      "step": 4363
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.6619096131292457,
      "learning_rate": 8.164507519594513e-06,
      "loss": 0.5174,
      "step": 4364
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.7504600771793601,
      "learning_rate": 8.16363563915057e-06,
      "loss": 0.5868,
      "step": 4365
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.905804567588821,
      "learning_rate": 8.162763598257342e-06,
      "loss": 0.5039,
      "step": 4366
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.042090202945499,
      "learning_rate": 8.161891396959056e-06,
      "loss": 0.5336,
      "step": 4367
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.2919885083987976,
      "learning_rate": 8.161019035299945e-06,
      "loss": 0.5096,
      "step": 4368
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.0864872920691884,
      "learning_rate": 8.160146513324256e-06,
      "loss": 0.5276,
      "step": 4369
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.761626124303962,
      "learning_rate": 8.159273831076235e-06,
      "loss": 0.5127,
      "step": 4370
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.7611576498482484,
      "learning_rate": 8.158400988600149e-06,
      "loss": 0.4906,
      "step": 4371
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.9059095355759403,
      "learning_rate": 8.157527985940259e-06,
      "loss": 0.5064,
      "step": 4372
    },
    {
      "epoch": 0.3,
      "grad_norm": 11.060607498245892,
      "learning_rate": 8.156654823140847e-06,
      "loss": 0.5003,
      "step": 4373
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.643369101202268,
      "learning_rate": 8.15578150024619e-06,
      "loss": 0.5663,
      "step": 4374
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.6275320632653867,
      "learning_rate": 8.154908017300586e-06,
      "loss": 0.5234,
      "step": 4375
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.4776915385195046,
      "learning_rate": 8.154034374348332e-06,
      "loss": 0.5909,
      "step": 4376
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.8460713405526676,
      "learning_rate": 8.153160571433738e-06,
      "loss": 0.4901,
      "step": 4377
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.5309890831101245,
      "learning_rate": 8.15228660860112e-06,
      "loss": 0.4955,
      "step": 4378
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.277545281012729,
      "learning_rate": 8.151412485894801e-06,
      "loss": 0.4892,
      "step": 4379
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.826376294816371,
      "learning_rate": 8.150538203359114e-06,
      "loss": 0.5239,
      "step": 4380
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.527723638131247,
      "learning_rate": 8.149663761038403e-06,
      "loss": 0.4835,
      "step": 4381
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.1006050713491518,
      "learning_rate": 8.148789158977012e-06,
      "loss": 0.5092,
      "step": 4382
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.965237301338892,
      "learning_rate": 8.147914397219303e-06,
      "loss": 0.483,
      "step": 4383
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.515770098363597,
      "learning_rate": 8.147039475809637e-06,
      "loss": 0.5134,
      "step": 4384
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.2527861017896713,
      "learning_rate": 8.14616439479239e-06,
      "loss": 0.4879,
      "step": 4385
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.0767023296813987,
      "learning_rate": 8.145289154211941e-06,
      "loss": 0.5415,
      "step": 4386
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.638121837478888,
      "learning_rate": 8.14441375411268e-06,
      "loss": 0.5706,
      "step": 4387
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.4311389801913452,
      "learning_rate": 8.143538194539007e-06,
      "loss": 0.5121,
      "step": 4388
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.4799989352215985,
      "learning_rate": 8.142662475535323e-06,
      "loss": 0.5136,
      "step": 4389
    },
    {
      "epoch": 0.31,
      "grad_norm": 3.2234652081437156,
      "learning_rate": 8.141786597146045e-06,
      "loss": 0.4931,
      "step": 4390
    },
    {
      "epoch": 0.31,
      "grad_norm": 3.022214137864965,
      "learning_rate": 8.140910559415594e-06,
      "loss": 0.5359,
      "step": 4391
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.6680776427558466,
      "learning_rate": 8.140034362388398e-06,
      "loss": 0.5331,
      "step": 4392
    },
    {
      "epoch": 0.31,
      "grad_norm": 4.614263989775939,
      "learning_rate": 8.139158006108897e-06,
      "loss": 0.5433,
      "step": 4393
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.089397617483196,
      "learning_rate": 8.138281490621535e-06,
      "loss": 0.4928,
      "step": 4394
    },
    {
      "epoch": 0.31,
      "grad_norm": 3.7571384276538287,
      "learning_rate": 8.137404815970769e-06,
      "loss": 0.4988,
      "step": 4395
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.0138451990034745,
      "learning_rate": 8.136527982201059e-06,
      "loss": 0.5398,
      "step": 4396
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.0659791533363863,
      "learning_rate": 8.135650989356875e-06,
      "loss": 0.5161,
      "step": 4397
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.254092700431278,
      "learning_rate": 8.134773837482695e-06,
      "loss": 0.4972,
      "step": 4398
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.172041177777773,
      "learning_rate": 8.133896526623007e-06,
      "loss": 0.5376,
      "step": 4399
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.274168488225893,
      "learning_rate": 8.133019056822303e-06,
      "loss": 0.5255,
      "step": 4400
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.2488494508395274,
      "learning_rate": 8.132141428125087e-06,
      "loss": 0.5577,
      "step": 4401
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.762281801829716,
      "learning_rate": 8.131263640575871e-06,
      "loss": 0.5205,
      "step": 4402
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.0065723905383965,
      "learning_rate": 8.130385694219169e-06,
      "loss": 0.5249,
      "step": 4403
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.3535785912040463,
      "learning_rate": 8.129507589099512e-06,
      "loss": 0.4967,
      "step": 4404
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.7539246191436841,
      "learning_rate": 8.128629325261432e-06,
      "loss": 0.4489,
      "step": 4405
    },
    {
      "epoch": 0.31,
      "grad_norm": 4.263460152090912,
      "learning_rate": 8.127750902749472e-06,
      "loss": 0.5241,
      "step": 4406
    },
    {
      "epoch": 0.31,
      "grad_norm": 3.931111021601079,
      "learning_rate": 8.126872321608185e-06,
      "loss": 0.5284,
      "step": 4407
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.4446956410746576,
      "learning_rate": 8.125993581882128e-06,
      "loss": 0.5114,
      "step": 4408
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.0418281489298575,
      "learning_rate": 8.125114683615866e-06,
      "loss": 0.4809,
      "step": 4409
    },
    {
      "epoch": 0.31,
      "grad_norm": 7.66798785714021,
      "learning_rate": 8.124235626853976e-06,
      "loss": 0.501,
      "step": 4410
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.9074712477436,
      "learning_rate": 8.123356411641042e-06,
      "loss": 0.4639,
      "step": 4411
    },
    {
      "epoch": 0.31,
      "grad_norm": 3.0202210806508587,
      "learning_rate": 8.122477038021653e-06,
      "loss": 0.5171,
      "step": 4412
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.8350734305150889,
      "learning_rate": 8.121597506040409e-06,
      "loss": 0.5507,
      "step": 4413
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.262661104655748,
      "learning_rate": 8.120717815741915e-06,
      "loss": 0.5333,
      "step": 4414
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.680042106552203,
      "learning_rate": 8.119837967170787e-06,
      "loss": 0.4661,
      "step": 4415
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.002575729031196,
      "learning_rate": 8.118957960371651e-06,
      "loss": 0.5119,
      "step": 4416
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.1616446216707152,
      "learning_rate": 8.118077795389135e-06,
      "loss": 0.4633,
      "step": 4417
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.734742297888762,
      "learning_rate": 8.117197472267878e-06,
      "loss": 0.5414,
      "step": 4418
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.107025200153843,
      "learning_rate": 8.116316991052527e-06,
      "loss": 0.5126,
      "step": 4419
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.322980963098008,
      "learning_rate": 8.11543635178774e-06,
      "loss": 0.4974,
      "step": 4420
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.792448125213548,
      "learning_rate": 8.114555554518178e-06,
      "loss": 0.4817,
      "step": 4421
    },
    {
      "epoch": 0.31,
      "grad_norm": 5.87838729031011,
      "learning_rate": 8.11367459928851e-06,
      "loss": 0.566,
      "step": 4422
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6535846357292234,
      "learning_rate": 8.11279348614342e-06,
      "loss": 0.4688,
      "step": 4423
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.7904913172670072,
      "learning_rate": 8.111912215127592e-06,
      "loss": 0.5285,
      "step": 4424
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.074291479843598,
      "learning_rate": 8.11103078628572e-06,
      "loss": 0.5481,
      "step": 4425
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.8691120325601998,
      "learning_rate": 8.110149199662511e-06,
      "loss": 0.4966,
      "step": 4426
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.106027647276071,
      "learning_rate": 8.109267455302674e-06,
      "loss": 0.5251,
      "step": 4427
    },
    {
      "epoch": 0.31,
      "grad_norm": 3.0012392175131772,
      "learning_rate": 8.108385553250927e-06,
      "loss": 0.5013,
      "step": 4428
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.4139786437483735,
      "learning_rate": 8.107503493552002e-06,
      "loss": 0.5528,
      "step": 4429
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.911427012304612,
      "learning_rate": 8.10662127625063e-06,
      "loss": 0.5174,
      "step": 4430
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.2150627851804825,
      "learning_rate": 8.105738901391553e-06,
      "loss": 0.5709,
      "step": 4431
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.3404162519994745,
      "learning_rate": 8.104856369019525e-06,
      "loss": 0.5854,
      "step": 4432
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.8539288184002327,
      "learning_rate": 8.103973679179305e-06,
      "loss": 0.5282,
      "step": 4433
    },
    {
      "epoch": 0.31,
      "grad_norm": 5.107218344731807,
      "learning_rate": 8.103090831915659e-06,
      "loss": 0.5319,
      "step": 4434
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.2846718696717216,
      "learning_rate": 8.102207827273362e-06,
      "loss": 0.5251,
      "step": 4435
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.7441219618595776,
      "learning_rate": 8.101324665297199e-06,
      "loss": 0.512,
      "step": 4436
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.8387401078745982,
      "learning_rate": 8.100441346031958e-06,
      "loss": 0.508,
      "step": 4437
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.795518543703666,
      "learning_rate": 8.099557869522441e-06,
      "loss": 0.52,
      "step": 4438
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.5705597469095416,
      "learning_rate": 8.098674235813456e-06,
      "loss": 0.5207,
      "step": 4439
    },
    {
      "epoch": 0.31,
      "grad_norm": 4.096118491698637,
      "learning_rate": 8.097790444949814e-06,
      "loss": 0.5604,
      "step": 4440
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6852326514602626,
      "learning_rate": 8.09690649697634e-06,
      "loss": 0.4687,
      "step": 4441
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.0898451497312753,
      "learning_rate": 8.096022391937866e-06,
      "loss": 0.5367,
      "step": 4442
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.066862486774606,
      "learning_rate": 8.095138129879228e-06,
      "loss": 0.5204,
      "step": 4443
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.213465136724529,
      "learning_rate": 8.094253710845277e-06,
      "loss": 0.5295,
      "step": 4444
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.183226917808578,
      "learning_rate": 8.093369134880864e-06,
      "loss": 0.5225,
      "step": 4445
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.091596150522395,
      "learning_rate": 8.092484402030853e-06,
      "loss": 0.514,
      "step": 4446
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.1836053395188544,
      "learning_rate": 8.091599512340117e-06,
      "loss": 0.4847,
      "step": 4447
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.464520098711343,
      "learning_rate": 8.090714465853534e-06,
      "loss": 0.4877,
      "step": 4448
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.2627950811286888,
      "learning_rate": 8.089829262615987e-06,
      "loss": 0.5432,
      "step": 4449
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.348201309287788,
      "learning_rate": 8.088943902672372e-06,
      "loss": 0.4885,
      "step": 4450
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.9669164931615892,
      "learning_rate": 8.088058386067597e-06,
      "loss": 0.5154,
      "step": 4451
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.562249486542435,
      "learning_rate": 8.087172712846565e-06,
      "loss": 0.5298,
      "step": 4452
    },
    {
      "epoch": 0.31,
      "grad_norm": 3.3995142421543463,
      "learning_rate": 8.086286883054198e-06,
      "loss": 0.4823,
      "step": 4453
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.6145682421924477,
      "learning_rate": 8.085400896735425e-06,
      "loss": 0.5362,
      "step": 4454
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.7151973470264775,
      "learning_rate": 8.084514753935173e-06,
      "loss": 0.4595,
      "step": 4455
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.6651969756277215,
      "learning_rate": 8.083628454698394e-06,
      "loss": 0.4559,
      "step": 4456
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.9761815206587117,
      "learning_rate": 8.08274199907003e-06,
      "loss": 0.5511,
      "step": 4457
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.2296486056574865,
      "learning_rate": 8.081855387095041e-06,
      "loss": 0.5253,
      "step": 4458
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.476056122168026,
      "learning_rate": 8.080968618818395e-06,
      "loss": 0.5299,
      "step": 4459
    },
    {
      "epoch": 0.31,
      "grad_norm": 3.1758419889894274,
      "learning_rate": 8.080081694285067e-06,
      "loss": 0.5326,
      "step": 4460
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.465558288412174,
      "learning_rate": 8.079194613540036e-06,
      "loss": 0.5459,
      "step": 4461
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.882201337350401,
      "learning_rate": 8.078307376628292e-06,
      "loss": 0.5258,
      "step": 4462
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.8807202032242634,
      "learning_rate": 8.077419983594835e-06,
      "loss": 0.5589,
      "step": 4463
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.7890734938365241,
      "learning_rate": 8.076532434484668e-06,
      "loss": 0.4667,
      "step": 4464
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.088164870426517,
      "learning_rate": 8.075644729342808e-06,
      "loss": 0.4713,
      "step": 4465
    },
    {
      "epoch": 0.31,
      "grad_norm": 5.016191911954078,
      "learning_rate": 8.074756868214272e-06,
      "loss": 0.5638,
      "step": 4466
    },
    {
      "epoch": 0.31,
      "grad_norm": 8.38888640044042,
      "learning_rate": 8.073868851144094e-06,
      "loss": 0.4947,
      "step": 4467
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.8937594111232656,
      "learning_rate": 8.07298067817731e-06,
      "loss": 0.5452,
      "step": 4468
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.190503661203261,
      "learning_rate": 8.072092349358963e-06,
      "loss": 0.5187,
      "step": 4469
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.11089590211645,
      "learning_rate": 8.071203864734108e-06,
      "loss": 0.5205,
      "step": 4470
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.1497712907022084,
      "learning_rate": 8.070315224347805e-06,
      "loss": 0.5533,
      "step": 4471
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.2352640644507162,
      "learning_rate": 8.069426428245124e-06,
      "loss": 0.536,
      "step": 4472
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.5295193815170154,
      "learning_rate": 8.06853747647114e-06,
      "loss": 0.5241,
      "step": 4473
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.114411102125488,
      "learning_rate": 8.067648369070942e-06,
      "loss": 0.4905,
      "step": 4474
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.042999650499204,
      "learning_rate": 8.06675910608962e-06,
      "loss": 0.5271,
      "step": 4475
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.3928420844146903,
      "learning_rate": 8.065869687572272e-06,
      "loss": 0.5269,
      "step": 4476
    },
    {
      "epoch": 0.31,
      "grad_norm": 4.387935577716668,
      "learning_rate": 8.06498011356401e-06,
      "loss": 0.4926,
      "step": 4477
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.071801247290807,
      "learning_rate": 8.064090384109949e-06,
      "loss": 0.5163,
      "step": 4478
    },
    {
      "epoch": 0.31,
      "grad_norm": 3.8385084611009277,
      "learning_rate": 8.063200499255213e-06,
      "loss": 0.55,
      "step": 4479
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.282724041495001,
      "learning_rate": 8.062310459044933e-06,
      "loss": 0.521,
      "step": 4480
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.8053242348841214,
      "learning_rate": 8.06142026352425e-06,
      "loss": 0.4979,
      "step": 4481
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.723010870277332,
      "learning_rate": 8.060529912738316e-06,
      "loss": 0.5095,
      "step": 4482
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.850783523688632,
      "learning_rate": 8.059639406732279e-06,
      "loss": 0.5201,
      "step": 4483
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.34842635941774,
      "learning_rate": 8.058748745551308e-06,
      "loss": 0.5159,
      "step": 4484
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.7054751169097595,
      "learning_rate": 8.057857929240571e-06,
      "loss": 0.5224,
      "step": 4485
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.7977598234546552,
      "learning_rate": 8.056966957845251e-06,
      "loss": 0.5062,
      "step": 4486
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.1068098405939333,
      "learning_rate": 8.056075831410533e-06,
      "loss": 0.5456,
      "step": 4487
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.9714399998608856,
      "learning_rate": 8.055184549981611e-06,
      "loss": 0.5218,
      "step": 4488
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.9025607584922033,
      "learning_rate": 8.05429311360369e-06,
      "loss": 0.528,
      "step": 4489
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.6657247745635533,
      "learning_rate": 8.05340152232198e-06,
      "loss": 0.5184,
      "step": 4490
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.9936111346185634,
      "learning_rate": 8.052509776181698e-06,
      "loss": 0.5315,
      "step": 4491
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.024091839732541,
      "learning_rate": 8.051617875228073e-06,
      "loss": 0.5281,
      "step": 4492
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.2019778769620895,
      "learning_rate": 8.05072581950634e-06,
      "loss": 0.5244,
      "step": 4493
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.522733851842558,
      "learning_rate": 8.049833609061737e-06,
      "loss": 0.5043,
      "step": 4494
    },
    {
      "epoch": 0.31,
      "grad_norm": 7.211709279459012,
      "learning_rate": 8.048941243939516e-06,
      "loss": 0.4594,
      "step": 4495
    },
    {
      "epoch": 0.31,
      "grad_norm": 3.155317185363296,
      "learning_rate": 8.048048724184936e-06,
      "loss": 0.5164,
      "step": 4496
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.6903183876322863,
      "learning_rate": 8.047156049843264e-06,
      "loss": 0.5346,
      "step": 4497
    },
    {
      "epoch": 0.31,
      "grad_norm": 11.218380395562555,
      "learning_rate": 8.046263220959767e-06,
      "loss": 0.5223,
      "step": 4498
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.2546393314212705,
      "learning_rate": 8.045370237579735e-06,
      "loss": 0.4888,
      "step": 4499
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.8429445548545311,
      "learning_rate": 8.044477099748451e-06,
      "loss": 0.4637,
      "step": 4500
    },
    {
      "epoch": 0.31,
      "grad_norm": 5.424382174101483,
      "learning_rate": 8.043583807511215e-06,
      "loss": 0.5312,
      "step": 4501
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.5311387368884115,
      "learning_rate": 8.04269036091333e-06,
      "loss": 0.5086,
      "step": 4502
    },
    {
      "epoch": 0.31,
      "grad_norm": 3.4651170889224536,
      "learning_rate": 8.041796760000111e-06,
      "loss": 0.5125,
      "step": 4503
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.693258494590633,
      "learning_rate": 8.040903004816874e-06,
      "loss": 0.463,
      "step": 4504
    },
    {
      "epoch": 0.31,
      "grad_norm": 4.124378476034145,
      "learning_rate": 8.040009095408953e-06,
      "loss": 0.568,
      "step": 4505
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.010915173588032,
      "learning_rate": 8.039115031821683e-06,
      "loss": 0.5467,
      "step": 4506
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.281352844076975,
      "learning_rate": 8.038220814100403e-06,
      "loss": 0.5128,
      "step": 4507
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.3249342152475747,
      "learning_rate": 8.037326442290472e-06,
      "loss": 0.4938,
      "step": 4508
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.164207314779154,
      "learning_rate": 8.036431916437244e-06,
      "loss": 0.5347,
      "step": 4509
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.45103703053251,
      "learning_rate": 8.035537236586088e-06,
      "loss": 0.5479,
      "step": 4510
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.9140904234773282,
      "learning_rate": 8.034642402782382e-06,
      "loss": 0.5263,
      "step": 4511
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.9931056492051886,
      "learning_rate": 8.033747415071507e-06,
      "loss": 0.5371,
      "step": 4512
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.9458711267075086,
      "learning_rate": 8.032852273498852e-06,
      "loss": 0.5475,
      "step": 4513
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.168340489684055,
      "learning_rate": 8.031956978109817e-06,
      "loss": 0.4824,
      "step": 4514
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.0257229108029415,
      "learning_rate": 8.03106152894981e-06,
      "loss": 0.4879,
      "step": 4515
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.11934169986408,
      "learning_rate": 8.030165926064244e-06,
      "loss": 0.5338,
      "step": 4516
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.528787000724328,
      "learning_rate": 8.029270169498539e-06,
      "loss": 0.5335,
      "step": 4517
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.133365820084458,
      "learning_rate": 8.02837425929813e-06,
      "loss": 0.5303,
      "step": 4518
    },
    {
      "epoch": 0.31,
      "grad_norm": 7.89961138297089,
      "learning_rate": 8.02747819550845e-06,
      "loss": 0.5115,
      "step": 4519
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.5399737995292155,
      "learning_rate": 8.026581978174947e-06,
      "loss": 0.5179,
      "step": 4520
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.853845137458071,
      "learning_rate": 8.025685607343073e-06,
      "loss": 0.477,
      "step": 4521
    },
    {
      "epoch": 0.31,
      "grad_norm": 3.0640036465219147,
      "learning_rate": 8.024789083058289e-06,
      "loss": 0.5355,
      "step": 4522
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.211264916306357,
      "learning_rate": 8.023892405366065e-06,
      "loss": 0.516,
      "step": 4523
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.1058217144677545,
      "learning_rate": 8.022995574311876e-06,
      "loss": 0.5412,
      "step": 4524
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.8465632720835714,
      "learning_rate": 8.022098589941206e-06,
      "loss": 0.531,
      "step": 4525
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.9786625890571072,
      "learning_rate": 8.021201452299549e-06,
      "loss": 0.4875,
      "step": 4526
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.8472161422848197,
      "learning_rate": 8.020304161432404e-06,
      "loss": 0.503,
      "step": 4527
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.191842690536332,
      "learning_rate": 8.01940671738528e-06,
      "loss": 0.5297,
      "step": 4528
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.2653183946429465,
      "learning_rate": 8.018509120203688e-06,
      "loss": 0.5098,
      "step": 4529
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.871865353116267,
      "learning_rate": 8.017611369933157e-06,
      "loss": 0.5111,
      "step": 4530
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.547988230444953,
      "learning_rate": 8.016713466619213e-06,
      "loss": 0.5331,
      "step": 4531
    },
    {
      "epoch": 0.32,
      "grad_norm": 5.009167209248288,
      "learning_rate": 8.0158154103074e-06,
      "loss": 0.543,
      "step": 4532
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.0063223055253423,
      "learning_rate": 8.01491720104326e-06,
      "loss": 0.5365,
      "step": 4533
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.1169752492224143,
      "learning_rate": 8.014018838872348e-06,
      "loss": 0.534,
      "step": 4534
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.3493578769242665,
      "learning_rate": 8.013120323840228e-06,
      "loss": 0.4995,
      "step": 4535
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.325550238139764,
      "learning_rate": 8.012221655992469e-06,
      "loss": 0.5396,
      "step": 4536
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.9746817833770025,
      "learning_rate": 8.011322835374646e-06,
      "loss": 0.473,
      "step": 4537
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.9678064772017745,
      "learning_rate": 8.010423862032347e-06,
      "loss": 0.4973,
      "step": 4538
    },
    {
      "epoch": 0.32,
      "grad_norm": 4.503341697923211,
      "learning_rate": 8.009524736011166e-06,
      "loss": 0.581,
      "step": 4539
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.0688359341802385,
      "learning_rate": 8.0086254573567e-06,
      "loss": 0.549,
      "step": 4540
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.0769209310229857,
      "learning_rate": 8.00772602611456e-06,
      "loss": 0.5131,
      "step": 4541
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6849845635780517,
      "learning_rate": 8.006826442330362e-06,
      "loss": 0.4529,
      "step": 4542
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.4624240477025108,
      "learning_rate": 8.005926706049728e-06,
      "loss": 0.529,
      "step": 4543
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.092884500429699,
      "learning_rate": 8.005026817318293e-06,
      "loss": 0.4634,
      "step": 4544
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.42947644463903,
      "learning_rate": 8.004126776181695e-06,
      "loss": 0.507,
      "step": 4545
    },
    {
      "epoch": 0.32,
      "grad_norm": 4.021785422723915,
      "learning_rate": 8.003226582685582e-06,
      "loss": 0.5347,
      "step": 4546
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.674208898456996,
      "learning_rate": 8.002326236875604e-06,
      "loss": 0.4393,
      "step": 4547
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.3605951087382886,
      "learning_rate": 8.00142573879743e-06,
      "loss": 0.5451,
      "step": 4548
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.5800146285519854,
      "learning_rate": 8.000525088496727e-06,
      "loss": 0.5215,
      "step": 4549
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.7042816346995069,
      "learning_rate": 7.999624286019175e-06,
      "loss": 0.5156,
      "step": 4550
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.8559223929491684,
      "learning_rate": 7.998723331410458e-06,
      "loss": 0.5431,
      "step": 4551
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.3114798924793694,
      "learning_rate": 7.997822224716269e-06,
      "loss": 0.5471,
      "step": 4552
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.9638268814867255,
      "learning_rate": 7.99692096598231e-06,
      "loss": 0.5483,
      "step": 4553
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.050106649998716,
      "learning_rate": 7.996019555254293e-06,
      "loss": 0.5033,
      "step": 4554
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.1426030714737108,
      "learning_rate": 7.99511799257793e-06,
      "loss": 0.5643,
      "step": 4555
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.392488397850189,
      "learning_rate": 7.994216277998947e-06,
      "loss": 0.5712,
      "step": 4556
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.132181011783326,
      "learning_rate": 7.993314411563075e-06,
      "loss": 0.508,
      "step": 4557
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.198724499447332,
      "learning_rate": 7.992412393316059e-06,
      "loss": 0.5693,
      "step": 4558
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.2574553946383933,
      "learning_rate": 7.991510223303637e-06,
      "loss": 0.4999,
      "step": 4559
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.0835593346706336,
      "learning_rate": 7.990607901571573e-06,
      "loss": 0.5346,
      "step": 4560
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.3524923106530835,
      "learning_rate": 7.989705428165623e-06,
      "loss": 0.5223,
      "step": 4561
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.753221677890463,
      "learning_rate": 7.988802803131563e-06,
      "loss": 0.4358,
      "step": 4562
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.184692441740533,
      "learning_rate": 7.987900026515167e-06,
      "loss": 0.5182,
      "step": 4563
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.743931107960903,
      "learning_rate": 7.986997098362225e-06,
      "loss": 0.522,
      "step": 4564
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.3880034204460263,
      "learning_rate": 7.986094018718527e-06,
      "loss": 0.5153,
      "step": 4565
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.018919466455868,
      "learning_rate": 7.985190787629877e-06,
      "loss": 0.5199,
      "step": 4566
    },
    {
      "epoch": 0.32,
      "grad_norm": 4.15068957522941,
      "learning_rate": 7.98428740514208e-06,
      "loss": 0.4976,
      "step": 4567
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.171975795752365,
      "learning_rate": 7.983383871300957e-06,
      "loss": 0.5372,
      "step": 4568
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.955963228364901,
      "learning_rate": 7.98248018615233e-06,
      "loss": 0.4806,
      "step": 4569
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.133212896268572,
      "learning_rate": 7.981576349742031e-06,
      "loss": 0.552,
      "step": 4570
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.1538651718267867,
      "learning_rate": 7.9806723621159e-06,
      "loss": 0.581,
      "step": 4571
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.697156648533851,
      "learning_rate": 7.979768223319786e-06,
      "loss": 0.4635,
      "step": 4572
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.234014967648966,
      "learning_rate": 7.978863933399542e-06,
      "loss": 0.532,
      "step": 4573
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.065416760745503,
      "learning_rate": 7.97795949240103e-06,
      "loss": 0.5628,
      "step": 4574
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.209571548266086,
      "learning_rate": 7.97705490037012e-06,
      "loss": 0.5254,
      "step": 4575
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.929663770711607,
      "learning_rate": 7.976150157352694e-06,
      "loss": 0.5191,
      "step": 4576
    },
    {
      "epoch": 0.32,
      "grad_norm": 8.054451487744952,
      "learning_rate": 7.975245263394632e-06,
      "loss": 0.5373,
      "step": 4577
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.1730376128312305,
      "learning_rate": 7.974340218541831e-06,
      "loss": 0.4989,
      "step": 4578
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.7807292859115906,
      "learning_rate": 7.973435022840192e-06,
      "loss": 0.5186,
      "step": 4579
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.43704248354523,
      "learning_rate": 7.972529676335623e-06,
      "loss": 0.5017,
      "step": 4580
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.0959470649152467,
      "learning_rate": 7.971624179074038e-06,
      "loss": 0.5051,
      "step": 4581
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.8596771780880368,
      "learning_rate": 7.970718531101365e-06,
      "loss": 0.4906,
      "step": 4582
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.2873957264147173,
      "learning_rate": 7.96981273246353e-06,
      "loss": 0.5541,
      "step": 4583
    },
    {
      "epoch": 0.32,
      "grad_norm": 5.952149890717142,
      "learning_rate": 7.968906783206478e-06,
      "loss": 0.5182,
      "step": 4584
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.209055429097221,
      "learning_rate": 7.968000683376152e-06,
      "loss": 0.5244,
      "step": 4585
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.775719519287281,
      "learning_rate": 7.967094433018508e-06,
      "loss": 0.4495,
      "step": 4586
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6602573673479973,
      "learning_rate": 7.966188032179507e-06,
      "loss": 0.4772,
      "step": 4587
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.7059766145530082,
      "learning_rate": 7.96528148090512e-06,
      "loss": 0.5386,
      "step": 4588
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.6475202587320656,
      "learning_rate": 7.964374779241324e-06,
      "loss": 0.5341,
      "step": 4589
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.784255774668208,
      "learning_rate": 7.963467927234103e-06,
      "loss": 0.5053,
      "step": 4590
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.5212999815155293,
      "learning_rate": 7.96256092492945e-06,
      "loss": 0.5622,
      "step": 4591
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.9403860705307026,
      "learning_rate": 7.961653772373366e-06,
      "loss": 0.5183,
      "step": 4592
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.121074607586989,
      "learning_rate": 7.960746469611858e-06,
      "loss": 0.4626,
      "step": 4593
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.3264770728057917,
      "learning_rate": 7.959839016690941e-06,
      "loss": 0.5325,
      "step": 4594
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.968043824135012,
      "learning_rate": 7.95893141365664e-06,
      "loss": 0.5054,
      "step": 4595
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.0634579067764887,
      "learning_rate": 7.958023660554983e-06,
      "loss": 0.5207,
      "step": 4596
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.361826081798922,
      "learning_rate": 7.95711575743201e-06,
      "loss": 0.4913,
      "step": 4597
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.0649155137664623,
      "learning_rate": 7.956207704333767e-06,
      "loss": 0.4694,
      "step": 4598
    },
    {
      "epoch": 0.32,
      "grad_norm": 7.1906110415987925,
      "learning_rate": 7.955299501306308e-06,
      "loss": 0.5296,
      "step": 4599
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.37907418426315,
      "learning_rate": 7.954391148395692e-06,
      "loss": 0.511,
      "step": 4600
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.9740227908048946,
      "learning_rate": 7.953482645647988e-06,
      "loss": 0.4864,
      "step": 4601
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.3568061408650642,
      "learning_rate": 7.952573993109273e-06,
      "loss": 0.4947,
      "step": 4602
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.5655839239737595,
      "learning_rate": 7.951665190825633e-06,
      "loss": 0.491,
      "step": 4603
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.0020726857980384,
      "learning_rate": 7.950756238843155e-06,
      "loss": 0.5706,
      "step": 4604
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.986025117629235,
      "learning_rate": 7.949847137207945e-06,
      "loss": 0.5337,
      "step": 4605
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.796839601171851,
      "learning_rate": 7.9489378859661e-06,
      "loss": 0.4763,
      "step": 4606
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.282958520468109,
      "learning_rate": 7.948028485163744e-06,
      "loss": 0.5478,
      "step": 4607
    },
    {
      "epoch": 0.32,
      "grad_norm": 5.249043164999294,
      "learning_rate": 7.94711893484699e-06,
      "loss": 0.5069,
      "step": 4608
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.5104591265412686,
      "learning_rate": 7.946209235061975e-06,
      "loss": 0.5398,
      "step": 4609
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.9576404033479926,
      "learning_rate": 7.945299385854831e-06,
      "loss": 0.5018,
      "step": 4610
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.5751701950153025,
      "learning_rate": 7.944389387271706e-06,
      "loss": 0.534,
      "step": 4611
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.1200079059646484,
      "learning_rate": 7.94347923935875e-06,
      "loss": 0.5419,
      "step": 4612
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.47480138339111,
      "learning_rate": 7.942568942162123e-06,
      "loss": 0.4693,
      "step": 4613
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.5260835343814296,
      "learning_rate": 7.941658495727991e-06,
      "loss": 0.5219,
      "step": 4614
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.7072644722076427,
      "learning_rate": 7.940747900102533e-06,
      "loss": 0.5318,
      "step": 4615
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.360637761363588,
      "learning_rate": 7.939837155331927e-06,
      "loss": 0.567,
      "step": 4616
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.027495539202454,
      "learning_rate": 7.938926261462366e-06,
      "loss": 0.4758,
      "step": 4617
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.4384597533122303,
      "learning_rate": 7.938015218540047e-06,
      "loss": 0.5025,
      "step": 4618
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.8331851646095494,
      "learning_rate": 7.937104026611173e-06,
      "loss": 0.5266,
      "step": 4619
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6868948876470174,
      "learning_rate": 7.93619268572196e-06,
      "loss": 0.4598,
      "step": 4620
    },
    {
      "epoch": 0.32,
      "grad_norm": 4.659408942468356,
      "learning_rate": 7.935281195918626e-06,
      "loss": 0.5031,
      "step": 4621
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.8245663241683694,
      "learning_rate": 7.934369557247397e-06,
      "loss": 0.5089,
      "step": 4622
    },
    {
      "epoch": 0.32,
      "grad_norm": 6.699526232506986,
      "learning_rate": 7.933457769754513e-06,
      "loss": 0.5106,
      "step": 4623
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.1108186337513275,
      "learning_rate": 7.932545833486214e-06,
      "loss": 0.4974,
      "step": 4624
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6892746384306637,
      "learning_rate": 7.931633748488752e-06,
      "loss": 0.4629,
      "step": 4625
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.505442058404124,
      "learning_rate": 7.930721514808383e-06,
      "loss": 0.4964,
      "step": 4626
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.8492067752160866,
      "learning_rate": 7.929809132491374e-06,
      "loss": 0.5317,
      "step": 4627
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.5387189874382248,
      "learning_rate": 7.928896601583996e-06,
      "loss": 0.5533,
      "step": 4628
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.431122859759822,
      "learning_rate": 7.927983922132533e-06,
      "loss": 0.5348,
      "step": 4629
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.5118564644836288,
      "learning_rate": 7.92707109418327e-06,
      "loss": 0.5095,
      "step": 4630
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.24030134399675,
      "learning_rate": 7.926158117782505e-06,
      "loss": 0.5203,
      "step": 4631
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.9013775952109269,
      "learning_rate": 7.925244992976538e-06,
      "loss": 0.478,
      "step": 4632
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.8960372768627667,
      "learning_rate": 7.924331719811685e-06,
      "loss": 0.5772,
      "step": 4633
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.0435376202603934,
      "learning_rate": 7.923418298334257e-06,
      "loss": 0.4823,
      "step": 4634
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.527425987483064,
      "learning_rate": 7.922504728590587e-06,
      "loss": 0.503,
      "step": 4635
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.8404983615744273,
      "learning_rate": 7.921591010627005e-06,
      "loss": 0.4942,
      "step": 4636
    },
    {
      "epoch": 0.32,
      "grad_norm": 10.491924311871653,
      "learning_rate": 7.92067714448985e-06,
      "loss": 0.4866,
      "step": 4637
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.6700474102407026,
      "learning_rate": 7.919763130225473e-06,
      "loss": 0.4847,
      "step": 4638
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.154326001300207,
      "learning_rate": 7.918848967880231e-06,
      "loss": 0.5551,
      "step": 4639
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.7835534182601283,
      "learning_rate": 7.917934657500483e-06,
      "loss": 0.5103,
      "step": 4640
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.3927642748793305,
      "learning_rate": 7.917020199132603e-06,
      "loss": 0.5385,
      "step": 4641
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.6167530552593625,
      "learning_rate": 7.916105592822966e-06,
      "loss": 0.5318,
      "step": 4642
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.2324332021431843,
      "learning_rate": 7.915190838617964e-06,
      "loss": 0.5521,
      "step": 4643
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.7040256197592596,
      "learning_rate": 7.914275936563986e-06,
      "loss": 0.4655,
      "step": 4644
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.043630636390039,
      "learning_rate": 7.913360886707434e-06,
      "loss": 0.5216,
      "step": 4645
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.4871862180144695,
      "learning_rate": 7.912445689094715e-06,
      "loss": 0.515,
      "step": 4646
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.3953522515550456,
      "learning_rate": 7.911530343772244e-06,
      "loss": 0.4954,
      "step": 4647
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.186326936916107,
      "learning_rate": 7.910614850786448e-06,
      "loss": 0.4889,
      "step": 4648
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.42374118463223,
      "learning_rate": 7.909699210183757e-06,
      "loss": 0.5534,
      "step": 4649
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.4520107397220814,
      "learning_rate": 7.908783422010605e-06,
      "loss": 0.5182,
      "step": 4650
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.418530080430182,
      "learning_rate": 7.907867486313444e-06,
      "loss": 0.5537,
      "step": 4651
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.8846711324781438,
      "learning_rate": 7.906951403138723e-06,
      "loss": 0.4853,
      "step": 4652
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.4295291755915684,
      "learning_rate": 7.906035172532904e-06,
      "loss": 0.5273,
      "step": 4653
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.6478893248338493,
      "learning_rate": 7.905118794542455e-06,
      "loss": 0.5331,
      "step": 4654
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.241901999517104,
      "learning_rate": 7.904202269213854e-06,
      "loss": 0.5343,
      "step": 4655
    },
    {
      "epoch": 0.32,
      "grad_norm": 18.782950381441644,
      "learning_rate": 7.903285596593579e-06,
      "loss": 0.4962,
      "step": 4656
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.7368533047012024,
      "learning_rate": 7.902368776728125e-06,
      "loss": 0.4555,
      "step": 4657
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.3335009775983506,
      "learning_rate": 7.90145180966399e-06,
      "loss": 0.4972,
      "step": 4658
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.133634860885085,
      "learning_rate": 7.900534695447677e-06,
      "loss": 0.5141,
      "step": 4659
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.8492923293375991,
      "learning_rate": 7.899617434125703e-06,
      "loss": 0.5137,
      "step": 4660
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.3226694756832638,
      "learning_rate": 7.898700025744583e-06,
      "loss": 0.5377,
      "step": 4661
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.930699913232399,
      "learning_rate": 7.89778247035085e-06,
      "loss": 0.499,
      "step": 4662
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.6758507328322425,
      "learning_rate": 7.896864767991037e-06,
      "loss": 0.541,
      "step": 4663
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.0154226145960257,
      "learning_rate": 7.895946918711688e-06,
      "loss": 0.5134,
      "step": 4664
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.5260187639716962,
      "learning_rate": 7.895028922559351e-06,
      "loss": 0.5471,
      "step": 4665
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.9570108449440209,
      "learning_rate": 7.894110779580587e-06,
      "loss": 0.5102,
      "step": 4666
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.043177470808907,
      "learning_rate": 7.893192489821958e-06,
      "loss": 0.5012,
      "step": 4667
    },
    {
      "epoch": 0.32,
      "grad_norm": 4.656849763693061,
      "learning_rate": 7.89227405333004e-06,
      "loss": 0.4538,
      "step": 4668
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.5225308768471417,
      "learning_rate": 7.89135547015141e-06,
      "loss": 0.5253,
      "step": 4669
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.045564451584992,
      "learning_rate": 7.890436740332656e-06,
      "loss": 0.5341,
      "step": 4670
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.7643357019357304,
      "learning_rate": 7.889517863920375e-06,
      "loss": 0.495,
      "step": 4671
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.1334009816694546,
      "learning_rate": 7.888598840961168e-06,
      "loss": 0.4936,
      "step": 4672
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.2556916031953236,
      "learning_rate": 7.887679671501647e-06,
      "loss": 0.4868,
      "step": 4673
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.8421662145570243,
      "learning_rate": 7.886760355588425e-06,
      "loss": 0.4897,
      "step": 4674
    },
    {
      "epoch": 0.33,
      "grad_norm": 4.058595734002707,
      "learning_rate": 7.88584089326813e-06,
      "loss": 0.5248,
      "step": 4675
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.3952057868730483,
      "learning_rate": 7.884921284587394e-06,
      "loss": 0.5308,
      "step": 4676
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.7741123025584582,
      "learning_rate": 7.884001529592855e-06,
      "loss": 0.5337,
      "step": 4677
    },
    {
      "epoch": 0.33,
      "grad_norm": 4.876011406555501,
      "learning_rate": 7.883081628331162e-06,
      "loss": 0.5316,
      "step": 4678
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.0895540617751953,
      "learning_rate": 7.882161580848966e-06,
      "loss": 0.5032,
      "step": 4679
    },
    {
      "epoch": 0.33,
      "grad_norm": 3.7196220553500123,
      "learning_rate": 7.881241387192933e-06,
      "loss": 0.5276,
      "step": 4680
    },
    {
      "epoch": 0.33,
      "grad_norm": 3.328260002778014,
      "learning_rate": 7.880321047409729e-06,
      "loss": 0.547,
      "step": 4681
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.6107818871999147,
      "learning_rate": 7.879400561546033e-06,
      "loss": 0.584,
      "step": 4682
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.3602067786020955,
      "learning_rate": 7.878479929648528e-06,
      "loss": 0.4781,
      "step": 4683
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.7714627591363326,
      "learning_rate": 7.877559151763905e-06,
      "loss": 0.5942,
      "step": 4684
    },
    {
      "epoch": 0.33,
      "grad_norm": 4.62763342312755,
      "learning_rate": 7.876638227938862e-06,
      "loss": 0.5215,
      "step": 4685
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.456437126480134,
      "learning_rate": 7.875717158220108e-06,
      "loss": 0.562,
      "step": 4686
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.0982309155434886,
      "learning_rate": 7.874795942654354e-06,
      "loss": 0.5012,
      "step": 4687
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6950680075594042,
      "learning_rate": 7.873874581288323e-06,
      "loss": 0.4584,
      "step": 4688
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.646188072463431,
      "learning_rate": 7.872953074168741e-06,
      "loss": 0.486,
      "step": 4689
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.312871783041934,
      "learning_rate": 7.872031421342348e-06,
      "loss": 0.5132,
      "step": 4690
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.897654260908229,
      "learning_rate": 7.871109622855882e-06,
      "loss": 0.4626,
      "step": 4691
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.050359504599332,
      "learning_rate": 7.870187678756099e-06,
      "loss": 0.537,
      "step": 4692
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.5936237554699684,
      "learning_rate": 7.869265589089751e-06,
      "loss": 0.4719,
      "step": 4693
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.469690087429975,
      "learning_rate": 7.868343353903611e-06,
      "loss": 0.526,
      "step": 4694
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6593470932421172,
      "learning_rate": 7.867420973244444e-06,
      "loss": 0.4591,
      "step": 4695
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.2505229738233665,
      "learning_rate": 7.866498447159035e-06,
      "loss": 0.4711,
      "step": 4696
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.304557456150934,
      "learning_rate": 7.86557577569417e-06,
      "loss": 0.5355,
      "step": 4697
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.1121826702520186,
      "learning_rate": 7.864652958896643e-06,
      "loss": 0.495,
      "step": 4698
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.8939023940615278,
      "learning_rate": 7.863729996813258e-06,
      "loss": 0.487,
      "step": 4699
    },
    {
      "epoch": 0.33,
      "grad_norm": 8.648993148561601,
      "learning_rate": 7.862806889490824e-06,
      "loss": 0.5353,
      "step": 4700
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.160095787185878,
      "learning_rate": 7.861883636976158e-06,
      "loss": 0.4962,
      "step": 4701
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.122291497186318,
      "learning_rate": 7.860960239316083e-06,
      "loss": 0.4686,
      "step": 4702
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.2480172791246407,
      "learning_rate": 7.860036696557432e-06,
      "loss": 0.5433,
      "step": 4703
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.8962670880199324,
      "learning_rate": 7.859113008747046e-06,
      "loss": 0.5014,
      "step": 4704
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.2373296236947318,
      "learning_rate": 7.858189175931767e-06,
      "loss": 0.5001,
      "step": 4705
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.1133758337694766,
      "learning_rate": 7.857265198158453e-06,
      "loss": 0.5287,
      "step": 4706
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.29162501113383,
      "learning_rate": 7.856341075473963e-06,
      "loss": 0.4797,
      "step": 4707
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.2019354046084354,
      "learning_rate": 7.855416807925165e-06,
      "loss": 0.5075,
      "step": 4708
    },
    {
      "epoch": 0.33,
      "grad_norm": 3.9990237907244235,
      "learning_rate": 7.854492395558935e-06,
      "loss": 0.516,
      "step": 4709
    },
    {
      "epoch": 0.33,
      "grad_norm": 4.848295107039732,
      "learning_rate": 7.85356783842216e-06,
      "loss": 0.5447,
      "step": 4710
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.393633198288847,
      "learning_rate": 7.852643136561724e-06,
      "loss": 0.4818,
      "step": 4711
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.4064994337570442,
      "learning_rate": 7.85171829002453e-06,
      "loss": 0.4828,
      "step": 4712
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.6650303384371554,
      "learning_rate": 7.850793298857481e-06,
      "loss": 0.5262,
      "step": 4713
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.0845434947322268,
      "learning_rate": 7.849868163107492e-06,
      "loss": 0.5003,
      "step": 4714
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.3463871675657804,
      "learning_rate": 7.848942882821479e-06,
      "loss": 0.5152,
      "step": 4715
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.4844275572642167,
      "learning_rate": 7.848017458046371e-06,
      "loss": 0.4474,
      "step": 4716
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.6571837901576005,
      "learning_rate": 7.847091888829102e-06,
      "loss": 0.5402,
      "step": 4717
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.256030094628385,
      "learning_rate": 7.846166175216617e-06,
      "loss": 0.5053,
      "step": 4718
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.9884091956744716,
      "learning_rate": 7.84524031725586e-06,
      "loss": 0.5282,
      "step": 4719
    },
    {
      "epoch": 0.33,
      "grad_norm": 5.476053094699378,
      "learning_rate": 7.844314314993791e-06,
      "loss": 0.5146,
      "step": 4720
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6374234945157244,
      "learning_rate": 7.843388168477373e-06,
      "loss": 0.4479,
      "step": 4721
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.81794334667149,
      "learning_rate": 7.842461877753575e-06,
      "loss": 0.5038,
      "step": 4722
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.572004170046185,
      "learning_rate": 7.841535442869381e-06,
      "loss": 0.5268,
      "step": 4723
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.9203425075610236,
      "learning_rate": 7.840608863871772e-06,
      "loss": 0.463,
      "step": 4724
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.7402055651912587,
      "learning_rate": 7.839682140807743e-06,
      "loss": 0.5008,
      "step": 4725
    },
    {
      "epoch": 0.33,
      "grad_norm": 3.948970533751612,
      "learning_rate": 7.838755273724293e-06,
      "loss": 0.5059,
      "step": 4726
    },
    {
      "epoch": 0.33,
      "grad_norm": 3.9262995736405073,
      "learning_rate": 7.83782826266843e-06,
      "loss": 0.4728,
      "step": 4727
    },
    {
      "epoch": 0.33,
      "grad_norm": 3.0486172603592836,
      "learning_rate": 7.83690110768717e-06,
      "loss": 0.4928,
      "step": 4728
    },
    {
      "epoch": 0.33,
      "grad_norm": 3.322135587641675,
      "learning_rate": 7.835973808827533e-06,
      "loss": 0.5522,
      "step": 4729
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.138536926811385,
      "learning_rate": 7.835046366136552e-06,
      "loss": 0.5442,
      "step": 4730
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.1996933921131974,
      "learning_rate": 7.834118779661262e-06,
      "loss": 0.5302,
      "step": 4731
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.957700545869205,
      "learning_rate": 7.833191049448706e-06,
      "loss": 0.4875,
      "step": 4732
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.4503156551684837,
      "learning_rate": 7.832263175545938e-06,
      "loss": 0.54,
      "step": 4733
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.533996985741702,
      "learning_rate": 7.831335158000015e-06,
      "loss": 0.5179,
      "step": 4734
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.9494405097238687,
      "learning_rate": 7.830406996858004e-06,
      "loss": 0.4988,
      "step": 4735
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.519189348595088,
      "learning_rate": 7.829478692166976e-06,
      "loss": 0.5509,
      "step": 4736
    },
    {
      "epoch": 0.33,
      "grad_norm": 3.011731880106427,
      "learning_rate": 7.828550243974015e-06,
      "loss": 0.5082,
      "step": 4737
    },
    {
      "epoch": 0.33,
      "grad_norm": 3.0042611698569517,
      "learning_rate": 7.827621652326207e-06,
      "loss": 0.4759,
      "step": 4738
    },
    {
      "epoch": 0.33,
      "grad_norm": 3.1229692288919293,
      "learning_rate": 7.826692917270648e-06,
      "loss": 0.5146,
      "step": 4739
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.142387955622162,
      "learning_rate": 7.825764038854438e-06,
      "loss": 0.5079,
      "step": 4740
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.9997509509388194,
      "learning_rate": 7.82483501712469e-06,
      "loss": 0.5432,
      "step": 4741
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.830317694312647,
      "learning_rate": 7.82390585212852e-06,
      "loss": 0.5236,
      "step": 4742
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.791721913177286,
      "learning_rate": 7.82297654391305e-06,
      "loss": 0.5361,
      "step": 4743
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.5427471657160337,
      "learning_rate": 7.822047092525413e-06,
      "loss": 0.5088,
      "step": 4744
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.9939216751532773,
      "learning_rate": 7.821117498012749e-06,
      "loss": 0.5641,
      "step": 4745
    },
    {
      "epoch": 0.33,
      "grad_norm": 4.0155005253818805,
      "learning_rate": 7.820187760422202e-06,
      "loss": 0.5362,
      "step": 4746
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.1752580688620555,
      "learning_rate": 7.819257879800927e-06,
      "loss": 0.533,
      "step": 4747
    },
    {
      "epoch": 0.33,
      "grad_norm": 3.0112577466016215,
      "learning_rate": 7.818327856196083e-06,
      "loss": 0.5301,
      "step": 4748
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.2862056359074394,
      "learning_rate": 7.81739768965484e-06,
      "loss": 0.5509,
      "step": 4749
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.2463563769644215,
      "learning_rate": 7.81646738022437e-06,
      "loss": 0.5006,
      "step": 4750
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.323239515782861,
      "learning_rate": 7.815536927951856e-06,
      "loss": 0.5376,
      "step": 4751
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.4314830655683575,
      "learning_rate": 7.81460633288449e-06,
      "loss": 0.5283,
      "step": 4752
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.0607619267227,
      "learning_rate": 7.813675595069466e-06,
      "loss": 0.5334,
      "step": 4753
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.6276371320071306,
      "learning_rate": 7.812744714553988e-06,
      "loss": 0.4982,
      "step": 4754
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.993673468017577,
      "learning_rate": 7.811813691385269e-06,
      "loss": 0.4688,
      "step": 4755
    },
    {
      "epoch": 0.33,
      "grad_norm": 5.474155273173021,
      "learning_rate": 7.810882525610526e-06,
      "loss": 0.5256,
      "step": 4756
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.698330601878375,
      "learning_rate": 7.809951217276986e-06,
      "loss": 0.566,
      "step": 4757
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.043803567796665,
      "learning_rate": 7.809019766431882e-06,
      "loss": 0.5105,
      "step": 4758
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.717990001221921,
      "learning_rate": 7.808088173122453e-06,
      "loss": 0.5031,
      "step": 4759
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.922011227275582,
      "learning_rate": 7.807156437395944e-06,
      "loss": 0.518,
      "step": 4760
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.283738871443289,
      "learning_rate": 7.806224559299615e-06,
      "loss": 0.4851,
      "step": 4761
    },
    {
      "epoch": 0.33,
      "grad_norm": 3.0797627789031066,
      "learning_rate": 7.805292538880724e-06,
      "loss": 0.4907,
      "step": 4762
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.4325222190302203,
      "learning_rate": 7.804360376186544e-06,
      "loss": 0.4891,
      "step": 4763
    },
    {
      "epoch": 0.33,
      "grad_norm": 3.451254112843299,
      "learning_rate": 7.803428071264345e-06,
      "loss": 0.5428,
      "step": 4764
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.4032186148927615,
      "learning_rate": 7.802495624161416e-06,
      "loss": 0.4953,
      "step": 4765
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.527501589837693,
      "learning_rate": 7.801563034925044e-06,
      "loss": 0.5388,
      "step": 4766
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.130836142678222,
      "learning_rate": 7.800630303602529e-06,
      "loss": 0.4971,
      "step": 4767
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.390281094462154,
      "learning_rate": 7.799697430241178e-06,
      "loss": 0.5131,
      "step": 4768
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.0282107657019663,
      "learning_rate": 7.798764414888298e-06,
      "loss": 0.5101,
      "step": 4769
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.1359997922400433,
      "learning_rate": 7.797831257591213e-06,
      "loss": 0.5238,
      "step": 4770
    },
    {
      "epoch": 0.33,
      "grad_norm": 3.5158799390981375,
      "learning_rate": 7.796897958397248e-06,
      "loss": 0.5343,
      "step": 4771
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.187815921688591,
      "learning_rate": 7.795964517353734e-06,
      "loss": 0.5142,
      "step": 4772
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.8113672496537796,
      "learning_rate": 7.79503093450802e-06,
      "loss": 0.53,
      "step": 4773
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.8616119720428834,
      "learning_rate": 7.794097209907445e-06,
      "loss": 0.5135,
      "step": 4774
    },
    {
      "epoch": 0.33,
      "grad_norm": 3.1655012941475893,
      "learning_rate": 7.79316334359937e-06,
      "loss": 0.5174,
      "step": 4775
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.9020800369893696,
      "learning_rate": 7.792229335631158e-06,
      "loss": 0.5208,
      "step": 4776
    },
    {
      "epoch": 0.33,
      "grad_norm": 4.147112220182778,
      "learning_rate": 7.791295186050176e-06,
      "loss": 0.5217,
      "step": 4777
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.209503002802142,
      "learning_rate": 7.790360894903802e-06,
      "loss": 0.4754,
      "step": 4778
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.091102362034983,
      "learning_rate": 7.789426462239421e-06,
      "loss": 0.5393,
      "step": 4779
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.1891644356578057,
      "learning_rate": 7.788491888104423e-06,
      "loss": 0.46,
      "step": 4780
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.0263547153188077,
      "learning_rate": 7.787557172546209e-06,
      "loss": 0.5131,
      "step": 4781
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.661423000759407,
      "learning_rate": 7.786622315612182e-06,
      "loss": 0.5043,
      "step": 4782
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.5955788575552545,
      "learning_rate": 7.785687317349757e-06,
      "loss": 0.4726,
      "step": 4783
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.1724936211776043,
      "learning_rate": 7.784752177806353e-06,
      "loss": 0.4896,
      "step": 4784
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.229881805745913,
      "learning_rate": 7.783816897029398e-06,
      "loss": 0.4981,
      "step": 4785
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.7184626856014883,
      "learning_rate": 7.782881475066324e-06,
      "loss": 0.467,
      "step": 4786
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.4998642564256808,
      "learning_rate": 7.781945911964574e-06,
      "loss": 0.5452,
      "step": 4787
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.9101232172231117,
      "learning_rate": 7.7810102077716e-06,
      "loss": 0.5214,
      "step": 4788
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.019676156987633,
      "learning_rate": 7.780074362534852e-06,
      "loss": 0.5379,
      "step": 4789
    },
    {
      "epoch": 0.33,
      "grad_norm": 3.0546718200520435,
      "learning_rate": 7.779138376301797e-06,
      "loss": 0.515,
      "step": 4790
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.47436526301264,
      "learning_rate": 7.778202249119905e-06,
      "loss": 0.512,
      "step": 4791
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.1182858959144912,
      "learning_rate": 7.77726598103665e-06,
      "loss": 0.5293,
      "step": 4792
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.356513987034762,
      "learning_rate": 7.77632957209952e-06,
      "loss": 0.5508,
      "step": 4793
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.7329359418590102,
      "learning_rate": 7.775393022356006e-06,
      "loss": 0.5343,
      "step": 4794
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.481100821757449,
      "learning_rate": 7.774456331853607e-06,
      "loss": 0.4909,
      "step": 4795
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.0751013287493563,
      "learning_rate": 7.773519500639826e-06,
      "loss": 0.5183,
      "step": 4796
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.288322819673797,
      "learning_rate": 7.772582528762179e-06,
      "loss": 0.5419,
      "step": 4797
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.9691187129967445,
      "learning_rate": 7.771645416268186e-06,
      "loss": 0.5221,
      "step": 4798
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5923680054852486,
      "learning_rate": 7.770708163205372e-06,
      "loss": 0.4409,
      "step": 4799
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.291199946717141,
      "learning_rate": 7.769770769621274e-06,
      "loss": 0.4953,
      "step": 4800
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.4061799391722216,
      "learning_rate": 7.768833235563433e-06,
      "loss": 0.5349,
      "step": 4801
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.3444312177373337,
      "learning_rate": 7.767895561079397e-06,
      "loss": 0.4922,
      "step": 4802
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.0588237223175296,
      "learning_rate": 7.76695774621672e-06,
      "loss": 0.5009,
      "step": 4803
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.902815122096465,
      "learning_rate": 7.76601979102297e-06,
      "loss": 0.4607,
      "step": 4804
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.821190887592362,
      "learning_rate": 7.765081695545712e-06,
      "loss": 0.5196,
      "step": 4805
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.7729489025575456,
      "learning_rate": 7.764143459832527e-06,
      "loss": 0.4756,
      "step": 4806
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.9074564316071818,
      "learning_rate": 7.763205083930995e-06,
      "loss": 0.5328,
      "step": 4807
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.680028484510861,
      "learning_rate": 7.762266567888712e-06,
      "loss": 0.4519,
      "step": 4808
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.7198740568560669,
      "learning_rate": 7.761327911753271e-06,
      "loss": 0.5531,
      "step": 4809
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6587510665467444,
      "learning_rate": 7.760389115572283e-06,
      "loss": 0.4417,
      "step": 4810
    },
    {
      "epoch": 0.33,
      "grad_norm": 3.8499399565079404,
      "learning_rate": 7.759450179393358e-06,
      "loss": 0.5346,
      "step": 4811
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.565036538209103,
      "learning_rate": 7.758511103264116e-06,
      "loss": 0.5575,
      "step": 4812
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.3887699411387153,
      "learning_rate": 7.757571887232185e-06,
      "loss": 0.5426,
      "step": 4813
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.9112660745871741,
      "learning_rate": 7.756632531345198e-06,
      "loss": 0.4727,
      "step": 4814
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.799954135154691,
      "learning_rate": 7.755693035650794e-06,
      "loss": 0.4828,
      "step": 4815
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.0003216964955257,
      "learning_rate": 7.754753400196627e-06,
      "loss": 0.4754,
      "step": 4816
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.344447806291711,
      "learning_rate": 7.753813625030344e-06,
      "loss": 0.4682,
      "step": 4817
    },
    {
      "epoch": 0.34,
      "grad_norm": 3.261171377441612,
      "learning_rate": 7.752873710199616e-06,
      "loss": 0.5158,
      "step": 4818
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.214743967914403,
      "learning_rate": 7.751933655752106e-06,
      "loss": 0.4835,
      "step": 4819
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.769094428952628,
      "learning_rate": 7.750993461735495e-06,
      "loss": 0.5051,
      "step": 4820
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.485710786651685,
      "learning_rate": 7.750053128197461e-06,
      "loss": 0.5804,
      "step": 4821
    },
    {
      "epoch": 0.34,
      "grad_norm": 3.2833134127836674,
      "learning_rate": 7.7491126551857e-06,
      "loss": 0.503,
      "step": 4822
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.037183636412484,
      "learning_rate": 7.748172042747908e-06,
      "loss": 0.486,
      "step": 4823
    },
    {
      "epoch": 0.34,
      "grad_norm": 3.522563060666532,
      "learning_rate": 7.74723129093179e-06,
      "loss": 0.4835,
      "step": 4824
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.1461418236416616,
      "learning_rate": 7.746290399785055e-06,
      "loss": 0.5139,
      "step": 4825
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.745836060230339,
      "learning_rate": 7.745349369355426e-06,
      "loss": 0.4731,
      "step": 4826
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.052208854244138,
      "learning_rate": 7.744408199690628e-06,
      "loss": 0.536,
      "step": 4827
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.373857819055284,
      "learning_rate": 7.743466890838393e-06,
      "loss": 0.4347,
      "step": 4828
    },
    {
      "epoch": 0.34,
      "grad_norm": 7.398147804478675,
      "learning_rate": 7.742525442846461e-06,
      "loss": 0.5082,
      "step": 4829
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.7300527959154937,
      "learning_rate": 7.74158385576258e-06,
      "loss": 0.5152,
      "step": 4830
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.5922153940765584,
      "learning_rate": 7.740642129634503e-06,
      "loss": 0.5102,
      "step": 4831
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.8636727415398893,
      "learning_rate": 7.739700264509993e-06,
      "loss": 0.5127,
      "step": 4832
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.286346047936732,
      "learning_rate": 7.738758260436817e-06,
      "loss": 0.5451,
      "step": 4833
    },
    {
      "epoch": 0.34,
      "grad_norm": 4.001977510078564,
      "learning_rate": 7.737816117462752e-06,
      "loss": 0.5334,
      "step": 4834
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.858531872707748,
      "learning_rate": 7.736873835635578e-06,
      "loss": 0.4913,
      "step": 4835
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.9647680916712968,
      "learning_rate": 7.73593141500309e-06,
      "loss": 0.5324,
      "step": 4836
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.5034938803488895,
      "learning_rate": 7.734988855613074e-06,
      "loss": 0.4997,
      "step": 4837
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.446272460230606,
      "learning_rate": 7.734046157513342e-06,
      "loss": 0.5467,
      "step": 4838
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.8837737374469095,
      "learning_rate": 7.733103320751703e-06,
      "loss": 0.5331,
      "step": 4839
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.9655398541687419,
      "learning_rate": 7.732160345375974e-06,
      "loss": 0.4822,
      "step": 4840
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.871105525789314,
      "learning_rate": 7.73121723143398e-06,
      "loss": 0.5005,
      "step": 4841
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.525687500194259,
      "learning_rate": 7.730273978973552e-06,
      "loss": 0.5252,
      "step": 4842
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.4454281373215943,
      "learning_rate": 7.72933058804253e-06,
      "loss": 0.4573,
      "step": 4843
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.5766953989532784,
      "learning_rate": 7.728387058688756e-06,
      "loss": 0.5056,
      "step": 4844
    },
    {
      "epoch": 0.34,
      "grad_norm": 27.97393858034375,
      "learning_rate": 7.727443390960087e-06,
      "loss": 0.5273,
      "step": 4845
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.2498306307862945,
      "learning_rate": 7.72649958490438e-06,
      "loss": 0.5212,
      "step": 4846
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.0788472064914414,
      "learning_rate": 7.725555640569506e-06,
      "loss": 0.58,
      "step": 4847
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.1179448272219665,
      "learning_rate": 7.724611558003333e-06,
      "loss": 0.5643,
      "step": 4848
    },
    {
      "epoch": 0.34,
      "grad_norm": 5.028064624520121,
      "learning_rate": 7.723667337253745e-06,
      "loss": 0.5228,
      "step": 4849
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.224960725911393,
      "learning_rate": 7.722722978368631e-06,
      "loss": 0.5121,
      "step": 4850
    },
    {
      "epoch": 0.34,
      "grad_norm": 4.567678362223646,
      "learning_rate": 7.721778481395883e-06,
      "loss": 0.528,
      "step": 4851
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.1136540933484627,
      "learning_rate": 7.720833846383403e-06,
      "loss": 0.4689,
      "step": 4852
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.444443615221693,
      "learning_rate": 7.719889073379102e-06,
      "loss": 0.5386,
      "step": 4853
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.1051531421213503,
      "learning_rate": 7.718944162430894e-06,
      "loss": 0.4883,
      "step": 4854
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.524720633583983,
      "learning_rate": 7.717999113586703e-06,
      "loss": 0.5001,
      "step": 4855
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.9012865624315025,
      "learning_rate": 7.717053926894458e-06,
      "loss": 0.5269,
      "step": 4856
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.470781246776169,
      "learning_rate": 7.716108602402094e-06,
      "loss": 0.5031,
      "step": 4857
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.7442193553080878,
      "learning_rate": 7.715163140157558e-06,
      "loss": 0.4576,
      "step": 4858
    },
    {
      "epoch": 0.34,
      "grad_norm": 4.277716823858241,
      "learning_rate": 7.714217540208802e-06,
      "loss": 0.535,
      "step": 4859
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.9776206625259083,
      "learning_rate": 7.713271802603777e-06,
      "loss": 0.4516,
      "step": 4860
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.231716782614636,
      "learning_rate": 7.712325927390454e-06,
      "loss": 0.5633,
      "step": 4861
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.2105478004732126,
      "learning_rate": 7.711379914616803e-06,
      "loss": 0.5342,
      "step": 4862
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.0360733865554903,
      "learning_rate": 7.710433764330802e-06,
      "loss": 0.5353,
      "step": 4863
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.215313313687492,
      "learning_rate": 7.709487476580436e-06,
      "loss": 0.5057,
      "step": 4864
    },
    {
      "epoch": 0.34,
      "grad_norm": 5.18117298266395,
      "learning_rate": 7.7085410514137e-06,
      "loss": 0.5171,
      "step": 4865
    },
    {
      "epoch": 0.34,
      "grad_norm": 3.565705038256913,
      "learning_rate": 7.707594488878592e-06,
      "loss": 0.5173,
      "step": 4866
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.7477047819818203,
      "learning_rate": 7.706647789023119e-06,
      "loss": 0.5492,
      "step": 4867
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.8026936924617263,
      "learning_rate": 7.705700951895292e-06,
      "loss": 0.4653,
      "step": 4868
    },
    {
      "epoch": 0.34,
      "grad_norm": 3.1549917697720473,
      "learning_rate": 7.704753977543138e-06,
      "loss": 0.549,
      "step": 4869
    },
    {
      "epoch": 0.34,
      "grad_norm": 3.478591463481703,
      "learning_rate": 7.703806866014677e-06,
      "loss": 0.5107,
      "step": 4870
    },
    {
      "epoch": 0.34,
      "grad_norm": 4.05056585336473,
      "learning_rate": 7.702859617357948e-06,
      "loss": 0.5294,
      "step": 4871
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6662378135969086,
      "learning_rate": 7.70191223162099e-06,
      "loss": 0.4602,
      "step": 4872
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.8942573289758347,
      "learning_rate": 7.700964708851852e-06,
      "loss": 0.5075,
      "step": 4873
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6478207939412345,
      "learning_rate": 7.70001704909859e-06,
      "loss": 0.4653,
      "step": 4874
    },
    {
      "epoch": 0.34,
      "grad_norm": 3.195495962383532,
      "learning_rate": 7.699069252409268e-06,
      "loss": 0.4962,
      "step": 4875
    },
    {
      "epoch": 0.34,
      "grad_norm": 4.608443325752443,
      "learning_rate": 7.698121318831952e-06,
      "loss": 0.4966,
      "step": 4876
    },
    {
      "epoch": 0.34,
      "grad_norm": 3.17350240708594,
      "learning_rate": 7.697173248414718e-06,
      "loss": 0.4956,
      "step": 4877
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.3713706722539563,
      "learning_rate": 7.69622504120565e-06,
      "loss": 0.5347,
      "step": 4878
    },
    {
      "epoch": 0.34,
      "grad_norm": 3.114502603794678,
      "learning_rate": 7.69527669725284e-06,
      "loss": 0.4866,
      "step": 4879
    },
    {
      "epoch": 0.34,
      "grad_norm": 3.257579690567695,
      "learning_rate": 7.69432821660438e-06,
      "loss": 0.5837,
      "step": 4880
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.4885931003668227,
      "learning_rate": 7.69337959930838e-06,
      "loss": 0.5205,
      "step": 4881
    },
    {
      "epoch": 0.34,
      "grad_norm": 3.053058059770659,
      "learning_rate": 7.692430845412946e-06,
      "loss": 0.5261,
      "step": 4882
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.3347235047466195,
      "learning_rate": 7.691481954966197e-06,
      "loss": 0.5192,
      "step": 4883
    },
    {
      "epoch": 0.34,
      "grad_norm": 3.6879505282613843,
      "learning_rate": 7.690532928016259e-06,
      "loss": 0.5394,
      "step": 4884
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.9640600140556943,
      "learning_rate": 7.689583764611261e-06,
      "loss": 0.5126,
      "step": 4885
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.3226933430487033,
      "learning_rate": 7.688634464799344e-06,
      "loss": 0.5182,
      "step": 4886
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.6713134956603664,
      "learning_rate": 7.687685028628653e-06,
      "loss": 0.5212,
      "step": 4887
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.1658663259820594,
      "learning_rate": 7.68673545614734e-06,
      "loss": 0.5308,
      "step": 4888
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.082631565674417,
      "learning_rate": 7.685785747403564e-06,
      "loss": 0.5227,
      "step": 4889
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.8138664712393595,
      "learning_rate": 7.684835902445489e-06,
      "loss": 0.5428,
      "step": 4890
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.179822485884628,
      "learning_rate": 7.683885921321293e-06,
      "loss": 0.5128,
      "step": 4891
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.051060389905209,
      "learning_rate": 7.68293580407915e-06,
      "loss": 0.5158,
      "step": 4892
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.3009433916024746,
      "learning_rate": 7.68198555076725e-06,
      "loss": 0.5289,
      "step": 4893
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.9340702675947892,
      "learning_rate": 7.681035161433789e-06,
      "loss": 0.531,
      "step": 4894
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.7398947941627847,
      "learning_rate": 7.680084636126964e-06,
      "loss": 0.4786,
      "step": 4895
    },
    {
      "epoch": 0.34,
      "grad_norm": 3.1751807352205814,
      "learning_rate": 7.679133974894984e-06,
      "loss": 0.5156,
      "step": 4896
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.8872962546075165,
      "learning_rate": 7.678183177786063e-06,
      "loss": 0.5086,
      "step": 4897
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.2122252590116864,
      "learning_rate": 7.677232244848423e-06,
      "loss": 0.4994,
      "step": 4898
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.113292195035374,
      "learning_rate": 7.67628117613029e-06,
      "loss": 0.5429,
      "step": 4899
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.896103045188627,
      "learning_rate": 7.675329971679905e-06,
      "loss": 0.5426,
      "step": 4900
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.1962285749010353,
      "learning_rate": 7.674378631545504e-06,
      "loss": 0.5078,
      "step": 4901
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.8816768914429824,
      "learning_rate": 7.673427155775336e-06,
      "loss": 0.4856,
      "step": 4902
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6856986442997112,
      "learning_rate": 7.672475544417662e-06,
      "loss": 0.451,
      "step": 4903
    },
    {
      "epoch": 0.34,
      "grad_norm": 3.2903715700010423,
      "learning_rate": 7.671523797520736e-06,
      "loss": 0.5056,
      "step": 4904
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.3918615327524506,
      "learning_rate": 7.670571915132837e-06,
      "loss": 0.5658,
      "step": 4905
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.944943058635423,
      "learning_rate": 7.669619897302236e-06,
      "loss": 0.5257,
      "step": 4906
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.8280570866976524,
      "learning_rate": 7.668667744077215e-06,
      "loss": 0.5234,
      "step": 4907
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.6883285592709036,
      "learning_rate": 7.66771545550607e-06,
      "loss": 0.5063,
      "step": 4908
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.9456375026691046,
      "learning_rate": 7.666763031637092e-06,
      "loss": 0.492,
      "step": 4909
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.7288896484215193,
      "learning_rate": 7.66581047251859e-06,
      "loss": 0.5292,
      "step": 4910
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.483893470327364,
      "learning_rate": 7.664857778198868e-06,
      "loss": 0.5721,
      "step": 4911
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.7482329023125652,
      "learning_rate": 7.66390494872625e-06,
      "loss": 0.4905,
      "step": 4912
    },
    {
      "epoch": 0.34,
      "grad_norm": 3.002670489672888,
      "learning_rate": 7.662951984149057e-06,
      "loss": 0.4667,
      "step": 4913
    },
    {
      "epoch": 0.34,
      "grad_norm": 3.36179963050994,
      "learning_rate": 7.66199888451562e-06,
      "loss": 0.5473,
      "step": 4914
    },
    {
      "epoch": 0.34,
      "grad_norm": 3.2525745867838007,
      "learning_rate": 7.661045649874279e-06,
      "loss": 0.5219,
      "step": 4915
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.9661752031686675,
      "learning_rate": 7.66009228027338e-06,
      "loss": 0.51,
      "step": 4916
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.206524005667557,
      "learning_rate": 7.65913877576127e-06,
      "loss": 0.5357,
      "step": 4917
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.762864659800331,
      "learning_rate": 7.65818513638631e-06,
      "loss": 0.4652,
      "step": 4918
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.7290838665605532,
      "learning_rate": 7.65723136219687e-06,
      "loss": 0.5321,
      "step": 4919
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.213940182719535,
      "learning_rate": 7.656277453241316e-06,
      "loss": 0.4884,
      "step": 4920
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.786439302575051,
      "learning_rate": 7.65532340956803e-06,
      "loss": 0.5461,
      "step": 4921
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.5006382008216574,
      "learning_rate": 7.654369231225398e-06,
      "loss": 0.5217,
      "step": 4922
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.3647116412527476,
      "learning_rate": 7.653414918261812e-06,
      "loss": 0.5342,
      "step": 4923
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.7767506048330202,
      "learning_rate": 7.652460470725671e-06,
      "loss": 0.5616,
      "step": 4924
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.987236238603116,
      "learning_rate": 7.651505888665384e-06,
      "loss": 0.4756,
      "step": 4925
    },
    {
      "epoch": 0.34,
      "grad_norm": 3.5017616989296454,
      "learning_rate": 7.650551172129362e-06,
      "loss": 0.5042,
      "step": 4926
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.8030853903339028,
      "learning_rate": 7.649596321166024e-06,
      "loss": 0.5038,
      "step": 4927
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.9233178880917705,
      "learning_rate": 7.648641335823802e-06,
      "loss": 0.4954,
      "step": 4928
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.0217656735607665,
      "learning_rate": 7.647686216151124e-06,
      "loss": 0.5166,
      "step": 4929
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.6495792132369174,
      "learning_rate": 7.646730962196436e-06,
      "loss": 0.5219,
      "step": 4930
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.992295531111637,
      "learning_rate": 7.645775574008181e-06,
      "loss": 0.4859,
      "step": 4931
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.9812943447078997,
      "learning_rate": 7.644820051634813e-06,
      "loss": 0.4897,
      "step": 4932
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.070056006960676,
      "learning_rate": 7.643864395124796e-06,
      "loss": 0.4923,
      "step": 4933
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.7812256968113114,
      "learning_rate": 7.642908604526596e-06,
      "loss": 0.5834,
      "step": 4934
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.9221474094201874,
      "learning_rate": 7.641952679888687e-06,
      "loss": 0.4889,
      "step": 4935
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.1346134436044326,
      "learning_rate": 7.640996621259553e-06,
      "loss": 0.5279,
      "step": 4936
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.7201827272999206,
      "learning_rate": 7.64004042868768e-06,
      "loss": 0.5074,
      "step": 4937
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.8756813111390098,
      "learning_rate": 7.639084102221563e-06,
      "loss": 0.538,
      "step": 4938
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.3501463477197886,
      "learning_rate": 7.638127641909705e-06,
      "loss": 0.488,
      "step": 4939
    },
    {
      "epoch": 0.34,
      "grad_norm": 3.2534786986414987,
      "learning_rate": 7.637171047800613e-06,
      "loss": 0.5028,
      "step": 4940
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.832921464070629,
      "learning_rate": 7.636214319942804e-06,
      "loss": 0.5626,
      "step": 4941
    },
    {
      "epoch": 0.34,
      "grad_norm": 4.692311372419486,
      "learning_rate": 7.635257458384799e-06,
      "loss": 0.5129,
      "step": 4942
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.3021966444523247,
      "learning_rate": 7.634300463175128e-06,
      "loss": 0.5852,
      "step": 4943
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.4214134556274307,
      "learning_rate": 7.633343334362324e-06,
      "loss": 0.5036,
      "step": 4944
    },
    {
      "epoch": 0.34,
      "grad_norm": 4.754275978633933,
      "learning_rate": 7.632386071994932e-06,
      "loss": 0.4791,
      "step": 4945
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.9542138976183097,
      "learning_rate": 7.631428676121502e-06,
      "loss": 0.5003,
      "step": 4946
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.8490009427862113,
      "learning_rate": 7.630471146790586e-06,
      "loss": 0.5228,
      "step": 4947
    },
    {
      "epoch": 0.34,
      "grad_norm": 3.09890573547422,
      "learning_rate": 7.62951348405075e-06,
      "loss": 0.5296,
      "step": 4948
    },
    {
      "epoch": 0.34,
      "grad_norm": 4.808502289440157,
      "learning_rate": 7.628555687950563e-06,
      "loss": 0.5416,
      "step": 4949
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6894691305761779,
      "learning_rate": 7.627597758538602e-06,
      "loss": 0.4526,
      "step": 4950
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.7277664980554766,
      "learning_rate": 7.626639695863447e-06,
      "loss": 0.4955,
      "step": 4951
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.74672857337318,
      "learning_rate": 7.625681499973693e-06,
      "loss": 0.5377,
      "step": 4952
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.4846077607529833,
      "learning_rate": 7.624723170917931e-06,
      "loss": 0.5296,
      "step": 4953
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.8812619285004653,
      "learning_rate": 7.623764708744767e-06,
      "loss": 0.4985,
      "step": 4954
    },
    {
      "epoch": 0.34,
      "grad_norm": 3.343194794469749,
      "learning_rate": 7.622806113502813e-06,
      "loss": 0.5187,
      "step": 4955
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.9928111174763794,
      "learning_rate": 7.6218473852406826e-06,
      "loss": 0.4974,
      "step": 4956
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.2342945709247464,
      "learning_rate": 7.6208885240069995e-06,
      "loss": 0.5029,
      "step": 4957
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.7650602593503795,
      "learning_rate": 7.619929529850397e-06,
      "loss": 0.5278,
      "step": 4958
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.9696445936903917,
      "learning_rate": 7.618970402819509e-06,
      "loss": 0.5342,
      "step": 4959
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.193385939068897,
      "learning_rate": 7.61801114296298e-06,
      "loss": 0.5511,
      "step": 4960
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.116288301506015,
      "learning_rate": 7.617051750329462e-06,
      "loss": 0.5237,
      "step": 4961
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.8941012232543388,
      "learning_rate": 7.61609222496761e-06,
      "loss": 0.5559,
      "step": 4962
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.9765022835856945,
      "learning_rate": 7.6151325669260915e-06,
      "loss": 0.482,
      "step": 4963
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.164217275688331,
      "learning_rate": 7.614172776253573e-06,
      "loss": 0.5165,
      "step": 4964
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.3372614576492583,
      "learning_rate": 7.613212852998735e-06,
      "loss": 0.5408,
      "step": 4965
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.34766729692619,
      "learning_rate": 7.61225279721026e-06,
      "loss": 0.4921,
      "step": 4966
    },
    {
      "epoch": 0.35,
      "grad_norm": 5.589544724309397,
      "learning_rate": 7.611292608936841e-06,
      "loss": 0.5608,
      "step": 4967
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.818772728406986,
      "learning_rate": 7.610332288227173e-06,
      "loss": 0.4391,
      "step": 4968
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.9412374219150184,
      "learning_rate": 7.609371835129962e-06,
      "loss": 0.4705,
      "step": 4969
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.330420335806335,
      "learning_rate": 7.6084112496939185e-06,
      "loss": 0.514,
      "step": 4970
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.333615844103652,
      "learning_rate": 7.6074505319677595e-06,
      "loss": 0.5536,
      "step": 4971
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.3050062733154237,
      "learning_rate": 7.606489682000211e-06,
      "loss": 0.4937,
      "step": 4972
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.3425046296266827,
      "learning_rate": 7.605528699840004e-06,
      "loss": 0.4916,
      "step": 4973
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.902229804671396,
      "learning_rate": 7.604567585535875e-06,
      "loss": 0.5314,
      "step": 4974
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.153919770102112,
      "learning_rate": 7.6036063391365685e-06,
      "loss": 0.4626,
      "step": 4975
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.4058262856014663,
      "learning_rate": 7.6026449606908395e-06,
      "loss": 0.5064,
      "step": 4976
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.7035036793447162,
      "learning_rate": 7.6016834502474415e-06,
      "loss": 0.4802,
      "step": 4977
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.7339178688632904,
      "learning_rate": 7.600721807855141e-06,
      "loss": 0.5291,
      "step": 4978
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.7518599030150273,
      "learning_rate": 7.599760033562708e-06,
      "loss": 0.499,
      "step": 4979
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.9847969974993869,
      "learning_rate": 7.598798127418923e-06,
      "loss": 0.5592,
      "step": 4980
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.0029636866502982,
      "learning_rate": 7.59783608947257e-06,
      "loss": 0.5295,
      "step": 4981
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.4306649261067386,
      "learning_rate": 7.596873919772438e-06,
      "loss": 0.5532,
      "step": 4982
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.4399965106678754,
      "learning_rate": 7.59591161836733e-06,
      "loss": 0.488,
      "step": 4983
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.878774602711635,
      "learning_rate": 7.5949491853060465e-06,
      "loss": 0.4878,
      "step": 4984
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.3794229136499743,
      "learning_rate": 7.5939866206374006e-06,
      "loss": 0.4726,
      "step": 4985
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.9226303503750426,
      "learning_rate": 7.593023924410209e-06,
      "loss": 0.5536,
      "step": 4986
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.449125609911391,
      "learning_rate": 7.592061096673299e-06,
      "loss": 0.5161,
      "step": 4987
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.0695305329018763,
      "learning_rate": 7.591098137475501e-06,
      "loss": 0.5404,
      "step": 4988
    },
    {
      "epoch": 0.35,
      "grad_norm": 3.2022615798862497,
      "learning_rate": 7.590135046865652e-06,
      "loss": 0.467,
      "step": 4989
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.8991165060927429,
      "learning_rate": 7.589171824892599e-06,
      "loss": 0.5093,
      "step": 4990
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.999323746544893,
      "learning_rate": 7.588208471605191e-06,
      "loss": 0.5579,
      "step": 4991
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.021197297867078,
      "learning_rate": 7.587244987052287e-06,
      "loss": 0.4793,
      "step": 4992
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.446599272169367,
      "learning_rate": 7.586281371282753e-06,
      "loss": 0.5125,
      "step": 4993
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.8915011592268336,
      "learning_rate": 7.585317624345459e-06,
      "loss": 0.5079,
      "step": 4994
    },
    {
      "epoch": 0.35,
      "grad_norm": 4.0259365380007965,
      "learning_rate": 7.584353746289283e-06,
      "loss": 0.5063,
      "step": 4995
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.8828470748027515,
      "learning_rate": 7.583389737163112e-06,
      "loss": 0.5344,
      "step": 4996
    },
    {
      "epoch": 0.35,
      "grad_norm": 3.0374661600511312,
      "learning_rate": 7.582425597015837e-06,
      "loss": 0.4929,
      "step": 4997
    },
    {
      "epoch": 0.35,
      "grad_norm": 3.6087812433546302,
      "learning_rate": 7.5814613258963535e-06,
      "loss": 0.5261,
      "step": 4998
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.3574646889251043,
      "learning_rate": 7.580496923853567e-06,
      "loss": 0.5023,
      "step": 4999
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.8212453086564264,
      "learning_rate": 7.579532390936391e-06,
      "loss": 0.4698,
      "step": 5000
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.8127770635064073,
      "learning_rate": 7.578567727193739e-06,
      "loss": 0.5226,
      "step": 5001
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.291737307735593,
      "learning_rate": 7.577602932674542e-06,
      "loss": 0.5026,
      "step": 5002
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.374216322488554,
      "learning_rate": 7.576638007427725e-06,
      "loss": 0.502,
      "step": 5003
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.995706465670761,
      "learning_rate": 7.575672951502229e-06,
      "loss": 0.4888,
      "step": 5004
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.3170055723358822,
      "learning_rate": 7.574707764946999e-06,
      "loss": 0.5436,
      "step": 5005
    },
    {
      "epoch": 0.35,
      "grad_norm": 3.08737775921136,
      "learning_rate": 7.5737424478109844e-06,
      "loss": 0.5177,
      "step": 5006
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.079099940326965,
      "learning_rate": 7.572777000143145e-06,
      "loss": 0.5182,
      "step": 5007
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.8543910245723826,
      "learning_rate": 7.571811421992442e-06,
      "loss": 0.4731,
      "step": 5008
    },
    {
      "epoch": 0.35,
      "grad_norm": 4.3184495371182265,
      "learning_rate": 7.57084571340785e-06,
      "loss": 0.5261,
      "step": 5009
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.7298438178388214,
      "learning_rate": 7.5698798744383436e-06,
      "loss": 0.5302,
      "step": 5010
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.814695747674982,
      "learning_rate": 7.568913905132911e-06,
      "loss": 0.5119,
      "step": 5011
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.674797338158811,
      "learning_rate": 7.567947805540536e-06,
      "loss": 0.475,
      "step": 5012
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.273194358991056,
      "learning_rate": 7.566981575710224e-06,
      "loss": 0.5227,
      "step": 5013
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.239231806616703,
      "learning_rate": 7.566015215690973e-06,
      "loss": 0.534,
      "step": 5014
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.479494571949089,
      "learning_rate": 7.565048725531797e-06,
      "loss": 0.4918,
      "step": 5015
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.5651612920872626,
      "learning_rate": 7.564082105281711e-06,
      "loss": 0.5255,
      "step": 5016
    },
    {
      "epoch": 0.35,
      "grad_norm": 4.078752683013544,
      "learning_rate": 7.563115354989742e-06,
      "loss": 0.5481,
      "step": 5017
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.2022354313345,
      "learning_rate": 7.562148474704916e-06,
      "loss": 0.5156,
      "step": 5018
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.555656058739279,
      "learning_rate": 7.561181464476275e-06,
      "loss": 0.5141,
      "step": 5019
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.3713952416889423,
      "learning_rate": 7.560214324352858e-06,
      "loss": 0.5215,
      "step": 5020
    },
    {
      "epoch": 0.35,
      "grad_norm": 3.1406404128685836,
      "learning_rate": 7.559247054383718e-06,
      "loss": 0.5669,
      "step": 5021
    },
    {
      "epoch": 0.35,
      "grad_norm": 4.898328294493636,
      "learning_rate": 7.5582796546179125e-06,
      "loss": 0.5122,
      "step": 5022
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.691671903088651,
      "learning_rate": 7.557312125104501e-06,
      "loss": 0.5066,
      "step": 5023
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.9580350685530188,
      "learning_rate": 7.556344465892557e-06,
      "loss": 0.5374,
      "step": 5024
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.175555369792885,
      "learning_rate": 7.555376677031156e-06,
      "loss": 0.5046,
      "step": 5025
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.344813809336599,
      "learning_rate": 7.5544087585693805e-06,
      "loss": 0.5037,
      "step": 5026
    },
    {
      "epoch": 0.35,
      "grad_norm": 3.277948903705201,
      "learning_rate": 7.553440710556321e-06,
      "loss": 0.4918,
      "step": 5027
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.246227546671934,
      "learning_rate": 7.552472533041073e-06,
      "loss": 0.5362,
      "step": 5028
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.2677722448555295,
      "learning_rate": 7.551504226072739e-06,
      "loss": 0.5343,
      "step": 5029
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.0674265299969323,
      "learning_rate": 7.55053578970043e-06,
      "loss": 0.5475,
      "step": 5030
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.027292257680904,
      "learning_rate": 7.549567223973261e-06,
      "loss": 0.5211,
      "step": 5031
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.3874109256240614,
      "learning_rate": 7.548598528940354e-06,
      "loss": 0.5123,
      "step": 5032
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.8962013574287047,
      "learning_rate": 7.547629704650839e-06,
      "loss": 0.4424,
      "step": 5033
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.9692976275359348,
      "learning_rate": 7.546660751153851e-06,
      "loss": 0.5546,
      "step": 5034
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.6854639302394147,
      "learning_rate": 7.5456916684985325e-06,
      "loss": 0.4418,
      "step": 5035
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.8245795492599763,
      "learning_rate": 7.54472245673403e-06,
      "loss": 0.5409,
      "step": 5036
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.32360182013456,
      "learning_rate": 7.543753115909504e-06,
      "loss": 0.5413,
      "step": 5037
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.0037725139289555,
      "learning_rate": 7.542783646074111e-06,
      "loss": 0.4891,
      "step": 5038
    },
    {
      "epoch": 0.35,
      "grad_norm": 5.739010242281316,
      "learning_rate": 7.541814047277023e-06,
      "loss": 0.5304,
      "step": 5039
    },
    {
      "epoch": 0.35,
      "grad_norm": 4.906825899586936,
      "learning_rate": 7.540844319567411e-06,
      "loss": 0.4791,
      "step": 5040
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.506170220511611,
      "learning_rate": 7.53987446299446e-06,
      "loss": 0.5134,
      "step": 5041
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.3499128219485494,
      "learning_rate": 7.5389044776073565e-06,
      "loss": 0.5153,
      "step": 5042
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.257859855012505,
      "learning_rate": 7.537934363455296e-06,
      "loss": 0.4867,
      "step": 5043
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.262288182176086,
      "learning_rate": 7.536964120587478e-06,
      "loss": 0.5039,
      "step": 5044
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.185641260180329,
      "learning_rate": 7.535993749053111e-06,
      "loss": 0.5432,
      "step": 5045
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.3920505314366785,
      "learning_rate": 7.535023248901409e-06,
      "loss": 0.5136,
      "step": 5046
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.3931039635470213,
      "learning_rate": 7.534052620181591e-06,
      "loss": 0.4791,
      "step": 5047
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.2172328178521745,
      "learning_rate": 7.533081862942888e-06,
      "loss": 0.5027,
      "step": 5048
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.5287837884205864,
      "learning_rate": 7.5321109772345305e-06,
      "loss": 0.4958,
      "step": 5049
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.0262256279482456,
      "learning_rate": 7.531139963105758e-06,
      "loss": 0.5121,
      "step": 5050
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.8825181030379492,
      "learning_rate": 7.530168820605819e-06,
      "loss": 0.5058,
      "step": 5051
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.449779370652453,
      "learning_rate": 7.529197549783967e-06,
      "loss": 0.5527,
      "step": 5052
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.790394746892136,
      "learning_rate": 7.528226150689461e-06,
      "loss": 0.5311,
      "step": 5053
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.5674255204500542,
      "learning_rate": 7.527254623371567e-06,
      "loss": 0.533,
      "step": 5054
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.0855378439593846,
      "learning_rate": 7.526282967879558e-06,
      "loss": 0.5322,
      "step": 5055
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.253102864813553,
      "learning_rate": 7.525311184262714e-06,
      "loss": 0.5318,
      "step": 5056
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.854342194419955,
      "learning_rate": 7.524339272570317e-06,
      "loss": 0.5345,
      "step": 5057
    },
    {
      "epoch": 0.35,
      "grad_norm": 3.1204717130853745,
      "learning_rate": 7.523367232851664e-06,
      "loss": 0.5049,
      "step": 5058
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.8646173671475774,
      "learning_rate": 7.522395065156049e-06,
      "loss": 0.5366,
      "step": 5059
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.530652883181931,
      "learning_rate": 7.5214227695327825e-06,
      "loss": 0.4914,
      "step": 5060
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.25265598630055,
      "learning_rate": 7.520450346031172e-06,
      "loss": 0.4931,
      "step": 5061
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.0759345716929496,
      "learning_rate": 7.519477794700538e-06,
      "loss": 0.5176,
      "step": 5062
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.4376466626329383,
      "learning_rate": 7.518505115590204e-06,
      "loss": 0.5429,
      "step": 5063
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.9046189536992768,
      "learning_rate": 7.5175323087495025e-06,
      "loss": 0.5078,
      "step": 5064
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.9505583342665114,
      "learning_rate": 7.5165593742277676e-06,
      "loss": 0.4644,
      "step": 5065
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.7997329792746675,
      "learning_rate": 7.5155863120743475e-06,
      "loss": 0.5019,
      "step": 5066
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.975207995908452,
      "learning_rate": 7.5146131223385895e-06,
      "loss": 0.5424,
      "step": 5067
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.317781679992994,
      "learning_rate": 7.513639805069855e-06,
      "loss": 0.5763,
      "step": 5068
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.194059630168068,
      "learning_rate": 7.5126663603175e-06,
      "loss": 0.5675,
      "step": 5069
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.431226426022407,
      "learning_rate": 7.511692788130902e-06,
      "loss": 0.507,
      "step": 5070
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.9527276055293648,
      "learning_rate": 7.510719088559433e-06,
      "loss": 0.5302,
      "step": 5071
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.145084164246023,
      "learning_rate": 7.509745261652479e-06,
      "loss": 0.5375,
      "step": 5072
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.7443690081295216,
      "learning_rate": 7.508771307459426e-06,
      "loss": 0.4869,
      "step": 5073
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.319159381514958,
      "learning_rate": 7.507797226029672e-06,
      "loss": 0.4868,
      "step": 5074
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.161118226384368,
      "learning_rate": 7.506823017412617e-06,
      "loss": 0.493,
      "step": 5075
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.289106291504954,
      "learning_rate": 7.505848681657674e-06,
      "loss": 0.4544,
      "step": 5076
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.0102496494520024,
      "learning_rate": 7.504874218814253e-06,
      "loss": 0.5182,
      "step": 5077
    },
    {
      "epoch": 0.35,
      "grad_norm": 3.203334561175475,
      "learning_rate": 7.503899628931781e-06,
      "loss": 0.5226,
      "step": 5078
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.8216981556315313,
      "learning_rate": 7.502924912059679e-06,
      "loss": 0.5118,
      "step": 5079
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.176696784536238,
      "learning_rate": 7.501950068247389e-06,
      "loss": 0.5335,
      "step": 5080
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.9379633430794443,
      "learning_rate": 7.500975097544346e-06,
      "loss": 0.5548,
      "step": 5081
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.1266103786764938,
      "learning_rate": 7.500000000000001e-06,
      "loss": 0.4892,
      "step": 5082
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.4270870821126684,
      "learning_rate": 7.499024775663806e-06,
      "loss": 0.498,
      "step": 5083
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.5529673730728657,
      "learning_rate": 7.498049424585222e-06,
      "loss": 0.5437,
      "step": 5084
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.7206215812886283,
      "learning_rate": 7.497073946813714e-06,
      "loss": 0.5234,
      "step": 5085
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.8199210099574827,
      "learning_rate": 7.496098342398758e-06,
      "loss": 0.4763,
      "step": 5086
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.0448361392810868,
      "learning_rate": 7.495122611389831e-06,
      "loss": 0.4909,
      "step": 5087
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.684931762250596,
      "learning_rate": 7.49414675383642e-06,
      "loss": 0.5061,
      "step": 5088
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.4107999188400586,
      "learning_rate": 7.4931707697880175e-06,
      "loss": 0.5684,
      "step": 5089
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.44813331101774,
      "learning_rate": 7.4921946592941206e-06,
      "loss": 0.5569,
      "step": 5090
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.3008079019315857,
      "learning_rate": 7.491218422404236e-06,
      "loss": 0.5789,
      "step": 5091
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.295863102206832,
      "learning_rate": 7.490242059167876e-06,
      "loss": 0.5152,
      "step": 5092
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.188376157121026,
      "learning_rate": 7.489265569634556e-06,
      "loss": 0.5021,
      "step": 5093
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.450357846564931,
      "learning_rate": 7.488288953853802e-06,
      "loss": 0.5193,
      "step": 5094
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.235974767734962,
      "learning_rate": 7.487312211875144e-06,
      "loss": 0.5342,
      "step": 5095
    },
    {
      "epoch": 0.35,
      "grad_norm": 3.0047243086234525,
      "learning_rate": 7.486335343748121e-06,
      "loss": 0.4803,
      "step": 5096
    },
    {
      "epoch": 0.35,
      "grad_norm": 7.4140680021740835,
      "learning_rate": 7.4853583495222745e-06,
      "loss": 0.4722,
      "step": 5097
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.4086585187276066,
      "learning_rate": 7.484381229247156e-06,
      "loss": 0.5248,
      "step": 5098
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.602803284844091,
      "learning_rate": 7.4834039829723214e-06,
      "loss": 0.5076,
      "step": 5099
    },
    {
      "epoch": 0.35,
      "grad_norm": 3.4132306784868582,
      "learning_rate": 7.482426610747333e-06,
      "loss": 0.4604,
      "step": 5100
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.9440311543352646,
      "learning_rate": 7.481449112621758e-06,
      "loss": 0.5133,
      "step": 5101
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.4448345356512005,
      "learning_rate": 7.480471488645175e-06,
      "loss": 0.517,
      "step": 5102
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.344161432907007,
      "learning_rate": 7.479493738867166e-06,
      "loss": 0.5255,
      "step": 5103
    },
    {
      "epoch": 0.35,
      "grad_norm": 4.031230605888784,
      "learning_rate": 7.478515863337317e-06,
      "loss": 0.5129,
      "step": 5104
    },
    {
      "epoch": 0.35,
      "grad_norm": 4.109013952919986,
      "learning_rate": 7.477537862105224e-06,
      "loss": 0.5,
      "step": 5105
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.8523563795327768,
      "learning_rate": 7.4765597352204885e-06,
      "loss": 0.4692,
      "step": 5106
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.114368714367275,
      "learning_rate": 7.475581482732717e-06,
      "loss": 0.4897,
      "step": 5107
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.105739076105253,
      "learning_rate": 7.4746031046915234e-06,
      "loss": 0.5035,
      "step": 5108
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.0339804629836755,
      "learning_rate": 7.473624601146529e-06,
      "loss": 0.5174,
      "step": 5109
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.5412580381636327,
      "learning_rate": 7.472645972147359e-06,
      "loss": 0.5112,
      "step": 5110
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.0901328816161366,
      "learning_rate": 7.471667217743646e-06,
      "loss": 0.5168,
      "step": 5111
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.8751878840810057,
      "learning_rate": 7.470688337985029e-06,
      "loss": 0.4826,
      "step": 5112
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.0113856166930026,
      "learning_rate": 7.469709332921155e-06,
      "loss": 0.542,
      "step": 5113
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.510436397055307,
      "learning_rate": 7.4687302026016765e-06,
      "loss": 0.4872,
      "step": 5114
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.4199693303374255,
      "learning_rate": 7.46775094707625e-06,
      "loss": 0.5094,
      "step": 5115
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.219072050660978,
      "learning_rate": 7.466771566394539e-06,
      "loss": 0.5,
      "step": 5116
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.446426369203396,
      "learning_rate": 7.465792060606218e-06,
      "loss": 0.5517,
      "step": 5117
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.1819486420268883,
      "learning_rate": 7.464812429760963e-06,
      "loss": 0.5188,
      "step": 5118
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.2444814359466125,
      "learning_rate": 7.463832673908458e-06,
      "loss": 0.5217,
      "step": 5119
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.676979987238077,
      "learning_rate": 7.46285279309839e-06,
      "loss": 0.4786,
      "step": 5120
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.8554091101719354,
      "learning_rate": 7.4618727873804586e-06,
      "loss": 0.5501,
      "step": 5121
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.227057099912009,
      "learning_rate": 7.460892656804366e-06,
      "loss": 0.5302,
      "step": 5122
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.741664323120344,
      "learning_rate": 7.4599124014198225e-06,
      "loss": 0.5042,
      "step": 5123
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.327481651764198,
      "learning_rate": 7.458932021276538e-06,
      "loss": 0.518,
      "step": 5124
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.1448697619857517,
      "learning_rate": 7.457951516424241e-06,
      "loss": 0.5213,
      "step": 5125
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.869726922151946,
      "learning_rate": 7.456970886912655e-06,
      "loss": 0.5538,
      "step": 5126
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7684366005099577,
      "learning_rate": 7.455990132791516e-06,
      "loss": 0.4648,
      "step": 5127
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.8253255303354694,
      "learning_rate": 7.455009254110565e-06,
      "loss": 0.5146,
      "step": 5128
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.202443429764813,
      "learning_rate": 7.454028250919547e-06,
      "loss": 0.5968,
      "step": 5129
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5779824264877758,
      "learning_rate": 7.453047123268218e-06,
      "loss": 0.4468,
      "step": 5130
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.1945610413647203,
      "learning_rate": 7.452065871206336e-06,
      "loss": 0.5473,
      "step": 5131
    },
    {
      "epoch": 0.36,
      "grad_norm": 4.009090278653568,
      "learning_rate": 7.451084494783668e-06,
      "loss": 0.506,
      "step": 5132
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.8950163989641904,
      "learning_rate": 7.450102994049985e-06,
      "loss": 0.5728,
      "step": 5133
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.85748927980677,
      "learning_rate": 7.449121369055066e-06,
      "loss": 0.6067,
      "step": 5134
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.259938115041518,
      "learning_rate": 7.448139619848695e-06,
      "loss": 0.5213,
      "step": 5135
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.2438425587452673,
      "learning_rate": 7.4471577464806635e-06,
      "loss": 0.5041,
      "step": 5136
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.9405385996678823,
      "learning_rate": 7.44617574900077e-06,
      "loss": 0.5198,
      "step": 5137
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.270795224088366,
      "learning_rate": 7.445193627458818e-06,
      "loss": 0.5426,
      "step": 5138
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.9369574306648243,
      "learning_rate": 7.4442113819046154e-06,
      "loss": 0.5006,
      "step": 5139
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.371980608406771,
      "learning_rate": 7.443229012387982e-06,
      "loss": 0.5455,
      "step": 5140
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.8345006550128693,
      "learning_rate": 7.442246518958738e-06,
      "loss": 0.5106,
      "step": 5141
    },
    {
      "epoch": 0.36,
      "grad_norm": 4.57671194907274,
      "learning_rate": 7.441263901666711e-06,
      "loss": 0.5456,
      "step": 5142
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.9258034341528307,
      "learning_rate": 7.4402811605617395e-06,
      "loss": 0.5353,
      "step": 5143
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.238192968940537,
      "learning_rate": 7.4392982956936644e-06,
      "loss": 0.5292,
      "step": 5144
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.184153085697301,
      "learning_rate": 7.438315307112331e-06,
      "loss": 0.5466,
      "step": 5145
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.0289882302915836,
      "learning_rate": 7.437332194867595e-06,
      "loss": 0.5139,
      "step": 5146
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.3577959020299475,
      "learning_rate": 7.436348959009316e-06,
      "loss": 0.5504,
      "step": 5147
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.1599243135311745,
      "learning_rate": 7.43536559958736e-06,
      "loss": 0.5602,
      "step": 5148
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.5043721958199314,
      "learning_rate": 7.4343821166516015e-06,
      "loss": 0.5862,
      "step": 5149
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.9960075280562575,
      "learning_rate": 7.433398510251918e-06,
      "loss": 0.5301,
      "step": 5150
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.0052424641243283,
      "learning_rate": 7.4324147804381956e-06,
      "loss": 0.5273,
      "step": 5151
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.840256330699494,
      "learning_rate": 7.431430927260326e-06,
      "loss": 0.4715,
      "step": 5152
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.7331199176036534,
      "learning_rate": 7.430446950768207e-06,
      "loss": 0.5752,
      "step": 5153
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.1033285848456593,
      "learning_rate": 7.4294628510117405e-06,
      "loss": 0.5455,
      "step": 5154
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.461349807117097,
      "learning_rate": 7.428478628040841e-06,
      "loss": 0.568,
      "step": 5155
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.6676581071904428,
      "learning_rate": 7.427494281905421e-06,
      "loss": 0.518,
      "step": 5156
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.490398968458805,
      "learning_rate": 7.4265098126554065e-06,
      "loss": 0.52,
      "step": 5157
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.2329558791430038,
      "learning_rate": 7.425525220340723e-06,
      "loss": 0.5255,
      "step": 5158
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7583029626463761,
      "learning_rate": 7.424540505011311e-06,
      "loss": 0.4754,
      "step": 5159
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.443375652029835,
      "learning_rate": 7.423555666717107e-06,
      "loss": 0.5054,
      "step": 5160
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.0333823073318964,
      "learning_rate": 7.422570705508062e-06,
      "loss": 0.5072,
      "step": 5161
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.5228134740386814,
      "learning_rate": 7.421585621434128e-06,
      "loss": 0.5182,
      "step": 5162
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.772640672185636,
      "learning_rate": 7.420600414545266e-06,
      "loss": 0.5211,
      "step": 5163
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.59935565077666,
      "learning_rate": 7.419615084891443e-06,
      "loss": 0.5319,
      "step": 5164
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.158309733289702,
      "learning_rate": 7.4186296325226315e-06,
      "loss": 0.5314,
      "step": 5165
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.2485809726564105,
      "learning_rate": 7.41764405748881e-06,
      "loss": 0.5449,
      "step": 5166
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.428409820649616,
      "learning_rate": 7.416658359839964e-06,
      "loss": 0.4917,
      "step": 5167
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.1155664017112366,
      "learning_rate": 7.415672539626084e-06,
      "loss": 0.487,
      "step": 5168
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.4913146877254158,
      "learning_rate": 7.414686596897169e-06,
      "loss": 0.5387,
      "step": 5169
    },
    {
      "epoch": 0.36,
      "grad_norm": 5.988677493368368,
      "learning_rate": 7.413700531703223e-06,
      "loss": 0.5535,
      "step": 5170
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.8257353306130872,
      "learning_rate": 7.4127143440942525e-06,
      "loss": 0.5639,
      "step": 5171
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.615659407452253,
      "learning_rate": 7.411728034120279e-06,
      "loss": 0.49,
      "step": 5172
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.44382691161156,
      "learning_rate": 7.41074160183132e-06,
      "loss": 0.5074,
      "step": 5173
    },
    {
      "epoch": 0.36,
      "grad_norm": 4.688829593643387,
      "learning_rate": 7.409755047277409e-06,
      "loss": 0.517,
      "step": 5174
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.928989503636903,
      "learning_rate": 7.408768370508577e-06,
      "loss": 0.5171,
      "step": 5175
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.094531493515904,
      "learning_rate": 7.407781571574866e-06,
      "loss": 0.5101,
      "step": 5176
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.8592958356177198,
      "learning_rate": 7.406794650526324e-06,
      "loss": 0.4752,
      "step": 5177
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.254344527824663,
      "learning_rate": 7.4058076074130044e-06,
      "loss": 0.5562,
      "step": 5178
    },
    {
      "epoch": 0.36,
      "grad_norm": 4.068884419650945,
      "learning_rate": 7.404820442284966e-06,
      "loss": 0.4752,
      "step": 5179
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.9936039160493386,
      "learning_rate": 7.403833155192275e-06,
      "loss": 0.4737,
      "step": 5180
    },
    {
      "epoch": 0.36,
      "grad_norm": 4.684832564438887,
      "learning_rate": 7.4028457461850015e-06,
      "loss": 0.5029,
      "step": 5181
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.9786128509857075,
      "learning_rate": 7.401858215313228e-06,
      "loss": 0.5274,
      "step": 5182
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.967351474533195,
      "learning_rate": 7.400870562627034e-06,
      "loss": 0.5231,
      "step": 5183
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.355841496670602,
      "learning_rate": 7.399882788176515e-06,
      "loss": 0.523,
      "step": 5184
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.8308570814764151,
      "learning_rate": 7.398894892011762e-06,
      "loss": 0.483,
      "step": 5185
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.6172077235926126,
      "learning_rate": 7.397906874182883e-06,
      "loss": 0.504,
      "step": 5186
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.0763491574464363,
      "learning_rate": 7.396918734739985e-06,
      "loss": 0.5442,
      "step": 5187
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.058960110860895,
      "learning_rate": 7.395930473733183e-06,
      "loss": 0.5246,
      "step": 5188
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.3500922104725737,
      "learning_rate": 7.394942091212598e-06,
      "loss": 0.4691,
      "step": 5189
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.855125134212107,
      "learning_rate": 7.393953587228359e-06,
      "loss": 0.546,
      "step": 5190
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.25043302993555,
      "learning_rate": 7.392964961830598e-06,
      "loss": 0.5029,
      "step": 5191
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.5232247278633344,
      "learning_rate": 7.391976215069456e-06,
      "loss": 0.4875,
      "step": 5192
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.0240941531509042,
      "learning_rate": 7.390987346995078e-06,
      "loss": 0.5326,
      "step": 5193
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.99396018844608,
      "learning_rate": 7.389998357657617e-06,
      "loss": 0.5021,
      "step": 5194
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.7669300884637893,
      "learning_rate": 7.389009247107232e-06,
      "loss": 0.5203,
      "step": 5195
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.258601949636292,
      "learning_rate": 7.388020015394086e-06,
      "loss": 0.5551,
      "step": 5196
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7357683524734879,
      "learning_rate": 7.38703066256835e-06,
      "loss": 0.4518,
      "step": 5197
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.2357276869379823,
      "learning_rate": 7.386041188680202e-06,
      "loss": 0.524,
      "step": 5198
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.348544863359894,
      "learning_rate": 7.3850515937798225e-06,
      "loss": 0.5288,
      "step": 5199
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.4186345530604068,
      "learning_rate": 7.3840618779174034e-06,
      "loss": 0.577,
      "step": 5200
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.519639524872649,
      "learning_rate": 7.383072041143137e-06,
      "loss": 0.5449,
      "step": 5201
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.228017989450665,
      "learning_rate": 7.382082083507226e-06,
      "loss": 0.5182,
      "step": 5202
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.0780443090286935,
      "learning_rate": 7.381092005059878e-06,
      "loss": 0.4181,
      "step": 5203
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.836651582348479,
      "learning_rate": 7.380101805851307e-06,
      "loss": 0.47,
      "step": 5204
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.259765872879785,
      "learning_rate": 7.379111485931731e-06,
      "loss": 0.479,
      "step": 5205
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.41313254184052,
      "learning_rate": 7.378121045351378e-06,
      "loss": 0.5316,
      "step": 5206
    },
    {
      "epoch": 0.36,
      "grad_norm": 7.88911173734466,
      "learning_rate": 7.3771304841604764e-06,
      "loss": 0.5286,
      "step": 5207
    },
    {
      "epoch": 0.36,
      "grad_norm": 4.091890003025081,
      "learning_rate": 7.376139802409268e-06,
      "loss": 0.5141,
      "step": 5208
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6798540505523675,
      "learning_rate": 7.375149000147995e-06,
      "loss": 0.4582,
      "step": 5209
    },
    {
      "epoch": 0.36,
      "grad_norm": 6.153158124766853,
      "learning_rate": 7.37415807742691e-06,
      "loss": 0.4876,
      "step": 5210
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.986434971681826,
      "learning_rate": 7.3731670342962655e-06,
      "loss": 0.5336,
      "step": 5211
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.357647325488373,
      "learning_rate": 7.372175870806327e-06,
      "loss": 0.5293,
      "step": 5212
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.3522333621016,
      "learning_rate": 7.3711845870073615e-06,
      "loss": 0.5229,
      "step": 5213
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.203393115295462,
      "learning_rate": 7.370193182949645e-06,
      "loss": 0.5205,
      "step": 5214
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.0794912827206273,
      "learning_rate": 7.369201658683456e-06,
      "loss": 0.5521,
      "step": 5215
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.748477603757091,
      "learning_rate": 7.3682100142590855e-06,
      "loss": 0.4886,
      "step": 5216
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.3438569613067806,
      "learning_rate": 7.367218249726821e-06,
      "loss": 0.5186,
      "step": 5217
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.85046061818596,
      "learning_rate": 7.366226365136966e-06,
      "loss": 0.4837,
      "step": 5218
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.400556533178488,
      "learning_rate": 7.365234360539824e-06,
      "loss": 0.4911,
      "step": 5219
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.599104343343338,
      "learning_rate": 7.3642422359857055e-06,
      "loss": 0.5616,
      "step": 5220
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.1010764724425757,
      "learning_rate": 7.36324999152493e-06,
      "loss": 0.5307,
      "step": 5221
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.028053165186592,
      "learning_rate": 7.362257627207818e-06,
      "loss": 0.5109,
      "step": 5222
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.458845176983407,
      "learning_rate": 7.361265143084703e-06,
      "loss": 0.5445,
      "step": 5223
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.071400461785985,
      "learning_rate": 7.360272539205917e-06,
      "loss": 0.5193,
      "step": 5224
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.524976295419588,
      "learning_rate": 7.359279815621801e-06,
      "loss": 0.495,
      "step": 5225
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.3009346044610828,
      "learning_rate": 7.3582869723827065e-06,
      "loss": 0.5035,
      "step": 5226
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.727487047247536,
      "learning_rate": 7.3572940095389845e-06,
      "loss": 0.4956,
      "step": 5227
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.01918098166251,
      "learning_rate": 7.356300927140996e-06,
      "loss": 0.5073,
      "step": 5228
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.4112497208630583,
      "learning_rate": 7.355307725239104e-06,
      "loss": 0.5378,
      "step": 5229
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.592996921394164,
      "learning_rate": 7.3543144038836865e-06,
      "loss": 0.5597,
      "step": 5230
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.8264362343530955,
      "learning_rate": 7.3533209631251155e-06,
      "loss": 0.5285,
      "step": 5231
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.8979345078895022,
      "learning_rate": 7.352327403013779e-06,
      "loss": 0.4899,
      "step": 5232
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.227223974515931,
      "learning_rate": 7.351333723600065e-06,
      "loss": 0.5356,
      "step": 5233
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.7596662199190596,
      "learning_rate": 7.35033992493437e-06,
      "loss": 0.5784,
      "step": 5234
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.2490160689236354,
      "learning_rate": 7.3493460070670975e-06,
      "loss": 0.5118,
      "step": 5235
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.09830809009621,
      "learning_rate": 7.348351970048654e-06,
      "loss": 0.4383,
      "step": 5236
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.8837521746870944,
      "learning_rate": 7.347357813929455e-06,
      "loss": 0.49,
      "step": 5237
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.090380894845896,
      "learning_rate": 7.34636353875992e-06,
      "loss": 0.5315,
      "step": 5238
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.211809293184168,
      "learning_rate": 7.345369144590476e-06,
      "loss": 0.5097,
      "step": 5239
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.1500169687430795,
      "learning_rate": 7.3443746314715554e-06,
      "loss": 0.4819,
      "step": 5240
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.411166758513922,
      "learning_rate": 7.343379999453597e-06,
      "loss": 0.5117,
      "step": 5241
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6981926809012354,
      "learning_rate": 7.342385248587044e-06,
      "loss": 0.461,
      "step": 5242
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.1236762631714474,
      "learning_rate": 7.34139037892235e-06,
      "loss": 0.4945,
      "step": 5243
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.040563294250098,
      "learning_rate": 7.340395390509968e-06,
      "loss": 0.5446,
      "step": 5244
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.3901127562280875,
      "learning_rate": 7.339400283400362e-06,
      "loss": 0.4972,
      "step": 5245
    },
    {
      "epoch": 0.36,
      "grad_norm": 7.02191171318842,
      "learning_rate": 7.338405057643999e-06,
      "loss": 0.5441,
      "step": 5246
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.8838231691872476,
      "learning_rate": 7.337409713291357e-06,
      "loss": 0.515,
      "step": 5247
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.1676472704518535,
      "learning_rate": 7.336414250392914e-06,
      "loss": 0.5522,
      "step": 5248
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.925254361610765,
      "learning_rate": 7.335418668999158e-06,
      "loss": 0.5099,
      "step": 5249
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.128989899318786,
      "learning_rate": 7.33442296916058e-06,
      "loss": 0.4817,
      "step": 5250
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.8525089813811133,
      "learning_rate": 7.33342715092768e-06,
      "loss": 0.4988,
      "step": 5251
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.350094562971126,
      "learning_rate": 7.332431214350962e-06,
      "loss": 0.5099,
      "step": 5252
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.0793802035914335,
      "learning_rate": 7.331435159480938e-06,
      "loss": 0.5303,
      "step": 5253
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.0619981849003457,
      "learning_rate": 7.330438986368124e-06,
      "loss": 0.5159,
      "step": 5254
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.2115575404020538,
      "learning_rate": 7.329442695063041e-06,
      "loss": 0.5241,
      "step": 5255
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.3018820814810277,
      "learning_rate": 7.32844628561622e-06,
      "loss": 0.549,
      "step": 5256
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.964564553360202,
      "learning_rate": 7.327449758078194e-06,
      "loss": 0.4639,
      "step": 5257
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.4478502658429138,
      "learning_rate": 7.326453112499503e-06,
      "loss": 0.5296,
      "step": 5258
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.7144924513316082,
      "learning_rate": 7.325456348930696e-06,
      "loss": 0.5429,
      "step": 5259
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.3832950314699755,
      "learning_rate": 7.324459467422323e-06,
      "loss": 0.5415,
      "step": 5260
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.2362026641230437,
      "learning_rate": 7.323462468024947e-06,
      "loss": 0.5035,
      "step": 5261
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.2750180722708957,
      "learning_rate": 7.322465350789126e-06,
      "loss": 0.5248,
      "step": 5262
    },
    {
      "epoch": 0.37,
      "grad_norm": 4.005321230173637,
      "learning_rate": 7.321468115765438e-06,
      "loss": 0.5158,
      "step": 5263
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.079071482944448,
      "learning_rate": 7.320470763004452e-06,
      "loss": 0.5308,
      "step": 5264
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.849110414550886,
      "learning_rate": 7.319473292556756e-06,
      "loss": 0.5532,
      "step": 5265
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.8736906073737853,
      "learning_rate": 7.318475704472936e-06,
      "loss": 0.5359,
      "step": 5266
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.9970829437241928,
      "learning_rate": 7.3174779988035885e-06,
      "loss": 0.4803,
      "step": 5267
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.030114027006437,
      "learning_rate": 7.31648017559931e-06,
      "loss": 0.5697,
      "step": 5268
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.1753625633746534,
      "learning_rate": 7.3154822349107106e-06,
      "loss": 0.5556,
      "step": 5269
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.090513117629989,
      "learning_rate": 7.314484176788399e-06,
      "loss": 0.5253,
      "step": 5270
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6897704074508669,
      "learning_rate": 7.313486001282998e-06,
      "loss": 0.4764,
      "step": 5271
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.4774132282151324,
      "learning_rate": 7.312487708445127e-06,
      "loss": 0.4522,
      "step": 5272
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.9932280144092056,
      "learning_rate": 7.311489298325422e-06,
      "loss": 0.4856,
      "step": 5273
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.087023687775448,
      "learning_rate": 7.310490770974512e-06,
      "loss": 0.5137,
      "step": 5274
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.4112194268777345,
      "learning_rate": 7.309492126443045e-06,
      "loss": 0.5206,
      "step": 5275
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.3757232579726044,
      "learning_rate": 7.308493364781666e-06,
      "loss": 0.5228,
      "step": 5276
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.0215551475436144,
      "learning_rate": 7.30749448604103e-06,
      "loss": 0.5332,
      "step": 5277
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.009405876155048,
      "learning_rate": 7.3064954902717966e-06,
      "loss": 0.4687,
      "step": 5278
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.7865664635234828,
      "learning_rate": 7.305496377524632e-06,
      "loss": 0.4907,
      "step": 5279
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.7328365912847,
      "learning_rate": 7.304497147850207e-06,
      "loss": 0.5075,
      "step": 5280
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7252945645056145,
      "learning_rate": 7.3034978012991996e-06,
      "loss": 0.4542,
      "step": 5281
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.974682053132488,
      "learning_rate": 7.302498337922293e-06,
      "loss": 0.5141,
      "step": 5282
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.5080900648187585,
      "learning_rate": 7.301498757770178e-06,
      "loss": 0.5083,
      "step": 5283
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.5774919119638624,
      "learning_rate": 7.300499060893549e-06,
      "loss": 0.5114,
      "step": 5284
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.9465068581681724,
      "learning_rate": 7.299499247343108e-06,
      "loss": 0.5146,
      "step": 5285
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.410501631257355,
      "learning_rate": 7.298499317169562e-06,
      "loss": 0.4423,
      "step": 5286
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.3303746566588788,
      "learning_rate": 7.297499270423623e-06,
      "loss": 0.532,
      "step": 5287
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.5081906569864594,
      "learning_rate": 7.296499107156013e-06,
      "loss": 0.5016,
      "step": 5288
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.462220837001772,
      "learning_rate": 7.295498827417455e-06,
      "loss": 0.5566,
      "step": 5289
    },
    {
      "epoch": 0.37,
      "grad_norm": 6.546879138136232,
      "learning_rate": 7.29449843125868e-06,
      "loss": 0.5066,
      "step": 5290
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.164505460346423,
      "learning_rate": 7.293497918730425e-06,
      "loss": 0.5253,
      "step": 5291
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.092762148323152,
      "learning_rate": 7.292497289883432e-06,
      "loss": 0.5396,
      "step": 5292
    },
    {
      "epoch": 0.37,
      "grad_norm": 3.856455829610332,
      "learning_rate": 7.291496544768452e-06,
      "loss": 0.4843,
      "step": 5293
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.7099895097629387,
      "learning_rate": 7.290495683436236e-06,
      "loss": 0.5682,
      "step": 5294
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.3166186958836694,
      "learning_rate": 7.289494705937548e-06,
      "loss": 0.5046,
      "step": 5295
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.0145239980953247,
      "learning_rate": 7.2884936123231506e-06,
      "loss": 0.503,
      "step": 5296
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.070880101177524,
      "learning_rate": 7.28749240264382e-06,
      "loss": 0.5253,
      "step": 5297
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.538847408109394,
      "learning_rate": 7.286491076950333e-06,
      "loss": 0.5625,
      "step": 5298
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.9881675819921216,
      "learning_rate": 7.285489635293472e-06,
      "loss": 0.5503,
      "step": 5299
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.3699357734990234,
      "learning_rate": 7.284488077724028e-06,
      "loss": 0.4842,
      "step": 5300
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.7385782206641123,
      "learning_rate": 7.283486404292796e-06,
      "loss": 0.4916,
      "step": 5301
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.2982132975906984,
      "learning_rate": 7.282484615050578e-06,
      "loss": 0.5187,
      "step": 5302
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.39348185607813,
      "learning_rate": 7.2814827100481825e-06,
      "loss": 0.5523,
      "step": 5303
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.0547125549789533,
      "learning_rate": 7.280480689336423e-06,
      "loss": 0.4837,
      "step": 5304
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.9990371239943165,
      "learning_rate": 7.279478552966115e-06,
      "loss": 0.4891,
      "step": 5305
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.993377921846666,
      "learning_rate": 7.2784763009880875e-06,
      "loss": 0.4794,
      "step": 5306
    },
    {
      "epoch": 0.37,
      "grad_norm": 4.4905641874442095,
      "learning_rate": 7.27747393345317e-06,
      "loss": 0.5139,
      "step": 5307
    },
    {
      "epoch": 0.37,
      "grad_norm": 3.380830589444735,
      "learning_rate": 7.276471450412201e-06,
      "loss": 0.5346,
      "step": 5308
    },
    {
      "epoch": 0.37,
      "grad_norm": 5.182095001996268,
      "learning_rate": 7.27546885191602e-06,
      "loss": 0.5191,
      "step": 5309
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7146456289834966,
      "learning_rate": 7.274466138015479e-06,
      "loss": 0.4386,
      "step": 5310
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.0183381752661242,
      "learning_rate": 7.27346330876143e-06,
      "loss": 0.5474,
      "step": 5311
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.3521781496729375,
      "learning_rate": 7.272460364204734e-06,
      "loss": 0.4733,
      "step": 5312
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.20629487372041,
      "learning_rate": 7.271457304396256e-06,
      "loss": 0.5072,
      "step": 5313
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.606262372138073,
      "learning_rate": 7.2704541293868705e-06,
      "loss": 0.5052,
      "step": 5314
    },
    {
      "epoch": 0.37,
      "grad_norm": 3.2185091020047807,
      "learning_rate": 7.269450839227452e-06,
      "loss": 0.5339,
      "step": 5315
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6811377314643139,
      "learning_rate": 7.268447433968887e-06,
      "loss": 0.4541,
      "step": 5316
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.843266846426336,
      "learning_rate": 7.2674439136620626e-06,
      "loss": 0.4961,
      "step": 5317
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.7983505050564688,
      "learning_rate": 7.266440278357876e-06,
      "loss": 0.5592,
      "step": 5318
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.3093940540137834,
      "learning_rate": 7.265436528107227e-06,
      "loss": 0.5182,
      "step": 5319
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.215431037598768,
      "learning_rate": 7.264432662961023e-06,
      "loss": 0.5247,
      "step": 5320
    },
    {
      "epoch": 0.37,
      "grad_norm": 3.122577048572856,
      "learning_rate": 7.263428682970178e-06,
      "loss": 0.5098,
      "step": 5321
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.6413108916793586,
      "learning_rate": 7.2624245881856094e-06,
      "loss": 0.4938,
      "step": 5322
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.0624167484627884,
      "learning_rate": 7.261420378658239e-06,
      "loss": 0.5077,
      "step": 5323
    },
    {
      "epoch": 0.37,
      "grad_norm": 3.0966611550938294,
      "learning_rate": 7.260416054439002e-06,
      "loss": 0.4803,
      "step": 5324
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.9910317415304266,
      "learning_rate": 7.259411615578832e-06,
      "loss": 0.5038,
      "step": 5325
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.8495744136512493,
      "learning_rate": 7.2584070621286705e-06,
      "loss": 0.4681,
      "step": 5326
    },
    {
      "epoch": 0.37,
      "grad_norm": 4.899446451970375,
      "learning_rate": 7.257402394139466e-06,
      "loss": 0.4863,
      "step": 5327
    },
    {
      "epoch": 0.37,
      "grad_norm": 6.578527844469295,
      "learning_rate": 7.256397611662172e-06,
      "loss": 0.511,
      "step": 5328
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.266779762645931,
      "learning_rate": 7.255392714747744e-06,
      "loss": 0.5335,
      "step": 5329
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.8637882199213238,
      "learning_rate": 7.254387703447154e-06,
      "loss": 0.5173,
      "step": 5330
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.3877414068344747,
      "learning_rate": 7.253382577811368e-06,
      "loss": 0.5246,
      "step": 5331
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.0719770849417385,
      "learning_rate": 7.2523773378913655e-06,
      "loss": 0.5135,
      "step": 5332
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.385402182878568,
      "learning_rate": 7.251371983738127e-06,
      "loss": 0.5728,
      "step": 5333
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.7158650549191736,
      "learning_rate": 7.250366515402643e-06,
      "loss": 0.5027,
      "step": 5334
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.125862749218214,
      "learning_rate": 7.2493609329359025e-06,
      "loss": 0.5204,
      "step": 5335
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.0073850534513027,
      "learning_rate": 7.248355236388911e-06,
      "loss": 0.5221,
      "step": 5336
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.7174175122957225,
      "learning_rate": 7.247349425812671e-06,
      "loss": 0.492,
      "step": 5337
    },
    {
      "epoch": 0.37,
      "grad_norm": 3.267150260039753,
      "learning_rate": 7.246343501258195e-06,
      "loss": 0.4941,
      "step": 5338
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.945906638342843,
      "learning_rate": 7.2453374627765e-06,
      "loss": 0.4945,
      "step": 5339
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.7372270849006823,
      "learning_rate": 7.244331310418611e-06,
      "loss": 0.4934,
      "step": 5340
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.769813607716155,
      "learning_rate": 7.243325044235552e-06,
      "loss": 0.4821,
      "step": 5341
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.1564892309086052,
      "learning_rate": 7.242318664278363e-06,
      "loss": 0.4873,
      "step": 5342
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.9868974298728015,
      "learning_rate": 7.241312170598079e-06,
      "loss": 0.5131,
      "step": 5343
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.1048037375575706,
      "learning_rate": 7.240305563245751e-06,
      "loss": 0.5411,
      "step": 5344
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.2609072384446773,
      "learning_rate": 7.239298842272429e-06,
      "loss": 0.5709,
      "step": 5345
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.590375883520702,
      "learning_rate": 7.238292007729169e-06,
      "loss": 0.4932,
      "step": 5346
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.8354116472074524,
      "learning_rate": 7.237285059667036e-06,
      "loss": 0.5362,
      "step": 5347
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.625462802293098,
      "learning_rate": 7.236277998137099e-06,
      "loss": 0.5262,
      "step": 5348
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.1917942629141036,
      "learning_rate": 7.235270823190431e-06,
      "loss": 0.5513,
      "step": 5349
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.9261262820513765,
      "learning_rate": 7.234263534878116e-06,
      "loss": 0.5333,
      "step": 5350
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.582878016894758,
      "learning_rate": 7.2332561332512375e-06,
      "loss": 0.5113,
      "step": 5351
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.217709518164161,
      "learning_rate": 7.232248618360889e-06,
      "loss": 0.5288,
      "step": 5352
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.7802802414412406,
      "learning_rate": 7.231240990258169e-06,
      "loss": 0.5,
      "step": 5353
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.1181201019528664,
      "learning_rate": 7.2302332489941805e-06,
      "loss": 0.5402,
      "step": 5354
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.5640531242677023,
      "learning_rate": 7.229225394620032e-06,
      "loss": 0.4979,
      "step": 5355
    },
    {
      "epoch": 0.37,
      "grad_norm": 3.9404643161901842,
      "learning_rate": 7.228217427186839e-06,
      "loss": 0.5272,
      "step": 5356
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.6211431079854948,
      "learning_rate": 7.2272093467457226e-06,
      "loss": 0.4773,
      "step": 5357
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.6052074695879064,
      "learning_rate": 7.226201153347809e-06,
      "loss": 0.5207,
      "step": 5358
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.209069749654144,
      "learning_rate": 7.225192847044231e-06,
      "loss": 0.4923,
      "step": 5359
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.6525554488101684,
      "learning_rate": 7.224184427886125e-06,
      "loss": 0.5392,
      "step": 5360
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.6887732160569036,
      "learning_rate": 7.223175895924638e-06,
      "loss": 0.5057,
      "step": 5361
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.8822301682317701,
      "learning_rate": 7.222167251210916e-06,
      "loss": 0.5201,
      "step": 5362
    },
    {
      "epoch": 0.37,
      "grad_norm": 3.396663776299046,
      "learning_rate": 7.2211584937961175e-06,
      "loss": 0.5093,
      "step": 5363
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.513665834906214,
      "learning_rate": 7.220149623731401e-06,
      "loss": 0.5002,
      "step": 5364
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.2062069659809183,
      "learning_rate": 7.2191406410679325e-06,
      "loss": 0.5145,
      "step": 5365
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.9021903494498058,
      "learning_rate": 7.2181315458568864e-06,
      "loss": 0.5578,
      "step": 5366
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.3634657969145945,
      "learning_rate": 7.217122338149441e-06,
      "loss": 0.4967,
      "step": 5367
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.048838875042623,
      "learning_rate": 7.216113017996776e-06,
      "loss": 0.5368,
      "step": 5368
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.198310663988668,
      "learning_rate": 7.2151035854500866e-06,
      "loss": 0.5466,
      "step": 5369
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.0972498956424506,
      "learning_rate": 7.214094040560563e-06,
      "loss": 0.5215,
      "step": 5370
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.9845612356347468,
      "learning_rate": 7.213084383379409e-06,
      "loss": 0.5541,
      "step": 5371
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.7222038485523905,
      "learning_rate": 7.212074613957829e-06,
      "loss": 0.4945,
      "step": 5372
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.9420623569964472,
      "learning_rate": 7.211064732347038e-06,
      "loss": 0.523,
      "step": 5373
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.1636660851982175,
      "learning_rate": 7.2100547385982515e-06,
      "loss": 0.5027,
      "step": 5374
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.0701507035548974,
      "learning_rate": 7.209044632762694e-06,
      "loss": 0.5066,
      "step": 5375
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.8955443372786778,
      "learning_rate": 7.208034414891594e-06,
      "loss": 0.4721,
      "step": 5376
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.0951834510192207,
      "learning_rate": 7.207024085036188e-06,
      "loss": 0.5053,
      "step": 5377
    },
    {
      "epoch": 0.37,
      "grad_norm": 4.862629362785594,
      "learning_rate": 7.2060136432477145e-06,
      "loss": 0.5102,
      "step": 5378
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.1266212303638383,
      "learning_rate": 7.2050030895774225e-06,
      "loss": 0.4786,
      "step": 5379
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.358351321081687,
      "learning_rate": 7.203992424076561e-06,
      "loss": 0.5207,
      "step": 5380
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.5570612954528305,
      "learning_rate": 7.2029816467963906e-06,
      "loss": 0.5381,
      "step": 5381
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.5335958027837595,
      "learning_rate": 7.201970757788172e-06,
      "loss": 0.544,
      "step": 5382
    },
    {
      "epoch": 0.37,
      "grad_norm": 3.0034569900635417,
      "learning_rate": 7.200959757103176e-06,
      "loss": 0.5182,
      "step": 5383
    },
    {
      "epoch": 0.37,
      "grad_norm": 3.59865284856948,
      "learning_rate": 7.199948644792676e-06,
      "loss": 0.5294,
      "step": 5384
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7444403999459551,
      "learning_rate": 7.1989374209079545e-06,
      "loss": 0.4423,
      "step": 5385
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.9560115576514316,
      "learning_rate": 7.197926085500294e-06,
      "loss": 0.5194,
      "step": 5386
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.8024860023897762,
      "learning_rate": 7.19691463862099e-06,
      "loss": 0.5416,
      "step": 5387
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.9030828935905348,
      "learning_rate": 7.195903080321338e-06,
      "loss": 0.5517,
      "step": 5388
    },
    {
      "epoch": 0.37,
      "grad_norm": 4.176846921482148,
      "learning_rate": 7.19489141065264e-06,
      "loss": 0.5333,
      "step": 5389
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6738429636394339,
      "learning_rate": 7.193879629666205e-06,
      "loss": 0.4642,
      "step": 5390
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.317610063680613,
      "learning_rate": 7.192867737413348e-06,
      "loss": 0.5344,
      "step": 5391
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.7850057873175205,
      "learning_rate": 7.191855733945388e-06,
      "loss": 0.4878,
      "step": 5392
    },
    {
      "epoch": 0.37,
      "grad_norm": 2.3985929043897087,
      "learning_rate": 7.190843619313652e-06,
      "loss": 0.5224,
      "step": 5393
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.614602337378426,
      "learning_rate": 7.189831393569469e-06,
      "loss": 0.5151,
      "step": 5394
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.0532060295407963,
      "learning_rate": 7.188819056764178e-06,
      "loss": 0.495,
      "step": 5395
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.018314983531811,
      "learning_rate": 7.187806608949119e-06,
      "loss": 0.5296,
      "step": 5396
    },
    {
      "epoch": 0.38,
      "grad_norm": 6.969250012683575,
      "learning_rate": 7.186794050175643e-06,
      "loss": 0.5008,
      "step": 5397
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.224098471928065,
      "learning_rate": 7.1857813804951014e-06,
      "loss": 0.5453,
      "step": 5398
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.158262519162634,
      "learning_rate": 7.184768599958854e-06,
      "loss": 0.5005,
      "step": 5399
    },
    {
      "epoch": 0.38,
      "grad_norm": 7.492020958242446,
      "learning_rate": 7.1837557086182676e-06,
      "loss": 0.4954,
      "step": 5400
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.235831808146535,
      "learning_rate": 7.18274270652471e-06,
      "loss": 0.4943,
      "step": 5401
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.770539042194107,
      "learning_rate": 7.181729593729558e-06,
      "loss": 0.4871,
      "step": 5402
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.064772776079459,
      "learning_rate": 7.180716370284195e-06,
      "loss": 0.5259,
      "step": 5403
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6901036053386854,
      "learning_rate": 7.1797030362400056e-06,
      "loss": 0.4573,
      "step": 5404
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.630729743539826,
      "learning_rate": 7.1786895916483855e-06,
      "loss": 0.4355,
      "step": 5405
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.6969377287486527,
      "learning_rate": 7.177676036560732e-06,
      "loss": 0.5227,
      "step": 5406
    },
    {
      "epoch": 0.38,
      "grad_norm": 3.339442521544649,
      "learning_rate": 7.17666237102845e-06,
      "loss": 0.5138,
      "step": 5407
    },
    {
      "epoch": 0.38,
      "grad_norm": 3.5972013985272953,
      "learning_rate": 7.175648595102949e-06,
      "loss": 0.5248,
      "step": 5408
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.3380710113764636,
      "learning_rate": 7.174634708835644e-06,
      "loss": 0.5419,
      "step": 5409
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.5631572402876284,
      "learning_rate": 7.1736207122779555e-06,
      "loss": 0.5328,
      "step": 5410
    },
    {
      "epoch": 0.38,
      "grad_norm": 14.713856073317242,
      "learning_rate": 7.172606605481311e-06,
      "loss": 0.4745,
      "step": 5411
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.1487572378016195,
      "learning_rate": 7.171592388497144e-06,
      "loss": 0.4927,
      "step": 5412
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.406291058586991,
      "learning_rate": 7.170578061376889e-06,
      "loss": 0.4588,
      "step": 5413
    },
    {
      "epoch": 0.38,
      "grad_norm": 24.866297827296627,
      "learning_rate": 7.169563624171993e-06,
      "loss": 0.5034,
      "step": 5414
    },
    {
      "epoch": 0.38,
      "grad_norm": 3.7496701931359033,
      "learning_rate": 7.168549076933902e-06,
      "loss": 0.5017,
      "step": 5415
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.0480077624939894,
      "learning_rate": 7.167534419714072e-06,
      "loss": 0.5342,
      "step": 5416
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.558629511593948,
      "learning_rate": 7.1665196525639635e-06,
      "loss": 0.5135,
      "step": 5417
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.7200352102108702,
      "learning_rate": 7.16550477553504e-06,
      "loss": 0.5304,
      "step": 5418
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.114534888690919,
      "learning_rate": 7.1644897886787745e-06,
      "loss": 0.5586,
      "step": 5419
    },
    {
      "epoch": 0.38,
      "grad_norm": 3.060335538182831,
      "learning_rate": 7.163474692046644e-06,
      "loss": 0.5118,
      "step": 5420
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.9761174779166035,
      "learning_rate": 7.162459485690131e-06,
      "loss": 0.562,
      "step": 5421
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.1823299909055556,
      "learning_rate": 7.161444169660723e-06,
      "loss": 0.4936,
      "step": 5422
    },
    {
      "epoch": 0.38,
      "grad_norm": 5.971600407464036,
      "learning_rate": 7.160428744009913e-06,
      "loss": 0.4838,
      "step": 5423
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.658729755598266,
      "learning_rate": 7.1594132087892e-06,
      "loss": 0.4737,
      "step": 5424
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.9144534740103043,
      "learning_rate": 7.158397564050089e-06,
      "loss": 0.5168,
      "step": 5425
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.62783137775263,
      "learning_rate": 7.15738180984409e-06,
      "loss": 0.5182,
      "step": 5426
    },
    {
      "epoch": 0.38,
      "grad_norm": 3.056843265877,
      "learning_rate": 7.156365946222721e-06,
      "loss": 0.5334,
      "step": 5427
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.9859157347941945,
      "learning_rate": 7.155349973237499e-06,
      "loss": 0.5161,
      "step": 5428
    },
    {
      "epoch": 0.38,
      "grad_norm": 3.734754528768037,
      "learning_rate": 7.154333890939955e-06,
      "loss": 0.4848,
      "step": 5429
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.651433726135321,
      "learning_rate": 7.1533176993816185e-06,
      "loss": 0.54,
      "step": 5430
    },
    {
      "epoch": 0.38,
      "grad_norm": 3.6257341580291382,
      "learning_rate": 7.15230139861403e-06,
      "loss": 0.4843,
      "step": 5431
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.7762467753190947,
      "learning_rate": 7.151284988688731e-06,
      "loss": 0.548,
      "step": 5432
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.8598930113440213,
      "learning_rate": 7.150268469657271e-06,
      "loss": 0.4977,
      "step": 5433
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.6445583229208602,
      "learning_rate": 7.149251841571204e-06,
      "loss": 0.5294,
      "step": 5434
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.8597225228630356,
      "learning_rate": 7.1482351044820895e-06,
      "loss": 0.5121,
      "step": 5435
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.7767217022018476,
      "learning_rate": 7.147218258441496e-06,
      "loss": 0.4917,
      "step": 5436
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.071918455441811,
      "learning_rate": 7.146201303500992e-06,
      "loss": 0.5272,
      "step": 5437
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.353775872635715,
      "learning_rate": 7.1451842397121556e-06,
      "loss": 0.4874,
      "step": 5438
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.441363725793162,
      "learning_rate": 7.144167067126566e-06,
      "loss": 0.4887,
      "step": 5439
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.9611473147754848,
      "learning_rate": 7.143149785795815e-06,
      "loss": 0.472,
      "step": 5440
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6297393189812087,
      "learning_rate": 7.1421323957714925e-06,
      "loss": 0.4658,
      "step": 5441
    },
    {
      "epoch": 0.38,
      "grad_norm": 4.899764523713336,
      "learning_rate": 7.141114897105202e-06,
      "loss": 0.5302,
      "step": 5442
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.3572239607075236,
      "learning_rate": 7.140097289848541e-06,
      "loss": 0.524,
      "step": 5443
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.27707890078416,
      "learning_rate": 7.139079574053125e-06,
      "loss": 0.4952,
      "step": 5444
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.0104368656378164,
      "learning_rate": 7.138061749770564e-06,
      "loss": 0.5157,
      "step": 5445
    },
    {
      "epoch": 0.38,
      "grad_norm": 3.9507631010302533,
      "learning_rate": 7.1370438170524835e-06,
      "loss": 0.4881,
      "step": 5446
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.761154929751346,
      "learning_rate": 7.136025775950507e-06,
      "loss": 0.5078,
      "step": 5447
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.2904964117766333,
      "learning_rate": 7.135007626516268e-06,
      "loss": 0.5203,
      "step": 5448
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.2699734089884127,
      "learning_rate": 7.133989368801402e-06,
      "loss": 0.5543,
      "step": 5449
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.2496982111352373,
      "learning_rate": 7.132971002857552e-06,
      "loss": 0.5376,
      "step": 5450
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.873872639879728,
      "learning_rate": 7.131952528736367e-06,
      "loss": 0.5409,
      "step": 5451
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.088677065689132,
      "learning_rate": 7.1309339464895e-06,
      "loss": 0.4751,
      "step": 5452
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.7070987811668052,
      "learning_rate": 7.12991525616861e-06,
      "loss": 0.537,
      "step": 5453
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.351710589853569,
      "learning_rate": 7.128896457825364e-06,
      "loss": 0.4968,
      "step": 5454
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.1676335878869155,
      "learning_rate": 7.1278775515114296e-06,
      "loss": 0.5182,
      "step": 5455
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.2346450275424434,
      "learning_rate": 7.1268585372784826e-06,
      "loss": 0.5633,
      "step": 5456
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.8929611961467026,
      "learning_rate": 7.125839415178204e-06,
      "loss": 0.4794,
      "step": 5457
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.909957509837452,
      "learning_rate": 7.124820185262282e-06,
      "loss": 0.5108,
      "step": 5458
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.532346720999752,
      "learning_rate": 7.123800847582407e-06,
      "loss": 0.5103,
      "step": 5459
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.7242242778457089,
      "learning_rate": 7.122781402190277e-06,
      "loss": 0.5086,
      "step": 5460
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.7772718756774837,
      "learning_rate": 7.121761849137594e-06,
      "loss": 0.5059,
      "step": 5461
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.9226873245323912,
      "learning_rate": 7.120742188476069e-06,
      "loss": 0.4976,
      "step": 5462
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.9659501873644127,
      "learning_rate": 7.1197224202574135e-06,
      "loss": 0.493,
      "step": 5463
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.8350861371912586,
      "learning_rate": 7.118702544533348e-06,
      "loss": 0.5755,
      "step": 5464
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.0847373862103424,
      "learning_rate": 7.117682561355596e-06,
      "loss": 0.5017,
      "step": 5465
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.5126329398825793,
      "learning_rate": 7.116662470775889e-06,
      "loss": 0.5134,
      "step": 5466
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.55376094839545,
      "learning_rate": 7.115642272845963e-06,
      "loss": 0.5141,
      "step": 5467
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.703141916644084,
      "learning_rate": 7.1146219676175575e-06,
      "loss": 0.4565,
      "step": 5468
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.432389113999703,
      "learning_rate": 7.11360155514242e-06,
      "loss": 0.5434,
      "step": 5469
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.9572290052626382,
      "learning_rate": 7.1125810354723016e-06,
      "loss": 0.5026,
      "step": 5470
    },
    {
      "epoch": 0.38,
      "grad_norm": 3.0297713217003674,
      "learning_rate": 7.1115604086589605e-06,
      "loss": 0.5237,
      "step": 5471
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.7943615252126246,
      "learning_rate": 7.11053967475416e-06,
      "loss": 0.5248,
      "step": 5472
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.487761758462591,
      "learning_rate": 7.109518833809668e-06,
      "loss": 0.4915,
      "step": 5473
    },
    {
      "epoch": 0.38,
      "grad_norm": 3.382523254648346,
      "learning_rate": 7.108497885877259e-06,
      "loss": 0.5077,
      "step": 5474
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.339574910864311,
      "learning_rate": 7.10747683100871e-06,
      "loss": 0.5395,
      "step": 5475
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.312943915052279,
      "learning_rate": 7.106455669255807e-06,
      "loss": 0.4976,
      "step": 5476
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.8604966233353812,
      "learning_rate": 7.105434400670341e-06,
      "loss": 0.525,
      "step": 5477
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.5902104954416156,
      "learning_rate": 7.104413025304106e-06,
      "loss": 0.514,
      "step": 5478
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.9758792241235423,
      "learning_rate": 7.103391543208903e-06,
      "loss": 0.5411,
      "step": 5479
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.0827622417239318,
      "learning_rate": 7.102369954436539e-06,
      "loss": 0.514,
      "step": 5480
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.0354492248929357,
      "learning_rate": 7.101348259038823e-06,
      "loss": 0.4979,
      "step": 5481
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.1028631728632186,
      "learning_rate": 7.100326457067576e-06,
      "loss": 0.5142,
      "step": 5482
    },
    {
      "epoch": 0.38,
      "grad_norm": 3.461322939740165,
      "learning_rate": 7.099304548574617e-06,
      "loss": 0.4853,
      "step": 5483
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.7098143470964062,
      "learning_rate": 7.098282533611777e-06,
      "loss": 0.4724,
      "step": 5484
    },
    {
      "epoch": 0.38,
      "grad_norm": 5.036870798962434,
      "learning_rate": 7.0972604122308865e-06,
      "loss": 0.5786,
      "step": 5485
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.20963558468661,
      "learning_rate": 7.096238184483786e-06,
      "loss": 0.5396,
      "step": 5486
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.9991176296858135,
      "learning_rate": 7.095215850422318e-06,
      "loss": 0.4677,
      "step": 5487
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.7223292444720368,
      "learning_rate": 7.094193410098333e-06,
      "loss": 0.4559,
      "step": 5488
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.431664304944615,
      "learning_rate": 7.093170863563688e-06,
      "loss": 0.5043,
      "step": 5489
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.3672546243571286,
      "learning_rate": 7.092148210870238e-06,
      "loss": 0.554,
      "step": 5490
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.462872339968182,
      "learning_rate": 7.091125452069853e-06,
      "loss": 0.5003,
      "step": 5491
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.549328307540467,
      "learning_rate": 7.090102587214402e-06,
      "loss": 0.4655,
      "step": 5492
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.5852565993729364,
      "learning_rate": 7.0890796163557625e-06,
      "loss": 0.537,
      "step": 5493
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.1785717407656997,
      "learning_rate": 7.088056539545815e-06,
      "loss": 0.515,
      "step": 5494
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.1810727631547144,
      "learning_rate": 7.087033356836448e-06,
      "loss": 0.527,
      "step": 5495
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.70301668470704,
      "learning_rate": 7.086010068279553e-06,
      "loss": 0.5274,
      "step": 5496
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.404377651882128,
      "learning_rate": 7.084986673927028e-06,
      "loss": 0.4825,
      "step": 5497
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.0160842143700224,
      "learning_rate": 7.083963173830775e-06,
      "loss": 0.5119,
      "step": 5498
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.8729510568313597,
      "learning_rate": 7.082939568042706e-06,
      "loss": 0.4782,
      "step": 5499
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.0004195715302413,
      "learning_rate": 7.081915856614733e-06,
      "loss": 0.5066,
      "step": 5500
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.6854008354244707,
      "learning_rate": 7.080892039598774e-06,
      "loss": 0.497,
      "step": 5501
    },
    {
      "epoch": 0.38,
      "grad_norm": 3.85684427510184,
      "learning_rate": 7.079868117046755e-06,
      "loss": 0.5639,
      "step": 5502
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.7169111592600272,
      "learning_rate": 7.078844089010607e-06,
      "loss": 0.4423,
      "step": 5503
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.8357065051501955,
      "learning_rate": 7.077819955542262e-06,
      "loss": 0.5,
      "step": 5504
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.9501200057924521,
      "learning_rate": 7.076795716693665e-06,
      "loss": 0.5142,
      "step": 5505
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.284272097910872,
      "learning_rate": 7.075771372516759e-06,
      "loss": 0.5239,
      "step": 5506
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.9605250813130641,
      "learning_rate": 7.074746923063497e-06,
      "loss": 0.4771,
      "step": 5507
    },
    {
      "epoch": 0.38,
      "grad_norm": 3.570143971474178,
      "learning_rate": 7.073722368385833e-06,
      "loss": 0.5392,
      "step": 5508
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.9601523849716411,
      "learning_rate": 7.072697708535734e-06,
      "loss": 0.5071,
      "step": 5509
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.9421503579076493,
      "learning_rate": 7.071672943565164e-06,
      "loss": 0.5038,
      "step": 5510
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.403299691891649,
      "learning_rate": 7.070648073526096e-06,
      "loss": 0.5314,
      "step": 5511
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.6252168788837,
      "learning_rate": 7.069623098470508e-06,
      "loss": 0.5448,
      "step": 5512
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.458865246139374,
      "learning_rate": 7.068598018450386e-06,
      "loss": 0.5232,
      "step": 5513
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.727773329071125,
      "learning_rate": 7.067572833517713e-06,
      "loss": 0.4767,
      "step": 5514
    },
    {
      "epoch": 0.38,
      "grad_norm": 3.995735609600978,
      "learning_rate": 7.066547543724489e-06,
      "loss": 0.5214,
      "step": 5515
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.8201227000814741,
      "learning_rate": 7.06552214912271e-06,
      "loss": 0.5212,
      "step": 5516
    },
    {
      "epoch": 0.38,
      "grad_norm": 4.479305548946494,
      "learning_rate": 7.064496649764381e-06,
      "loss": 0.4903,
      "step": 5517
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.6894476760174986,
      "learning_rate": 7.063471045701513e-06,
      "loss": 0.4748,
      "step": 5518
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6504478691591605,
      "learning_rate": 7.062445336986121e-06,
      "loss": 0.4383,
      "step": 5519
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.1257427560278437,
      "learning_rate": 7.0614195236702255e-06,
      "loss": 0.5747,
      "step": 5520
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.0795176573229144,
      "learning_rate": 7.060393605805853e-06,
      "loss": 0.5857,
      "step": 5521
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.162508464373732,
      "learning_rate": 7.059367583445034e-06,
      "loss": 0.5366,
      "step": 5522
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.547355244292498,
      "learning_rate": 7.058341456639806e-06,
      "loss": 0.5727,
      "step": 5523
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.2915373807166612,
      "learning_rate": 7.057315225442207e-06,
      "loss": 0.4756,
      "step": 5524
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.613559784571604,
      "learning_rate": 7.056288889904289e-06,
      "loss": 0.5444,
      "step": 5525
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.0981201025640535,
      "learning_rate": 7.055262450078102e-06,
      "loss": 0.5231,
      "step": 5526
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.069072644156784,
      "learning_rate": 7.054235906015704e-06,
      "loss": 0.507,
      "step": 5527
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.3207620310428765,
      "learning_rate": 7.053209257769157e-06,
      "loss": 0.5048,
      "step": 5528
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.0129235311987834,
      "learning_rate": 7.0521825053905326e-06,
      "loss": 0.5636,
      "step": 5529
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.6467510839934338,
      "learning_rate": 7.0511556489319e-06,
      "loss": 0.4995,
      "step": 5530
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.0372980396284133,
      "learning_rate": 7.0501286884453415e-06,
      "loss": 0.5103,
      "step": 5531
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.1091232518617202,
      "learning_rate": 7.049101623982938e-06,
      "loss": 0.5133,
      "step": 5532
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6555391125373117,
      "learning_rate": 7.048074455596782e-06,
      "loss": 0.4599,
      "step": 5533
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.185707974903649,
      "learning_rate": 7.047047183338967e-06,
      "loss": 0.5187,
      "step": 5534
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.630645397458728,
      "learning_rate": 7.046019807261593e-06,
      "loss": 0.5163,
      "step": 5535
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.330152730712316,
      "learning_rate": 7.044992327416762e-06,
      "loss": 0.4858,
      "step": 5536
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.346103557824221,
      "learning_rate": 7.0439647438565895e-06,
      "loss": 0.5361,
      "step": 5537
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.4281597097378085,
      "learning_rate": 7.042937056633188e-06,
      "loss": 0.5263,
      "step": 5538
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.2275770702175937,
      "learning_rate": 7.0419092657986796e-06,
      "loss": 0.4666,
      "step": 5539
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.273838385831964,
      "learning_rate": 7.04088137140519e-06,
      "loss": 0.5228,
      "step": 5540
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.2067203793949703,
      "learning_rate": 7.039853373504851e-06,
      "loss": 0.5177,
      "step": 5541
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.321589057651974,
      "learning_rate": 7.0388252721498e-06,
      "loss": 0.5036,
      "step": 5542
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.1692935019677337,
      "learning_rate": 7.037797067392178e-06,
      "loss": 0.5327,
      "step": 5543
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.1940173724588106,
      "learning_rate": 7.036768759284131e-06,
      "loss": 0.5087,
      "step": 5544
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.6765509474806946,
      "learning_rate": 7.035740347877815e-06,
      "loss": 0.5265,
      "step": 5545
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.2964295648021205,
      "learning_rate": 7.034711833225384e-06,
      "loss": 0.5653,
      "step": 5546
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.1395272023578387,
      "learning_rate": 7.033683215379002e-06,
      "loss": 0.4819,
      "step": 5547
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.30189846115439,
      "learning_rate": 7.032654494390838e-06,
      "loss": 0.4908,
      "step": 5548
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.4729165323474116,
      "learning_rate": 7.031625670313065e-06,
      "loss": 0.5388,
      "step": 5549
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.7283275712415773,
      "learning_rate": 7.030596743197862e-06,
      "loss": 0.49,
      "step": 5550
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.365071761351669,
      "learning_rate": 7.029567713097412e-06,
      "loss": 0.5082,
      "step": 5551
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.6831210691610345,
      "learning_rate": 7.028538580063903e-06,
      "loss": 0.5383,
      "step": 5552
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.788349408309809,
      "learning_rate": 7.02750934414953e-06,
      "loss": 0.5204,
      "step": 5553
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.102213160049188,
      "learning_rate": 7.026480005406496e-06,
      "loss": 0.4882,
      "step": 5554
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6843712893922064,
      "learning_rate": 7.025450563887002e-06,
      "loss": 0.4687,
      "step": 5555
    },
    {
      "epoch": 0.39,
      "grad_norm": 5.01549376312739,
      "learning_rate": 7.024421019643259e-06,
      "loss": 0.498,
      "step": 5556
    },
    {
      "epoch": 0.39,
      "grad_norm": 4.314308840493869,
      "learning_rate": 7.02339137272748e-06,
      "loss": 0.5363,
      "step": 5557
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.0716992385672595,
      "learning_rate": 7.022361623191889e-06,
      "loss": 0.5658,
      "step": 5558
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.8353087074019805,
      "learning_rate": 7.021331771088708e-06,
      "loss": 0.5215,
      "step": 5559
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6851811939563895,
      "learning_rate": 7.020301816470172e-06,
      "loss": 0.4279,
      "step": 5560
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.5194205577914306,
      "learning_rate": 7.019271759388513e-06,
      "loss": 0.5133,
      "step": 5561
    },
    {
      "epoch": 0.39,
      "grad_norm": 3.73240053726577,
      "learning_rate": 7.018241599895974e-06,
      "loss": 0.5074,
      "step": 5562
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.8102161836835642,
      "learning_rate": 7.0172113380448e-06,
      "loss": 0.5195,
      "step": 5563
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.7061567137093927,
      "learning_rate": 7.016180973887244e-06,
      "loss": 0.5142,
      "step": 5564
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.510923136240371,
      "learning_rate": 7.015150507475564e-06,
      "loss": 0.517,
      "step": 5565
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.1033111223889094,
      "learning_rate": 7.0141199388620165e-06,
      "loss": 0.6046,
      "step": 5566
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.0602470713160708,
      "learning_rate": 7.013089268098874e-06,
      "loss": 0.5015,
      "step": 5567
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.9349494147959592,
      "learning_rate": 7.012058495238408e-06,
      "loss": 0.4858,
      "step": 5568
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.8958622449461744,
      "learning_rate": 7.011027620332893e-06,
      "loss": 0.5284,
      "step": 5569
    },
    {
      "epoch": 0.39,
      "grad_norm": 3.2540556851967564,
      "learning_rate": 7.009996643434613e-06,
      "loss": 0.5245,
      "step": 5570
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.7214748513131958,
      "learning_rate": 7.008965564595857e-06,
      "loss": 0.4622,
      "step": 5571
    },
    {
      "epoch": 0.39,
      "grad_norm": 3.5151402699895025,
      "learning_rate": 7.007934383868917e-06,
      "loss": 0.5149,
      "step": 5572
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.7459516357890894,
      "learning_rate": 7.006903101306091e-06,
      "loss": 0.4608,
      "step": 5573
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.5137032951132507,
      "learning_rate": 7.0058717169596845e-06,
      "loss": 0.5231,
      "step": 5574
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.1290703347362254,
      "learning_rate": 7.004840230882002e-06,
      "loss": 0.5173,
      "step": 5575
    },
    {
      "epoch": 0.39,
      "grad_norm": 4.1034642244265385,
      "learning_rate": 7.003808643125361e-06,
      "loss": 0.5159,
      "step": 5576
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.8450808867884436,
      "learning_rate": 7.002776953742078e-06,
      "loss": 0.488,
      "step": 5577
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.0005558557487735,
      "learning_rate": 7.0017451627844765e-06,
      "loss": 0.5123,
      "step": 5578
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.9621967707278447,
      "learning_rate": 7.000713270304885e-06,
      "loss": 0.5667,
      "step": 5579
    },
    {
      "epoch": 0.39,
      "grad_norm": 3.761023684922206,
      "learning_rate": 6.999681276355641e-06,
      "loss": 0.5075,
      "step": 5580
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.142285560865204,
      "learning_rate": 6.998649180989081e-06,
      "loss": 0.5344,
      "step": 5581
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.3846902745241763,
      "learning_rate": 6.9976169842575526e-06,
      "loss": 0.5418,
      "step": 5582
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.3558973755234347,
      "learning_rate": 6.996584686213401e-06,
      "loss": 0.5024,
      "step": 5583
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.5648626332085027,
      "learning_rate": 6.9955522869089844e-06,
      "loss": 0.5417,
      "step": 5584
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.191032646704132,
      "learning_rate": 6.9945197863966606e-06,
      "loss": 0.508,
      "step": 5585
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.311914155145928,
      "learning_rate": 6.9934871847287975e-06,
      "loss": 0.5408,
      "step": 5586
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.4466977000178565,
      "learning_rate": 6.992454481957762e-06,
      "loss": 0.5255,
      "step": 5587
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.9952960180501247,
      "learning_rate": 6.9914216781359324e-06,
      "loss": 0.4688,
      "step": 5588
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.9592991424751516,
      "learning_rate": 6.990388773315687e-06,
      "loss": 0.4776,
      "step": 5589
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.6683228956278484,
      "learning_rate": 6.989355767549413e-06,
      "loss": 0.4692,
      "step": 5590
    },
    {
      "epoch": 0.39,
      "grad_norm": 3.218038163445381,
      "learning_rate": 6.988322660889498e-06,
      "loss": 0.5014,
      "step": 5591
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.3726830310046547,
      "learning_rate": 6.9872894533883415e-06,
      "loss": 0.5238,
      "step": 5592
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.6259646544145827,
      "learning_rate": 6.986256145098342e-06,
      "loss": 0.5237,
      "step": 5593
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.563800949767376,
      "learning_rate": 6.985222736071908e-06,
      "loss": 0.4816,
      "step": 5594
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.031103648557118,
      "learning_rate": 6.984189226361446e-06,
      "loss": 0.5137,
      "step": 5595
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.0264595807393486,
      "learning_rate": 6.9831556160193795e-06,
      "loss": 0.5192,
      "step": 5596
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.752918739164838,
      "learning_rate": 6.982121905098122e-06,
      "loss": 0.4848,
      "step": 5597
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.3396498808480377,
      "learning_rate": 6.981088093650104e-06,
      "loss": 0.485,
      "step": 5598
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.774925028606901,
      "learning_rate": 6.980054181727759e-06,
      "loss": 0.4641,
      "step": 5599
    },
    {
      "epoch": 0.39,
      "grad_norm": 3.704530528485299,
      "learning_rate": 6.979020169383519e-06,
      "loss": 0.5192,
      "step": 5600
    },
    {
      "epoch": 0.39,
      "grad_norm": 3.840990046619235,
      "learning_rate": 6.977986056669829e-06,
      "loss": 0.5252,
      "step": 5601
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.956291058044315,
      "learning_rate": 6.976951843639135e-06,
      "loss": 0.4797,
      "step": 5602
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.027913576910974,
      "learning_rate": 6.975917530343887e-06,
      "loss": 0.5003,
      "step": 5603
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.40240719986597,
      "learning_rate": 6.974883116836546e-06,
      "loss": 0.5082,
      "step": 5604
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.980242438318907,
      "learning_rate": 6.97384860316957e-06,
      "loss": 0.4894,
      "step": 5605
    },
    {
      "epoch": 0.39,
      "grad_norm": 3.072213697606035,
      "learning_rate": 6.972813989395429e-06,
      "loss": 0.5125,
      "step": 5606
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.187310364094856,
      "learning_rate": 6.971779275566593e-06,
      "loss": 0.529,
      "step": 5607
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.8724755934806487,
      "learning_rate": 6.9707444617355425e-06,
      "loss": 0.5294,
      "step": 5608
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.0664577177915966,
      "learning_rate": 6.9697095479547564e-06,
      "loss": 0.4986,
      "step": 5609
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.1377605533455672,
      "learning_rate": 6.968674534276724e-06,
      "loss": 0.4874,
      "step": 5610
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.604565279911731,
      "learning_rate": 6.9676394207539375e-06,
      "loss": 0.4864,
      "step": 5611
    },
    {
      "epoch": 0.39,
      "grad_norm": 6.388473857920956,
      "learning_rate": 6.966604207438895e-06,
      "loss": 0.4838,
      "step": 5612
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.2078748091516367,
      "learning_rate": 6.965568894384098e-06,
      "loss": 0.5686,
      "step": 5613
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.031938106834707,
      "learning_rate": 6.964533481642055e-06,
      "loss": 0.4992,
      "step": 5614
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.237535108799019,
      "learning_rate": 6.963497969265278e-06,
      "loss": 0.4843,
      "step": 5615
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.9158773349226643,
      "learning_rate": 6.962462357306286e-06,
      "loss": 0.5223,
      "step": 5616
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.2741583679953545,
      "learning_rate": 6.9614266458176e-06,
      "loss": 0.5466,
      "step": 5617
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.901515677456506,
      "learning_rate": 6.96039083485175e-06,
      "loss": 0.5127,
      "step": 5618
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.8859422704188313,
      "learning_rate": 6.959354924461269e-06,
      "loss": 0.5049,
      "step": 5619
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.3137473016858636,
      "learning_rate": 6.958318914698693e-06,
      "loss": 0.4728,
      "step": 5620
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.046276601586321,
      "learning_rate": 6.957282805616567e-06,
      "loss": 0.5282,
      "step": 5621
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6919660627319137,
      "learning_rate": 6.956246597267438e-06,
      "loss": 0.4888,
      "step": 5622
    },
    {
      "epoch": 0.39,
      "grad_norm": 3.6693838384253037,
      "learning_rate": 6.95521028970386e-06,
      "loss": 0.4931,
      "step": 5623
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.7483870094230447,
      "learning_rate": 6.954173882978388e-06,
      "loss": 0.5299,
      "step": 5624
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.9248679339113548,
      "learning_rate": 6.95313737714359e-06,
      "loss": 0.5279,
      "step": 5625
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.309408589518592,
      "learning_rate": 6.952100772252031e-06,
      "loss": 0.5393,
      "step": 5626
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.2162128281142204,
      "learning_rate": 6.951064068356285e-06,
      "loss": 0.5162,
      "step": 5627
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.622640687704145,
      "learning_rate": 6.950027265508929e-06,
      "loss": 0.4559,
      "step": 5628
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.70839445533581,
      "learning_rate": 6.948990363762549e-06,
      "loss": 0.4617,
      "step": 5629
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.265687341958359,
      "learning_rate": 6.9479533631697316e-06,
      "loss": 0.491,
      "step": 5630
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.7571858859542384,
      "learning_rate": 6.94691626378307e-06,
      "loss": 0.4374,
      "step": 5631
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.968363008056571,
      "learning_rate": 6.945879065655164e-06,
      "loss": 0.4716,
      "step": 5632
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.2867887799058004,
      "learning_rate": 6.944841768838615e-06,
      "loss": 0.4891,
      "step": 5633
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.3167130792455612,
      "learning_rate": 6.943804373386032e-06,
      "loss": 0.517,
      "step": 5634
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.8755456691050334,
      "learning_rate": 6.942766879350029e-06,
      "loss": 0.514,
      "step": 5635
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.8333022301822153,
      "learning_rate": 6.941729286783222e-06,
      "loss": 0.5404,
      "step": 5636
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.6719866762305262,
      "learning_rate": 6.940691595738237e-06,
      "loss": 0.5142,
      "step": 5637
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.1310499367746756,
      "learning_rate": 6.939653806267701e-06,
      "loss": 0.528,
      "step": 5638
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.0884838476253433,
      "learning_rate": 6.938615918424248e-06,
      "loss": 0.4955,
      "step": 5639
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.7419806452964974,
      "learning_rate": 6.9375779322605154e-06,
      "loss": 0.4607,
      "step": 5640
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.8486755101587808,
      "learning_rate": 6.936539847829147e-06,
      "loss": 0.5479,
      "step": 5641
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.576387411997639,
      "learning_rate": 6.935501665182791e-06,
      "loss": 0.488,
      "step": 5642
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.1410384511409766,
      "learning_rate": 6.934463384374102e-06,
      "loss": 0.499,
      "step": 5643
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.5743846964481674,
      "learning_rate": 6.9334250054557354e-06,
      "loss": 0.5031,
      "step": 5644
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.7895135062544956,
      "learning_rate": 6.932386528480357e-06,
      "loss": 0.4987,
      "step": 5645
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.144036816713782,
      "learning_rate": 6.931347953500632e-06,
      "loss": 0.4825,
      "step": 5646
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.9584306492112324,
      "learning_rate": 6.930309280569236e-06,
      "loss": 0.4985,
      "step": 5647
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.232709686516662,
      "learning_rate": 6.929270509738847e-06,
      "loss": 0.5252,
      "step": 5648
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.5020148972914233,
      "learning_rate": 6.9282316410621476e-06,
      "loss": 0.501,
      "step": 5649
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.370068175310226,
      "learning_rate": 6.927192674591825e-06,
      "loss": 0.4739,
      "step": 5650
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.011072670787626,
      "learning_rate": 6.9261536103805735e-06,
      "loss": 0.4921,
      "step": 5651
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.7851083621129498,
      "learning_rate": 6.925114448481089e-06,
      "loss": 0.5493,
      "step": 5652
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6590725643993244,
      "learning_rate": 6.924075188946079e-06,
      "loss": 0.4619,
      "step": 5653
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.0014316841742454,
      "learning_rate": 6.9230358318282454e-06,
      "loss": 0.536,
      "step": 5654
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.3062317902482867,
      "learning_rate": 6.921996377180305e-06,
      "loss": 0.5494,
      "step": 5655
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.2696589250177346,
      "learning_rate": 6.9209568250549765e-06,
      "loss": 0.5188,
      "step": 5656
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.10417161126539,
      "learning_rate": 6.919917175504978e-06,
      "loss": 0.5692,
      "step": 5657
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.163369975762836,
      "learning_rate": 6.91887742858304e-06,
      "loss": 0.5153,
      "step": 5658
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.1887043529684247,
      "learning_rate": 6.9178375843418956e-06,
      "loss": 0.5001,
      "step": 5659
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.9234908251719747,
      "learning_rate": 6.91679764283428e-06,
      "loss": 0.4919,
      "step": 5660
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.9046170692488609,
      "learning_rate": 6.915757604112938e-06,
      "loss": 0.4691,
      "step": 5661
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.6964142002892694,
      "learning_rate": 6.914717468230615e-06,
      "loss": 0.4278,
      "step": 5662
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.128774474109482,
      "learning_rate": 6.913677235240066e-06,
      "loss": 0.496,
      "step": 5663
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.8044611047441776,
      "learning_rate": 6.912636905194044e-06,
      "loss": 0.5066,
      "step": 5664
    },
    {
      "epoch": 0.39,
      "grad_norm": 4.199856047366572,
      "learning_rate": 6.911596478145317e-06,
      "loss": 0.4957,
      "step": 5665
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.0657637371593,
      "learning_rate": 6.910555954146647e-06,
      "loss": 0.5397,
      "step": 5666
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.767068906473119,
      "learning_rate": 6.909515333250809e-06,
      "loss": 0.4934,
      "step": 5667
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.129149590807686,
      "learning_rate": 6.908474615510576e-06,
      "loss": 0.5104,
      "step": 5668
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.170128433817971,
      "learning_rate": 6.9074338009787355e-06,
      "loss": 0.4982,
      "step": 5669
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.7329638079360694,
      "learning_rate": 6.906392889708069e-06,
      "loss": 0.4978,
      "step": 5670
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.9171071628401428,
      "learning_rate": 6.905351881751372e-06,
      "loss": 0.5351,
      "step": 5671
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.8871821300063167,
      "learning_rate": 6.904310777161438e-06,
      "loss": 0.5268,
      "step": 5672
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.9255438098659774,
      "learning_rate": 6.903269575991071e-06,
      "loss": 0.5213,
      "step": 5673
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.5847711863225262,
      "learning_rate": 6.902228278293075e-06,
      "loss": 0.5706,
      "step": 5674
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.9728409423437852,
      "learning_rate": 6.901186884120264e-06,
      "loss": 0.4804,
      "step": 5675
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.072116511809369,
      "learning_rate": 6.900145393525449e-06,
      "loss": 0.5302,
      "step": 5676
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.7712089913953353,
      "learning_rate": 6.899103806561458e-06,
      "loss": 0.5454,
      "step": 5677
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.5866595672644155,
      "learning_rate": 6.898062123281113e-06,
      "loss": 0.5248,
      "step": 5678
    },
    {
      "epoch": 0.39,
      "grad_norm": 23.905344264852538,
      "learning_rate": 6.897020343737244e-06,
      "loss": 0.5037,
      "step": 5679
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.056639858831183,
      "learning_rate": 6.895978467982687e-06,
      "loss": 0.457,
      "step": 5680
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.693498651003162,
      "learning_rate": 6.894936496070284e-06,
      "loss": 0.449,
      "step": 5681
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.248020559251677,
      "learning_rate": 6.893894428052881e-06,
      "loss": 0.5501,
      "step": 5682
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.1636293089228475,
      "learning_rate": 6.8928522639833255e-06,
      "loss": 0.5327,
      "step": 5683
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.218548746118411,
      "learning_rate": 6.891810003914475e-06,
      "loss": 0.5426,
      "step": 5684
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.332030013193473,
      "learning_rate": 6.890767647899189e-06,
      "loss": 0.5169,
      "step": 5685
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.6303123627087903,
      "learning_rate": 6.889725195990333e-06,
      "loss": 0.5162,
      "step": 5686
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.2997107081022987,
      "learning_rate": 6.888682648240773e-06,
      "loss": 0.5367,
      "step": 5687
    },
    {
      "epoch": 0.4,
      "grad_norm": 3.5781526254087495,
      "learning_rate": 6.887640004703389e-06,
      "loss": 0.4934,
      "step": 5688
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.7902135361147107,
      "learning_rate": 6.8865972654310584e-06,
      "loss": 0.4936,
      "step": 5689
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.877411887164376,
      "learning_rate": 6.885554430476664e-06,
      "loss": 0.4958,
      "step": 5690
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.7603951311020136,
      "learning_rate": 6.8845114998930965e-06,
      "loss": 0.4789,
      "step": 5691
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.8718374808755789,
      "learning_rate": 6.883468473733249e-06,
      "loss": 0.5349,
      "step": 5692
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.1244062560608064,
      "learning_rate": 6.882425352050021e-06,
      "loss": 0.4922,
      "step": 5693
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.0161919169249876,
      "learning_rate": 6.881382134896317e-06,
      "loss": 0.5416,
      "step": 5694
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.9872984336296002,
      "learning_rate": 6.880338822325043e-06,
      "loss": 0.5014,
      "step": 5695
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.0269273936961527,
      "learning_rate": 6.879295414389117e-06,
      "loss": 0.5266,
      "step": 5696
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.5848646303671892,
      "learning_rate": 6.8782519111414515e-06,
      "loss": 0.528,
      "step": 5697
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.55008791025814,
      "learning_rate": 6.877208312634975e-06,
      "loss": 0.5118,
      "step": 5698
    },
    {
      "epoch": 0.4,
      "grad_norm": 4.599173166508656,
      "learning_rate": 6.876164618922612e-06,
      "loss": 0.4735,
      "step": 5699
    },
    {
      "epoch": 0.4,
      "grad_norm": 3.1175469900439365,
      "learning_rate": 6.875120830057297e-06,
      "loss": 0.5074,
      "step": 5700
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.6870069778374526,
      "learning_rate": 6.874076946091966e-06,
      "loss": 0.4965,
      "step": 5701
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.5711580598680905,
      "learning_rate": 6.873032967079562e-06,
      "loss": 0.5643,
      "step": 5702
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.9021827633905701,
      "learning_rate": 6.871988893073032e-06,
      "loss": 0.537,
      "step": 5703
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.797293243626591,
      "learning_rate": 6.870944724125328e-06,
      "loss": 0.5023,
      "step": 5704
    },
    {
      "epoch": 0.4,
      "grad_norm": 3.7536770231987786,
      "learning_rate": 6.869900460289407e-06,
      "loss": 0.5604,
      "step": 5705
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.7804349162462176,
      "learning_rate": 6.868856101618233e-06,
      "loss": 0.4837,
      "step": 5706
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.6085294722852863,
      "learning_rate": 6.867811648164769e-06,
      "loss": 0.5187,
      "step": 5707
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.091444471984515,
      "learning_rate": 6.8667670999819876e-06,
      "loss": 0.4977,
      "step": 5708
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.9677257865505973,
      "learning_rate": 6.8657224571228645e-06,
      "loss": 0.4877,
      "step": 5709
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.171590770134823,
      "learning_rate": 6.864677719640382e-06,
      "loss": 0.5086,
      "step": 5710
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.0352100873908445,
      "learning_rate": 6.863632887587524e-06,
      "loss": 0.4826,
      "step": 5711
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.8453779644608552,
      "learning_rate": 6.862587961017283e-06,
      "loss": 0.5527,
      "step": 5712
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.9904298666779727,
      "learning_rate": 6.861542939982652e-06,
      "loss": 0.5251,
      "step": 5713
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6937865947452936,
      "learning_rate": 6.860497824536631e-06,
      "loss": 0.4809,
      "step": 5714
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5910213090477261,
      "learning_rate": 6.859452614732227e-06,
      "loss": 0.4661,
      "step": 5715
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.4275083834662174,
      "learning_rate": 6.8584073106224505e-06,
      "loss": 0.4842,
      "step": 5716
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.1085538209243437,
      "learning_rate": 6.857361912260311e-06,
      "loss": 0.5145,
      "step": 5717
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.813271589674195,
      "learning_rate": 6.856316419698832e-06,
      "loss": 0.5218,
      "step": 5718
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6160438538947124,
      "learning_rate": 6.855270832991035e-06,
      "loss": 0.4514,
      "step": 5719
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.7269560380225122,
      "learning_rate": 6.854225152189951e-06,
      "loss": 0.4932,
      "step": 5720
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.8653525515821574,
      "learning_rate": 6.853179377348611e-06,
      "loss": 0.5128,
      "step": 5721
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.667798140261781,
      "learning_rate": 6.852133508520057e-06,
      "loss": 0.5176,
      "step": 5722
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.344342213957191,
      "learning_rate": 6.851087545757329e-06,
      "loss": 0.5421,
      "step": 5723
    },
    {
      "epoch": 0.4,
      "grad_norm": 3.3033881068155635,
      "learning_rate": 6.850041489113475e-06,
      "loss": 0.5379,
      "step": 5724
    },
    {
      "epoch": 0.4,
      "grad_norm": 3.9920670781414866,
      "learning_rate": 6.848995338641548e-06,
      "loss": 0.5168,
      "step": 5725
    },
    {
      "epoch": 0.4,
      "grad_norm": 5.099995511941063,
      "learning_rate": 6.847949094394606e-06,
      "loss": 0.5004,
      "step": 5726
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.0419934926475047,
      "learning_rate": 6.846902756425709e-06,
      "loss": 0.5629,
      "step": 5727
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.7796355730662163,
      "learning_rate": 6.845856324787928e-06,
      "loss": 0.5208,
      "step": 5728
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6685311934548065,
      "learning_rate": 6.844809799534331e-06,
      "loss": 0.4452,
      "step": 5729
    },
    {
      "epoch": 0.4,
      "grad_norm": 5.528272945729331,
      "learning_rate": 6.8437631807179945e-06,
      "loss": 0.4671,
      "step": 5730
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.2493345439588066,
      "learning_rate": 6.8427164683920015e-06,
      "loss": 0.5578,
      "step": 5731
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.7926308838874605,
      "learning_rate": 6.841669662609437e-06,
      "loss": 0.5254,
      "step": 5732
    },
    {
      "epoch": 0.4,
      "grad_norm": 4.445829898163315,
      "learning_rate": 6.840622763423391e-06,
      "loss": 0.5065,
      "step": 5733
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.064057374478242,
      "learning_rate": 6.839575770886959e-06,
      "loss": 0.473,
      "step": 5734
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.454172817451714,
      "learning_rate": 6.8385286850532415e-06,
      "loss": 0.5053,
      "step": 5735
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.2072737830216296,
      "learning_rate": 6.837481505975343e-06,
      "loss": 0.5095,
      "step": 5736
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.0858531022786533,
      "learning_rate": 6.836434233706372e-06,
      "loss": 0.494,
      "step": 5737
    },
    {
      "epoch": 0.4,
      "grad_norm": 3.3507461369602747,
      "learning_rate": 6.8353868682994465e-06,
      "loss": 0.5862,
      "step": 5738
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.424437901832274,
      "learning_rate": 6.83433940980768e-06,
      "loss": 0.4983,
      "step": 5739
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.560888990025125,
      "learning_rate": 6.8332918582842e-06,
      "loss": 0.5152,
      "step": 5740
    },
    {
      "epoch": 0.4,
      "grad_norm": 3.4793342008418207,
      "learning_rate": 6.832244213782133e-06,
      "loss": 0.537,
      "step": 5741
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.1523095605667995,
      "learning_rate": 6.831196476354615e-06,
      "loss": 0.5396,
      "step": 5742
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.2083301251067193,
      "learning_rate": 6.83014864605478e-06,
      "loss": 0.5093,
      "step": 5743
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.265479901912102,
      "learning_rate": 6.8291007229357735e-06,
      "loss": 0.4594,
      "step": 5744
    },
    {
      "epoch": 0.4,
      "grad_norm": 4.106491929134269,
      "learning_rate": 6.828052707050741e-06,
      "loss": 0.5578,
      "step": 5745
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.24986220366758,
      "learning_rate": 6.827004598452833e-06,
      "loss": 0.554,
      "step": 5746
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.6331759869669,
      "learning_rate": 6.825956397195211e-06,
      "loss": 0.529,
      "step": 5747
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6238114169024206,
      "learning_rate": 6.824908103331031e-06,
      "loss": 0.4455,
      "step": 5748
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.749182193286464,
      "learning_rate": 6.823859716913465e-06,
      "loss": 0.5519,
      "step": 5749
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.0840840974447636,
      "learning_rate": 6.822811237995677e-06,
      "loss": 0.462,
      "step": 5750
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.8341840075104054,
      "learning_rate": 6.821762666630848e-06,
      "loss": 0.5047,
      "step": 5751
    },
    {
      "epoch": 0.4,
      "grad_norm": 3.3976763466970104,
      "learning_rate": 6.820714002872154e-06,
      "loss": 0.5232,
      "step": 5752
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.8532264867534258,
      "learning_rate": 6.819665246772783e-06,
      "loss": 0.5226,
      "step": 5753
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.9669172908938046,
      "learning_rate": 6.818616398385922e-06,
      "loss": 0.5339,
      "step": 5754
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.85264810981413,
      "learning_rate": 6.817567457764768e-06,
      "loss": 0.4702,
      "step": 5755
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.906339369281979,
      "learning_rate": 6.816518424962517e-06,
      "loss": 0.4875,
      "step": 5756
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.2352064406907064,
      "learning_rate": 6.815469300032374e-06,
      "loss": 0.5781,
      "step": 5757
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.8694016093143353,
      "learning_rate": 6.814420083027547e-06,
      "loss": 0.4773,
      "step": 5758
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.5800287129018504,
      "learning_rate": 6.813370774001248e-06,
      "loss": 0.5293,
      "step": 5759
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.364659478042328,
      "learning_rate": 6.812321373006695e-06,
      "loss": 0.5647,
      "step": 5760
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.1036592572079345,
      "learning_rate": 6.8112718800971114e-06,
      "loss": 0.515,
      "step": 5761
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.0772360540765797,
      "learning_rate": 6.810222295325723e-06,
      "loss": 0.5739,
      "step": 5762
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.797904645920752,
      "learning_rate": 6.80917261874576e-06,
      "loss": 0.5318,
      "step": 5763
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.8136017560807862,
      "learning_rate": 6.808122850410461e-06,
      "loss": 0.4908,
      "step": 5764
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.531959248589047,
      "learning_rate": 6.807072990373067e-06,
      "loss": 0.5235,
      "step": 5765
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.739073546481394,
      "learning_rate": 6.806023038686822e-06,
      "loss": 0.4816,
      "step": 5766
    },
    {
      "epoch": 0.4,
      "grad_norm": 5.573462202292051,
      "learning_rate": 6.804972995404977e-06,
      "loss": 0.5199,
      "step": 5767
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.8879460471327405,
      "learning_rate": 6.803922860580784e-06,
      "loss": 0.5161,
      "step": 5768
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.8603142156131316,
      "learning_rate": 6.802872634267507e-06,
      "loss": 0.4739,
      "step": 5769
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.032244497038922,
      "learning_rate": 6.801822316518405e-06,
      "loss": 0.5088,
      "step": 5770
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.526655227726805,
      "learning_rate": 6.800771907386752e-06,
      "loss": 0.5353,
      "step": 5771
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.8258268835594629,
      "learning_rate": 6.7997214069258166e-06,
      "loss": 0.4779,
      "step": 5772
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.654397665245018,
      "learning_rate": 6.79867081518888e-06,
      "loss": 0.4965,
      "step": 5773
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.8252422146050327,
      "learning_rate": 6.797620132229224e-06,
      "loss": 0.5075,
      "step": 5774
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.9290022657971944,
      "learning_rate": 6.796569358100135e-06,
      "loss": 0.5351,
      "step": 5775
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.617241762093912,
      "learning_rate": 6.795518492854905e-06,
      "loss": 0.5063,
      "step": 5776
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.257110021060131,
      "learning_rate": 6.794467536546831e-06,
      "loss": 0.5106,
      "step": 5777
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.2283220931054766,
      "learning_rate": 6.793416489229214e-06,
      "loss": 0.554,
      "step": 5778
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6971666762362414,
      "learning_rate": 6.79236535095536e-06,
      "loss": 0.4612,
      "step": 5779
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.10385346789094,
      "learning_rate": 6.791314121778577e-06,
      "loss": 0.5532,
      "step": 5780
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.9818194001551221,
      "learning_rate": 6.790262801752184e-06,
      "loss": 0.4992,
      "step": 5781
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.1623129432235517,
      "learning_rate": 6.789211390929497e-06,
      "loss": 0.5205,
      "step": 5782
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.0164370772974807,
      "learning_rate": 6.788159889363842e-06,
      "loss": 0.5163,
      "step": 5783
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.7985596497035596,
      "learning_rate": 6.787108297108547e-06,
      "loss": 0.5325,
      "step": 5784
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.311663195082987,
      "learning_rate": 6.786056614216945e-06,
      "loss": 0.4961,
      "step": 5785
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.629178245944982,
      "learning_rate": 6.7850048407423744e-06,
      "loss": 0.4996,
      "step": 5786
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.9642299548286712,
      "learning_rate": 6.7839529767381785e-06,
      "loss": 0.4805,
      "step": 5787
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.90505334229241,
      "learning_rate": 6.782901022257702e-06,
      "loss": 0.4975,
      "step": 5788
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.5739432882369213,
      "learning_rate": 6.7818489773543005e-06,
      "loss": 0.5412,
      "step": 5789
    },
    {
      "epoch": 0.4,
      "grad_norm": 3.4925210791453445,
      "learning_rate": 6.780796842081328e-06,
      "loss": 0.5104,
      "step": 5790
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.2086941671143525,
      "learning_rate": 6.7797446164921445e-06,
      "loss": 0.539,
      "step": 5791
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.937874551668736,
      "learning_rate": 6.778692300640115e-06,
      "loss": 0.4995,
      "step": 5792
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.0979102140987704,
      "learning_rate": 6.7776398945786135e-06,
      "loss": 0.5013,
      "step": 5793
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.699444544144746,
      "learning_rate": 6.7765873983610095e-06,
      "loss": 0.4833,
      "step": 5794
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.4682858616740866,
      "learning_rate": 6.775534812040686e-06,
      "loss": 0.5882,
      "step": 5795
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.04574023421369,
      "learning_rate": 6.774482135671026e-06,
      "loss": 0.5283,
      "step": 5796
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.105225872445558,
      "learning_rate": 6.773429369305415e-06,
      "loss": 0.463,
      "step": 5797
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.634684195724128,
      "learning_rate": 6.772376512997249e-06,
      "loss": 0.5381,
      "step": 5798
    },
    {
      "epoch": 0.4,
      "grad_norm": 4.692651662932836,
      "learning_rate": 6.771323566799927e-06,
      "loss": 0.4987,
      "step": 5799
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.3947539289517246,
      "learning_rate": 6.770270530766847e-06,
      "loss": 0.5081,
      "step": 5800
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.9082610170620196,
      "learning_rate": 6.769217404951416e-06,
      "loss": 0.5299,
      "step": 5801
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.4344273042555606,
      "learning_rate": 6.768164189407047e-06,
      "loss": 0.527,
      "step": 5802
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.7054036180318777,
      "learning_rate": 6.7671108841871545e-06,
      "loss": 0.5316,
      "step": 5803
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.2978792023648995,
      "learning_rate": 6.766057489345159e-06,
      "loss": 0.478,
      "step": 5804
    },
    {
      "epoch": 0.4,
      "grad_norm": 4.834662383426714,
      "learning_rate": 6.765004004934487e-06,
      "loss": 0.5117,
      "step": 5805
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.7630092298940079,
      "learning_rate": 6.763950431008564e-06,
      "loss": 0.5086,
      "step": 5806
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.1573612520952667,
      "learning_rate": 6.762896767620827e-06,
      "loss": 0.5014,
      "step": 5807
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.9568895150047005,
      "learning_rate": 6.761843014824712e-06,
      "loss": 0.5005,
      "step": 5808
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.6035088144520317,
      "learning_rate": 6.760789172673664e-06,
      "loss": 0.5075,
      "step": 5809
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.93813191504078,
      "learning_rate": 6.759735241221131e-06,
      "loss": 0.5296,
      "step": 5810
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.3950121263296613,
      "learning_rate": 6.758681220520562e-06,
      "loss": 0.5213,
      "step": 5811
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.521691333645733,
      "learning_rate": 6.757627110625417e-06,
      "loss": 0.5259,
      "step": 5812
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.8013997073692198,
      "learning_rate": 6.756572911589152e-06,
      "loss": 0.5153,
      "step": 5813
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.288495880611918,
      "learning_rate": 6.755518623465238e-06,
      "loss": 0.5108,
      "step": 5814
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.8677821733379,
      "learning_rate": 6.754464246307142e-06,
      "loss": 0.5204,
      "step": 5815
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.7627866985920602,
      "learning_rate": 6.753409780168341e-06,
      "loss": 0.4642,
      "step": 5816
    },
    {
      "epoch": 0.4,
      "grad_norm": 3.9267131831891806,
      "learning_rate": 6.752355225102309e-06,
      "loss": 0.47,
      "step": 5817
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.0462327682386543,
      "learning_rate": 6.751300581162537e-06,
      "loss": 0.4939,
      "step": 5818
    },
    {
      "epoch": 0.4,
      "grad_norm": 6.527599632992438,
      "learning_rate": 6.7502458484025055e-06,
      "loss": 0.5502,
      "step": 5819
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.6681620795743823,
      "learning_rate": 6.749191026875712e-06,
      "loss": 0.4608,
      "step": 5820
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.7230684697928793,
      "learning_rate": 6.748136116635653e-06,
      "loss": 0.5251,
      "step": 5821
    },
    {
      "epoch": 0.4,
      "grad_norm": 6.431150883793788,
      "learning_rate": 6.747081117735829e-06,
      "loss": 0.4956,
      "step": 5822
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.572389924431,
      "learning_rate": 6.746026030229747e-06,
      "loss": 0.5288,
      "step": 5823
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.3223225068915077,
      "learning_rate": 6.744970854170917e-06,
      "loss": 0.504,
      "step": 5824
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6366670800920506,
      "learning_rate": 6.7439155896128525e-06,
      "loss": 0.4523,
      "step": 5825
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.0505154241251757,
      "learning_rate": 6.7428602366090764e-06,
      "loss": 0.494,
      "step": 5826
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.669505133178854,
      "learning_rate": 6.741804795213112e-06,
      "loss": 0.5193,
      "step": 5827
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.2586812592642085,
      "learning_rate": 6.7407492654784855e-06,
      "loss": 0.5316,
      "step": 5828
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.289571197408954,
      "learning_rate": 6.739693647458731e-06,
      "loss": 0.5361,
      "step": 5829
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.227934973023882,
      "learning_rate": 6.738637941207388e-06,
      "loss": 0.5181,
      "step": 5830
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.118293825742686,
      "learning_rate": 6.737582146777995e-06,
      "loss": 0.4777,
      "step": 5831
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.475909920571551,
      "learning_rate": 6.736526264224101e-06,
      "loss": 0.4818,
      "step": 5832
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.7992832212174577,
      "learning_rate": 6.735470293599258e-06,
      "loss": 0.5082,
      "step": 5833
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.775427399881179,
      "learning_rate": 6.7344142349570185e-06,
      "loss": 0.5007,
      "step": 5834
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.6904819440894183,
      "learning_rate": 6.733358088350943e-06,
      "loss": 0.4585,
      "step": 5835
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.9742721035555504,
      "learning_rate": 6.732301853834597e-06,
      "loss": 0.543,
      "step": 5836
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6661578751504704,
      "learning_rate": 6.7312455314615475e-06,
      "loss": 0.4598,
      "step": 5837
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.200271793974412,
      "learning_rate": 6.730189121285371e-06,
      "loss": 0.5476,
      "step": 5838
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.9592695248535092,
      "learning_rate": 6.729132623359641e-06,
      "loss": 0.5228,
      "step": 5839
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.9449008057615391,
      "learning_rate": 6.728076037737943e-06,
      "loss": 0.5303,
      "step": 5840
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.594449416903762,
      "learning_rate": 6.727019364473861e-06,
      "loss": 0.5433,
      "step": 5841
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.166198555515203,
      "learning_rate": 6.725962603620988e-06,
      "loss": 0.5256,
      "step": 5842
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.8072050503832413,
      "learning_rate": 6.7249057552329175e-06,
      "loss": 0.507,
      "step": 5843
    },
    {
      "epoch": 0.41,
      "grad_norm": 5.742955530172074,
      "learning_rate": 6.723848819363253e-06,
      "loss": 0.463,
      "step": 5844
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.841222076072639,
      "learning_rate": 6.722791796065596e-06,
      "loss": 0.4951,
      "step": 5845
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.9571215245018756,
      "learning_rate": 6.721734685393554e-06,
      "loss": 0.5409,
      "step": 5846
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.2661372215354763,
      "learning_rate": 6.7206774874007415e-06,
      "loss": 0.5123,
      "step": 5847
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.161106516786282,
      "learning_rate": 6.71962020214078e-06,
      "loss": 0.522,
      "step": 5848
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.358890393152963,
      "learning_rate": 6.718562829667284e-06,
      "loss": 0.5546,
      "step": 5849
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.6896606341068054,
      "learning_rate": 6.717505370033887e-06,
      "loss": 0.5376,
      "step": 5850
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.8547604818331496,
      "learning_rate": 6.716447823294215e-06,
      "loss": 0.4722,
      "step": 5851
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.7916730685679054,
      "learning_rate": 6.715390189501907e-06,
      "loss": 0.5326,
      "step": 5852
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.848782750886842,
      "learning_rate": 6.7143324687106e-06,
      "loss": 0.5511,
      "step": 5853
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.98996686643567,
      "learning_rate": 6.713274660973941e-06,
      "loss": 0.5172,
      "step": 5854
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.9570702580039956,
      "learning_rate": 6.712216766345575e-06,
      "loss": 0.4603,
      "step": 5855
    },
    {
      "epoch": 0.41,
      "grad_norm": 4.832894917193961,
      "learning_rate": 6.711158784879157e-06,
      "loss": 0.5016,
      "step": 5856
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.5454336036204315,
      "learning_rate": 6.710100716628345e-06,
      "loss": 0.5124,
      "step": 5857
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.7718463488499554,
      "learning_rate": 6.709042561646799e-06,
      "loss": 0.4913,
      "step": 5858
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.7025573259965439,
      "learning_rate": 6.7079843199881854e-06,
      "loss": 0.506,
      "step": 5859
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.8986140227436707,
      "learning_rate": 6.706925991706178e-06,
      "loss": 0.5537,
      "step": 5860
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.04499049498339,
      "learning_rate": 6.705867576854447e-06,
      "loss": 0.47,
      "step": 5861
    },
    {
      "epoch": 0.41,
      "grad_norm": 21.496370950098356,
      "learning_rate": 6.704809075486674e-06,
      "loss": 0.4938,
      "step": 5862
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.9553545609000074,
      "learning_rate": 6.703750487656544e-06,
      "loss": 0.509,
      "step": 5863
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.7245161385553383,
      "learning_rate": 6.702691813417743e-06,
      "loss": 0.5534,
      "step": 5864
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.3767152960344453,
      "learning_rate": 6.7016330528239635e-06,
      "loss": 0.4996,
      "step": 5865
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.4616009352930392,
      "learning_rate": 6.700574205928905e-06,
      "loss": 0.5361,
      "step": 5866
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.6135805339093785,
      "learning_rate": 6.6995152727862654e-06,
      "loss": 0.5388,
      "step": 5867
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.1425520890535448,
      "learning_rate": 6.698456253449754e-06,
      "loss": 0.5188,
      "step": 5868
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.6832902941216632,
      "learning_rate": 6.697397147973077e-06,
      "loss": 0.5346,
      "step": 5869
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.0617608014442004,
      "learning_rate": 6.696337956409951e-06,
      "loss": 0.5045,
      "step": 5870
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.334554396410867,
      "learning_rate": 6.6952786788140936e-06,
      "loss": 0.5264,
      "step": 5871
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.0584631127337696,
      "learning_rate": 6.694219315239228e-06,
      "loss": 0.5592,
      "step": 5872
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.557707137119458,
      "learning_rate": 6.693159865739083e-06,
      "loss": 0.5097,
      "step": 5873
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.946148384129456,
      "learning_rate": 6.6921003303673895e-06,
      "loss": 0.5248,
      "step": 5874
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.254592957833778,
      "learning_rate": 6.691040709177885e-06,
      "loss": 0.5329,
      "step": 5875
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.663889415557295,
      "learning_rate": 6.689981002224306e-06,
      "loss": 0.5178,
      "step": 5876
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.2777802797529767,
      "learning_rate": 6.6889212095604036e-06,
      "loss": 0.4981,
      "step": 5877
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.150443477161267,
      "learning_rate": 6.6878613312399225e-06,
      "loss": 0.5001,
      "step": 5878
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.064787639869558,
      "learning_rate": 6.686801367316618e-06,
      "loss": 0.518,
      "step": 5879
    },
    {
      "epoch": 0.41,
      "grad_norm": 6.272978566893585,
      "learning_rate": 6.685741317844245e-06,
      "loss": 0.4891,
      "step": 5880
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.1242431244061812,
      "learning_rate": 6.68468118287657e-06,
      "loss": 0.5108,
      "step": 5881
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.776306613709431,
      "learning_rate": 6.6836209624673575e-06,
      "loss": 0.5497,
      "step": 5882
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.881261597022634,
      "learning_rate": 6.68256065667038e-06,
      "loss": 0.4869,
      "step": 5883
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.7185245213680662,
      "learning_rate": 6.681500265539409e-06,
      "loss": 0.5116,
      "step": 5884
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.2756533384295223,
      "learning_rate": 6.680439789128228e-06,
      "loss": 0.5462,
      "step": 5885
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.8331708082808447,
      "learning_rate": 6.6793792274906185e-06,
      "loss": 0.503,
      "step": 5886
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.8973527064724878,
      "learning_rate": 6.678318580680371e-06,
      "loss": 0.4799,
      "step": 5887
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.6761780898051934,
      "learning_rate": 6.677257848751276e-06,
      "loss": 0.4424,
      "step": 5888
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.3853751416147224,
      "learning_rate": 6.676197031757131e-06,
      "loss": 0.5526,
      "step": 5889
    },
    {
      "epoch": 0.41,
      "grad_norm": 3.2221009769860984,
      "learning_rate": 6.675136129751737e-06,
      "loss": 0.4967,
      "step": 5890
    },
    {
      "epoch": 0.41,
      "grad_norm": 3.518419663795329,
      "learning_rate": 6.6740751427889e-06,
      "loss": 0.5133,
      "step": 5891
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.9912332082901698,
      "learning_rate": 6.67301407092243e-06,
      "loss": 0.5177,
      "step": 5892
    },
    {
      "epoch": 0.41,
      "grad_norm": 3.600725134764995,
      "learning_rate": 6.6719529142061415e-06,
      "loss": 0.5122,
      "step": 5893
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.6649593281687884,
      "learning_rate": 6.67089167269385e-06,
      "loss": 0.4979,
      "step": 5894
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.15974085540673,
      "learning_rate": 6.669830346439381e-06,
      "loss": 0.4855,
      "step": 5895
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.1649847921233074,
      "learning_rate": 6.668768935496561e-06,
      "loss": 0.5087,
      "step": 5896
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.6135385562354034,
      "learning_rate": 6.667707439919221e-06,
      "loss": 0.5437,
      "step": 5897
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.235053802306436,
      "learning_rate": 6.666645859761196e-06,
      "loss": 0.5321,
      "step": 5898
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.4545538334053214,
      "learning_rate": 6.665584195076329e-06,
      "loss": 0.4838,
      "step": 5899
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.7373048630041014,
      "learning_rate": 6.66452244591846e-06,
      "loss": 0.4698,
      "step": 5900
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.8483760862026584,
      "learning_rate": 6.6634606123414395e-06,
      "loss": 0.5135,
      "step": 5901
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.892876572876232,
      "learning_rate": 6.662398694399119e-06,
      "loss": 0.5243,
      "step": 5902
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.0393993257508107,
      "learning_rate": 6.661336692145358e-06,
      "loss": 0.5258,
      "step": 5903
    },
    {
      "epoch": 0.41,
      "grad_norm": 3.500823208424005,
      "learning_rate": 6.660274605634015e-06,
      "loss": 0.4748,
      "step": 5904
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.7319082211115207,
      "learning_rate": 6.659212434918958e-06,
      "loss": 0.5004,
      "step": 5905
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.9240387791534368,
      "learning_rate": 6.658150180054054e-06,
      "loss": 0.5292,
      "step": 5906
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.95770419911436,
      "learning_rate": 6.657087841093179e-06,
      "loss": 0.4795,
      "step": 5907
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.9622191430978335,
      "learning_rate": 6.6560254180902115e-06,
      "loss": 0.538,
      "step": 5908
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.8489748158082957,
      "learning_rate": 6.654962911099035e-06,
      "loss": 0.5186,
      "step": 5909
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.6913132390678847,
      "learning_rate": 6.653900320173533e-06,
      "loss": 0.5013,
      "step": 5910
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.7827025173373061,
      "learning_rate": 6.652837645367601e-06,
      "loss": 0.5097,
      "step": 5911
    },
    {
      "epoch": 0.41,
      "grad_norm": 3.3864811740273075,
      "learning_rate": 6.651774886735132e-06,
      "loss": 0.5138,
      "step": 5912
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.6647200445741146,
      "learning_rate": 6.650712044330024e-06,
      "loss": 0.5381,
      "step": 5913
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.9582698814847932,
      "learning_rate": 6.649649118206184e-06,
      "loss": 0.5078,
      "step": 5914
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.973731513615494,
      "learning_rate": 6.648586108417519e-06,
      "loss": 0.5095,
      "step": 5915
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.9055374345770622,
      "learning_rate": 6.647523015017941e-06,
      "loss": 0.5158,
      "step": 5916
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.949552138537158,
      "learning_rate": 6.646459838061367e-06,
      "loss": 0.4946,
      "step": 5917
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.1790661378596177,
      "learning_rate": 6.645396577601716e-06,
      "loss": 0.5168,
      "step": 5918
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.9537607997977648,
      "learning_rate": 6.644333233692917e-06,
      "loss": 0.5481,
      "step": 5919
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.8370412211780296,
      "learning_rate": 6.643269806388897e-06,
      "loss": 0.5096,
      "step": 5920
    },
    {
      "epoch": 0.41,
      "grad_norm": 4.0961996952182025,
      "learning_rate": 6.642206295743589e-06,
      "loss": 0.5421,
      "step": 5921
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.3654256295677727,
      "learning_rate": 6.641142701810932e-06,
      "loss": 0.5321,
      "step": 5922
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.8441778261396662,
      "learning_rate": 6.6400790246448685e-06,
      "loss": 0.5133,
      "step": 5923
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.364101558035472,
      "learning_rate": 6.639015264299342e-06,
      "loss": 0.5135,
      "step": 5924
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.1515943693211708,
      "learning_rate": 6.637951420828307e-06,
      "loss": 0.5398,
      "step": 5925
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.754595934033363,
      "learning_rate": 6.636887494285713e-06,
      "loss": 0.478,
      "step": 5926
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.7419859025534083,
      "learning_rate": 6.635823484725525e-06,
      "loss": 0.4854,
      "step": 5927
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.7873307483130805,
      "learning_rate": 6.6347593922017e-06,
      "loss": 0.5063,
      "step": 5928
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.6304726757231622,
      "learning_rate": 6.6336952167682116e-06,
      "loss": 0.4803,
      "step": 5929
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.9007230233564487,
      "learning_rate": 6.632630958479025e-06,
      "loss": 0.5625,
      "step": 5930
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.658054896176399,
      "learning_rate": 6.63156661738812e-06,
      "loss": 0.5061,
      "step": 5931
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.448400884757512,
      "learning_rate": 6.6305021935494755e-06,
      "loss": 0.485,
      "step": 5932
    },
    {
      "epoch": 0.41,
      "grad_norm": 3.0158266972676553,
      "learning_rate": 6.629437687017075e-06,
      "loss": 0.5304,
      "step": 5933
    },
    {
      "epoch": 0.41,
      "grad_norm": 3.6779858682129367,
      "learning_rate": 6.628373097844909e-06,
      "loss": 0.5013,
      "step": 5934
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.663895277728577,
      "learning_rate": 6.6273084260869665e-06,
      "loss": 0.4888,
      "step": 5935
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.7011751849770924,
      "learning_rate": 6.626243671797246e-06,
      "loss": 0.4888,
      "step": 5936
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.6127027989748437,
      "learning_rate": 6.625178835029749e-06,
      "loss": 0.4971,
      "step": 5937
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.0673199698011095,
      "learning_rate": 6.624113915838479e-06,
      "loss": 0.489,
      "step": 5938
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.975322989881532,
      "learning_rate": 6.623048914277446e-06,
      "loss": 0.4975,
      "step": 5939
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.9835476892388273,
      "learning_rate": 6.621983830400665e-06,
      "loss": 0.5066,
      "step": 5940
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.908659797359091,
      "learning_rate": 6.62091866426215e-06,
      "loss": 0.5068,
      "step": 5941
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.2363626057171353,
      "learning_rate": 6.619853415915926e-06,
      "loss": 0.5035,
      "step": 5942
    },
    {
      "epoch": 0.41,
      "grad_norm": 13.641460525670727,
      "learning_rate": 6.618788085416019e-06,
      "loss": 0.5435,
      "step": 5943
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.7262876761483292,
      "learning_rate": 6.617722672816457e-06,
      "loss": 0.4316,
      "step": 5944
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.5033540943495174,
      "learning_rate": 6.616657178171275e-06,
      "loss": 0.5228,
      "step": 5945
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.1829090546367484,
      "learning_rate": 6.615591601534513e-06,
      "loss": 0.4617,
      "step": 5946
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.485219088449637,
      "learning_rate": 6.614525942960209e-06,
      "loss": 0.4981,
      "step": 5947
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.671887162420791,
      "learning_rate": 6.613460202502414e-06,
      "loss": 0.5009,
      "step": 5948
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.777383847707945,
      "learning_rate": 6.612394380215178e-06,
      "loss": 0.5277,
      "step": 5949
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.478734934608689,
      "learning_rate": 6.611328476152557e-06,
      "loss": 0.4856,
      "step": 5950
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.4252287837834396,
      "learning_rate": 6.610262490368606e-06,
      "loss": 0.5409,
      "step": 5951
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.98378801138799,
      "learning_rate": 6.609196422917394e-06,
      "loss": 0.5377,
      "step": 5952
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.8281051801454713,
      "learning_rate": 6.608130273852984e-06,
      "loss": 0.5358,
      "step": 5953
    },
    {
      "epoch": 0.41,
      "grad_norm": 3.2744155349288984,
      "learning_rate": 6.60706404322945e-06,
      "loss": 0.5176,
      "step": 5954
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.7239317405999584,
      "learning_rate": 6.605997731100868e-06,
      "loss": 0.4735,
      "step": 5955
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.671402736238369,
      "learning_rate": 6.604931337521316e-06,
      "loss": 0.4468,
      "step": 5956
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.228810220816891,
      "learning_rate": 6.603864862544879e-06,
      "loss": 0.5421,
      "step": 5957
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.8551004430622837,
      "learning_rate": 6.6027983062256455e-06,
      "loss": 0.5258,
      "step": 5958
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.9359671774198224,
      "learning_rate": 6.6017316686177055e-06,
      "loss": 0.5322,
      "step": 5959
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.239048326127158,
      "learning_rate": 6.60066494977516e-06,
      "loss": 0.458,
      "step": 5960
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.133306009219905,
      "learning_rate": 6.5995981497521045e-06,
      "loss": 0.5008,
      "step": 5961
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.6022031782067379,
      "learning_rate": 6.598531268602646e-06,
      "loss": 0.453,
      "step": 5962
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.078353926714914,
      "learning_rate": 6.5974643063808945e-06,
      "loss": 0.5347,
      "step": 5963
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.553996922445491,
      "learning_rate": 6.59639726314096e-06,
      "loss": 0.4726,
      "step": 5964
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.1818504982584472,
      "learning_rate": 6.595330138936961e-06,
      "loss": 0.5225,
      "step": 5965
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.0621153005033452,
      "learning_rate": 6.594262933823019e-06,
      "loss": 0.5098,
      "step": 5966
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.7599427191962052,
      "learning_rate": 6.5931956478532585e-06,
      "loss": 0.4466,
      "step": 5967
    },
    {
      "epoch": 0.41,
      "grad_norm": 4.620418288461357,
      "learning_rate": 6.59212828108181e-06,
      "loss": 0.5138,
      "step": 5968
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.2656115349940187,
      "learning_rate": 6.591060833562803e-06,
      "loss": 0.4922,
      "step": 5969
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.2567752030711477,
      "learning_rate": 6.5899933053503804e-06,
      "loss": 0.5277,
      "step": 5970
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.2649818783080717,
      "learning_rate": 6.588925696498679e-06,
      "loss": 0.4883,
      "step": 5971
    },
    {
      "epoch": 0.42,
      "grad_norm": 3.9051121526412187,
      "learning_rate": 6.587858007061848e-06,
      "loss": 0.5439,
      "step": 5972
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.8645088757417985,
      "learning_rate": 6.586790237094034e-06,
      "loss": 0.4899,
      "step": 5973
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.1933553654800737,
      "learning_rate": 6.585722386649394e-06,
      "loss": 0.5035,
      "step": 5974
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.7327215197915191,
      "learning_rate": 6.584654455782083e-06,
      "loss": 0.4827,
      "step": 5975
    },
    {
      "epoch": 0.42,
      "grad_norm": 3.124544275364743,
      "learning_rate": 6.583586444546265e-06,
      "loss": 0.5236,
      "step": 5976
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.5967840651935905,
      "learning_rate": 6.5825183529961046e-06,
      "loss": 0.5139,
      "step": 5977
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.6971344913777688,
      "learning_rate": 6.581450181185773e-06,
      "loss": 0.4884,
      "step": 5978
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.751028402166859,
      "learning_rate": 6.580381929169446e-06,
      "loss": 0.5362,
      "step": 5979
    },
    {
      "epoch": 0.42,
      "grad_norm": 5.029286211248185,
      "learning_rate": 6.579313597001298e-06,
      "loss": 0.4784,
      "step": 5980
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.0667803178022983,
      "learning_rate": 6.578245184735513e-06,
      "loss": 0.4794,
      "step": 5981
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.797961894473001,
      "learning_rate": 6.5771766924262795e-06,
      "loss": 0.5072,
      "step": 5982
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.8668733448389643,
      "learning_rate": 6.576108120127783e-06,
      "loss": 0.5778,
      "step": 5983
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.9291697827938843,
      "learning_rate": 6.575039467894223e-06,
      "loss": 0.5049,
      "step": 5984
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.7270466015219104,
      "learning_rate": 6.573970735779796e-06,
      "loss": 0.5072,
      "step": 5985
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.959518153204676,
      "learning_rate": 6.572901923838704e-06,
      "loss": 0.4819,
      "step": 5986
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.7064699299462865,
      "learning_rate": 6.571833032125154e-06,
      "loss": 0.4426,
      "step": 5987
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.722117634178258,
      "learning_rate": 6.570764060693359e-06,
      "loss": 0.5742,
      "step": 5988
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.136399942017868,
      "learning_rate": 6.569695009597531e-06,
      "loss": 0.4773,
      "step": 5989
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.84940311530577,
      "learning_rate": 6.56862587889189e-06,
      "loss": 0.4943,
      "step": 5990
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.5894746135014932,
      "learning_rate": 6.567556668630657e-06,
      "loss": 0.4897,
      "step": 5991
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.0908554155444645,
      "learning_rate": 6.566487378868062e-06,
      "loss": 0.5608,
      "step": 5992
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.88935039870045,
      "learning_rate": 6.565418009658332e-06,
      "loss": 0.5294,
      "step": 5993
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.0707042887885487,
      "learning_rate": 6.564348561055705e-06,
      "loss": 0.4802,
      "step": 5994
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.752452050661505,
      "learning_rate": 6.563279033114421e-06,
      "loss": 0.4815,
      "step": 5995
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.063885199389435,
      "learning_rate": 6.562209425888718e-06,
      "loss": 0.4921,
      "step": 5996
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6344005134793328,
      "learning_rate": 6.5611397394328465e-06,
      "loss": 0.4716,
      "step": 5997
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.1387136442759793,
      "learning_rate": 6.56006997380106e-06,
      "loss": 0.5122,
      "step": 5998
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6123409380733537,
      "learning_rate": 6.559000129047607e-06,
      "loss": 0.424,
      "step": 5999
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.9453046568551815,
      "learning_rate": 6.557930205226752e-06,
      "loss": 0.5081,
      "step": 6000
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.794597441366289,
      "learning_rate": 6.556860202392757e-06,
      "loss": 0.4905,
      "step": 6001
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.9097912949981448,
      "learning_rate": 6.555790120599885e-06,
      "loss": 0.4922,
      "step": 6002
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.275894892873848,
      "learning_rate": 6.554719959902414e-06,
      "loss": 0.5585,
      "step": 6003
    },
    {
      "epoch": 0.42,
      "grad_norm": 3.458677920546218,
      "learning_rate": 6.553649720354612e-06,
      "loss": 0.5251,
      "step": 6004
    },
    {
      "epoch": 0.42,
      "grad_norm": 9.024762595254838,
      "learning_rate": 6.5525794020107634e-06,
      "loss": 0.5187,
      "step": 6005
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.486563876982144,
      "learning_rate": 6.551509004925149e-06,
      "loss": 0.4827,
      "step": 6006
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.1877106002259725,
      "learning_rate": 6.5504385291520554e-06,
      "loss": 0.538,
      "step": 6007
    },
    {
      "epoch": 0.42,
      "grad_norm": 4.8084960456815615,
      "learning_rate": 6.549367974745775e-06,
      "loss": 0.5672,
      "step": 6008
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.6419607753748022,
      "learning_rate": 6.548297341760601e-06,
      "loss": 0.4923,
      "step": 6009
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6840378677558242,
      "learning_rate": 6.547226630250836e-06,
      "loss": 0.4763,
      "step": 6010
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.696568861364011,
      "learning_rate": 6.546155840270778e-06,
      "loss": 0.499,
      "step": 6011
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.7158536799147253,
      "learning_rate": 6.545084971874738e-06,
      "loss": 0.467,
      "step": 6012
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.295479301069819,
      "learning_rate": 6.544014025117025e-06,
      "loss": 0.5141,
      "step": 6013
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.5412946031079795,
      "learning_rate": 6.542943000051954e-06,
      "loss": 0.4974,
      "step": 6014
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.1721196461627903,
      "learning_rate": 6.541871896733845e-06,
      "loss": 0.4875,
      "step": 6015
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.752071288882088,
      "learning_rate": 6.5408007152170194e-06,
      "loss": 0.5159,
      "step": 6016
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.8829281735956596,
      "learning_rate": 6.539729455555805e-06,
      "loss": 0.4772,
      "step": 6017
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.4653339010467636,
      "learning_rate": 6.538658117804532e-06,
      "loss": 0.5237,
      "step": 6018
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.687428402022985,
      "learning_rate": 6.537586702017538e-06,
      "loss": 0.5411,
      "step": 6019
    },
    {
      "epoch": 0.42,
      "grad_norm": 3.8423455971689666,
      "learning_rate": 6.5365152082491566e-06,
      "loss": 0.4872,
      "step": 6020
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6811110328290251,
      "learning_rate": 6.5354436365537355e-06,
      "loss": 0.4327,
      "step": 6021
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.043188317860781,
      "learning_rate": 6.534371986985618e-06,
      "loss": 0.5378,
      "step": 6022
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.699779217942912,
      "learning_rate": 6.5333002595991555e-06,
      "loss": 0.4593,
      "step": 6023
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.3423152458560716,
      "learning_rate": 6.532228454448702e-06,
      "loss": 0.524,
      "step": 6024
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5849167671262833,
      "learning_rate": 6.531156571588618e-06,
      "loss": 0.4393,
      "step": 6025
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.9763086021257035,
      "learning_rate": 6.530084611073263e-06,
      "loss": 0.5075,
      "step": 6026
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.8881328121182943,
      "learning_rate": 6.5290125729570066e-06,
      "loss": 0.5421,
      "step": 6027
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.557732820803082,
      "learning_rate": 6.527940457294215e-06,
      "loss": 0.5514,
      "step": 6028
    },
    {
      "epoch": 0.42,
      "grad_norm": 4.313503393979462,
      "learning_rate": 6.526868264139267e-06,
      "loss": 0.5203,
      "step": 6029
    },
    {
      "epoch": 0.42,
      "grad_norm": 3.653738529784156,
      "learning_rate": 6.5257959935465374e-06,
      "loss": 0.5163,
      "step": 6030
    },
    {
      "epoch": 0.42,
      "grad_norm": 3.382377485942328,
      "learning_rate": 6.52472364557041e-06,
      "loss": 0.5184,
      "step": 6031
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.0312076693732783,
      "learning_rate": 6.523651220265269e-06,
      "loss": 0.4855,
      "step": 6032
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.311032336220973,
      "learning_rate": 6.522578717685507e-06,
      "loss": 0.4648,
      "step": 6033
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.4138368119334883,
      "learning_rate": 6.521506137885516e-06,
      "loss": 0.5321,
      "step": 6034
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.782040005321962,
      "learning_rate": 6.520433480919695e-06,
      "loss": 0.475,
      "step": 6035
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.381636948171357,
      "learning_rate": 6.519360746842442e-06,
      "loss": 0.5078,
      "step": 6036
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.0133824338756523,
      "learning_rate": 6.518287935708168e-06,
      "loss": 0.5031,
      "step": 6037
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.0845749032741416,
      "learning_rate": 6.517215047571277e-06,
      "loss": 0.5241,
      "step": 6038
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.1576383773640977,
      "learning_rate": 6.516142082486188e-06,
      "loss": 0.4959,
      "step": 6039
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.914657653531514,
      "learning_rate": 6.5150690405073135e-06,
      "loss": 0.5047,
      "step": 6040
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.8607105980595369,
      "learning_rate": 6.513995921689078e-06,
      "loss": 0.5378,
      "step": 6041
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.2124988796130065,
      "learning_rate": 6.512922726085904e-06,
      "loss": 0.4685,
      "step": 6042
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.0103399424120756,
      "learning_rate": 6.5118494537522235e-06,
      "loss": 0.5084,
      "step": 6043
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.1547196140553986,
      "learning_rate": 6.510776104742467e-06,
      "loss": 0.483,
      "step": 6044
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.8554072918802729,
      "learning_rate": 6.50970267911107e-06,
      "loss": 0.5064,
      "step": 6045
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.7448122572252158,
      "learning_rate": 6.508629176912478e-06,
      "loss": 0.4596,
      "step": 6046
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.397997578141328,
      "learning_rate": 6.507555598201132e-06,
      "loss": 0.5535,
      "step": 6047
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.7398271790471025,
      "learning_rate": 6.506481943031479e-06,
      "loss": 0.5591,
      "step": 6048
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.6897547652388352,
      "learning_rate": 6.5054082114579744e-06,
      "loss": 0.5423,
      "step": 6049
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.1355426859313527,
      "learning_rate": 6.504334403535073e-06,
      "loss": 0.4861,
      "step": 6050
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.8282563382266306,
      "learning_rate": 6.503260519317236e-06,
      "loss": 0.5629,
      "step": 6051
    },
    {
      "epoch": 0.42,
      "grad_norm": 4.2256491915753545,
      "learning_rate": 6.502186558858925e-06,
      "loss": 0.5201,
      "step": 6052
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.696375342144634,
      "learning_rate": 6.50111252221461e-06,
      "loss": 0.5098,
      "step": 6053
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.097438147837049,
      "learning_rate": 6.50003840943876e-06,
      "loss": 0.5237,
      "step": 6054
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6751154514522303,
      "learning_rate": 6.498964220585855e-06,
      "loss": 0.4543,
      "step": 6055
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.6403360148060093,
      "learning_rate": 6.49788995571037e-06,
      "loss": 0.5093,
      "step": 6056
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.5832389153892059,
      "learning_rate": 6.496815614866792e-06,
      "loss": 0.4384,
      "step": 6057
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.0605208233155694,
      "learning_rate": 6.495741198109603e-06,
      "loss": 0.4985,
      "step": 6058
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.72904716667315,
      "learning_rate": 6.494666705493299e-06,
      "loss": 0.4788,
      "step": 6059
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.3719476576239766,
      "learning_rate": 6.493592137072371e-06,
      "loss": 0.4999,
      "step": 6060
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.3973223589727,
      "learning_rate": 6.492517492901321e-06,
      "loss": 0.4785,
      "step": 6061
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.3367707096854753,
      "learning_rate": 6.4914427730346465e-06,
      "loss": 0.5071,
      "step": 6062
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.469674215908696,
      "learning_rate": 6.4903679775268595e-06,
      "loss": 0.5155,
      "step": 6063
    },
    {
      "epoch": 0.42,
      "grad_norm": 3.9301737757076722,
      "learning_rate": 6.489293106432466e-06,
      "loss": 0.4965,
      "step": 6064
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.578765497302323,
      "learning_rate": 6.488218159805983e-06,
      "loss": 0.5195,
      "step": 6065
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.6046131338268292,
      "learning_rate": 6.487143137701925e-06,
      "loss": 0.4895,
      "step": 6066
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.9551443147715366,
      "learning_rate": 6.486068040174818e-06,
      "loss": 0.4869,
      "step": 6067
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.8010549857270064,
      "learning_rate": 6.484992867279184e-06,
      "loss": 0.5228,
      "step": 6068
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.4279752562945607,
      "learning_rate": 6.483917619069552e-06,
      "loss": 0.5621,
      "step": 6069
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.2741579007146653,
      "learning_rate": 6.482842295600458e-06,
      "loss": 0.4739,
      "step": 6070
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.2658758904818797,
      "learning_rate": 6.481766896926434e-06,
      "loss": 0.4618,
      "step": 6071
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.7299407718752923,
      "learning_rate": 6.480691423102028e-06,
      "loss": 0.4737,
      "step": 6072
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.64319795447884,
      "learning_rate": 6.479615874181777e-06,
      "loss": 0.5241,
      "step": 6073
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.63783989683804,
      "learning_rate": 6.4785402502202345e-06,
      "loss": 0.4998,
      "step": 6074
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.0071908175976114,
      "learning_rate": 6.477464551271949e-06,
      "loss": 0.5109,
      "step": 6075
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.7572239871466797,
      "learning_rate": 6.47638877739148e-06,
      "loss": 0.484,
      "step": 6076
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.403932876530472,
      "learning_rate": 6.475312928633386e-06,
      "loss": 0.5047,
      "step": 6077
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.0403733809184783,
      "learning_rate": 6.474237005052228e-06,
      "loss": 0.5251,
      "step": 6078
    },
    {
      "epoch": 0.42,
      "grad_norm": 3.4126096948765294,
      "learning_rate": 6.473161006702578e-06,
      "loss": 0.5103,
      "step": 6079
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.7082578525701693,
      "learning_rate": 6.472084933639002e-06,
      "loss": 0.5175,
      "step": 6080
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.034797386482688,
      "learning_rate": 6.471008785916078e-06,
      "loss": 0.5022,
      "step": 6081
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.1106853208332015,
      "learning_rate": 6.469932563588386e-06,
      "loss": 0.575,
      "step": 6082
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.6849520267125202,
      "learning_rate": 6.4688562667105035e-06,
      "loss": 0.52,
      "step": 6083
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.436143943719915,
      "learning_rate": 6.467779895337022e-06,
      "loss": 0.501,
      "step": 6084
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.346205621152987,
      "learning_rate": 6.466703449522529e-06,
      "loss": 0.4881,
      "step": 6085
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.7766885107385737,
      "learning_rate": 6.4656269293216186e-06,
      "loss": 0.5196,
      "step": 6086
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.982712507423235,
      "learning_rate": 6.464550334788888e-06,
      "loss": 0.5224,
      "step": 6087
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.2638312600855546,
      "learning_rate": 6.463473665978941e-06,
      "loss": 0.5433,
      "step": 6088
    },
    {
      "epoch": 0.42,
      "grad_norm": 3.4778186076724484,
      "learning_rate": 6.46239692294638e-06,
      "loss": 0.5331,
      "step": 6089
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.6762531478672567,
      "learning_rate": 6.461320105745815e-06,
      "loss": 0.4745,
      "step": 6090
    },
    {
      "epoch": 0.42,
      "grad_norm": 14.278382780163051,
      "learning_rate": 6.460243214431857e-06,
      "loss": 0.4801,
      "step": 6091
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.8528285717985202,
      "learning_rate": 6.459166249059125e-06,
      "loss": 0.508,
      "step": 6092
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.127575153083209,
      "learning_rate": 6.458089209682238e-06,
      "loss": 0.4975,
      "step": 6093
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.2792407927358918,
      "learning_rate": 6.457012096355819e-06,
      "loss": 0.5133,
      "step": 6094
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.9013735237108536,
      "learning_rate": 6.4559349091344984e-06,
      "loss": 0.5003,
      "step": 6095
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.1652537679406425,
      "learning_rate": 6.4548576480729045e-06,
      "loss": 0.4843,
      "step": 6096
    },
    {
      "epoch": 0.42,
      "grad_norm": 3.356897468741257,
      "learning_rate": 6.4537803132256724e-06,
      "loss": 0.5553,
      "step": 6097
    },
    {
      "epoch": 0.42,
      "grad_norm": 6.154410647644762,
      "learning_rate": 6.452702904647445e-06,
      "loss": 0.5031,
      "step": 6098
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.81013346936653,
      "learning_rate": 6.451625422392861e-06,
      "loss": 0.4978,
      "step": 6099
    },
    {
      "epoch": 0.42,
      "grad_norm": 3.033056633803141,
      "learning_rate": 6.450547866516569e-06,
      "loss": 0.5334,
      "step": 6100
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.6911802888715433,
      "learning_rate": 6.4494702370732186e-06,
      "loss": 0.5321,
      "step": 6101
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.5640061132570013,
      "learning_rate": 6.4483925341174625e-06,
      "loss": 0.4843,
      "step": 6102
    },
    {
      "epoch": 0.42,
      "grad_norm": 3.4287255505167162,
      "learning_rate": 6.447314757703958e-06,
      "loss": 0.4882,
      "step": 6103
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.8575824057515438,
      "learning_rate": 6.44623690788737e-06,
      "loss": 0.5838,
      "step": 6104
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.2167879059930704,
      "learning_rate": 6.445158984722358e-06,
      "loss": 0.5131,
      "step": 6105
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.9439038742954777,
      "learning_rate": 6.4440809882635966e-06,
      "loss": 0.5504,
      "step": 6106
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.0109163471539806,
      "learning_rate": 6.443002918565754e-06,
      "loss": 0.5517,
      "step": 6107
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.6832872496088929,
      "learning_rate": 6.441924775683508e-06,
      "loss": 0.5174,
      "step": 6108
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.739595309447666,
      "learning_rate": 6.440846559671539e-06,
      "loss": 0.5023,
      "step": 6109
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.9613774435762006,
      "learning_rate": 6.439768270584529e-06,
      "loss": 0.5499,
      "step": 6110
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.6843855534753738,
      "learning_rate": 6.438689908477167e-06,
      "loss": 0.5195,
      "step": 6111
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.7141223233496015,
      "learning_rate": 6.437611473404143e-06,
      "loss": 0.531,
      "step": 6112
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6215772461836001,
      "learning_rate": 6.436532965420151e-06,
      "loss": 0.4766,
      "step": 6113
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.5755080378983144,
      "learning_rate": 6.4354543845798925e-06,
      "loss": 0.4908,
      "step": 6114
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.7105962182423384,
      "learning_rate": 6.434375730938065e-06,
      "loss": 0.5173,
      "step": 6115
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.72653392509794,
      "learning_rate": 6.433297004549378e-06,
      "loss": 0.561,
      "step": 6116
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.8831095545146521,
      "learning_rate": 6.432218205468539e-06,
      "loss": 0.4974,
      "step": 6117
    },
    {
      "epoch": 0.43,
      "grad_norm": 10.744772817404082,
      "learning_rate": 6.431139333750262e-06,
      "loss": 0.5681,
      "step": 6118
    },
    {
      "epoch": 0.43,
      "grad_norm": 3.234070554992316,
      "learning_rate": 6.430060389449265e-06,
      "loss": 0.5113,
      "step": 6119
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.9192009768317564,
      "learning_rate": 6.4289813726202665e-06,
      "loss": 0.5235,
      "step": 6120
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.8842411459575505,
      "learning_rate": 6.427902283317991e-06,
      "loss": 0.5081,
      "step": 6121
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.1387843329268628,
      "learning_rate": 6.426823121597169e-06,
      "loss": 0.4858,
      "step": 6122
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.8907944871681797,
      "learning_rate": 6.425743887512529e-06,
      "loss": 0.506,
      "step": 6123
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.5310499910371727,
      "learning_rate": 6.424664581118807e-06,
      "loss": 0.5248,
      "step": 6124
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.812167203247735,
      "learning_rate": 6.423585202470741e-06,
      "loss": 0.5109,
      "step": 6125
    },
    {
      "epoch": 0.43,
      "grad_norm": 3.763709428506718,
      "learning_rate": 6.422505751623076e-06,
      "loss": 0.5002,
      "step": 6126
    },
    {
      "epoch": 0.43,
      "grad_norm": 5.924304275707608,
      "learning_rate": 6.421426228630556e-06,
      "loss": 0.4946,
      "step": 6127
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.8861255134222104,
      "learning_rate": 6.4203466335479315e-06,
      "loss": 0.5043,
      "step": 6128
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.691134123243314,
      "learning_rate": 6.419266966429958e-06,
      "loss": 0.5028,
      "step": 6129
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.9329086902357757,
      "learning_rate": 6.418187227331389e-06,
      "loss": 0.4956,
      "step": 6130
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.7170948811724553,
      "learning_rate": 6.417107416306989e-06,
      "loss": 0.4791,
      "step": 6131
    },
    {
      "epoch": 0.43,
      "grad_norm": 3.1405724442430625,
      "learning_rate": 6.41602753341152e-06,
      "loss": 0.5016,
      "step": 6132
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.6261549493440466,
      "learning_rate": 6.4149475786997515e-06,
      "loss": 0.5124,
      "step": 6133
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.8728913363194402,
      "learning_rate": 6.413867552226456e-06,
      "loss": 0.5476,
      "step": 6134
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.426609728871625,
      "learning_rate": 6.412787454046407e-06,
      "loss": 0.4906,
      "step": 6135
    },
    {
      "epoch": 0.43,
      "grad_norm": 6.985928127991831,
      "learning_rate": 6.411707284214384e-06,
      "loss": 0.4926,
      "step": 6136
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.9687605782347035,
      "learning_rate": 6.410627042785169e-06,
      "loss": 0.4781,
      "step": 6137
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.1129764482921045,
      "learning_rate": 6.4095467298135495e-06,
      "loss": 0.4999,
      "step": 6138
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.5055156339002282,
      "learning_rate": 6.408466345354316e-06,
      "loss": 0.536,
      "step": 6139
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.4134274116132715,
      "learning_rate": 6.407385889462261e-06,
      "loss": 0.4922,
      "step": 6140
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6557998359880765,
      "learning_rate": 6.406305362192182e-06,
      "loss": 0.4474,
      "step": 6141
    },
    {
      "epoch": 0.43,
      "grad_norm": 14.530005108468556,
      "learning_rate": 6.40522476359888e-06,
      "loss": 0.464,
      "step": 6142
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.979784812001482,
      "learning_rate": 6.404144093737159e-06,
      "loss": 0.4774,
      "step": 6143
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.8561914929447911,
      "learning_rate": 6.403063352661829e-06,
      "loss": 0.514,
      "step": 6144
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.8130243834948574,
      "learning_rate": 6.401982540427698e-06,
      "loss": 0.5168,
      "step": 6145
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.7287643152917984,
      "learning_rate": 6.400901657089584e-06,
      "loss": 0.5582,
      "step": 6146
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.6735277428511495,
      "learning_rate": 6.3998207027023056e-06,
      "loss": 0.5,
      "step": 6147
    },
    {
      "epoch": 0.43,
      "grad_norm": 3.0708802998660603,
      "learning_rate": 6.398739677320683e-06,
      "loss": 0.524,
      "step": 6148
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.54459172170531,
      "learning_rate": 6.397658580999546e-06,
      "loss": 0.5439,
      "step": 6149
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.217232824603781,
      "learning_rate": 6.396577413793721e-06,
      "loss": 0.5283,
      "step": 6150
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.6345925175399545,
      "learning_rate": 6.395496175758045e-06,
      "loss": 0.4941,
      "step": 6151
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.894089284913841,
      "learning_rate": 6.394414866947349e-06,
      "loss": 0.5627,
      "step": 6152
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.5449949939300367,
      "learning_rate": 6.39333348741648e-06,
      "loss": 0.4876,
      "step": 6153
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.806803198349805,
      "learning_rate": 6.392252037220278e-06,
      "loss": 0.5041,
      "step": 6154
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.400933518572389,
      "learning_rate": 6.391170516413592e-06,
      "loss": 0.5423,
      "step": 6155
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.031725770755787,
      "learning_rate": 6.390088925051273e-06,
      "loss": 0.514,
      "step": 6156
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.172851708195436,
      "learning_rate": 6.389007263188176e-06,
      "loss": 0.4788,
      "step": 6157
    },
    {
      "epoch": 0.43,
      "grad_norm": 4.170243824792224,
      "learning_rate": 6.387925530879158e-06,
      "loss": 0.508,
      "step": 6158
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.3509482912148756,
      "learning_rate": 6.386843728179082e-06,
      "loss": 0.4795,
      "step": 6159
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.0769257105187213,
      "learning_rate": 6.385761855142813e-06,
      "loss": 0.5259,
      "step": 6160
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.8774792048202618,
      "learning_rate": 6.384679911825222e-06,
      "loss": 0.5075,
      "step": 6161
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.653256051193777,
      "learning_rate": 6.383597898281179e-06,
      "loss": 0.578,
      "step": 6162
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.7251985225738115,
      "learning_rate": 6.382515814565563e-06,
      "loss": 0.4422,
      "step": 6163
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.1115906997520066,
      "learning_rate": 6.38143366073325e-06,
      "loss": 0.5206,
      "step": 6164
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.742132485166047,
      "learning_rate": 6.380351436839127e-06,
      "loss": 0.4566,
      "step": 6165
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.9548066150332446,
      "learning_rate": 6.379269142938078e-06,
      "loss": 0.5204,
      "step": 6166
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.3065674619011434,
      "learning_rate": 6.378186779084996e-06,
      "loss": 0.5063,
      "step": 6167
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.9709431995918685,
      "learning_rate": 6.377104345334775e-06,
      "loss": 0.4932,
      "step": 6168
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.174131395696291,
      "learning_rate": 6.3760218417423096e-06,
      "loss": 0.5597,
      "step": 6169
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.3061348075635824,
      "learning_rate": 6.374939268362501e-06,
      "loss": 0.5633,
      "step": 6170
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.9750513755996495,
      "learning_rate": 6.373856625250257e-06,
      "loss": 0.52,
      "step": 6171
    },
    {
      "epoch": 0.43,
      "grad_norm": 6.841798014677437,
      "learning_rate": 6.372773912460484e-06,
      "loss": 0.462,
      "step": 6172
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.941785435734733,
      "learning_rate": 6.371691130048093e-06,
      "loss": 0.5056,
      "step": 6173
    },
    {
      "epoch": 0.43,
      "grad_norm": 3.1291282913958094,
      "learning_rate": 6.370608278068e-06,
      "loss": 0.509,
      "step": 6174
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.6709480480958412,
      "learning_rate": 6.369525356575123e-06,
      "loss": 0.516,
      "step": 6175
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.050370464801014,
      "learning_rate": 6.368442365624386e-06,
      "loss": 0.4982,
      "step": 6176
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.8062015239137954,
      "learning_rate": 6.367359305270714e-06,
      "loss": 0.4835,
      "step": 6177
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.1161562860799994,
      "learning_rate": 6.366276175569035e-06,
      "loss": 0.5642,
      "step": 6178
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.7307903154903028,
      "learning_rate": 6.365192976574284e-06,
      "loss": 0.5459,
      "step": 6179
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.729779540861252,
      "learning_rate": 6.364109708341394e-06,
      "loss": 0.4515,
      "step": 6180
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.368922515298341,
      "learning_rate": 6.363026370925309e-06,
      "loss": 0.5159,
      "step": 6181
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6960435784129078,
      "learning_rate": 6.361942964380967e-06,
      "loss": 0.4559,
      "step": 6182
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.7176756789188612,
      "learning_rate": 6.36085948876332e-06,
      "loss": 0.4652,
      "step": 6183
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.6880151438024857,
      "learning_rate": 6.3597759441273155e-06,
      "loss": 0.4978,
      "step": 6184
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.0316945673137403,
      "learning_rate": 6.3586923305279104e-06,
      "loss": 0.4953,
      "step": 6185
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.319659389858744,
      "learning_rate": 6.357608648020057e-06,
      "loss": 0.5223,
      "step": 6186
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.8961046373212491,
      "learning_rate": 6.356524896658721e-06,
      "loss": 0.5516,
      "step": 6187
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.9753974299666057,
      "learning_rate": 6.355441076498864e-06,
      "loss": 0.5166,
      "step": 6188
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.630604650553858,
      "learning_rate": 6.354357187595454e-06,
      "loss": 0.525,
      "step": 6189
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.8677892297120184,
      "learning_rate": 6.353273230003465e-06,
      "loss": 0.4735,
      "step": 6190
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.4672270410671078,
      "learning_rate": 6.35218920377787e-06,
      "loss": 0.5075,
      "step": 6191
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.6873194784506336,
      "learning_rate": 6.351105108973644e-06,
      "loss": 0.5134,
      "step": 6192
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.667556554299372,
      "learning_rate": 6.350020945645773e-06,
      "loss": 0.4986,
      "step": 6193
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.1877968494957365,
      "learning_rate": 6.348936713849241e-06,
      "loss": 0.4931,
      "step": 6194
    },
    {
      "epoch": 0.43,
      "grad_norm": 9.059640754131934,
      "learning_rate": 6.347852413639036e-06,
      "loss": 0.518,
      "step": 6195
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.503176586187713,
      "learning_rate": 6.346768045070153e-06,
      "loss": 0.5134,
      "step": 6196
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.656702791887758,
      "learning_rate": 6.345683608197582e-06,
      "loss": 0.5266,
      "step": 6197
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.1893506080624925,
      "learning_rate": 6.344599103076329e-06,
      "loss": 0.5421,
      "step": 6198
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.9567301166389546,
      "learning_rate": 6.343514529761392e-06,
      "loss": 0.4954,
      "step": 6199
    },
    {
      "epoch": 0.43,
      "grad_norm": 3.066612660644593,
      "learning_rate": 6.3424298883077775e-06,
      "loss": 0.5239,
      "step": 6200
    },
    {
      "epoch": 0.43,
      "grad_norm": 4.7831282101769625,
      "learning_rate": 6.3413451787704975e-06,
      "loss": 0.5268,
      "step": 6201
    },
    {
      "epoch": 0.43,
      "grad_norm": 3.2803336541203745,
      "learning_rate": 6.340260401204561e-06,
      "loss": 0.4799,
      "step": 6202
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.002825251841669,
      "learning_rate": 6.339175555664987e-06,
      "loss": 0.5305,
      "step": 6203
    },
    {
      "epoch": 0.43,
      "grad_norm": 3.7417163247729777,
      "learning_rate": 6.3380906422067955e-06,
      "loss": 0.4692,
      "step": 6204
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.9513151894858467,
      "learning_rate": 6.337005660885007e-06,
      "loss": 0.4912,
      "step": 6205
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.7066461680358556,
      "learning_rate": 6.335920611754652e-06,
      "loss": 0.5226,
      "step": 6206
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.772427879276383,
      "learning_rate": 6.334835494870759e-06,
      "loss": 0.5188,
      "step": 6207
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.2614361896428945,
      "learning_rate": 6.333750310288361e-06,
      "loss": 0.5079,
      "step": 6208
    },
    {
      "epoch": 0.43,
      "grad_norm": 3.2908211525060316,
      "learning_rate": 6.3326650580624946e-06,
      "loss": 0.5406,
      "step": 6209
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.006826197261,
      "learning_rate": 6.331579738248204e-06,
      "loss": 0.5183,
      "step": 6210
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.395855523537981,
      "learning_rate": 6.330494350900529e-06,
      "loss": 0.4909,
      "step": 6211
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.025702447999108,
      "learning_rate": 6.329408896074518e-06,
      "loss": 0.4733,
      "step": 6212
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.64179841731452,
      "learning_rate": 6.32832337382522e-06,
      "loss": 0.5591,
      "step": 6213
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.0162673600025256,
      "learning_rate": 6.327237784207693e-06,
      "loss": 0.5244,
      "step": 6214
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.083934600498144,
      "learning_rate": 6.326152127276992e-06,
      "loss": 0.5513,
      "step": 6215
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.8409545173348916,
      "learning_rate": 6.32506640308818e-06,
      "loss": 0.5045,
      "step": 6216
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.0913986280074948,
      "learning_rate": 6.323980611696319e-06,
      "loss": 0.4964,
      "step": 6217
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.7918476451118142,
      "learning_rate": 6.3228947531564775e-06,
      "loss": 0.479,
      "step": 6218
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.7757427921368918,
      "learning_rate": 6.3218088275237265e-06,
      "loss": 0.4867,
      "step": 6219
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.7503996018698565,
      "learning_rate": 6.3207228348531425e-06,
      "loss": 0.4372,
      "step": 6220
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.7149372122304354,
      "learning_rate": 6.3196367751998e-06,
      "loss": 0.4565,
      "step": 6221
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.7251927739899875,
      "learning_rate": 6.318550648618785e-06,
      "loss": 0.4933,
      "step": 6222
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.289239172312135,
      "learning_rate": 6.3174644551651795e-06,
      "loss": 0.5549,
      "step": 6223
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6782878635826419,
      "learning_rate": 6.316378194894072e-06,
      "loss": 0.4473,
      "step": 6224
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.1409555018740662,
      "learning_rate": 6.315291867860552e-06,
      "loss": 0.5226,
      "step": 6225
    },
    {
      "epoch": 0.43,
      "grad_norm": 14.566057091575564,
      "learning_rate": 6.3142054741197186e-06,
      "loss": 0.5163,
      "step": 6226
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.119577039460233,
      "learning_rate": 6.313119013726667e-06,
      "loss": 0.5191,
      "step": 6227
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.7090257075767326,
      "learning_rate": 6.312032486736501e-06,
      "loss": 0.4935,
      "step": 6228
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.198016886692466,
      "learning_rate": 6.310945893204324e-06,
      "loss": 0.5129,
      "step": 6229
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.9190576623530775,
      "learning_rate": 6.309859233185246e-06,
      "loss": 0.5063,
      "step": 6230
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.8809276452473886,
      "learning_rate": 6.308772506734377e-06,
      "loss": 0.5254,
      "step": 6231
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.781982457298504,
      "learning_rate": 6.307685713906835e-06,
      "loss": 0.5308,
      "step": 6232
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.9161944246760754,
      "learning_rate": 6.306598854757735e-06,
      "loss": 0.5409,
      "step": 6233
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.8919674618622275,
      "learning_rate": 6.305511929342202e-06,
      "loss": 0.4637,
      "step": 6234
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.9915404625526019,
      "learning_rate": 6.30442493771536e-06,
      "loss": 0.4803,
      "step": 6235
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.0757429425167446,
      "learning_rate": 6.303337879932339e-06,
      "loss": 0.5349,
      "step": 6236
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.0828841787795636,
      "learning_rate": 6.302250756048267e-06,
      "loss": 0.5498,
      "step": 6237
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.7308387622514458,
      "learning_rate": 6.301163566118285e-06,
      "loss": 0.5306,
      "step": 6238
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.8094611211791551,
      "learning_rate": 6.300076310197526e-06,
      "loss": 0.5521,
      "step": 6239
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.257211747826202,
      "learning_rate": 6.298988988341137e-06,
      "loss": 0.5298,
      "step": 6240
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.6365926499290292,
      "learning_rate": 6.297901600604261e-06,
      "loss": 0.4495,
      "step": 6241
    },
    {
      "epoch": 0.43,
      "grad_norm": 4.272912159031776,
      "learning_rate": 6.296814147042048e-06,
      "loss": 0.5271,
      "step": 6242
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.5686710279858875,
      "learning_rate": 6.2957266277096474e-06,
      "loss": 0.4885,
      "step": 6243
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.6247160255175022,
      "learning_rate": 6.294639042662219e-06,
      "loss": 0.5272,
      "step": 6244
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.437265466788676,
      "learning_rate": 6.293551391954918e-06,
      "loss": 0.574,
      "step": 6245
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.1126197437443293,
      "learning_rate": 6.292463675642908e-06,
      "loss": 0.524,
      "step": 6246
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.8132082042845046,
      "learning_rate": 6.291375893781353e-06,
      "loss": 0.472,
      "step": 6247
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.9195405800513903,
      "learning_rate": 6.290288046425424e-06,
      "loss": 0.4996,
      "step": 6248
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.4075368518545552,
      "learning_rate": 6.289200133630291e-06,
      "loss": 0.5074,
      "step": 6249
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.146232735210782,
      "learning_rate": 6.288112155451132e-06,
      "loss": 0.4872,
      "step": 6250
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.0337306236011483,
      "learning_rate": 6.28702411194312e-06,
      "loss": 0.5562,
      "step": 6251
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.086792859355425,
      "learning_rate": 6.285936003161445e-06,
      "loss": 0.5208,
      "step": 6252
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.9378890296537659,
      "learning_rate": 6.284847829161285e-06,
      "loss": 0.4952,
      "step": 6253
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.229711855233511,
      "learning_rate": 6.283759589997835e-06,
      "loss": 0.4835,
      "step": 6254
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.2168975213678643,
      "learning_rate": 6.282671285726283e-06,
      "loss": 0.5241,
      "step": 6255
    },
    {
      "epoch": 0.43,
      "grad_norm": 9.236523777642695,
      "learning_rate": 6.281582916401825e-06,
      "loss": 0.53,
      "step": 6256
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.7871240820329657,
      "learning_rate": 6.2804944820796596e-06,
      "loss": 0.4914,
      "step": 6257
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.698767558304161,
      "learning_rate": 6.2794059828149874e-06,
      "loss": 0.5151,
      "step": 6258
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.8170220736866896,
      "learning_rate": 6.278317418663017e-06,
      "loss": 0.5163,
      "step": 6259
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.7438016435882917,
      "learning_rate": 6.277228789678953e-06,
      "loss": 0.4399,
      "step": 6260
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.9346104650352032,
      "learning_rate": 6.276140095918011e-06,
      "loss": 0.5037,
      "step": 6261
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.7913555907711673,
      "learning_rate": 6.275051337435401e-06,
      "loss": 0.4996,
      "step": 6262
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.27673864716701,
      "learning_rate": 6.273962514286346e-06,
      "loss": 0.4904,
      "step": 6263
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.8550425990068296,
      "learning_rate": 6.272873626526064e-06,
      "loss": 0.505,
      "step": 6264
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.3716222082752587,
      "learning_rate": 6.271784674209783e-06,
      "loss": 0.5417,
      "step": 6265
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.37409654955646,
      "learning_rate": 6.270695657392729e-06,
      "loss": 0.4468,
      "step": 6266
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6203840830028801,
      "learning_rate": 6.269606576130135e-06,
      "loss": 0.4483,
      "step": 6267
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.233158006810897,
      "learning_rate": 6.268517430477234e-06,
      "loss": 0.5066,
      "step": 6268
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.0948922751890273,
      "learning_rate": 6.267428220489263e-06,
      "loss": 0.5197,
      "step": 6269
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.0436870403386296,
      "learning_rate": 6.266338946221466e-06,
      "loss": 0.5338,
      "step": 6270
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.0059355552045792,
      "learning_rate": 6.265249607729087e-06,
      "loss": 0.5236,
      "step": 6271
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.0319531196680987,
      "learning_rate": 6.264160205067371e-06,
      "loss": 0.4953,
      "step": 6272
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.6382058412905782,
      "learning_rate": 6.263070738291572e-06,
      "loss": 0.5592,
      "step": 6273
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.8163803831457936,
      "learning_rate": 6.261981207456942e-06,
      "loss": 0.4996,
      "step": 6274
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.904929049665046,
      "learning_rate": 6.26089161261874e-06,
      "loss": 0.4971,
      "step": 6275
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.233091825916373,
      "learning_rate": 6.259801953832226e-06,
      "loss": 0.4694,
      "step": 6276
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.1690049403625835,
      "learning_rate": 6.258712231152665e-06,
      "loss": 0.5233,
      "step": 6277
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.9301648415283736,
      "learning_rate": 6.257622444635323e-06,
      "loss": 0.5219,
      "step": 6278
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.0768083221899696,
      "learning_rate": 6.256532594335471e-06,
      "loss": 0.5428,
      "step": 6279
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.735126848049944,
      "learning_rate": 6.255442680308381e-06,
      "loss": 0.5014,
      "step": 6280
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.0969559975056122,
      "learning_rate": 6.254352702609332e-06,
      "loss": 0.4389,
      "step": 6281
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.011310287016503,
      "learning_rate": 6.2532626612936035e-06,
      "loss": 0.5271,
      "step": 6282
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6473389352126123,
      "learning_rate": 6.2521725564164785e-06,
      "loss": 0.4457,
      "step": 6283
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.243449647749217,
      "learning_rate": 6.251082388033243e-06,
      "loss": 0.493,
      "step": 6284
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.4215949891674136,
      "learning_rate": 6.249992156199189e-06,
      "loss": 0.5332,
      "step": 6285
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.6470573627157186,
      "learning_rate": 6.248901860969607e-06,
      "loss": 0.5219,
      "step": 6286
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.998422989207388,
      "learning_rate": 6.247811502399795e-06,
      "loss": 0.5542,
      "step": 6287
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.5695980358541424,
      "learning_rate": 6.2467210805450505e-06,
      "loss": 0.5089,
      "step": 6288
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.5102902115539334,
      "learning_rate": 6.2456305954606784e-06,
      "loss": 0.5085,
      "step": 6289
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.8221176026691366,
      "learning_rate": 6.244540047201984e-06,
      "loss": 0.5053,
      "step": 6290
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.7455813756001763,
      "learning_rate": 6.243449435824276e-06,
      "loss": 0.514,
      "step": 6291
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.8088123606177942,
      "learning_rate": 6.242358761382864e-06,
      "loss": 0.5304,
      "step": 6292
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.297626450852458,
      "learning_rate": 6.241268023933068e-06,
      "loss": 0.5454,
      "step": 6293
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.1189023374999243,
      "learning_rate": 6.240177223530204e-06,
      "loss": 0.5452,
      "step": 6294
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.690914330644645,
      "learning_rate": 6.239086360229595e-06,
      "loss": 0.5444,
      "step": 6295
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.5431968076573122,
      "learning_rate": 6.237995434086565e-06,
      "loss": 0.5053,
      "step": 6296
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.1767473165691245,
      "learning_rate": 6.236904445156442e-06,
      "loss": 0.5097,
      "step": 6297
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.774372757148897,
      "learning_rate": 6.235813393494558e-06,
      "loss": 0.5695,
      "step": 6298
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.0829798058926126,
      "learning_rate": 6.234722279156249e-06,
      "loss": 0.5633,
      "step": 6299
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.013270836579975,
      "learning_rate": 6.233631102196851e-06,
      "loss": 0.535,
      "step": 6300
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.7407691994471923,
      "learning_rate": 6.232539862671706e-06,
      "loss": 0.5617,
      "step": 6301
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.910046788719485,
      "learning_rate": 6.231448560636157e-06,
      "loss": 0.4947,
      "step": 6302
    },
    {
      "epoch": 0.44,
      "grad_norm": 3.714794670166937,
      "learning_rate": 6.2303571961455514e-06,
      "loss": 0.5688,
      "step": 6303
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.3824716769834904,
      "learning_rate": 6.2292657692552394e-06,
      "loss": 0.5316,
      "step": 6304
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.9357052910993455,
      "learning_rate": 6.228174280020576e-06,
      "loss": 0.5208,
      "step": 6305
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.1199317948686316,
      "learning_rate": 6.227082728496916e-06,
      "loss": 0.5595,
      "step": 6306
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.7818013552539944,
      "learning_rate": 6.225991114739622e-06,
      "loss": 0.5204,
      "step": 6307
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.9854533469747129,
      "learning_rate": 6.2248994388040555e-06,
      "loss": 0.4679,
      "step": 6308
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.7175050903585554,
      "learning_rate": 6.223807700745582e-06,
      "loss": 0.5529,
      "step": 6309
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.4865901117217635,
      "learning_rate": 6.222715900619573e-06,
      "loss": 0.4921,
      "step": 6310
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.1931435577815996,
      "learning_rate": 6.2216240384813985e-06,
      "loss": 0.529,
      "step": 6311
    },
    {
      "epoch": 0.44,
      "grad_norm": 3.4459491847059556,
      "learning_rate": 6.220532114386437e-06,
      "loss": 0.5141,
      "step": 6312
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.816874273881075,
      "learning_rate": 6.2194401283900654e-06,
      "loss": 0.4994,
      "step": 6313
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.8164443634345262,
      "learning_rate": 6.2183480805476646e-06,
      "loss": 0.4843,
      "step": 6314
    },
    {
      "epoch": 0.44,
      "grad_norm": 5.636249374134424,
      "learning_rate": 6.217255970914623e-06,
      "loss": 0.5014,
      "step": 6315
    },
    {
      "epoch": 0.44,
      "grad_norm": 3.9479614416244675,
      "learning_rate": 6.216163799546326e-06,
      "loss": 0.4955,
      "step": 6316
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.8650023955368105,
      "learning_rate": 6.215071566498167e-06,
      "loss": 0.4807,
      "step": 6317
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.3623315442029247,
      "learning_rate": 6.213979271825538e-06,
      "loss": 0.4718,
      "step": 6318
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.786525050054551,
      "learning_rate": 6.212886915583839e-06,
      "loss": 0.4807,
      "step": 6319
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.434541386999021,
      "learning_rate": 6.21179449782847e-06,
      "loss": 0.5242,
      "step": 6320
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.018121600557904,
      "learning_rate": 6.210702018614833e-06,
      "loss": 0.5131,
      "step": 6321
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.393839272896913,
      "learning_rate": 6.209609477998339e-06,
      "loss": 0.5303,
      "step": 6322
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.8165049712414731,
      "learning_rate": 6.208516876034395e-06,
      "loss": 0.5079,
      "step": 6323
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.8002162338710372,
      "learning_rate": 6.207424212778416e-06,
      "loss": 0.5247,
      "step": 6324
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.0824299735917116,
      "learning_rate": 6.206331488285816e-06,
      "loss": 0.5052,
      "step": 6325
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.629867174456036,
      "learning_rate": 6.205238702612016e-06,
      "loss": 0.4736,
      "step": 6326
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.847100649342314,
      "learning_rate": 6.204145855812439e-06,
      "loss": 0.534,
      "step": 6327
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.0820971497200116,
      "learning_rate": 6.203052947942509e-06,
      "loss": 0.5371,
      "step": 6328
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.048186415483352,
      "learning_rate": 6.2019599790576565e-06,
      "loss": 0.5238,
      "step": 6329
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.7857363750297133,
      "learning_rate": 6.200866949213312e-06,
      "loss": 0.5,
      "step": 6330
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.7954115034400464,
      "learning_rate": 6.19977385846491e-06,
      "loss": 0.4496,
      "step": 6331
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.648523381012552,
      "learning_rate": 6.1986807068678926e-06,
      "loss": 0.4954,
      "step": 6332
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.4611703772547773,
      "learning_rate": 6.197587494477695e-06,
      "loss": 0.4874,
      "step": 6333
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.071397912256851,
      "learning_rate": 6.1964942213497645e-06,
      "loss": 0.4624,
      "step": 6334
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.2375702851594608,
      "learning_rate": 6.195400887539548e-06,
      "loss": 0.4531,
      "step": 6335
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.7821982861234855,
      "learning_rate": 6.194307493102496e-06,
      "loss": 0.5015,
      "step": 6336
    },
    {
      "epoch": 0.44,
      "grad_norm": 3.7405231406889734,
      "learning_rate": 6.193214038094061e-06,
      "loss": 0.5049,
      "step": 6337
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.659603763914219,
      "learning_rate": 6.1921205225697e-06,
      "loss": 0.4241,
      "step": 6338
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.222030930603271,
      "learning_rate": 6.191026946584873e-06,
      "loss": 0.4915,
      "step": 6339
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.831266664560207,
      "learning_rate": 6.189933310195042e-06,
      "loss": 0.5175,
      "step": 6340
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6127789286816102,
      "learning_rate": 6.188839613455673e-06,
      "loss": 0.4296,
      "step": 6341
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.9642978035074936,
      "learning_rate": 6.187745856422236e-06,
      "loss": 0.5167,
      "step": 6342
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.107727322274695,
      "learning_rate": 6.186652039150199e-06,
      "loss": 0.5106,
      "step": 6343
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.6386588756122842,
      "learning_rate": 6.185558161695041e-06,
      "loss": 0.4872,
      "step": 6344
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.285702227033805,
      "learning_rate": 6.1844642241122374e-06,
      "loss": 0.4994,
      "step": 6345
    },
    {
      "epoch": 0.44,
      "grad_norm": 3.367859479771421,
      "learning_rate": 6.183370226457272e-06,
      "loss": 0.5378,
      "step": 6346
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.634213214134195,
      "learning_rate": 6.182276168785624e-06,
      "loss": 0.4494,
      "step": 6347
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.7367961544473456,
      "learning_rate": 6.181182051152784e-06,
      "loss": 0.53,
      "step": 6348
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.4189159756948526,
      "learning_rate": 6.180087873614241e-06,
      "loss": 0.5085,
      "step": 6349
    },
    {
      "epoch": 0.44,
      "grad_norm": 9.024904540666359,
      "learning_rate": 6.1789936362254885e-06,
      "loss": 0.4982,
      "step": 6350
    },
    {
      "epoch": 0.44,
      "grad_norm": 4.057681013000895,
      "learning_rate": 6.177899339042023e-06,
      "loss": 0.4835,
      "step": 6351
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.7347309458906204,
      "learning_rate": 6.176804982119343e-06,
      "loss": 0.5294,
      "step": 6352
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.6155743882450997,
      "learning_rate": 6.17571056551295e-06,
      "loss": 0.4732,
      "step": 6353
    },
    {
      "epoch": 0.44,
      "grad_norm": 3.1790033170483127,
      "learning_rate": 6.1746160892783515e-06,
      "loss": 0.5479,
      "step": 6354
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.8377460757541018,
      "learning_rate": 6.173521553471054e-06,
      "loss": 0.5048,
      "step": 6355
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.975906104797315,
      "learning_rate": 6.172426958146569e-06,
      "loss": 0.5703,
      "step": 6356
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.572822324089403,
      "learning_rate": 6.171332303360411e-06,
      "loss": 0.5279,
      "step": 6357
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.8072257119258528,
      "learning_rate": 6.1702375891680985e-06,
      "loss": 0.4877,
      "step": 6358
    },
    {
      "epoch": 0.44,
      "grad_norm": 3.1993681572429575,
      "learning_rate": 6.169142815625148e-06,
      "loss": 0.5055,
      "step": 6359
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6547808639419335,
      "learning_rate": 6.168047982787089e-06,
      "loss": 0.4194,
      "step": 6360
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.4985475637194265,
      "learning_rate": 6.166953090709442e-06,
      "loss": 0.4719,
      "step": 6361
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.3621493598785728,
      "learning_rate": 6.165858139447739e-06,
      "loss": 0.5206,
      "step": 6362
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.7874207105097313,
      "learning_rate": 6.164763129057511e-06,
      "loss": 0.5052,
      "step": 6363
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.0160550260847026,
      "learning_rate": 6.163668059594296e-06,
      "loss": 0.5103,
      "step": 6364
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.8004420034481647,
      "learning_rate": 6.1625729311136306e-06,
      "loss": 0.4924,
      "step": 6365
    },
    {
      "epoch": 0.44,
      "grad_norm": 3.821931080107815,
      "learning_rate": 6.161477743671057e-06,
      "loss": 0.4877,
      "step": 6366
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.691433638881111,
      "learning_rate": 6.16038249732212e-06,
      "loss": 0.5215,
      "step": 6367
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.9189876404100787,
      "learning_rate": 6.159287192122363e-06,
      "loss": 0.527,
      "step": 6368
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.035408657751228,
      "learning_rate": 6.15819182812734e-06,
      "loss": 0.4601,
      "step": 6369
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.9007402539467455,
      "learning_rate": 6.157096405392604e-06,
      "loss": 0.5264,
      "step": 6370
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.2590116628074575,
      "learning_rate": 6.156000923973709e-06,
      "loss": 0.544,
      "step": 6371
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.5845706623911315,
      "learning_rate": 6.154905383926218e-06,
      "loss": 0.5404,
      "step": 6372
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.0997852791270373,
      "learning_rate": 6.153809785305689e-06,
      "loss": 0.4652,
      "step": 6373
    },
    {
      "epoch": 0.44,
      "grad_norm": 5.57480278122333,
      "learning_rate": 6.152714128167691e-06,
      "loss": 0.4983,
      "step": 6374
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.7059590174291077,
      "learning_rate": 6.15161841256779e-06,
      "loss": 0.5532,
      "step": 6375
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.8098710253817802,
      "learning_rate": 6.150522638561558e-06,
      "loss": 0.5043,
      "step": 6376
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.6697447971139405,
      "learning_rate": 6.149426806204568e-06,
      "loss": 0.5245,
      "step": 6377
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.007869865424819,
      "learning_rate": 6.148330915552398e-06,
      "loss": 0.5412,
      "step": 6378
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.728848926941275,
      "learning_rate": 6.147234966660628e-06,
      "loss": 0.4757,
      "step": 6379
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.7654600827714235,
      "learning_rate": 6.1461389595848406e-06,
      "loss": 0.4998,
      "step": 6380
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.842588580231822,
      "learning_rate": 6.1450428943806214e-06,
      "loss": 0.5182,
      "step": 6381
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.3189848383093943,
      "learning_rate": 6.143946771103561e-06,
      "loss": 0.5277,
      "step": 6382
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.476689914069226,
      "learning_rate": 6.142850589809248e-06,
      "loss": 0.5052,
      "step": 6383
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.4291984239098734,
      "learning_rate": 6.141754350553279e-06,
      "loss": 0.4855,
      "step": 6384
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.6565669299853145,
      "learning_rate": 6.140658053391253e-06,
      "loss": 0.4977,
      "step": 6385
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.757398872456333,
      "learning_rate": 6.139561698378768e-06,
      "loss": 0.488,
      "step": 6386
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.9000170124068165,
      "learning_rate": 6.1384652855714295e-06,
      "loss": 0.5294,
      "step": 6387
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.74972305488332,
      "learning_rate": 6.1373688150248434e-06,
      "loss": 0.5445,
      "step": 6388
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.8409170928936345,
      "learning_rate": 6.136272286794619e-06,
      "loss": 0.4756,
      "step": 6389
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.0274242235974405,
      "learning_rate": 6.135175700936369e-06,
      "loss": 0.4841,
      "step": 6390
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.6158720182492202,
      "learning_rate": 6.134079057505708e-06,
      "loss": 0.4521,
      "step": 6391
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.56833349542992,
      "learning_rate": 6.132982356558254e-06,
      "loss": 0.5017,
      "step": 6392
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.0383618931290113,
      "learning_rate": 6.13188559814963e-06,
      "loss": 0.5084,
      "step": 6393
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.1052809688534344,
      "learning_rate": 6.130788782335457e-06,
      "loss": 0.461,
      "step": 6394
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.7278712002064511,
      "learning_rate": 6.129691909171366e-06,
      "loss": 0.5046,
      "step": 6395
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.265905200492501,
      "learning_rate": 6.128594978712982e-06,
      "loss": 0.4964,
      "step": 6396
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.866947904768699,
      "learning_rate": 6.1274979910159405e-06,
      "loss": 0.489,
      "step": 6397
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.0137122597463315,
      "learning_rate": 6.126400946135876e-06,
      "loss": 0.539,
      "step": 6398
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.7439068120223684,
      "learning_rate": 6.125303844128429e-06,
      "loss": 0.505,
      "step": 6399
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.912989891630572,
      "learning_rate": 6.124206685049241e-06,
      "loss": 0.4753,
      "step": 6400
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.9547512823143267,
      "learning_rate": 6.123109468953954e-06,
      "loss": 0.4936,
      "step": 6401
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6304446230298034,
      "learning_rate": 6.122012195898216e-06,
      "loss": 0.4617,
      "step": 6402
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.0965150977876825,
      "learning_rate": 6.1209148659376775e-06,
      "loss": 0.5152,
      "step": 6403
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.2913282545387474,
      "learning_rate": 6.119817479127991e-06,
      "loss": 0.5243,
      "step": 6404
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.8898445693247465,
      "learning_rate": 6.1187200355248135e-06,
      "loss": 0.5608,
      "step": 6405
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.729161324712061,
      "learning_rate": 6.117622535183802e-06,
      "loss": 0.522,
      "step": 6406
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.4257206197030317,
      "learning_rate": 6.11652497816062e-06,
      "loss": 0.4925,
      "step": 6407
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.4094734308285077,
      "learning_rate": 6.11542736451093e-06,
      "loss": 0.519,
      "step": 6408
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.717229168642536,
      "learning_rate": 6.114329694290401e-06,
      "loss": 0.4754,
      "step": 6409
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.8234679147184707,
      "learning_rate": 6.113231967554704e-06,
      "loss": 0.4978,
      "step": 6410
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.8010620962617883,
      "learning_rate": 6.112134184359509e-06,
      "loss": 0.4573,
      "step": 6411
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.273958497810184,
      "learning_rate": 6.111036344760497e-06,
      "loss": 0.5087,
      "step": 6412
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6370155749425002,
      "learning_rate": 6.109938448813342e-06,
      "loss": 0.4506,
      "step": 6413
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.68168129919049,
      "learning_rate": 6.108840496573727e-06,
      "loss": 0.5242,
      "step": 6414
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.2488051047980884,
      "learning_rate": 6.107742488097338e-06,
      "loss": 0.5328,
      "step": 6415
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.7135841129330416,
      "learning_rate": 6.10664442343986e-06,
      "loss": 0.4339,
      "step": 6416
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.249545299414174,
      "learning_rate": 6.105546302656986e-06,
      "loss": 0.5073,
      "step": 6417
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.0341855484682267,
      "learning_rate": 6.104448125804407e-06,
      "loss": 0.5013,
      "step": 6418
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.3113928363804477,
      "learning_rate": 6.103349892937821e-06,
      "loss": 0.5669,
      "step": 6419
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.683626855756831,
      "learning_rate": 6.102251604112924e-06,
      "loss": 0.4943,
      "step": 6420
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.8229169864426107,
      "learning_rate": 6.10115325938542e-06,
      "loss": 0.5769,
      "step": 6421
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.198896233599736,
      "learning_rate": 6.100054858811012e-06,
      "loss": 0.5285,
      "step": 6422
    },
    {
      "epoch": 0.45,
      "grad_norm": 4.5102951257646,
      "learning_rate": 6.098956402445409e-06,
      "loss": 0.4882,
      "step": 6423
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.705666259846726,
      "learning_rate": 6.097857890344321e-06,
      "loss": 0.5483,
      "step": 6424
    },
    {
      "epoch": 0.45,
      "grad_norm": 3.094954099084096,
      "learning_rate": 6.0967593225634584e-06,
      "loss": 0.4963,
      "step": 6425
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.1773510412099886,
      "learning_rate": 6.095660699158539e-06,
      "loss": 0.5246,
      "step": 6426
    },
    {
      "epoch": 0.45,
      "grad_norm": 3.1385512778235802,
      "learning_rate": 6.094562020185281e-06,
      "loss": 0.5167,
      "step": 6427
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.253293016193746,
      "learning_rate": 6.093463285699404e-06,
      "loss": 0.4984,
      "step": 6428
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.281225738172747,
      "learning_rate": 6.0923644957566375e-06,
      "loss": 0.5214,
      "step": 6429
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.8577570623977564,
      "learning_rate": 6.091265650412702e-06,
      "loss": 0.4544,
      "step": 6430
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.9294045361811127,
      "learning_rate": 6.0901667497233315e-06,
      "loss": 0.5193,
      "step": 6431
    },
    {
      "epoch": 0.45,
      "grad_norm": 10.023004349908286,
      "learning_rate": 6.089067793744258e-06,
      "loss": 0.5136,
      "step": 6432
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.9502659391920532,
      "learning_rate": 6.087968782531217e-06,
      "loss": 0.5284,
      "step": 6433
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.3999891772628725,
      "learning_rate": 6.086869716139946e-06,
      "loss": 0.5488,
      "step": 6434
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.51146383419693,
      "learning_rate": 6.085770594626187e-06,
      "loss": 0.4934,
      "step": 6435
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.896499808227468,
      "learning_rate": 6.084671418045681e-06,
      "loss": 0.4993,
      "step": 6436
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.364319418082362,
      "learning_rate": 6.083572186454178e-06,
      "loss": 0.4729,
      "step": 6437
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.2109364109954135,
      "learning_rate": 6.082472899907428e-06,
      "loss": 0.4992,
      "step": 6438
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.9412807300141488,
      "learning_rate": 6.08137355846118e-06,
      "loss": 0.5005,
      "step": 6439
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.6391523314683982,
      "learning_rate": 6.0802741621711906e-06,
      "loss": 0.4988,
      "step": 6440
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.9881239437559812,
      "learning_rate": 6.079174711093217e-06,
      "loss": 0.532,
      "step": 6441
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.9850967560461126,
      "learning_rate": 6.078075205283022e-06,
      "loss": 0.5168,
      "step": 6442
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.5002790182447683,
      "learning_rate": 6.0769756447963666e-06,
      "loss": 0.5461,
      "step": 6443
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.6152636524139865,
      "learning_rate": 6.075876029689016e-06,
      "loss": 0.5318,
      "step": 6444
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.729489305900585,
      "learning_rate": 6.074776360016743e-06,
      "loss": 0.5291,
      "step": 6445
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.0286449635586523,
      "learning_rate": 6.073676635835317e-06,
      "loss": 0.4562,
      "step": 6446
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.076037595899538,
      "learning_rate": 6.072576857200512e-06,
      "loss": 0.4911,
      "step": 6447
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.343445871944506,
      "learning_rate": 6.0714770241681054e-06,
      "loss": 0.5309,
      "step": 6448
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.5663485875178904,
      "learning_rate": 6.070377136793876e-06,
      "loss": 0.519,
      "step": 6449
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.9381851459700083,
      "learning_rate": 6.069277195133609e-06,
      "loss": 0.5009,
      "step": 6450
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.71281247700696,
      "learning_rate": 6.06817719924309e-06,
      "loss": 0.4869,
      "step": 6451
    },
    {
      "epoch": 0.45,
      "grad_norm": 3.23045458554774,
      "learning_rate": 6.067077149178105e-06,
      "loss": 0.5545,
      "step": 6452
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.6991466350649869,
      "learning_rate": 6.065977044994445e-06,
      "loss": 0.5426,
      "step": 6453
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.7085092860482256,
      "learning_rate": 6.064876886747905e-06,
      "loss": 0.5227,
      "step": 6454
    },
    {
      "epoch": 0.45,
      "grad_norm": 3.461131911239915,
      "learning_rate": 6.063776674494282e-06,
      "loss": 0.5052,
      "step": 6455
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.0941734260325435,
      "learning_rate": 6.062676408289372e-06,
      "loss": 0.5374,
      "step": 6456
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.015651682521762,
      "learning_rate": 6.061576088188981e-06,
      "loss": 0.5184,
      "step": 6457
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.7440125793690973,
      "learning_rate": 6.060475714248911e-06,
      "loss": 0.5286,
      "step": 6458
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.084311477683949,
      "learning_rate": 6.05937528652497e-06,
      "loss": 0.4976,
      "step": 6459
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.9213391226595036,
      "learning_rate": 6.0582748050729686e-06,
      "loss": 0.5147,
      "step": 6460
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.430331650710148,
      "learning_rate": 6.057174269948719e-06,
      "loss": 0.5083,
      "step": 6461
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.33805737738433,
      "learning_rate": 6.056073681208038e-06,
      "loss": 0.4933,
      "step": 6462
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.240284893442449,
      "learning_rate": 6.054973038906741e-06,
      "loss": 0.5096,
      "step": 6463
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.171089861245346,
      "learning_rate": 6.053872343100653e-06,
      "loss": 0.5096,
      "step": 6464
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.8407224020489346,
      "learning_rate": 6.0527715938455935e-06,
      "loss": 0.4911,
      "step": 6465
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.5973580153372477,
      "learning_rate": 6.051670791197393e-06,
      "loss": 0.5541,
      "step": 6466
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.8342187700850516,
      "learning_rate": 6.050569935211878e-06,
      "loss": 0.5468,
      "step": 6467
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.9968733168175832,
      "learning_rate": 6.0494690259448805e-06,
      "loss": 0.5186,
      "step": 6468
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6429674691546989,
      "learning_rate": 6.0483680634522346e-06,
      "loss": 0.4552,
      "step": 6469
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.6436574081005324,
      "learning_rate": 6.0472670477897796e-06,
      "loss": 0.4981,
      "step": 6470
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.9764152984169654,
      "learning_rate": 6.0461659790133545e-06,
      "loss": 0.5284,
      "step": 6471
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.7859392716497167,
      "learning_rate": 6.045064857178801e-06,
      "loss": 0.4836,
      "step": 6472
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.3463825480333034,
      "learning_rate": 6.043963682341964e-06,
      "loss": 0.5038,
      "step": 6473
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.776666001216495,
      "learning_rate": 6.042862454558694e-06,
      "loss": 0.5074,
      "step": 6474
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.9641520783791768,
      "learning_rate": 6.04176117388484e-06,
      "loss": 0.4958,
      "step": 6475
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.531640522736558,
      "learning_rate": 6.040659840376256e-06,
      "loss": 0.4912,
      "step": 6476
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.7879985040758926,
      "learning_rate": 6.039558454088796e-06,
      "loss": 0.5363,
      "step": 6477
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.8261061120248339,
      "learning_rate": 6.038457015078323e-06,
      "loss": 0.5157,
      "step": 6478
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.9498486465718872,
      "learning_rate": 6.0373555234006946e-06,
      "loss": 0.5056,
      "step": 6479
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.321092690957054,
      "learning_rate": 6.0362539791117755e-06,
      "loss": 0.5074,
      "step": 6480
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.8512448879856003,
      "learning_rate": 6.0351523822674325e-06,
      "loss": 0.505,
      "step": 6481
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.4497940284870365,
      "learning_rate": 6.034050732923538e-06,
      "loss": 0.4854,
      "step": 6482
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.048688655211211,
      "learning_rate": 6.032949031135958e-06,
      "loss": 0.4718,
      "step": 6483
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.5849576528904255,
      "learning_rate": 6.031847276960573e-06,
      "loss": 0.4897,
      "step": 6484
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.6883695132364043,
      "learning_rate": 6.030745470453257e-06,
      "loss": 0.4856,
      "step": 6485
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.8861845384972264,
      "learning_rate": 6.029643611669892e-06,
      "loss": 0.494,
      "step": 6486
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.416141556181693,
      "learning_rate": 6.028541700666359e-06,
      "loss": 0.5555,
      "step": 6487
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.5768101791256335,
      "learning_rate": 6.027439737498546e-06,
      "loss": 0.4836,
      "step": 6488
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.6426421549355437,
      "learning_rate": 6.026337722222337e-06,
      "loss": 0.4332,
      "step": 6489
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.1742408846683245,
      "learning_rate": 6.025235654893626e-06,
      "loss": 0.474,
      "step": 6490
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.824280359508967,
      "learning_rate": 6.024133535568305e-06,
      "loss": 0.494,
      "step": 6491
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.8614538241696665,
      "learning_rate": 6.02303136430227e-06,
      "loss": 0.5329,
      "step": 6492
    },
    {
      "epoch": 0.45,
      "grad_norm": 3.2595763036521506,
      "learning_rate": 6.0219291411514195e-06,
      "loss": 0.5128,
      "step": 6493
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.9196104458401344,
      "learning_rate": 6.020826866171654e-06,
      "loss": 0.4967,
      "step": 6494
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.8172767345444034,
      "learning_rate": 6.019724539418878e-06,
      "loss": 0.4842,
      "step": 6495
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.0633608639561127,
      "learning_rate": 6.018622160948998e-06,
      "loss": 0.5111,
      "step": 6496
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.8525393036003672,
      "learning_rate": 6.017519730817922e-06,
      "loss": 0.5371,
      "step": 6497
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.228085250433745,
      "learning_rate": 6.016417249081564e-06,
      "loss": 0.5325,
      "step": 6498
    },
    {
      "epoch": 0.45,
      "grad_norm": 3.114351610652492,
      "learning_rate": 6.0153147157958365e-06,
      "loss": 0.5122,
      "step": 6499
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.563341658991216,
      "learning_rate": 6.014212131016657e-06,
      "loss": 0.4963,
      "step": 6500
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.956237406243491,
      "learning_rate": 6.013109494799945e-06,
      "loss": 0.5263,
      "step": 6501
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.2959847940954052,
      "learning_rate": 6.012006807201623e-06,
      "loss": 0.5134,
      "step": 6502
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.0952989254821963,
      "learning_rate": 6.010904068277612e-06,
      "loss": 0.5101,
      "step": 6503
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.075677720583985,
      "learning_rate": 6.009801278083845e-06,
      "loss": 0.4865,
      "step": 6504
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.8007675606342841,
      "learning_rate": 6.008698436676248e-06,
      "loss": 0.5387,
      "step": 6505
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.6417745395973005,
      "learning_rate": 6.007595544110756e-06,
      "loss": 0.5084,
      "step": 6506
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.686059917101925,
      "learning_rate": 6.006492600443301e-06,
      "loss": 0.4784,
      "step": 6507
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.4262927290199494,
      "learning_rate": 6.005389605729824e-06,
      "loss": 0.4532,
      "step": 6508
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.449907951263252,
      "learning_rate": 6.004286560026264e-06,
      "loss": 0.479,
      "step": 6509
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.098537459782603,
      "learning_rate": 6.003183463388565e-06,
      "loss": 0.508,
      "step": 6510
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.7258707682312555,
      "learning_rate": 6.002080315872668e-06,
      "loss": 0.5361,
      "step": 6511
    },
    {
      "epoch": 0.45,
      "grad_norm": 10.922753380615099,
      "learning_rate": 6.000977117534527e-06,
      "loss": 0.4489,
      "step": 6512
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.1359525485486985,
      "learning_rate": 5.999873868430089e-06,
      "loss": 0.5029,
      "step": 6513
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.271843515041354,
      "learning_rate": 5.9987705686153085e-06,
      "loss": 0.5572,
      "step": 6514
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.7025704060997155,
      "learning_rate": 5.997667218146142e-06,
      "loss": 0.5547,
      "step": 6515
    },
    {
      "epoch": 0.45,
      "grad_norm": 5.354642040221612,
      "learning_rate": 5.996563817078544e-06,
      "loss": 0.5404,
      "step": 6516
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.0452459668115086,
      "learning_rate": 5.995460365468482e-06,
      "loss": 0.5594,
      "step": 6517
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.1122397623313596,
      "learning_rate": 5.9943568633719115e-06,
      "loss": 0.5264,
      "step": 6518
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.127890302884355,
      "learning_rate": 5.993253310844805e-06,
      "loss": 0.5364,
      "step": 6519
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.8439304875544815,
      "learning_rate": 5.992149707943129e-06,
      "loss": 0.493,
      "step": 6520
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.8458837332432534,
      "learning_rate": 5.991046054722854e-06,
      "loss": 0.5128,
      "step": 6521
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.9417196298551294,
      "learning_rate": 5.989942351239954e-06,
      "loss": 0.4727,
      "step": 6522
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.853638989837607,
      "learning_rate": 5.988838597550406e-06,
      "loss": 0.5423,
      "step": 6523
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.2298414546092404,
      "learning_rate": 5.987734793710187e-06,
      "loss": 0.4771,
      "step": 6524
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.0799375104298297,
      "learning_rate": 5.986630939775281e-06,
      "loss": 0.4916,
      "step": 6525
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.8714916561929442,
      "learning_rate": 5.985527035801668e-06,
      "loss": 0.5552,
      "step": 6526
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.9035683770988097,
      "learning_rate": 5.984423081845339e-06,
      "loss": 0.5231,
      "step": 6527
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.9303103421394205,
      "learning_rate": 5.98331907796228e-06,
      "loss": 0.5325,
      "step": 6528
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.0975512196633956,
      "learning_rate": 5.982215024208482e-06,
      "loss": 0.5104,
      "step": 6529
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.9244491242150001,
      "learning_rate": 5.981110920639941e-06,
      "loss": 0.5261,
      "step": 6530
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.7695674655109923,
      "learning_rate": 5.9800067673126526e-06,
      "loss": 0.5177,
      "step": 6531
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.141557836802779,
      "learning_rate": 5.978902564282616e-06,
      "loss": 0.5457,
      "step": 6532
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.708753179599674,
      "learning_rate": 5.977798311605834e-06,
      "loss": 0.4852,
      "step": 6533
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.8518493793571837,
      "learning_rate": 5.976694009338309e-06,
      "loss": 0.4942,
      "step": 6534
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.9653182211141333,
      "learning_rate": 5.975589657536047e-06,
      "loss": 0.4831,
      "step": 6535
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.1517071088848114,
      "learning_rate": 5.974485256255058e-06,
      "loss": 0.4418,
      "step": 6536
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.834760899968395,
      "learning_rate": 5.973380805551354e-06,
      "loss": 0.5472,
      "step": 6537
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.1532756548798546,
      "learning_rate": 5.97227630548095e-06,
      "loss": 0.4806,
      "step": 6538
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.9954637202937373,
      "learning_rate": 5.97117175609986e-06,
      "loss": 0.4903,
      "step": 6539
    },
    {
      "epoch": 0.45,
      "grad_norm": 3.3566426986018025,
      "learning_rate": 5.9700671574641054e-06,
      "loss": 0.4725,
      "step": 6540
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.8894536843931269,
      "learning_rate": 5.968962509629709e-06,
      "loss": 0.5103,
      "step": 6541
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.8940301203354288,
      "learning_rate": 5.967857812652691e-06,
      "loss": 0.5006,
      "step": 6542
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.7613939022031497,
      "learning_rate": 5.966753066589081e-06,
      "loss": 0.5276,
      "step": 6543
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.6397034436350024,
      "learning_rate": 5.965648271494906e-06,
      "loss": 0.5313,
      "step": 6544
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.9593870796643,
      "learning_rate": 5.9645434274262e-06,
      "loss": 0.5258,
      "step": 6545
    },
    {
      "epoch": 0.46,
      "grad_norm": 5.410855415900926,
      "learning_rate": 5.963438534438997e-06,
      "loss": 0.5473,
      "step": 6546
    },
    {
      "epoch": 0.46,
      "grad_norm": 3.4188439069286205,
      "learning_rate": 5.962333592589331e-06,
      "loss": 0.5179,
      "step": 6547
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.6567380192745604,
      "learning_rate": 5.961228601933242e-06,
      "loss": 0.515,
      "step": 6548
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.9762118449988835,
      "learning_rate": 5.960123562526774e-06,
      "loss": 0.5256,
      "step": 6549
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.6542249455496285,
      "learning_rate": 5.959018474425967e-06,
      "loss": 0.5125,
      "step": 6550
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.9527397209704185,
      "learning_rate": 5.9579133376868715e-06,
      "loss": 0.518,
      "step": 6551
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.254308667579645,
      "learning_rate": 5.956808152365532e-06,
      "loss": 0.4805,
      "step": 6552
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.121219617777347,
      "learning_rate": 5.955702918518005e-06,
      "loss": 0.5108,
      "step": 6553
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.6938329460022545,
      "learning_rate": 5.95459763620034e-06,
      "loss": 0.4614,
      "step": 6554
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.234938957361938,
      "learning_rate": 5.953492305468597e-06,
      "loss": 0.5322,
      "step": 6555
    },
    {
      "epoch": 0.46,
      "grad_norm": 3.974856359040458,
      "learning_rate": 5.9523869263788314e-06,
      "loss": 0.5224,
      "step": 6556
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.007294929002526,
      "learning_rate": 5.951281498987106e-06,
      "loss": 0.5065,
      "step": 6557
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.0275801873325827,
      "learning_rate": 5.950176023349484e-06,
      "loss": 0.5678,
      "step": 6558
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.024392124484648,
      "learning_rate": 5.9490704995220325e-06,
      "loss": 0.472,
      "step": 6559
    },
    {
      "epoch": 0.46,
      "grad_norm": 3.1110146933964336,
      "learning_rate": 5.947964927560819e-06,
      "loss": 0.4782,
      "step": 6560
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.565357937282089,
      "learning_rate": 5.946859307521915e-06,
      "loss": 0.5265,
      "step": 6561
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.63467974881213,
      "learning_rate": 5.945753639461393e-06,
      "loss": 0.4507,
      "step": 6562
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.8973656444162073,
      "learning_rate": 5.944647923435332e-06,
      "loss": 0.5667,
      "step": 6563
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.8204543629252854,
      "learning_rate": 5.943542159499805e-06,
      "loss": 0.5282,
      "step": 6564
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.5531311027290915,
      "learning_rate": 5.942436347710899e-06,
      "loss": 0.4686,
      "step": 6565
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.9754835944791642,
      "learning_rate": 5.9413304881246915e-06,
      "loss": 0.4957,
      "step": 6566
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6425254767416383,
      "learning_rate": 5.940224580797272e-06,
      "loss": 0.4307,
      "step": 6567
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.7553360509339047,
      "learning_rate": 5.9391186257847275e-06,
      "loss": 0.5007,
      "step": 6568
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.7619610530693228,
      "learning_rate": 5.938012623143148e-06,
      "loss": 0.4992,
      "step": 6569
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.06964759669849,
      "learning_rate": 5.936906572928625e-06,
      "loss": 0.4729,
      "step": 6570
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.9448896543084284,
      "learning_rate": 5.9358004751972555e-06,
      "loss": 0.4935,
      "step": 6571
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.183224931862912,
      "learning_rate": 5.934694330005136e-06,
      "loss": 0.485,
      "step": 6572
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.6641521225668223,
      "learning_rate": 5.933588137408368e-06,
      "loss": 0.5435,
      "step": 6573
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.0810669378327917,
      "learning_rate": 5.932481897463054e-06,
      "loss": 0.5132,
      "step": 6574
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.0150601933194143,
      "learning_rate": 5.931375610225297e-06,
      "loss": 0.513,
      "step": 6575
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.7185967356553629,
      "learning_rate": 5.930269275751206e-06,
      "loss": 0.4843,
      "step": 6576
    },
    {
      "epoch": 0.46,
      "grad_norm": 5.066576578457697,
      "learning_rate": 5.929162894096891e-06,
      "loss": 0.4695,
      "step": 6577
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.69104677370277,
      "learning_rate": 5.928056465318462e-06,
      "loss": 0.4898,
      "step": 6578
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.79429371555338,
      "learning_rate": 5.926949989472036e-06,
      "loss": 0.4908,
      "step": 6579
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.6583694658549222,
      "learning_rate": 5.925843466613729e-06,
      "loss": 0.5201,
      "step": 6580
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.9282423197448062,
      "learning_rate": 5.924736896799658e-06,
      "loss": 0.4856,
      "step": 6581
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.0102258476657244,
      "learning_rate": 5.923630280085948e-06,
      "loss": 0.5118,
      "step": 6582
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.945296194602119,
      "learning_rate": 5.922523616528719e-06,
      "loss": 0.4964,
      "step": 6583
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.2186003862163153,
      "learning_rate": 5.921416906184102e-06,
      "loss": 0.5511,
      "step": 6584
    },
    {
      "epoch": 0.46,
      "grad_norm": 3.4560319161517596,
      "learning_rate": 5.920310149108223e-06,
      "loss": 0.5386,
      "step": 6585
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.489613245330508,
      "learning_rate": 5.919203345357214e-06,
      "loss": 0.508,
      "step": 6586
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.140339649322824,
      "learning_rate": 5.918096494987206e-06,
      "loss": 0.5079,
      "step": 6587
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.6213382388893436,
      "learning_rate": 5.91698959805434e-06,
      "loss": 0.4934,
      "step": 6588
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.9682602045888895,
      "learning_rate": 5.91588265461475e-06,
      "loss": 0.487,
      "step": 6589
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.7123308934860384,
      "learning_rate": 5.914775664724578e-06,
      "loss": 0.4973,
      "step": 6590
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.8240196941954372,
      "learning_rate": 5.913668628439965e-06,
      "loss": 0.5531,
      "step": 6591
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.6597338461661724,
      "learning_rate": 5.9125615458170595e-06,
      "loss": 0.5221,
      "step": 6592
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.0208844273301723,
      "learning_rate": 5.911454416912006e-06,
      "loss": 0.4898,
      "step": 6593
    },
    {
      "epoch": 0.46,
      "grad_norm": 5.384299360286614,
      "learning_rate": 5.910347241780958e-06,
      "loss": 0.5158,
      "step": 6594
    },
    {
      "epoch": 0.46,
      "grad_norm": 3.2336045065661074,
      "learning_rate": 5.9092400204800636e-06,
      "loss": 0.4933,
      "step": 6595
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.036050364480943,
      "learning_rate": 5.908132753065482e-06,
      "loss": 0.5282,
      "step": 6596
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.8733664496587934,
      "learning_rate": 5.907025439593366e-06,
      "loss": 0.5282,
      "step": 6597
    },
    {
      "epoch": 0.46,
      "grad_norm": 5.475181768853928,
      "learning_rate": 5.905918080119877e-06,
      "loss": 0.517,
      "step": 6598
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.721536262433419,
      "learning_rate": 5.904810674701177e-06,
      "loss": 0.4939,
      "step": 6599
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.9518581677258515,
      "learning_rate": 5.9037032233934284e-06,
      "loss": 0.4922,
      "step": 6600
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.9418603053448196,
      "learning_rate": 5.902595726252801e-06,
      "loss": 0.5081,
      "step": 6601
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.8086602322477878,
      "learning_rate": 5.90148818333546e-06,
      "loss": 0.5007,
      "step": 6602
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.9454114352028944,
      "learning_rate": 5.900380594697576e-06,
      "loss": 0.5127,
      "step": 6603
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.5861913106740726,
      "learning_rate": 5.899272960395324e-06,
      "loss": 0.4968,
      "step": 6604
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.2255217742912787,
      "learning_rate": 5.89816528048488e-06,
      "loss": 0.5043,
      "step": 6605
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.04635492363397,
      "learning_rate": 5.897057555022421e-06,
      "loss": 0.4703,
      "step": 6606
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.10640694874259,
      "learning_rate": 5.895949784064126e-06,
      "loss": 0.5354,
      "step": 6607
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.622108187933339,
      "learning_rate": 5.894841967666181e-06,
      "loss": 0.5331,
      "step": 6608
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.7045928359550058,
      "learning_rate": 5.893734105884768e-06,
      "loss": 0.5184,
      "step": 6609
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.71605652846336,
      "learning_rate": 5.892626198776075e-06,
      "loss": 0.5193,
      "step": 6610
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.6330456424675381,
      "learning_rate": 5.891518246396291e-06,
      "loss": 0.5146,
      "step": 6611
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.9824879712815322,
      "learning_rate": 5.890410248801608e-06,
      "loss": 0.532,
      "step": 6612
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.783013440457055,
      "learning_rate": 5.889302206048221e-06,
      "loss": 0.5292,
      "step": 6613
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.963103336272317,
      "learning_rate": 5.8881941181923255e-06,
      "loss": 0.5448,
      "step": 6614
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.0551971901656625,
      "learning_rate": 5.8870859852901175e-06,
      "loss": 0.5783,
      "step": 6615
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.3502640851035252,
      "learning_rate": 5.885977807397803e-06,
      "loss": 0.4831,
      "step": 6616
    },
    {
      "epoch": 0.46,
      "grad_norm": 3.26683174233066,
      "learning_rate": 5.884869584571581e-06,
      "loss": 0.4934,
      "step": 6617
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.9730653743999698,
      "learning_rate": 5.88376131686766e-06,
      "loss": 0.4663,
      "step": 6618
    },
    {
      "epoch": 0.46,
      "grad_norm": 8.443196419631114,
      "learning_rate": 5.882653004342245e-06,
      "loss": 0.4987,
      "step": 6619
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.0591158789046378,
      "learning_rate": 5.881544647051547e-06,
      "loss": 0.5121,
      "step": 6620
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.8153917867445382,
      "learning_rate": 5.88043624505178e-06,
      "loss": 0.487,
      "step": 6621
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.0698394128361377,
      "learning_rate": 5.879327798399155e-06,
      "loss": 0.5139,
      "step": 6622
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.913432393109537,
      "learning_rate": 5.878219307149892e-06,
      "loss": 0.4681,
      "step": 6623
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.1204241865367965,
      "learning_rate": 5.87711077136021e-06,
      "loss": 0.4974,
      "step": 6624
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.9360357754824211,
      "learning_rate": 5.876002191086327e-06,
      "loss": 0.4803,
      "step": 6625
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.3749538826912318,
      "learning_rate": 5.874893566384471e-06,
      "loss": 0.5095,
      "step": 6626
    },
    {
      "epoch": 0.46,
      "grad_norm": 3.941461466906186,
      "learning_rate": 5.873784897310864e-06,
      "loss": 0.4855,
      "step": 6627
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.456365449335473,
      "learning_rate": 5.872676183921737e-06,
      "loss": 0.4832,
      "step": 6628
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.6606225119229854,
      "learning_rate": 5.871567426273317e-06,
      "loss": 0.4699,
      "step": 6629
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.3244552939457477,
      "learning_rate": 5.870458624421841e-06,
      "loss": 0.5404,
      "step": 6630
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.537692623619679,
      "learning_rate": 5.86934977842354e-06,
      "loss": 0.5327,
      "step": 6631
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.708196872387938,
      "learning_rate": 5.8682408883346535e-06,
      "loss": 0.4949,
      "step": 6632
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.13987696696071,
      "learning_rate": 5.867131954211418e-06,
      "loss": 0.4793,
      "step": 6633
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6466350209527525,
      "learning_rate": 5.866022976110078e-06,
      "loss": 0.4225,
      "step": 6634
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.7747102248002926,
      "learning_rate": 5.864913954086876e-06,
      "loss": 0.527,
      "step": 6635
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.2879746284719715,
      "learning_rate": 5.863804888198059e-06,
      "loss": 0.5367,
      "step": 6636
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.8244694762205633,
      "learning_rate": 5.862695778499872e-06,
      "loss": 0.5297,
      "step": 6637
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.9273453622989898,
      "learning_rate": 5.86158662504857e-06,
      "loss": 0.5525,
      "step": 6638
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.3138781847738294,
      "learning_rate": 5.860477427900401e-06,
      "loss": 0.5154,
      "step": 6639
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.0540413781496767,
      "learning_rate": 5.859368187111623e-06,
      "loss": 0.4666,
      "step": 6640
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.6762458703543197,
      "learning_rate": 5.858258902738493e-06,
      "loss": 0.5127,
      "step": 6641
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.8187335745966355,
      "learning_rate": 5.857149574837269e-06,
      "loss": 0.5239,
      "step": 6642
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.8821759540490324,
      "learning_rate": 5.856040203464213e-06,
      "loss": 0.4771,
      "step": 6643
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.6909700275424124,
      "learning_rate": 5.854930788675589e-06,
      "loss": 0.4981,
      "step": 6644
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6297855931550744,
      "learning_rate": 5.853821330527662e-06,
      "loss": 0.4409,
      "step": 6645
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.976970910341936,
      "learning_rate": 5.852711829076702e-06,
      "loss": 0.5229,
      "step": 6646
    },
    {
      "epoch": 0.46,
      "grad_norm": 4.50370156900449,
      "learning_rate": 5.851602284378978e-06,
      "loss": 0.4902,
      "step": 6647
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.6132542239350436,
      "learning_rate": 5.850492696490761e-06,
      "loss": 0.4602,
      "step": 6648
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.427783908615051,
      "learning_rate": 5.849383065468328e-06,
      "loss": 0.5271,
      "step": 6649
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.8271623338206946,
      "learning_rate": 5.848273391367955e-06,
      "loss": 0.5225,
      "step": 6650
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.8450132533973649,
      "learning_rate": 5.8471636742459215e-06,
      "loss": 0.5087,
      "step": 6651
    },
    {
      "epoch": 0.46,
      "grad_norm": 3.101241260072715,
      "learning_rate": 5.846053914158507e-06,
      "loss": 0.521,
      "step": 6652
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.6780258400819612,
      "learning_rate": 5.844944111161999e-06,
      "loss": 0.5088,
      "step": 6653
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.8911600327094809,
      "learning_rate": 5.843834265312678e-06,
      "loss": 0.5169,
      "step": 6654
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.217969274910564,
      "learning_rate": 5.842724376666834e-06,
      "loss": 0.4928,
      "step": 6655
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.8328523725645487,
      "learning_rate": 5.841614445280759e-06,
      "loss": 0.4831,
      "step": 6656
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.5430148923191602,
      "learning_rate": 5.840504471210742e-06,
      "loss": 0.508,
      "step": 6657
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.232610717374424,
      "learning_rate": 5.8393944545130774e-06,
      "loss": 0.4943,
      "step": 6658
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.9002666064016827,
      "learning_rate": 5.838284395244065e-06,
      "loss": 0.5006,
      "step": 6659
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.1058703993597225,
      "learning_rate": 5.837174293459999e-06,
      "loss": 0.4978,
      "step": 6660
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.7115271730263417,
      "learning_rate": 5.836064149217183e-06,
      "loss": 0.5145,
      "step": 6661
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5805340215026873,
      "learning_rate": 5.834953962571919e-06,
      "loss": 0.4326,
      "step": 6662
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.6120553594689435,
      "learning_rate": 5.8338437335805124e-06,
      "loss": 0.4702,
      "step": 6663
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.861679563754155,
      "learning_rate": 5.832733462299269e-06,
      "loss": 0.5291,
      "step": 6664
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.552788798879958,
      "learning_rate": 5.831623148784501e-06,
      "loss": 0.5155,
      "step": 6665
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.045302548677886,
      "learning_rate": 5.830512793092517e-06,
      "loss": 0.5326,
      "step": 6666
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.1098040641170663,
      "learning_rate": 5.829402395279632e-06,
      "loss": 0.5408,
      "step": 6667
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.7404535567115562,
      "learning_rate": 5.828291955402161e-06,
      "loss": 0.5173,
      "step": 6668
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.170107997764914,
      "learning_rate": 5.827181473516423e-06,
      "loss": 0.5906,
      "step": 6669
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.9407945900313486,
      "learning_rate": 5.826070949678737e-06,
      "loss": 0.5109,
      "step": 6670
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.0134457899585345,
      "learning_rate": 5.824960383945427e-06,
      "loss": 0.5145,
      "step": 6671
    },
    {
      "epoch": 0.46,
      "grad_norm": 5.725008713385351,
      "learning_rate": 5.823849776372814e-06,
      "loss": 0.5097,
      "step": 6672
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.6266554921310794,
      "learning_rate": 5.822739127017227e-06,
      "loss": 0.5321,
      "step": 6673
    },
    {
      "epoch": 0.46,
      "grad_norm": 3.0367875217388813,
      "learning_rate": 5.821628435934994e-06,
      "loss": 0.5238,
      "step": 6674
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6182325881434734,
      "learning_rate": 5.820517703182446e-06,
      "loss": 0.449,
      "step": 6675
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.0504850924799976,
      "learning_rate": 5.819406928815912e-06,
      "loss": 0.4915,
      "step": 6676
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.941279657136233,
      "learning_rate": 5.8182961128917336e-06,
      "loss": 0.501,
      "step": 6677
    },
    {
      "epoch": 0.46,
      "grad_norm": 3.2153346645998946,
      "learning_rate": 5.817185255466244e-06,
      "loss": 0.4774,
      "step": 6678
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.779119152591202,
      "learning_rate": 5.81607435659578e-06,
      "loss": 0.5119,
      "step": 6679
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6636800042189116,
      "learning_rate": 5.814963416336688e-06,
      "loss": 0.4396,
      "step": 6680
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.7054263879004123,
      "learning_rate": 5.813852434745306e-06,
      "loss": 0.5151,
      "step": 6681
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.056565963036672,
      "learning_rate": 5.8127414118779825e-06,
      "loss": 0.5541,
      "step": 6682
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.6176247910854413,
      "learning_rate": 5.811630347791065e-06,
      "loss": 0.4675,
      "step": 6683
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.9761235026579997,
      "learning_rate": 5.8105192425409015e-06,
      "loss": 0.5122,
      "step": 6684
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.9998531891493634,
      "learning_rate": 5.809408096183845e-06,
      "loss": 0.5183,
      "step": 6685
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.5772839013537925,
      "learning_rate": 5.808296908776247e-06,
      "loss": 0.4507,
      "step": 6686
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.924606343629396,
      "learning_rate": 5.807185680374467e-06,
      "loss": 0.4918,
      "step": 6687
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.744731646846023,
      "learning_rate": 5.806074411034861e-06,
      "loss": 0.4873,
      "step": 6688
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.1496738412227976,
      "learning_rate": 5.8049631008137885e-06,
      "loss": 0.5261,
      "step": 6689
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.5511059806546557,
      "learning_rate": 5.8038517497676116e-06,
      "loss": 0.5304,
      "step": 6690
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.7241363795359244,
      "learning_rate": 5.802740357952695e-06,
      "loss": 0.5014,
      "step": 6691
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6132224381941583,
      "learning_rate": 5.801628925425403e-06,
      "loss": 0.4343,
      "step": 6692
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.8933045813295288,
      "learning_rate": 5.800517452242107e-06,
      "loss": 0.5195,
      "step": 6693
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.6739432166757835,
      "learning_rate": 5.799405938459175e-06,
      "loss": 0.5285,
      "step": 6694
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.8016501931725957,
      "learning_rate": 5.798294384132981e-06,
      "loss": 0.5136,
      "step": 6695
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.6266314186134352,
      "learning_rate": 5.797182789319896e-06,
      "loss": 0.4902,
      "step": 6696
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.029103140287273,
      "learning_rate": 5.796071154076301e-06,
      "loss": 0.4886,
      "step": 6697
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.8975281160684203,
      "learning_rate": 5.794959478458572e-06,
      "loss": 0.518,
      "step": 6698
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.5507951677565406,
      "learning_rate": 5.793847762523091e-06,
      "loss": 0.5102,
      "step": 6699
    },
    {
      "epoch": 0.47,
      "grad_norm": 5.749795147170065,
      "learning_rate": 5.792736006326237e-06,
      "loss": 0.4733,
      "step": 6700
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.596193781978491,
      "learning_rate": 5.791624209924399e-06,
      "loss": 0.4746,
      "step": 6701
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.315593023553026,
      "learning_rate": 5.790512373373962e-06,
      "loss": 0.5092,
      "step": 6702
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.8650054392046689,
      "learning_rate": 5.789400496731315e-06,
      "loss": 0.5073,
      "step": 6703
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.8238645393660036,
      "learning_rate": 5.788288580052846e-06,
      "loss": 0.549,
      "step": 6704
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.019781250547342,
      "learning_rate": 5.787176623394952e-06,
      "loss": 0.5576,
      "step": 6705
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.9783647384497063,
      "learning_rate": 5.786064626814026e-06,
      "loss": 0.5043,
      "step": 6706
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.2633899561277264,
      "learning_rate": 5.7849525903664636e-06,
      "loss": 0.4586,
      "step": 6707
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.7080284071581624,
      "learning_rate": 5.783840514108667e-06,
      "loss": 0.4617,
      "step": 6708
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.296413031968979,
      "learning_rate": 5.782728398097033e-06,
      "loss": 0.5043,
      "step": 6709
    },
    {
      "epoch": 0.47,
      "grad_norm": 3.00063535181937,
      "learning_rate": 5.781616242387968e-06,
      "loss": 0.4513,
      "step": 6710
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.3886668294344013,
      "learning_rate": 5.780504047037876e-06,
      "loss": 0.495,
      "step": 6711
    },
    {
      "epoch": 0.47,
      "grad_norm": 3.1895853547892257,
      "learning_rate": 5.779391812103162e-06,
      "loss": 0.4946,
      "step": 6712
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.8059292507931797,
      "learning_rate": 5.778279537640236e-06,
      "loss": 0.5213,
      "step": 6713
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.71744702115413,
      "learning_rate": 5.7771672237055096e-06,
      "loss": 0.5161,
      "step": 6714
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.576194675928576,
      "learning_rate": 5.776054870355395e-06,
      "loss": 0.4865,
      "step": 6715
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.3218722795485585,
      "learning_rate": 5.774942477646308e-06,
      "loss": 0.5264,
      "step": 6716
    },
    {
      "epoch": 0.47,
      "grad_norm": 3.077600845039822,
      "learning_rate": 5.773830045634664e-06,
      "loss": 0.4857,
      "step": 6717
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.3851551692377724,
      "learning_rate": 5.772717574376885e-06,
      "loss": 0.4939,
      "step": 6718
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.287946910419911,
      "learning_rate": 5.771605063929388e-06,
      "loss": 0.521,
      "step": 6719
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.970826335349677,
      "learning_rate": 5.770492514348598e-06,
      "loss": 0.4693,
      "step": 6720
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.8437271711897527,
      "learning_rate": 5.76937992569094e-06,
      "loss": 0.5028,
      "step": 6721
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.759724471073667,
      "learning_rate": 5.768267298012841e-06,
      "loss": 0.5069,
      "step": 6722
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.8656345134681132,
      "learning_rate": 5.767154631370728e-06,
      "loss": 0.4836,
      "step": 6723
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.8574219041639874,
      "learning_rate": 5.766041925821036e-06,
      "loss": 0.4609,
      "step": 6724
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.7511893247887143,
      "learning_rate": 5.764929181420191e-06,
      "loss": 0.4694,
      "step": 6725
    },
    {
      "epoch": 0.47,
      "grad_norm": 3.7147638295379646,
      "learning_rate": 5.763816398224634e-06,
      "loss": 0.4964,
      "step": 6726
    },
    {
      "epoch": 0.47,
      "grad_norm": 6.250267959982999,
      "learning_rate": 5.762703576290798e-06,
      "loss": 0.4998,
      "step": 6727
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.723591486860669,
      "learning_rate": 5.7615907156751246e-06,
      "loss": 0.4968,
      "step": 6728
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.8612211806646457,
      "learning_rate": 5.760477816434053e-06,
      "loss": 0.4758,
      "step": 6729
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.690786307134026,
      "learning_rate": 5.759364878624025e-06,
      "loss": 0.4503,
      "step": 6730
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.6991343373120498,
      "learning_rate": 5.758251902301486e-06,
      "loss": 0.5338,
      "step": 6731
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.8357712957830024,
      "learning_rate": 5.757138887522884e-06,
      "loss": 0.5197,
      "step": 6732
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.6436617764673493,
      "learning_rate": 5.756025834344664e-06,
      "loss": 0.5322,
      "step": 6733
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.8413280624476391,
      "learning_rate": 5.754912742823281e-06,
      "loss": 0.4936,
      "step": 6734
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.0131077539328017,
      "learning_rate": 5.753799613015183e-06,
      "loss": 0.5222,
      "step": 6735
    },
    {
      "epoch": 0.47,
      "grad_norm": 3.850669870740585,
      "learning_rate": 5.7526864449768276e-06,
      "loss": 0.4643,
      "step": 6736
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.8079343059326078,
      "learning_rate": 5.751573238764667e-06,
      "loss": 0.5195,
      "step": 6737
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.35497883744214,
      "learning_rate": 5.750459994435165e-06,
      "loss": 0.5301,
      "step": 6738
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.6924481717400544,
      "learning_rate": 5.749346712044777e-06,
      "loss": 0.5338,
      "step": 6739
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.3392552365019097,
      "learning_rate": 5.7482333916499665e-06,
      "loss": 0.5206,
      "step": 6740
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.8901992146125115,
      "learning_rate": 5.747120033307198e-06,
      "loss": 0.524,
      "step": 6741
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.7674529168311295,
      "learning_rate": 5.746006637072938e-06,
      "loss": 0.4763,
      "step": 6742
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.9076368382119704,
      "learning_rate": 5.744893203003653e-06,
      "loss": 0.5329,
      "step": 6743
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.8074098220339696,
      "learning_rate": 5.743779731155813e-06,
      "loss": 0.4772,
      "step": 6744
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.5441901778072964,
      "learning_rate": 5.74266622158589e-06,
      "loss": 0.5069,
      "step": 6745
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.6934554148807732,
      "learning_rate": 5.741552674350359e-06,
      "loss": 0.4949,
      "step": 6746
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.761260828848333,
      "learning_rate": 5.740439089505691e-06,
      "loss": 0.5062,
      "step": 6747
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.742220209291228,
      "learning_rate": 5.73932546710837e-06,
      "loss": 0.5107,
      "step": 6748
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.786156602477017,
      "learning_rate": 5.738211807214868e-06,
      "loss": 0.4957,
      "step": 6749
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.013877425921948,
      "learning_rate": 5.737098109881673e-06,
      "loss": 0.5172,
      "step": 6750
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.7641822190257002,
      "learning_rate": 5.7359843751652625e-06,
      "loss": 0.5209,
      "step": 6751
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.9129457212446386,
      "learning_rate": 5.7348706031221245e-06,
      "loss": 0.5345,
      "step": 6752
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.598498190162126,
      "learning_rate": 5.733756793808745e-06,
      "loss": 0.5017,
      "step": 6753
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.792433701341303,
      "learning_rate": 5.732642947281615e-06,
      "loss": 0.5042,
      "step": 6754
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.8431057464873373,
      "learning_rate": 5.731529063597221e-06,
      "loss": 0.5255,
      "step": 6755
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.3108355670394767,
      "learning_rate": 5.730415142812059e-06,
      "loss": 0.5615,
      "step": 6756
    },
    {
      "epoch": 0.47,
      "grad_norm": 6.4919134369910685,
      "learning_rate": 5.729301184982622e-06,
      "loss": 0.5094,
      "step": 6757
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.1173823841631454,
      "learning_rate": 5.728187190165408e-06,
      "loss": 0.5468,
      "step": 6758
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.9831677281799944,
      "learning_rate": 5.727073158416911e-06,
      "loss": 0.4507,
      "step": 6759
    },
    {
      "epoch": 0.47,
      "grad_norm": 3.2703545678915846,
      "learning_rate": 5.725959089793636e-06,
      "loss": 0.5222,
      "step": 6760
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.7812060588760823,
      "learning_rate": 5.724844984352081e-06,
      "loss": 0.5079,
      "step": 6761
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.221460327945099,
      "learning_rate": 5.723730842148752e-06,
      "loss": 0.5064,
      "step": 6762
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.9319034710268033,
      "learning_rate": 5.722616663240155e-06,
      "loss": 0.4907,
      "step": 6763
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.6470130089465365,
      "learning_rate": 5.721502447682796e-06,
      "loss": 0.4697,
      "step": 6764
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.0505479275256797,
      "learning_rate": 5.720388195533185e-06,
      "loss": 0.5113,
      "step": 6765
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6171011290365663,
      "learning_rate": 5.719273906847834e-06,
      "loss": 0.4249,
      "step": 6766
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.8280513216178926,
      "learning_rate": 5.7181595816832544e-06,
      "loss": 0.5507,
      "step": 6767
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.5600858376720406,
      "learning_rate": 5.7170452200959635e-06,
      "loss": 0.4926,
      "step": 6768
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.103536640382465,
      "learning_rate": 5.715930822142477e-06,
      "loss": 0.4819,
      "step": 6769
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.6430321007973208,
      "learning_rate": 5.714816387879312e-06,
      "loss": 0.4811,
      "step": 6770
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.114031093797495,
      "learning_rate": 5.71370191736299e-06,
      "loss": 0.5025,
      "step": 6771
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.653351932087162,
      "learning_rate": 5.712587410650034e-06,
      "loss": 0.438,
      "step": 6772
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.89492605339916,
      "learning_rate": 5.7114728677969684e-06,
      "loss": 0.4922,
      "step": 6773
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.0328265283749376,
      "learning_rate": 5.710358288860317e-06,
      "loss": 0.4947,
      "step": 6774
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.8539907905996331,
      "learning_rate": 5.7092436738966105e-06,
      "loss": 0.4805,
      "step": 6775
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.041218160664123,
      "learning_rate": 5.708129022962377e-06,
      "loss": 0.5024,
      "step": 6776
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.6240519912130125,
      "learning_rate": 5.707014336114147e-06,
      "loss": 0.4661,
      "step": 6777
    },
    {
      "epoch": 0.47,
      "grad_norm": 3.2748100790532266,
      "learning_rate": 5.705899613408456e-06,
      "loss": 0.4801,
      "step": 6778
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.1966690716536093,
      "learning_rate": 5.704784854901839e-06,
      "loss": 0.4985,
      "step": 6779
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.1126507793554143,
      "learning_rate": 5.70367006065083e-06,
      "loss": 0.5358,
      "step": 6780
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.9684879074796398,
      "learning_rate": 5.70255523071197e-06,
      "loss": 0.5375,
      "step": 6781
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.052578338196785,
      "learning_rate": 5.701440365141799e-06,
      "loss": 0.5137,
      "step": 6782
    },
    {
      "epoch": 0.47,
      "grad_norm": 3.2139520145351788,
      "learning_rate": 5.7003254639968595e-06,
      "loss": 0.4865,
      "step": 6783
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.8166707879634196,
      "learning_rate": 5.6992105273336964e-06,
      "loss": 0.5364,
      "step": 6784
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.6845834290970336,
      "learning_rate": 5.698095555208854e-06,
      "loss": 0.4952,
      "step": 6785
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.6994946260439383,
      "learning_rate": 5.6969805476788805e-06,
      "loss": 0.5393,
      "step": 6786
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.766094569479812,
      "learning_rate": 5.695865504800328e-06,
      "loss": 0.5109,
      "step": 6787
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.3380537875885783,
      "learning_rate": 5.694750426629744e-06,
      "loss": 0.5248,
      "step": 6788
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.7194640002829422,
      "learning_rate": 5.693635313223684e-06,
      "loss": 0.4918,
      "step": 6789
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.7996579517082036,
      "learning_rate": 5.692520164638703e-06,
      "loss": 0.516,
      "step": 6790
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.752633209474584,
      "learning_rate": 5.691404980931357e-06,
      "loss": 0.5163,
      "step": 6791
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.6635187598068134,
      "learning_rate": 5.690289762158203e-06,
      "loss": 0.4396,
      "step": 6792
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.9679266637332276,
      "learning_rate": 5.689174508375803e-06,
      "loss": 0.5223,
      "step": 6793
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.9774709288336862,
      "learning_rate": 5.688059219640719e-06,
      "loss": 0.5492,
      "step": 6794
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.0514338999859634,
      "learning_rate": 5.686943896009516e-06,
      "loss": 0.5145,
      "step": 6795
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.5596449151673581,
      "learning_rate": 5.685828537538756e-06,
      "loss": 0.5123,
      "step": 6796
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.6025393947903797,
      "learning_rate": 5.68471314428501e-06,
      "loss": 0.5652,
      "step": 6797
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.8021625755416943,
      "learning_rate": 5.683597716304844e-06,
      "loss": 0.5223,
      "step": 6798
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.6510611153616397,
      "learning_rate": 5.682482253654832e-06,
      "loss": 0.5038,
      "step": 6799
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.7225057547013132,
      "learning_rate": 5.681366756391544e-06,
      "loss": 0.5653,
      "step": 6800
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.9576988507961357,
      "learning_rate": 5.680251224571557e-06,
      "loss": 0.5147,
      "step": 6801
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.9684556064450334,
      "learning_rate": 5.679135658251444e-06,
      "loss": 0.4631,
      "step": 6802
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.6693787502606123,
      "learning_rate": 5.678020057487787e-06,
      "loss": 0.5368,
      "step": 6803
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.9170774981578014,
      "learning_rate": 5.676904422337161e-06,
      "loss": 0.4773,
      "step": 6804
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.222501649961704,
      "learning_rate": 5.67578875285615e-06,
      "loss": 0.5044,
      "step": 6805
    },
    {
      "epoch": 0.47,
      "grad_norm": 6.6611127692573024,
      "learning_rate": 5.674673049101336e-06,
      "loss": 0.4942,
      "step": 6806
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.7991104141423409,
      "learning_rate": 5.673557311129306e-06,
      "loss": 0.5023,
      "step": 6807
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.0321057664923643,
      "learning_rate": 5.672441538996643e-06,
      "loss": 0.5171,
      "step": 6808
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.8775888649835648,
      "learning_rate": 5.67132573275994e-06,
      "loss": 0.5367,
      "step": 6809
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.2036063371051715,
      "learning_rate": 5.670209892475782e-06,
      "loss": 0.4621,
      "step": 6810
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.6334305705432408,
      "learning_rate": 5.669094018200764e-06,
      "loss": 0.5532,
      "step": 6811
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.167636084155193,
      "learning_rate": 5.667978109991481e-06,
      "loss": 0.4989,
      "step": 6812
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.066766192991195,
      "learning_rate": 5.666862167904524e-06,
      "loss": 0.5163,
      "step": 6813
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.5791280932528755,
      "learning_rate": 5.665746191996492e-06,
      "loss": 0.5025,
      "step": 6814
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.7931297930293095,
      "learning_rate": 5.6646301823239845e-06,
      "loss": 0.5403,
      "step": 6815
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.1998092299260863,
      "learning_rate": 5.6635141389436e-06,
      "loss": 0.4901,
      "step": 6816
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.01394627565698,
      "learning_rate": 5.662398061911943e-06,
      "loss": 0.539,
      "step": 6817
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.859320670302105,
      "learning_rate": 5.661281951285613e-06,
      "loss": 0.5137,
      "step": 6818
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.7999858439249974,
      "learning_rate": 5.66016580712122e-06,
      "loss": 0.5317,
      "step": 6819
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.8746542792168597,
      "learning_rate": 5.659049629475369e-06,
      "loss": 0.5501,
      "step": 6820
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.128351884795401,
      "learning_rate": 5.657933418404671e-06,
      "loss": 0.5024,
      "step": 6821
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.6181052517974495,
      "learning_rate": 5.656817173965733e-06,
      "loss": 0.5382,
      "step": 6822
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.687128240432698,
      "learning_rate": 5.655700896215171e-06,
      "loss": 0.4953,
      "step": 6823
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.997119144529394,
      "learning_rate": 5.654584585209596e-06,
      "loss": 0.528,
      "step": 6824
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.9038049575850904,
      "learning_rate": 5.6534682410056265e-06,
      "loss": 0.4936,
      "step": 6825
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.6930324579735343,
      "learning_rate": 5.652351863659876e-06,
      "loss": 0.4784,
      "step": 6826
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.8861622320763736,
      "learning_rate": 5.651235453228967e-06,
      "loss": 0.519,
      "step": 6827
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.7577646019973403,
      "learning_rate": 5.650119009769519e-06,
      "loss": 0.4753,
      "step": 6828
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.7427627923196498,
      "learning_rate": 5.649002533338155e-06,
      "loss": 0.4647,
      "step": 6829
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.190739185109771,
      "learning_rate": 5.647886023991496e-06,
      "loss": 0.4979,
      "step": 6830
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.4006219132665727,
      "learning_rate": 5.6467694817861715e-06,
      "loss": 0.4913,
      "step": 6831
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.9673521487427406,
      "learning_rate": 5.645652906778808e-06,
      "loss": 0.5187,
      "step": 6832
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6815870792175317,
      "learning_rate": 5.644536299026033e-06,
      "loss": 0.4672,
      "step": 6833
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.808953296168066,
      "learning_rate": 5.643419658584479e-06,
      "loss": 0.5278,
      "step": 6834
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6135737550716089,
      "learning_rate": 5.642302985510778e-06,
      "loss": 0.4359,
      "step": 6835
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.7579681676985988,
      "learning_rate": 5.641186279861563e-06,
      "loss": 0.4683,
      "step": 6836
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.6786724139035245,
      "learning_rate": 5.64006954169347e-06,
      "loss": 0.4518,
      "step": 6837
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.9134477013782905,
      "learning_rate": 5.6389527710631374e-06,
      "loss": 0.5082,
      "step": 6838
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.1828629925871463,
      "learning_rate": 5.637835968027202e-06,
      "loss": 0.5318,
      "step": 6839
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.9172309539220649,
      "learning_rate": 5.636719132642308e-06,
      "loss": 0.529,
      "step": 6840
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6879551174760169,
      "learning_rate": 5.635602264965093e-06,
      "loss": 0.4352,
      "step": 6841
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.7736292088022692,
      "learning_rate": 5.6344853650522045e-06,
      "loss": 0.4827,
      "step": 6842
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.5565503261454647,
      "learning_rate": 5.633368432960286e-06,
      "loss": 0.5322,
      "step": 6843
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5845796350915013,
      "learning_rate": 5.632251468745987e-06,
      "loss": 0.4444,
      "step": 6844
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.7705498930936883,
      "learning_rate": 5.631134472465954e-06,
      "loss": 0.5,
      "step": 6845
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.2236433579506527,
      "learning_rate": 5.630017444176838e-06,
      "loss": 0.5085,
      "step": 6846
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.7020301752323264,
      "learning_rate": 5.628900383935292e-06,
      "loss": 0.5518,
      "step": 6847
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.739183021617071,
      "learning_rate": 5.627783291797968e-06,
      "loss": 0.4722,
      "step": 6848
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.9758359751017545,
      "learning_rate": 5.626666167821522e-06,
      "loss": 0.5242,
      "step": 6849
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.219596197483262,
      "learning_rate": 5.625549012062611e-06,
      "loss": 0.4929,
      "step": 6850
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.831674080134527,
      "learning_rate": 5.624431824577894e-06,
      "loss": 0.5165,
      "step": 6851
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.8079292573819885,
      "learning_rate": 5.623314605424031e-06,
      "loss": 0.5144,
      "step": 6852
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.8128895134457614,
      "learning_rate": 5.622197354657682e-06,
      "loss": 0.4976,
      "step": 6853
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.9731691242657805,
      "learning_rate": 5.621080072335513e-06,
      "loss": 0.5046,
      "step": 6854
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.677354360754731,
      "learning_rate": 5.619962758514186e-06,
      "loss": 0.4791,
      "step": 6855
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.874676523987269,
      "learning_rate": 5.618845413250371e-06,
      "loss": 0.4824,
      "step": 6856
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6328002732171458,
      "learning_rate": 5.617728036600734e-06,
      "loss": 0.4353,
      "step": 6857
    },
    {
      "epoch": 0.48,
      "grad_norm": 3.2370405696738174,
      "learning_rate": 5.616610628621944e-06,
      "loss": 0.5033,
      "step": 6858
    },
    {
      "epoch": 0.48,
      "grad_norm": 3.6468673642166825,
      "learning_rate": 5.615493189370673e-06,
      "loss": 0.498,
      "step": 6859
    },
    {
      "epoch": 0.48,
      "grad_norm": 3.8843470140805763,
      "learning_rate": 5.614375718903594e-06,
      "loss": 0.4789,
      "step": 6860
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.098498763369612,
      "learning_rate": 5.613258217277382e-06,
      "loss": 0.4973,
      "step": 6861
    },
    {
      "epoch": 0.48,
      "grad_norm": 3.1231648095284004,
      "learning_rate": 5.612140684548713e-06,
      "loss": 0.4839,
      "step": 6862
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.7084299154327542,
      "learning_rate": 5.611023120774263e-06,
      "loss": 0.5361,
      "step": 6863
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.168954262107486,
      "learning_rate": 5.609905526010713e-06,
      "loss": 0.5196,
      "step": 6864
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.7489675906231428,
      "learning_rate": 5.608787900314742e-06,
      "loss": 0.5119,
      "step": 6865
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.844973784835224,
      "learning_rate": 5.607670243743036e-06,
      "loss": 0.5272,
      "step": 6866
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.380866559985107,
      "learning_rate": 5.606552556352275e-06,
      "loss": 0.4978,
      "step": 6867
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.98684573603973,
      "learning_rate": 5.605434838199145e-06,
      "loss": 0.5119,
      "step": 6868
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.431734210146787,
      "learning_rate": 5.604317089340336e-06,
      "loss": 0.4897,
      "step": 6869
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.8545221125269,
      "learning_rate": 5.603199309832533e-06,
      "loss": 0.5299,
      "step": 6870
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.0272002044417023,
      "learning_rate": 5.602081499732427e-06,
      "loss": 0.4685,
      "step": 6871
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.8414607144006443,
      "learning_rate": 5.600963659096711e-06,
      "loss": 0.4913,
      "step": 6872
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.933829948388819,
      "learning_rate": 5.599845787982077e-06,
      "loss": 0.5401,
      "step": 6873
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.0689499841864505,
      "learning_rate": 5.598727886445221e-06,
      "loss": 0.5183,
      "step": 6874
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.406722776132998,
      "learning_rate": 5.597609954542838e-06,
      "loss": 0.5476,
      "step": 6875
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.04418722240501,
      "learning_rate": 5.596491992331626e-06,
      "loss": 0.5283,
      "step": 6876
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.107275114678416,
      "learning_rate": 5.595373999868285e-06,
      "loss": 0.5122,
      "step": 6877
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.8818289455799146,
      "learning_rate": 5.594255977209516e-06,
      "loss": 0.4976,
      "step": 6878
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5955046834109186,
      "learning_rate": 5.593137924412022e-06,
      "loss": 0.437,
      "step": 6879
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.589582808176119,
      "learning_rate": 5.592019841532507e-06,
      "loss": 0.4436,
      "step": 6880
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.7453139509815425,
      "learning_rate": 5.590901728627673e-06,
      "loss": 0.4972,
      "step": 6881
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.6524949801715412,
      "learning_rate": 5.5897835857542315e-06,
      "loss": 0.5232,
      "step": 6882
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.9007032013508325,
      "learning_rate": 5.588665412968888e-06,
      "loss": 0.5105,
      "step": 6883
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5909429948912546,
      "learning_rate": 5.587547210328356e-06,
      "loss": 0.4499,
      "step": 6884
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.852693691402175,
      "learning_rate": 5.586428977889342e-06,
      "loss": 0.505,
      "step": 6885
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.6528232635778675,
      "learning_rate": 5.585310715708565e-06,
      "loss": 0.4722,
      "step": 6886
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.4335236022204674,
      "learning_rate": 5.584192423842735e-06,
      "loss": 0.4908,
      "step": 6887
    },
    {
      "epoch": 0.48,
      "grad_norm": 3.3988291507109003,
      "learning_rate": 5.583074102348571e-06,
      "loss": 0.5337,
      "step": 6888
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.7654609876992062,
      "learning_rate": 5.581955751282788e-06,
      "loss": 0.4777,
      "step": 6889
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.4205212518971155,
      "learning_rate": 5.580837370702108e-06,
      "loss": 0.5495,
      "step": 6890
    },
    {
      "epoch": 0.48,
      "grad_norm": 3.3762086947788292,
      "learning_rate": 5.579718960663251e-06,
      "loss": 0.5386,
      "step": 6891
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6380092304806063,
      "learning_rate": 5.5786005212229365e-06,
      "loss": 0.4348,
      "step": 6892
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.9696630889232147,
      "learning_rate": 5.577482052437891e-06,
      "loss": 0.5133,
      "step": 6893
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.8031940922487684,
      "learning_rate": 5.576363554364838e-06,
      "loss": 0.5042,
      "step": 6894
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.031113079227803,
      "learning_rate": 5.575245027060503e-06,
      "loss": 0.5614,
      "step": 6895
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.098200743398253,
      "learning_rate": 5.574126470581617e-06,
      "loss": 0.4879,
      "step": 6896
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.755537625369568,
      "learning_rate": 5.573007884984909e-06,
      "loss": 0.5137,
      "step": 6897
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.549861705424619,
      "learning_rate": 5.571889270327107e-06,
      "loss": 0.5397,
      "step": 6898
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.018330938424309,
      "learning_rate": 5.570770626664947e-06,
      "loss": 0.5221,
      "step": 6899
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.2837945534228155,
      "learning_rate": 5.569651954055163e-06,
      "loss": 0.4882,
      "step": 6900
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.9412585614318285,
      "learning_rate": 5.568533252554489e-06,
      "loss": 0.4728,
      "step": 6901
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.1845378592639815,
      "learning_rate": 5.5674145222196596e-06,
      "loss": 0.5417,
      "step": 6902
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.9934902951827262,
      "learning_rate": 5.566295763107418e-06,
      "loss": 0.4928,
      "step": 6903
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.0926003557670065,
      "learning_rate": 5.5651769752744985e-06,
      "loss": 0.499,
      "step": 6904
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.1124672365779977,
      "learning_rate": 5.564058158777647e-06,
      "loss": 0.5333,
      "step": 6905
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.170540710456087,
      "learning_rate": 5.562939313673605e-06,
      "loss": 0.4779,
      "step": 6906
    },
    {
      "epoch": 0.48,
      "grad_norm": 3.9502073171669827,
      "learning_rate": 5.561820440019117e-06,
      "loss": 0.5244,
      "step": 6907
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.7491557026805051,
      "learning_rate": 5.560701537870926e-06,
      "loss": 0.5355,
      "step": 6908
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.7448439872513746,
      "learning_rate": 5.559582607285783e-06,
      "loss": 0.5403,
      "step": 6909
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.1378734796344228,
      "learning_rate": 5.558463648320432e-06,
      "loss": 0.5323,
      "step": 6910
    },
    {
      "epoch": 0.48,
      "grad_norm": 3.5063381608587485,
      "learning_rate": 5.557344661031628e-06,
      "loss": 0.4624,
      "step": 6911
    },
    {
      "epoch": 0.48,
      "grad_norm": 13.591224725387423,
      "learning_rate": 5.556225645476119e-06,
      "loss": 0.4694,
      "step": 6912
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.8476159914480823,
      "learning_rate": 5.555106601710659e-06,
      "loss": 0.4819,
      "step": 6913
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.161601357452719,
      "learning_rate": 5.553987529792001e-06,
      "loss": 0.4858,
      "step": 6914
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.6000508365077908,
      "learning_rate": 5.552868429776902e-06,
      "loss": 0.4612,
      "step": 6915
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.1418251682989506,
      "learning_rate": 5.551749301722118e-06,
      "loss": 0.4624,
      "step": 6916
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.619465104002434,
      "learning_rate": 5.550630145684409e-06,
      "loss": 0.4472,
      "step": 6917
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.531984043048339,
      "learning_rate": 5.549510961720533e-06,
      "loss": 0.4785,
      "step": 6918
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.062576463804697,
      "learning_rate": 5.548391749887255e-06,
      "loss": 0.5591,
      "step": 6919
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.845840292460994,
      "learning_rate": 5.547272510241333e-06,
      "loss": 0.5224,
      "step": 6920
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.4199381705097993,
      "learning_rate": 5.546153242839535e-06,
      "loss": 0.5262,
      "step": 6921
    },
    {
      "epoch": 0.48,
      "grad_norm": 4.0185566157510495,
      "learning_rate": 5.545033947738624e-06,
      "loss": 0.4871,
      "step": 6922
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.414596432346152,
      "learning_rate": 5.543914624995369e-06,
      "loss": 0.5222,
      "step": 6923
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.835190716576795,
      "learning_rate": 5.542795274666537e-06,
      "loss": 0.4926,
      "step": 6924
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.9518118186356517,
      "learning_rate": 5.541675896808899e-06,
      "loss": 0.5206,
      "step": 6925
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.9902324452801654,
      "learning_rate": 5.540556491479224e-06,
      "loss": 0.5253,
      "step": 6926
    },
    {
      "epoch": 0.48,
      "grad_norm": 10.466831163747958,
      "learning_rate": 5.539437058734287e-06,
      "loss": 0.5335,
      "step": 6927
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6265328551627071,
      "learning_rate": 5.5383175986308605e-06,
      "loss": 0.4421,
      "step": 6928
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.2877223095193706,
      "learning_rate": 5.537198111225721e-06,
      "loss": 0.4857,
      "step": 6929
    },
    {
      "epoch": 0.48,
      "grad_norm": 3.2187841802852373,
      "learning_rate": 5.5360785965756445e-06,
      "loss": 0.5289,
      "step": 6930
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.7654977864685064,
      "learning_rate": 5.53495905473741e-06,
      "loss": 0.5038,
      "step": 6931
    },
    {
      "epoch": 0.48,
      "grad_norm": 4.454903021886483,
      "learning_rate": 5.533839485767795e-06,
      "loss": 0.4905,
      "step": 6932
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.0699690520897915,
      "learning_rate": 5.532719889723582e-06,
      "loss": 0.4713,
      "step": 6933
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.395284047592855,
      "learning_rate": 5.531600266661554e-06,
      "loss": 0.5436,
      "step": 6934
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.8489606656104844,
      "learning_rate": 5.530480616638492e-06,
      "loss": 0.5398,
      "step": 6935
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.7910475202345502,
      "learning_rate": 5.529360939711184e-06,
      "loss": 0.5096,
      "step": 6936
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.6663900641157627,
      "learning_rate": 5.528241235936415e-06,
      "loss": 0.5223,
      "step": 6937
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6173386263037591,
      "learning_rate": 5.527121505370971e-06,
      "loss": 0.4424,
      "step": 6938
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.6261843759352799,
      "learning_rate": 5.526001748071645e-06,
      "loss": 0.4724,
      "step": 6939
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.8710872947614234,
      "learning_rate": 5.524881964095222e-06,
      "loss": 0.4811,
      "step": 6940
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.7100398601665774,
      "learning_rate": 5.5237621534985e-06,
      "loss": 0.4598,
      "step": 6941
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.6820687022415017,
      "learning_rate": 5.522642316338268e-06,
      "loss": 0.5034,
      "step": 6942
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.9266777440264842,
      "learning_rate": 5.521522452671322e-06,
      "loss": 0.4604,
      "step": 6943
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.9511999328175074,
      "learning_rate": 5.520402562554456e-06,
      "loss": 0.4781,
      "step": 6944
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.0835789072121487,
      "learning_rate": 5.519282646044471e-06,
      "loss": 0.4736,
      "step": 6945
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.832899783211146,
      "learning_rate": 5.518162703198162e-06,
      "loss": 0.5258,
      "step": 6946
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.5988050683436004,
      "learning_rate": 5.517042734072331e-06,
      "loss": 0.5795,
      "step": 6947
    },
    {
      "epoch": 0.48,
      "grad_norm": 4.8098369612221665,
      "learning_rate": 5.515922738723777e-06,
      "loss": 0.5119,
      "step": 6948
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.5261176575095632,
      "learning_rate": 5.514802717209304e-06,
      "loss": 0.4905,
      "step": 6949
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.8947523384196014,
      "learning_rate": 5.513682669585715e-06,
      "loss": 0.4964,
      "step": 6950
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.09075780335306,
      "learning_rate": 5.512562595909816e-06,
      "loss": 0.5008,
      "step": 6951
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.1020260853400856,
      "learning_rate": 5.511442496238413e-06,
      "loss": 0.4793,
      "step": 6952
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.720393872500033,
      "learning_rate": 5.510322370628315e-06,
      "loss": 0.5296,
      "step": 6953
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.019443982222393,
      "learning_rate": 5.5092022191363285e-06,
      "loss": 0.4955,
      "step": 6954
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.8455948695200577,
      "learning_rate": 5.5080820418192674e-06,
      "loss": 0.5324,
      "step": 6955
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.155164071990522,
      "learning_rate": 5.5069618387339395e-06,
      "loss": 0.5176,
      "step": 6956
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.9160824589872147,
      "learning_rate": 5.505841609937162e-06,
      "loss": 0.4911,
      "step": 6957
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.6421325210603226,
      "learning_rate": 5.504721355485746e-06,
      "loss": 0.5224,
      "step": 6958
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.3443664322766216,
      "learning_rate": 5.503601075436509e-06,
      "loss": 0.493,
      "step": 6959
    },
    {
      "epoch": 0.48,
      "grad_norm": 3.748231049196393,
      "learning_rate": 5.502480769846267e-06,
      "loss": 0.5049,
      "step": 6960
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.3835419955669703,
      "learning_rate": 5.501360438771838e-06,
      "loss": 0.4825,
      "step": 6961
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.2936872519705993,
      "learning_rate": 5.5002400822700415e-06,
      "loss": 0.5136,
      "step": 6962
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.9355800054314454,
      "learning_rate": 5.4991197003977e-06,
      "loss": 0.519,
      "step": 6963
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.7233634961396145,
      "learning_rate": 5.497999293211636e-06,
      "loss": 0.5331,
      "step": 6964
    },
    {
      "epoch": 0.48,
      "grad_norm": 10.133184452354392,
      "learning_rate": 5.496878860768669e-06,
      "loss": 0.5042,
      "step": 6965
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.2183910216991056,
      "learning_rate": 5.495758403125626e-06,
      "loss": 0.484,
      "step": 6966
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.3426240651543973,
      "learning_rate": 5.494637920339335e-06,
      "loss": 0.5357,
      "step": 6967
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.2621725990931654,
      "learning_rate": 5.49351741246662e-06,
      "loss": 0.4677,
      "step": 6968
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.834549684368437,
      "learning_rate": 5.4923968795643115e-06,
      "loss": 0.4676,
      "step": 6969
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.9157311605549143,
      "learning_rate": 5.4912763216892386e-06,
      "loss": 0.4741,
      "step": 6970
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.7895573821149107,
      "learning_rate": 5.490155738898231e-06,
      "loss": 0.5181,
      "step": 6971
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.9113373899011905,
      "learning_rate": 5.489035131248124e-06,
      "loss": 0.5179,
      "step": 6972
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.7891284692542737,
      "learning_rate": 5.487914498795748e-06,
      "loss": 0.5144,
      "step": 6973
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.8311567065136436,
      "learning_rate": 5.486793841597941e-06,
      "loss": 0.5521,
      "step": 6974
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.607369061639887,
      "learning_rate": 5.485673159711535e-06,
      "loss": 0.4882,
      "step": 6975
    },
    {
      "epoch": 0.49,
      "grad_norm": 5.523780415923373,
      "learning_rate": 5.484552453193371e-06,
      "loss": 0.522,
      "step": 6976
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.0202641040025955,
      "learning_rate": 5.4834317221002866e-06,
      "loss": 0.5107,
      "step": 6977
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.1573529081696012,
      "learning_rate": 5.482310966489122e-06,
      "loss": 0.4993,
      "step": 6978
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.9975115715655911,
      "learning_rate": 5.481190186416716e-06,
      "loss": 0.512,
      "step": 6979
    },
    {
      "epoch": 0.49,
      "grad_norm": 11.028429305062385,
      "learning_rate": 5.480069381939914e-06,
      "loss": 0.5084,
      "step": 6980
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.4491818444909454,
      "learning_rate": 5.478948553115557e-06,
      "loss": 0.4593,
      "step": 6981
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.344511353052606,
      "learning_rate": 5.477827700000492e-06,
      "loss": 0.4884,
      "step": 6982
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.7937461013595002,
      "learning_rate": 5.4767068226515614e-06,
      "loss": 0.4399,
      "step": 6983
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.078153214778454,
      "learning_rate": 5.475585921125618e-06,
      "loss": 0.5279,
      "step": 6984
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.1520950913421757,
      "learning_rate": 5.4744649954795045e-06,
      "loss": 0.4669,
      "step": 6985
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.8615505495035596,
      "learning_rate": 5.473344045770075e-06,
      "loss": 0.5422,
      "step": 6986
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.8036411497296003,
      "learning_rate": 5.472223072054178e-06,
      "loss": 0.5003,
      "step": 6987
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.1591967437467683,
      "learning_rate": 5.471102074388667e-06,
      "loss": 0.4588,
      "step": 6988
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.9279960563462986,
      "learning_rate": 5.4699810528303934e-06,
      "loss": 0.532,
      "step": 6989
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.867855260253691,
      "learning_rate": 5.468860007436214e-06,
      "loss": 0.5051,
      "step": 6990
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.937398985692815,
      "learning_rate": 5.467738938262984e-06,
      "loss": 0.5365,
      "step": 6991
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.9516076698041434,
      "learning_rate": 5.46661784536756e-06,
      "loss": 0.5455,
      "step": 6992
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.9223155185283085,
      "learning_rate": 5.4654967288067985e-06,
      "loss": 0.5305,
      "step": 6993
    },
    {
      "epoch": 0.49,
      "grad_norm": 3.015645759886005,
      "learning_rate": 5.464375588637563e-06,
      "loss": 0.5381,
      "step": 6994
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.1839765081763334,
      "learning_rate": 5.463254424916709e-06,
      "loss": 0.4947,
      "step": 6995
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.9138918189969514,
      "learning_rate": 5.462133237701103e-06,
      "loss": 0.5077,
      "step": 6996
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.5606486215123427,
      "learning_rate": 5.461012027047603e-06,
      "loss": 0.4799,
      "step": 6997
    },
    {
      "epoch": 0.49,
      "grad_norm": 4.1461369458669735,
      "learning_rate": 5.459890793013078e-06,
      "loss": 0.5001,
      "step": 6998
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.4110647344526943,
      "learning_rate": 5.458769535654392e-06,
      "loss": 0.5009,
      "step": 6999
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.8729851818424246,
      "learning_rate": 5.457648255028409e-06,
      "loss": 0.4888,
      "step": 7000
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6008685855983056,
      "learning_rate": 5.4565269511920006e-06,
      "loss": 0.4356,
      "step": 7001
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.950232895452359,
      "learning_rate": 5.455405624202032e-06,
      "loss": 0.4747,
      "step": 7002
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.022842324064796,
      "learning_rate": 5.454284274115376e-06,
      "loss": 0.5144,
      "step": 7003
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.6952687039686334,
      "learning_rate": 5.453162900988902e-06,
      "loss": 0.5083,
      "step": 7004
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.371957540807494,
      "learning_rate": 5.452041504879483e-06,
      "loss": 0.4837,
      "step": 7005
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.70833706839961,
      "learning_rate": 5.450920085843993e-06,
      "loss": 0.4997,
      "step": 7006
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.7742980039495355,
      "learning_rate": 5.449798643939305e-06,
      "loss": 0.5051,
      "step": 7007
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.8809994983542457,
      "learning_rate": 5.448677179222298e-06,
      "loss": 0.5237,
      "step": 7008
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.0743209801090794,
      "learning_rate": 5.447555691749845e-06,
      "loss": 0.524,
      "step": 7009
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.7913770542136787,
      "learning_rate": 5.446434181578829e-06,
      "loss": 0.4973,
      "step": 7010
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.8903323065026136,
      "learning_rate": 5.445312648766125e-06,
      "loss": 0.5153,
      "step": 7011
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.0087753560690618,
      "learning_rate": 5.444191093368616e-06,
      "loss": 0.5291,
      "step": 7012
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.6872716634243545,
      "learning_rate": 5.443069515443184e-06,
      "loss": 0.519,
      "step": 7013
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.910775419826911,
      "learning_rate": 5.441947915046709e-06,
      "loss": 0.5042,
      "step": 7014
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.0543692827885227,
      "learning_rate": 5.440826292236076e-06,
      "loss": 0.5177,
      "step": 7015
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6323371434309701,
      "learning_rate": 5.439704647068173e-06,
      "loss": 0.4503,
      "step": 7016
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.0747534583421747,
      "learning_rate": 5.4385829795998815e-06,
      "loss": 0.5134,
      "step": 7017
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.013363839738171,
      "learning_rate": 5.4374612898880926e-06,
      "loss": 0.4805,
      "step": 7018
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.8020550115746683,
      "learning_rate": 5.436339577989692e-06,
      "loss": 0.5011,
      "step": 7019
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.0984206927775135,
      "learning_rate": 5.435217843961572e-06,
      "loss": 0.4956,
      "step": 7020
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.0171271509418243,
      "learning_rate": 5.434096087860621e-06,
      "loss": 0.4878,
      "step": 7021
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.2255216989473956,
      "learning_rate": 5.4329743097437316e-06,
      "loss": 0.5292,
      "step": 7022
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.7890069126171675,
      "learning_rate": 5.4318525096677966e-06,
      "loss": 0.5188,
      "step": 7023
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.977195187387465,
      "learning_rate": 5.430730687689711e-06,
      "loss": 0.5155,
      "step": 7024
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.9121876384707035,
      "learning_rate": 5.4296088438663695e-06,
      "loss": 0.525,
      "step": 7025
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.7983117826621087,
      "learning_rate": 5.428486978254667e-06,
      "loss": 0.551,
      "step": 7026
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.4131492853765075,
      "learning_rate": 5.4273650909115024e-06,
      "loss": 0.4957,
      "step": 7027
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.443991882749352,
      "learning_rate": 5.4262431818937736e-06,
      "loss": 0.5158,
      "step": 7028
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.5636379993755884,
      "learning_rate": 5.425121251258381e-06,
      "loss": 0.4647,
      "step": 7029
    },
    {
      "epoch": 0.49,
      "grad_norm": 6.216349383345411,
      "learning_rate": 5.423999299062222e-06,
      "loss": 0.5186,
      "step": 7030
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.1279060395907257,
      "learning_rate": 5.422877325362203e-06,
      "loss": 0.4776,
      "step": 7031
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.9436683592351351,
      "learning_rate": 5.421755330215223e-06,
      "loss": 0.5289,
      "step": 7032
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.1691260285794574,
      "learning_rate": 5.420633313678191e-06,
      "loss": 0.5183,
      "step": 7033
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.2146090061210186,
      "learning_rate": 5.4195112758080075e-06,
      "loss": 0.5304,
      "step": 7034
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.893498418260393,
      "learning_rate": 5.41838921666158e-06,
      "loss": 0.5027,
      "step": 7035
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.0848545008128747,
      "learning_rate": 5.417267136295813e-06,
      "loss": 0.5387,
      "step": 7036
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.9102974308989238,
      "learning_rate": 5.416145034767618e-06,
      "loss": 0.5144,
      "step": 7037
    },
    {
      "epoch": 0.49,
      "grad_norm": 4.074963806960698,
      "learning_rate": 5.415022912133904e-06,
      "loss": 0.5226,
      "step": 7038
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.9435576126332679,
      "learning_rate": 5.413900768451582e-06,
      "loss": 0.5031,
      "step": 7039
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.7190566303657027,
      "learning_rate": 5.412778603777561e-06,
      "loss": 0.473,
      "step": 7040
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.7265059897165773,
      "learning_rate": 5.4116564181687555e-06,
      "loss": 0.4572,
      "step": 7041
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.9134151827821133,
      "learning_rate": 5.410534211682078e-06,
      "loss": 0.5147,
      "step": 7042
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.4566362277484717,
      "learning_rate": 5.409411984374444e-06,
      "loss": 0.4466,
      "step": 7043
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.142442936370118,
      "learning_rate": 5.408289736302769e-06,
      "loss": 0.4974,
      "step": 7044
    },
    {
      "epoch": 0.49,
      "grad_norm": 4.370037160309874,
      "learning_rate": 5.407167467523971e-06,
      "loss": 0.5204,
      "step": 7045
    },
    {
      "epoch": 0.49,
      "grad_norm": 3.868777248035845,
      "learning_rate": 5.406045178094965e-06,
      "loss": 0.5046,
      "step": 7046
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.1509109311166466,
      "learning_rate": 5.404922868072673e-06,
      "loss": 0.5199,
      "step": 7047
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.6377208360314945,
      "learning_rate": 5.4038005375140105e-06,
      "loss": 0.4944,
      "step": 7048
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.261455566595081,
      "learning_rate": 5.402678186475904e-06,
      "loss": 0.4734,
      "step": 7049
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.033343510896092,
      "learning_rate": 5.40155581501527e-06,
      "loss": 0.5087,
      "step": 7050
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.4934945491500993,
      "learning_rate": 5.4004334231890355e-06,
      "loss": 0.5268,
      "step": 7051
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.0330715488687185,
      "learning_rate": 5.399311011054122e-06,
      "loss": 0.5234,
      "step": 7052
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.8661464888665658,
      "learning_rate": 5.398188578667458e-06,
      "loss": 0.5117,
      "step": 7053
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.7455208066179413,
      "learning_rate": 5.397066126085967e-06,
      "loss": 0.5505,
      "step": 7054
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.03232459908695,
      "learning_rate": 5.3959436533665765e-06,
      "loss": 0.4854,
      "step": 7055
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.0272924051005687,
      "learning_rate": 5.394821160566214e-06,
      "loss": 0.4836,
      "step": 7056
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.2564257674843486,
      "learning_rate": 5.39369864774181e-06,
      "loss": 0.5689,
      "step": 7057
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.739576052223066,
      "learning_rate": 5.392576114950294e-06,
      "loss": 0.4996,
      "step": 7058
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.7079974010670713,
      "learning_rate": 5.391453562248597e-06,
      "loss": 0.5335,
      "step": 7059
    },
    {
      "epoch": 0.49,
      "grad_norm": 4.975282603679347,
      "learning_rate": 5.390330989693652e-06,
      "loss": 0.5417,
      "step": 7060
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.9925178936471986,
      "learning_rate": 5.389208397342393e-06,
      "loss": 0.5135,
      "step": 7061
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.1576832100248002,
      "learning_rate": 5.38808578525175e-06,
      "loss": 0.5645,
      "step": 7062
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.7934742768626073,
      "learning_rate": 5.386963153478663e-06,
      "loss": 0.4978,
      "step": 7063
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.6003441702916366,
      "learning_rate": 5.3858405020800666e-06,
      "loss": 0.5105,
      "step": 7064
    },
    {
      "epoch": 0.49,
      "grad_norm": 3.060298619256058,
      "learning_rate": 5.384717831112898e-06,
      "loss": 0.4525,
      "step": 7065
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.729246829069994,
      "learning_rate": 5.383595140634093e-06,
      "loss": 0.5034,
      "step": 7066
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.736751946310659,
      "learning_rate": 5.382472430700596e-06,
      "loss": 0.4666,
      "step": 7067
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6556726476507215,
      "learning_rate": 5.381349701369343e-06,
      "loss": 0.4149,
      "step": 7068
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.7471528660968856,
      "learning_rate": 5.380226952697278e-06,
      "loss": 0.5154,
      "step": 7069
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.7009642058008858,
      "learning_rate": 5.379104184741338e-06,
      "loss": 0.4775,
      "step": 7070
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.044454165530509,
      "learning_rate": 5.377981397558473e-06,
      "loss": 0.5512,
      "step": 7071
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6029449738844749,
      "learning_rate": 5.376858591205622e-06,
      "loss": 0.4502,
      "step": 7072
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.6481488031634357,
      "learning_rate": 5.375735765739733e-06,
      "loss": 0.5252,
      "step": 7073
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.6950538996099966,
      "learning_rate": 5.374612921217749e-06,
      "loss": 0.51,
      "step": 7074
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.7591584221006256,
      "learning_rate": 5.373490057696621e-06,
      "loss": 0.4917,
      "step": 7075
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.780675207917985,
      "learning_rate": 5.372367175233293e-06,
      "loss": 0.4746,
      "step": 7076
    },
    {
      "epoch": 0.49,
      "grad_norm": 6.252755420361032,
      "learning_rate": 5.371244273884718e-06,
      "loss": 0.4928,
      "step": 7077
    },
    {
      "epoch": 0.49,
      "grad_norm": 4.2793270530726835,
      "learning_rate": 5.370121353707842e-06,
      "loss": 0.452,
      "step": 7078
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.8510237515962333,
      "learning_rate": 5.3689984147596184e-06,
      "loss": 0.4945,
      "step": 7079
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.886066643069767,
      "learning_rate": 5.367875457096999e-06,
      "loss": 0.5176,
      "step": 7080
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.6568831943787008,
      "learning_rate": 5.3667524807769355e-06,
      "loss": 0.4694,
      "step": 7081
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.8678491054955424,
      "learning_rate": 5.365629485856381e-06,
      "loss": 0.5184,
      "step": 7082
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.6179060858216334,
      "learning_rate": 5.364506472392291e-06,
      "loss": 0.4842,
      "step": 7083
    },
    {
      "epoch": 0.49,
      "grad_norm": 4.815435795076831,
      "learning_rate": 5.36338344044162e-06,
      "loss": 0.4797,
      "step": 7084
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.8673243988540893,
      "learning_rate": 5.362260390061329e-06,
      "loss": 0.4496,
      "step": 7085
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.9700146777230443,
      "learning_rate": 5.3611373213083695e-06,
      "loss": 0.4984,
      "step": 7086
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.013155859323619,
      "learning_rate": 5.360014234239704e-06,
      "loss": 0.5046,
      "step": 7087
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.1106750789816293,
      "learning_rate": 5.358891128912288e-06,
      "loss": 0.5513,
      "step": 7088
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.1877450236538647,
      "learning_rate": 5.357768005383085e-06,
      "loss": 0.4984,
      "step": 7089
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.1710961989093245,
      "learning_rate": 5.356644863709055e-06,
      "loss": 0.4987,
      "step": 7090
    },
    {
      "epoch": 0.49,
      "grad_norm": 3.709168997752031,
      "learning_rate": 5.355521703947161e-06,
      "loss": 0.5427,
      "step": 7091
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.9727746844763936,
      "learning_rate": 5.354398526154365e-06,
      "loss": 0.4577,
      "step": 7092
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.6916354290047526,
      "learning_rate": 5.35327533038763e-06,
      "loss": 0.4794,
      "step": 7093
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.132234840416399,
      "learning_rate": 5.352152116703925e-06,
      "loss": 0.5087,
      "step": 7094
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.1684125524992615,
      "learning_rate": 5.35102888516021e-06,
      "loss": 0.5335,
      "step": 7095
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.67808554923588,
      "learning_rate": 5.349905635813455e-06,
      "loss": 0.5433,
      "step": 7096
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.2761025521426776,
      "learning_rate": 5.348782368720627e-06,
      "loss": 0.5612,
      "step": 7097
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.038023598776012,
      "learning_rate": 5.347659083938694e-06,
      "loss": 0.4648,
      "step": 7098
    },
    {
      "epoch": 0.49,
      "grad_norm": 3.1729612043844058,
      "learning_rate": 5.346535781524626e-06,
      "loss": 0.5044,
      "step": 7099
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.426364493937028,
      "learning_rate": 5.345412461535393e-06,
      "loss": 0.5227,
      "step": 7100
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.7553533960574148,
      "learning_rate": 5.344289124027967e-06,
      "loss": 0.489,
      "step": 7101
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.640831536855093,
      "learning_rate": 5.343165769059318e-06,
      "loss": 0.4425,
      "step": 7102
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.7477790489364529,
      "learning_rate": 5.34204239668642e-06,
      "loss": 0.4793,
      "step": 7103
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.506662265209529,
      "learning_rate": 5.3409190069662474e-06,
      "loss": 0.5348,
      "step": 7104
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.9116556990883213,
      "learning_rate": 5.339795599955772e-06,
      "loss": 0.4985,
      "step": 7105
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.742664837940034,
      "learning_rate": 5.338672175711975e-06,
      "loss": 0.4856,
      "step": 7106
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.7363684045792012,
      "learning_rate": 5.337548734291827e-06,
      "loss": 0.5194,
      "step": 7107
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.0372384921090623,
      "learning_rate": 5.336425275752308e-06,
      "loss": 0.484,
      "step": 7108
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.6034525271203157,
      "learning_rate": 5.335301800150397e-06,
      "loss": 0.5315,
      "step": 7109
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.461551041625295,
      "learning_rate": 5.334178307543071e-06,
      "loss": 0.504,
      "step": 7110
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.6581940704942644,
      "learning_rate": 5.333054797987309e-06,
      "loss": 0.5081,
      "step": 7111
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.2201268500443683,
      "learning_rate": 5.331931271540096e-06,
      "loss": 0.5446,
      "step": 7112
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.5497542112226401,
      "learning_rate": 5.330807728258411e-06,
      "loss": 0.4981,
      "step": 7113
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.0498375969537546,
      "learning_rate": 5.329684168199236e-06,
      "loss": 0.4884,
      "step": 7114
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.3389566191995494,
      "learning_rate": 5.328560591419554e-06,
      "loss": 0.5388,
      "step": 7115
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.05841692825947,
      "learning_rate": 5.3274369979763514e-06,
      "loss": 0.529,
      "step": 7116
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.2159223894272793,
      "learning_rate": 5.3263133879266105e-06,
      "loss": 0.519,
      "step": 7117
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6667074260046938,
      "learning_rate": 5.32518976132732e-06,
      "loss": 0.4387,
      "step": 7118
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.298364472005364,
      "learning_rate": 5.324066118235462e-06,
      "loss": 0.4945,
      "step": 7119
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.7366355869865224,
      "learning_rate": 5.322942458708029e-06,
      "loss": 0.4825,
      "step": 7120
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.4685688620387016,
      "learning_rate": 5.321818782802007e-06,
      "loss": 0.4874,
      "step": 7121
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.784671030754447,
      "learning_rate": 5.320695090574386e-06,
      "loss": 0.5136,
      "step": 7122
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.076313801961266,
      "learning_rate": 5.319571382082156e-06,
      "loss": 0.5544,
      "step": 7123
    },
    {
      "epoch": 0.5,
      "grad_norm": 3.791485801534696,
      "learning_rate": 5.318447657382306e-06,
      "loss": 0.5072,
      "step": 7124
    },
    {
      "epoch": 0.5,
      "grad_norm": 7.514686699871594,
      "learning_rate": 5.317323916531831e-06,
      "loss": 0.5074,
      "step": 7125
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.827830439902187,
      "learning_rate": 5.31620015958772e-06,
      "loss": 0.4937,
      "step": 7126
    },
    {
      "epoch": 0.5,
      "grad_norm": 5.958741463303701,
      "learning_rate": 5.315076386606967e-06,
      "loss": 0.4627,
      "step": 7127
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.7845950500749828,
      "learning_rate": 5.3139525976465675e-06,
      "loss": 0.4525,
      "step": 7128
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.1053808767730984,
      "learning_rate": 5.312828792763516e-06,
      "loss": 0.5046,
      "step": 7129
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.8650332287084719,
      "learning_rate": 5.311704972014808e-06,
      "loss": 0.5538,
      "step": 7130
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.4864303735223063,
      "learning_rate": 5.31058113545744e-06,
      "loss": 0.5133,
      "step": 7131
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.4409127213379005,
      "learning_rate": 5.30945728314841e-06,
      "loss": 0.5115,
      "step": 7132
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.6380720327848226,
      "learning_rate": 5.308333415144714e-06,
      "loss": 0.5071,
      "step": 7133
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.0233414983117957,
      "learning_rate": 5.307209531503354e-06,
      "loss": 0.4688,
      "step": 7134
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.9746850900298991,
      "learning_rate": 5.306085632281328e-06,
      "loss": 0.563,
      "step": 7135
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.9353081522703994,
      "learning_rate": 5.304961717535636e-06,
      "loss": 0.482,
      "step": 7136
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.8002618898072467,
      "learning_rate": 5.30383778732328e-06,
      "loss": 0.5053,
      "step": 7137
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.0226998141326997,
      "learning_rate": 5.302713841701263e-06,
      "loss": 0.5118,
      "step": 7138
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.7682738345418296,
      "learning_rate": 5.301589880726584e-06,
      "loss": 0.538,
      "step": 7139
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.3086492532461436,
      "learning_rate": 5.300465904456252e-06,
      "loss": 0.5208,
      "step": 7140
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.0708571417433035,
      "learning_rate": 5.299341912947268e-06,
      "loss": 0.528,
      "step": 7141
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.9717723028399183,
      "learning_rate": 5.298217906256638e-06,
      "loss": 0.4928,
      "step": 7142
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.7886454108744883,
      "learning_rate": 5.2970938844413684e-06,
      "loss": 0.4753,
      "step": 7143
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.7144254597805393,
      "learning_rate": 5.295969847558467e-06,
      "loss": 0.5155,
      "step": 7144
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.9329259554267517,
      "learning_rate": 5.294845795664937e-06,
      "loss": 0.4713,
      "step": 7145
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.178284584692796,
      "learning_rate": 5.2937217288177915e-06,
      "loss": 0.5661,
      "step": 7146
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.8733051069911029,
      "learning_rate": 5.292597647074037e-06,
      "loss": 0.4941,
      "step": 7147
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.851764824243122,
      "learning_rate": 5.2914735504906845e-06,
      "loss": 0.5406,
      "step": 7148
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.1566403216302126,
      "learning_rate": 5.290349439124742e-06,
      "loss": 0.4624,
      "step": 7149
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.8251301319203672,
      "learning_rate": 5.289225313033224e-06,
      "loss": 0.502,
      "step": 7150
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.5761315199932742,
      "learning_rate": 5.28810117227314e-06,
      "loss": 0.5253,
      "step": 7151
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.903606314134231,
      "learning_rate": 5.286977016901503e-06,
      "loss": 0.57,
      "step": 7152
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.211215642999083,
      "learning_rate": 5.28585284697533e-06,
      "loss": 0.5265,
      "step": 7153
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.7182010335969622,
      "learning_rate": 5.284728662551631e-06,
      "loss": 0.5584,
      "step": 7154
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.850703568930366,
      "learning_rate": 5.283604463687423e-06,
      "loss": 0.5033,
      "step": 7155
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.642841165511065,
      "learning_rate": 5.282480250439721e-06,
      "loss": 0.5602,
      "step": 7156
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.9557568532947902,
      "learning_rate": 5.281356022865542e-06,
      "loss": 0.5499,
      "step": 7157
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.466376768927526,
      "learning_rate": 5.2802317810219016e-06,
      "loss": 0.5199,
      "step": 7158
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.2196536357768775,
      "learning_rate": 5.27910752496582e-06,
      "loss": 0.496,
      "step": 7159
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.706742996009473,
      "learning_rate": 5.277983254754314e-06,
      "loss": 0.5187,
      "step": 7160
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.9138204126906397,
      "learning_rate": 5.276858970444404e-06,
      "loss": 0.5174,
      "step": 7161
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.1241424208350876,
      "learning_rate": 5.275734672093109e-06,
      "loss": 0.4737,
      "step": 7162
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.0179708469225397,
      "learning_rate": 5.274610359757452e-06,
      "loss": 0.4884,
      "step": 7163
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.0710387043072416,
      "learning_rate": 5.2734860334944504e-06,
      "loss": 0.536,
      "step": 7164
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.0638203387762015,
      "learning_rate": 5.272361693361131e-06,
      "loss": 0.5069,
      "step": 7165
    },
    {
      "epoch": 0.5,
      "grad_norm": 6.217830612513898,
      "learning_rate": 5.271237339414512e-06,
      "loss": 0.4631,
      "step": 7166
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6045319858009384,
      "learning_rate": 5.2701129717116215e-06,
      "loss": 0.4341,
      "step": 7167
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.7091560393525953,
      "learning_rate": 5.2689885903094815e-06,
      "loss": 0.5076,
      "step": 7168
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.732332845579528,
      "learning_rate": 5.267864195265118e-06,
      "loss": 0.478,
      "step": 7169
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.195372525824193,
      "learning_rate": 5.266739786635554e-06,
      "loss": 0.5727,
      "step": 7170
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.9341833760145246,
      "learning_rate": 5.265615364477818e-06,
      "loss": 0.5311,
      "step": 7171
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.5639482172707195,
      "learning_rate": 5.2644909288489365e-06,
      "loss": 0.4327,
      "step": 7172
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.7818999125670252,
      "learning_rate": 5.2633664798059395e-06,
      "loss": 0.5137,
      "step": 7173
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.8017363816302898,
      "learning_rate": 5.262242017405851e-06,
      "loss": 0.5438,
      "step": 7174
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.8079921910110714,
      "learning_rate": 5.2611175417057024e-06,
      "loss": 0.4779,
      "step": 7175
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.7946717454723478,
      "learning_rate": 5.259993052762523e-06,
      "loss": 0.4945,
      "step": 7176
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.603431493972657,
      "learning_rate": 5.258868550633346e-06,
      "loss": 0.4648,
      "step": 7177
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.3593714703901907,
      "learning_rate": 5.257744035375198e-06,
      "loss": 0.5002,
      "step": 7178
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.965132198505615,
      "learning_rate": 5.256619507045113e-06,
      "loss": 0.4917,
      "step": 7179
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.7512202463211588,
      "learning_rate": 5.2554949657001246e-06,
      "loss": 0.5191,
      "step": 7180
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.18464833262244,
      "learning_rate": 5.254370411397264e-06,
      "loss": 0.4612,
      "step": 7181
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.813933135567678,
      "learning_rate": 5.253245844193564e-06,
      "loss": 0.4863,
      "step": 7182
    },
    {
      "epoch": 0.5,
      "grad_norm": 3.2137055862931856,
      "learning_rate": 5.252121264146062e-06,
      "loss": 0.4705,
      "step": 7183
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.0517796436101747,
      "learning_rate": 5.25099667131179e-06,
      "loss": 0.4879,
      "step": 7184
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.8750481439576139,
      "learning_rate": 5.249872065747786e-06,
      "loss": 0.4932,
      "step": 7185
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.6668670017593774,
      "learning_rate": 5.248747447511085e-06,
      "loss": 0.4934,
      "step": 7186
    },
    {
      "epoch": 0.5,
      "grad_norm": 13.08196003734438,
      "learning_rate": 5.247622816658726e-06,
      "loss": 0.5086,
      "step": 7187
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.5777451601014587,
      "learning_rate": 5.2464981732477424e-06,
      "loss": 0.5425,
      "step": 7188
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.6536557453486185,
      "learning_rate": 5.245373517335177e-06,
      "loss": 0.495,
      "step": 7189
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.5517975402389041,
      "learning_rate": 5.244248848978067e-06,
      "loss": 0.4656,
      "step": 7190
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.1255522730485,
      "learning_rate": 5.243124168233452e-06,
      "loss": 0.5212,
      "step": 7191
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.87749479629844,
      "learning_rate": 5.2419994751583704e-06,
      "loss": 0.4963,
      "step": 7192
    },
    {
      "epoch": 0.5,
      "grad_norm": 4.16323746558794,
      "learning_rate": 5.240874769809865e-06,
      "loss": 0.4937,
      "step": 7193
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.034711445388358,
      "learning_rate": 5.239750052244975e-06,
      "loss": 0.4848,
      "step": 7194
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.744963976472698,
      "learning_rate": 5.238625322520746e-06,
      "loss": 0.4951,
      "step": 7195
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.2355705683292255,
      "learning_rate": 5.237500580694218e-06,
      "loss": 0.514,
      "step": 7196
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6292741819942606,
      "learning_rate": 5.236375826822435e-06,
      "loss": 0.4407,
      "step": 7197
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.0092815298915876,
      "learning_rate": 5.23525106096244e-06,
      "loss": 0.5676,
      "step": 7198
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.5820837695959672,
      "learning_rate": 5.2341262831712795e-06,
      "loss": 0.4372,
      "step": 7199
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.604364287983457,
      "learning_rate": 5.2330014935059945e-06,
      "loss": 0.4926,
      "step": 7200
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.0965657486043905,
      "learning_rate": 5.231876692023636e-06,
      "loss": 0.5241,
      "step": 7201
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.017567967844421,
      "learning_rate": 5.230751878781247e-06,
      "loss": 0.5009,
      "step": 7202
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.835209900666137,
      "learning_rate": 5.229627053835876e-06,
      "loss": 0.4715,
      "step": 7203
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.6850515203791847,
      "learning_rate": 5.228502217244568e-06,
      "loss": 0.5274,
      "step": 7204
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.655603858605091,
      "learning_rate": 5.2273773690643725e-06,
      "loss": 0.5258,
      "step": 7205
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.7620973625675247,
      "learning_rate": 5.2262525093523384e-06,
      "loss": 0.5008,
      "step": 7206
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.8709170853577626,
      "learning_rate": 5.225127638165514e-06,
      "loss": 0.5166,
      "step": 7207
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.2983038105487212,
      "learning_rate": 5.22400275556095e-06,
      "loss": 0.4898,
      "step": 7208
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.8134952943361333,
      "learning_rate": 5.222877861595698e-06,
      "loss": 0.5016,
      "step": 7209
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.848939758637447,
      "learning_rate": 5.221752956326806e-06,
      "loss": 0.5018,
      "step": 7210
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.3329086292262953,
      "learning_rate": 5.220628039811328e-06,
      "loss": 0.487,
      "step": 7211
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.389617692845825,
      "learning_rate": 5.2195031121063145e-06,
      "loss": 0.5376,
      "step": 7212
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.7264441551361638,
      "learning_rate": 5.218378173268819e-06,
      "loss": 0.5608,
      "step": 7213
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.6659388859088256,
      "learning_rate": 5.217253223355895e-06,
      "loss": 0.5018,
      "step": 7214
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.9130460098164463,
      "learning_rate": 5.216128262424596e-06,
      "loss": 0.5098,
      "step": 7215
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.4938241026165953,
      "learning_rate": 5.215003290531974e-06,
      "loss": 0.5182,
      "step": 7216
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.8876562038969285,
      "learning_rate": 5.213878307735088e-06,
      "loss": 0.5339,
      "step": 7217
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6119269377469118,
      "learning_rate": 5.21275331409099e-06,
      "loss": 0.4501,
      "step": 7218
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.0524628756872443,
      "learning_rate": 5.211628309656738e-06,
      "loss": 0.5255,
      "step": 7219
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.9245719793676141,
      "learning_rate": 5.210503294489388e-06,
      "loss": 0.4966,
      "step": 7220
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.416645254740193,
      "learning_rate": 5.209378268645998e-06,
      "loss": 0.4927,
      "step": 7221
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.022489967449185,
      "learning_rate": 5.208253232183625e-06,
      "loss": 0.5115,
      "step": 7222
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.906935323260105,
      "learning_rate": 5.207128185159327e-06,
      "loss": 0.5271,
      "step": 7223
    },
    {
      "epoch": 0.5,
      "grad_norm": 6.856782486443917,
      "learning_rate": 5.206003127630163e-06,
      "loss": 0.4851,
      "step": 7224
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.9788486160848522,
      "learning_rate": 5.20487805965319e-06,
      "loss": 0.5631,
      "step": 7225
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.53641821268403,
      "learning_rate": 5.203752981285472e-06,
      "loss": 0.4662,
      "step": 7226
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.8716277899615206,
      "learning_rate": 5.2026278925840656e-06,
      "loss": 0.4865,
      "step": 7227
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.9876295799825232,
      "learning_rate": 5.201502793606034e-06,
      "loss": 0.4886,
      "step": 7228
    },
    {
      "epoch": 0.5,
      "grad_norm": 3.3848992062777854,
      "learning_rate": 5.200377684408436e-06,
      "loss": 0.5114,
      "step": 7229
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.4672293213714522,
      "learning_rate": 5.199252565048337e-06,
      "loss": 0.4701,
      "step": 7230
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.971814451486946,
      "learning_rate": 5.198127435582796e-06,
      "loss": 0.5101,
      "step": 7231
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.5460716855765155,
      "learning_rate": 5.197002296068878e-06,
      "loss": 0.4914,
      "step": 7232
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.9467075740441695,
      "learning_rate": 5.195877146563646e-06,
      "loss": 0.5406,
      "step": 7233
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.7677532105860987,
      "learning_rate": 5.194751987124165e-06,
      "loss": 0.4889,
      "step": 7234
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.3098808397852992,
      "learning_rate": 5.193626817807497e-06,
      "loss": 0.4711,
      "step": 7235
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.179673692761168,
      "learning_rate": 5.192501638670709e-06,
      "loss": 0.4857,
      "step": 7236
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.7240106565492728,
      "learning_rate": 5.191376449770863e-06,
      "loss": 0.5235,
      "step": 7237
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.5342703611394746,
      "learning_rate": 5.1902512511650295e-06,
      "loss": 0.5516,
      "step": 7238
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.5665656066507463,
      "learning_rate": 5.189126042910271e-06,
      "loss": 0.497,
      "step": 7239
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.5595182050486691,
      "learning_rate": 5.188000825063658e-06,
      "loss": 0.4609,
      "step": 7240
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.064994638882183,
      "learning_rate": 5.186875597682255e-06,
      "loss": 0.4888,
      "step": 7241
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.6396128905216213,
      "learning_rate": 5.18575036082313e-06,
      "loss": 0.4269,
      "step": 7242
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.648394439861631,
      "learning_rate": 5.184625114543354e-06,
      "loss": 0.4428,
      "step": 7243
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.645844289796284,
      "learning_rate": 5.183499858899994e-06,
      "loss": 0.5178,
      "step": 7244
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.1304198394217506,
      "learning_rate": 5.182374593950119e-06,
      "loss": 0.5419,
      "step": 7245
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.6307362229708997,
      "learning_rate": 5.181249319750799e-06,
      "loss": 0.5013,
      "step": 7246
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.5664368500138335,
      "learning_rate": 5.180124036359106e-06,
      "loss": 0.4877,
      "step": 7247
    },
    {
      "epoch": 0.5,
      "grad_norm": 3.0244296192041125,
      "learning_rate": 5.1789987438321075e-06,
      "loss": 0.5153,
      "step": 7248
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.1966843827048907,
      "learning_rate": 5.177873442226876e-06,
      "loss": 0.521,
      "step": 7249
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.8054994101130193,
      "learning_rate": 5.176748131600484e-06,
      "loss": 0.5073,
      "step": 7250
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.4423738516697853,
      "learning_rate": 5.175622812010003e-06,
      "loss": 0.4986,
      "step": 7251
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.5223767168266626,
      "learning_rate": 5.174497483512506e-06,
      "loss": 0.4977,
      "step": 7252
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.8187033851368768,
      "learning_rate": 5.1733721461650646e-06,
      "loss": 0.4839,
      "step": 7253
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.9594784567943648,
      "learning_rate": 5.172246800024754e-06,
      "loss": 0.5045,
      "step": 7254
    },
    {
      "epoch": 0.5,
      "grad_norm": 3.4872419082802137,
      "learning_rate": 5.171121445148646e-06,
      "loss": 0.5005,
      "step": 7255
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.0407361839979434,
      "learning_rate": 5.169996081593818e-06,
      "loss": 0.5308,
      "step": 7256
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.9120712424571402,
      "learning_rate": 5.168870709417342e-06,
      "loss": 0.4624,
      "step": 7257
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.2658755568621105,
      "learning_rate": 5.167745328676295e-06,
      "loss": 0.5062,
      "step": 7258
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.7905763546751774,
      "learning_rate": 5.166619939427749e-06,
      "loss": 0.471,
      "step": 7259
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.8062203228936997,
      "learning_rate": 5.165494541728786e-06,
      "loss": 0.4403,
      "step": 7260
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.8370212895772506,
      "learning_rate": 5.164369135636478e-06,
      "loss": 0.4643,
      "step": 7261
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.8640103725444066,
      "learning_rate": 5.163243721207903e-06,
      "loss": 0.4961,
      "step": 7262
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.456913794521458,
      "learning_rate": 5.162118298500139e-06,
      "loss": 0.5134,
      "step": 7263
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.6688883731890085,
      "learning_rate": 5.160992867570265e-06,
      "loss": 0.4672,
      "step": 7264
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.0090626876515985,
      "learning_rate": 5.159867428475354e-06,
      "loss": 0.4845,
      "step": 7265
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.0683986214770975,
      "learning_rate": 5.158741981272493e-06,
      "loss": 0.5357,
      "step": 7266
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.3497079232211244,
      "learning_rate": 5.157616526018753e-06,
      "loss": 0.5073,
      "step": 7267
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.8941186929850091,
      "learning_rate": 5.156491062771217e-06,
      "loss": 0.509,
      "step": 7268
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.5853488606661688,
      "learning_rate": 5.155365591586966e-06,
      "loss": 0.5079,
      "step": 7269
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.7901631183437388,
      "learning_rate": 5.154240112523078e-06,
      "loss": 0.4966,
      "step": 7270
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.05045012030669,
      "learning_rate": 5.153114625636632e-06,
      "loss": 0.5061,
      "step": 7271
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.088669171236612,
      "learning_rate": 5.151989130984715e-06,
      "loss": 0.4738,
      "step": 7272
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.1004501538068305,
      "learning_rate": 5.150863628624402e-06,
      "loss": 0.4423,
      "step": 7273
    },
    {
      "epoch": 0.51,
      "grad_norm": 4.301257343578629,
      "learning_rate": 5.14973811861278e-06,
      "loss": 0.5291,
      "step": 7274
    },
    {
      "epoch": 0.51,
      "grad_norm": 5.464830243615508,
      "learning_rate": 5.148612601006926e-06,
      "loss": 0.5295,
      "step": 7275
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.1281958562232504,
      "learning_rate": 5.147487075863927e-06,
      "loss": 0.5664,
      "step": 7276
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.6767338454718594,
      "learning_rate": 5.146361543240864e-06,
      "loss": 0.5229,
      "step": 7277
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.439299410540586,
      "learning_rate": 5.145236003194822e-06,
      "loss": 0.511,
      "step": 7278
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.8307766016714457,
      "learning_rate": 5.144110455782881e-06,
      "loss": 0.4982,
      "step": 7279
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.5940333384413332,
      "learning_rate": 5.142984901062131e-06,
      "loss": 0.4819,
      "step": 7280
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.3346571596926604,
      "learning_rate": 5.14185933908965e-06,
      "loss": 0.5079,
      "step": 7281
    },
    {
      "epoch": 0.51,
      "grad_norm": 8.814573141249348,
      "learning_rate": 5.140733769922525e-06,
      "loss": 0.5213,
      "step": 7282
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.8024498541917375,
      "learning_rate": 5.139608193617846e-06,
      "loss": 0.5442,
      "step": 7283
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.904839520703676,
      "learning_rate": 5.138482610232691e-06,
      "loss": 0.4512,
      "step": 7284
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.1783867014211284,
      "learning_rate": 5.1373570198241505e-06,
      "loss": 0.4868,
      "step": 7285
    },
    {
      "epoch": 0.51,
      "grad_norm": 4.697984328661791,
      "learning_rate": 5.13623142244931e-06,
      "loss": 0.5258,
      "step": 7286
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.862628461677743,
      "learning_rate": 5.135105818165256e-06,
      "loss": 0.4985,
      "step": 7287
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.3220888108284226,
      "learning_rate": 5.133980207029075e-06,
      "loss": 0.5147,
      "step": 7288
    },
    {
      "epoch": 0.51,
      "grad_norm": 3.8489899675036674,
      "learning_rate": 5.132854589097855e-06,
      "loss": 0.484,
      "step": 7289
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.8545456047551558,
      "learning_rate": 5.131728964428684e-06,
      "loss": 0.4564,
      "step": 7290
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.9054953639946723,
      "learning_rate": 5.13060333307865e-06,
      "loss": 0.4899,
      "step": 7291
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.1175274702332483,
      "learning_rate": 5.129477695104839e-06,
      "loss": 0.5274,
      "step": 7292
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.6603209918112793,
      "learning_rate": 5.128352050564341e-06,
      "loss": 0.5105,
      "step": 7293
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.2408201539415864,
      "learning_rate": 5.127226399514246e-06,
      "loss": 0.4803,
      "step": 7294
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.7716119170157643,
      "learning_rate": 5.126100742011644e-06,
      "loss": 0.5131,
      "step": 7295
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6630700913696319,
      "learning_rate": 5.124975078113622e-06,
      "loss": 0.4477,
      "step": 7296
    },
    {
      "epoch": 0.51,
      "grad_norm": 3.01851724996318,
      "learning_rate": 5.123849407877273e-06,
      "loss": 0.5126,
      "step": 7297
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.134537066977342,
      "learning_rate": 5.122723731359683e-06,
      "loss": 0.5174,
      "step": 7298
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.785139807110379,
      "learning_rate": 5.1215980486179486e-06,
      "loss": 0.5017,
      "step": 7299
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.8620782416677302,
      "learning_rate": 5.120472359709155e-06,
      "loss": 0.4979,
      "step": 7300
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.7111638602143473,
      "learning_rate": 5.119346664690398e-06,
      "loss": 0.4773,
      "step": 7301
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.121299159773346,
      "learning_rate": 5.118220963618767e-06,
      "loss": 0.4692,
      "step": 7302
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.7267682648174232,
      "learning_rate": 5.117095256551354e-06,
      "loss": 0.4877,
      "step": 7303
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.8436444516726775,
      "learning_rate": 5.115969543545252e-06,
      "loss": 0.5126,
      "step": 7304
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.6174502886172673,
      "learning_rate": 5.114843824657552e-06,
      "loss": 0.5156,
      "step": 7305
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.7459384324092597,
      "learning_rate": 5.113718099945346e-06,
      "loss": 0.4857,
      "step": 7306
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.9016583188197749,
      "learning_rate": 5.112592369465731e-06,
      "loss": 0.5773,
      "step": 7307
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.678307352435436,
      "learning_rate": 5.111466633275797e-06,
      "loss": 0.5281,
      "step": 7308
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.041553740218663,
      "learning_rate": 5.11034089143264e-06,
      "loss": 0.5741,
      "step": 7309
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.0560473244180564,
      "learning_rate": 5.109215143993352e-06,
      "loss": 0.4788,
      "step": 7310
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.0631137306647473,
      "learning_rate": 5.108089391015028e-06,
      "loss": 0.5268,
      "step": 7311
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.0251841747659207,
      "learning_rate": 5.106963632554762e-06,
      "loss": 0.4522,
      "step": 7312
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.8445911696616644,
      "learning_rate": 5.10583786866965e-06,
      "loss": 0.4914,
      "step": 7313
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.8843037292951144,
      "learning_rate": 5.1047120994167855e-06,
      "loss": 0.4615,
      "step": 7314
    },
    {
      "epoch": 0.51,
      "grad_norm": 3.2168690639459827,
      "learning_rate": 5.103586324853266e-06,
      "loss": 0.5303,
      "step": 7315
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.03101614005366,
      "learning_rate": 5.102460545036184e-06,
      "loss": 0.5459,
      "step": 7316
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.6286694923962672,
      "learning_rate": 5.101334760022639e-06,
      "loss": 0.4818,
      "step": 7317
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.191313671350167,
      "learning_rate": 5.100208969869723e-06,
      "loss": 0.5767,
      "step": 7318
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.674773558065533,
      "learning_rate": 5.099083174634537e-06,
      "loss": 0.4873,
      "step": 7319
    },
    {
      "epoch": 0.51,
      "grad_norm": 3.4810992460837804,
      "learning_rate": 5.097957374374174e-06,
      "loss": 0.5172,
      "step": 7320
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.386813728554435,
      "learning_rate": 5.096831569145733e-06,
      "loss": 0.5178,
      "step": 7321
    },
    {
      "epoch": 0.51,
      "grad_norm": 4.535256030941456,
      "learning_rate": 5.095705759006311e-06,
      "loss": 0.488,
      "step": 7322
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.9812445610649145,
      "learning_rate": 5.094579944013005e-06,
      "loss": 0.5085,
      "step": 7323
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.9032149293649336,
      "learning_rate": 5.093454124222912e-06,
      "loss": 0.5145,
      "step": 7324
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.3598832033923443,
      "learning_rate": 5.092328299693131e-06,
      "loss": 0.4829,
      "step": 7325
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.7947120392016351,
      "learning_rate": 5.0912024704807585e-06,
      "loss": 0.5476,
      "step": 7326
    },
    {
      "epoch": 0.51,
      "grad_norm": 15.581523456572615,
      "learning_rate": 5.090076636642896e-06,
      "loss": 0.4668,
      "step": 7327
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.7549816443179629,
      "learning_rate": 5.0889507982366385e-06,
      "loss": 0.466,
      "step": 7328
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.000262408186387,
      "learning_rate": 5.0878249553190864e-06,
      "loss": 0.517,
      "step": 7329
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.015178606742615,
      "learning_rate": 5.08669910794734e-06,
      "loss": 0.4962,
      "step": 7330
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.6770057898690116,
      "learning_rate": 5.0855732561784966e-06,
      "loss": 0.5253,
      "step": 7331
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.8837216808806472,
      "learning_rate": 5.084447400069656e-06,
      "loss": 0.5154,
      "step": 7332
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.8014006466656238,
      "learning_rate": 5.08332153967792e-06,
      "loss": 0.5149,
      "step": 7333
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.7011093083386852,
      "learning_rate": 5.0821956750603866e-06,
      "loss": 0.5364,
      "step": 7334
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.2894929124833565,
      "learning_rate": 5.081069806274156e-06,
      "loss": 0.469,
      "step": 7335
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.7380351579728497,
      "learning_rate": 5.07994393337633e-06,
      "loss": 0.5386,
      "step": 7336
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.482085118073553,
      "learning_rate": 5.0788180564240084e-06,
      "loss": 0.4973,
      "step": 7337
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.5905385724628276,
      "learning_rate": 5.077692175474292e-06,
      "loss": 0.5288,
      "step": 7338
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.8451914489924426,
      "learning_rate": 5.076566290584282e-06,
      "loss": 0.5195,
      "step": 7339
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.2921809433011435,
      "learning_rate": 5.075440401811077e-06,
      "loss": 0.4869,
      "step": 7340
    },
    {
      "epoch": 0.51,
      "grad_norm": 6.589916814089708,
      "learning_rate": 5.074314509211783e-06,
      "loss": 0.4787,
      "step": 7341
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.5476591118371954,
      "learning_rate": 5.073188612843498e-06,
      "loss": 0.4701,
      "step": 7342
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.7968821192650906,
      "learning_rate": 5.072062712763327e-06,
      "loss": 0.484,
      "step": 7343
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.9031111405006615,
      "learning_rate": 5.070936809028368e-06,
      "loss": 0.5222,
      "step": 7344
    },
    {
      "epoch": 0.51,
      "grad_norm": 3.1250871152954685,
      "learning_rate": 5.069810901695727e-06,
      "loss": 0.5011,
      "step": 7345
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.007003741755173,
      "learning_rate": 5.068684990822505e-06,
      "loss": 0.4606,
      "step": 7346
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.9510864811920445,
      "learning_rate": 5.067559076465803e-06,
      "loss": 0.5164,
      "step": 7347
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.9497064203019134,
      "learning_rate": 5.066433158682725e-06,
      "loss": 0.5275,
      "step": 7348
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6578011178257965,
      "learning_rate": 5.065307237530373e-06,
      "loss": 0.4469,
      "step": 7349
    },
    {
      "epoch": 0.51,
      "grad_norm": 3.05861111914756,
      "learning_rate": 5.064181313065853e-06,
      "loss": 0.4937,
      "step": 7350
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.009296289279742,
      "learning_rate": 5.063055385346264e-06,
      "loss": 0.4649,
      "step": 7351
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.76934121022203,
      "learning_rate": 5.061929454428712e-06,
      "loss": 0.5081,
      "step": 7352
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.781701387946058,
      "learning_rate": 5.0608035203703e-06,
      "loss": 0.5027,
      "step": 7353
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.5796102169141486,
      "learning_rate": 5.059677583228133e-06,
      "loss": 0.5239,
      "step": 7354
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.0299320458646117,
      "learning_rate": 5.058551643059312e-06,
      "loss": 0.5043,
      "step": 7355
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.8531947859675566,
      "learning_rate": 5.057425699920943e-06,
      "loss": 0.5126,
      "step": 7356
    },
    {
      "epoch": 0.51,
      "grad_norm": 3.0066796402848817,
      "learning_rate": 5.0562997538701295e-06,
      "loss": 0.5003,
      "step": 7357
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.8677086410691732,
      "learning_rate": 5.0551738049639774e-06,
      "loss": 0.4661,
      "step": 7358
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.6508169728342805,
      "learning_rate": 5.0540478532595886e-06,
      "loss": 0.5081,
      "step": 7359
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.8039261407587335,
      "learning_rate": 5.052921898814068e-06,
      "loss": 0.5209,
      "step": 7360
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.7733834540516746,
      "learning_rate": 5.051795941684522e-06,
      "loss": 0.5183,
      "step": 7361
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.6593607030889648,
      "learning_rate": 5.050669981928056e-06,
      "loss": 0.5421,
      "step": 7362
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.1472996275704666,
      "learning_rate": 5.049544019601772e-06,
      "loss": 0.4895,
      "step": 7363
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.0019039609865183,
      "learning_rate": 5.048418054762777e-06,
      "loss": 0.5081,
      "step": 7364
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.828364389829577,
      "learning_rate": 5.047292087468176e-06,
      "loss": 0.5389,
      "step": 7365
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6367103450921151,
      "learning_rate": 5.046166117775076e-06,
      "loss": 0.4675,
      "step": 7366
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.419018844191794,
      "learning_rate": 5.04504014574058e-06,
      "loss": 0.4891,
      "step": 7367
    },
    {
      "epoch": 0.51,
      "grad_norm": 3.862285821826585,
      "learning_rate": 5.043914171421794e-06,
      "loss": 0.5352,
      "step": 7368
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.063229355899113,
      "learning_rate": 5.0427881948758265e-06,
      "loss": 0.5125,
      "step": 7369
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.389079229297548,
      "learning_rate": 5.04166221615978e-06,
      "loss": 0.5178,
      "step": 7370
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.340954995447461,
      "learning_rate": 5.040536235330761e-06,
      "loss": 0.5286,
      "step": 7371
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.8948379001826643,
      "learning_rate": 5.039410252445878e-06,
      "loss": 0.532,
      "step": 7372
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.2202561049818113,
      "learning_rate": 5.038284267562234e-06,
      "loss": 0.5194,
      "step": 7373
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.038704012639013,
      "learning_rate": 5.0371582807369365e-06,
      "loss": 0.5079,
      "step": 7374
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.920655608926733,
      "learning_rate": 5.036032292027092e-06,
      "loss": 0.4566,
      "step": 7375
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.126666091389763,
      "learning_rate": 5.034906301489808e-06,
      "loss": 0.5056,
      "step": 7376
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.216798449080596,
      "learning_rate": 5.0337803091821905e-06,
      "loss": 0.4688,
      "step": 7377
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.1409322563384885,
      "learning_rate": 5.032654315161345e-06,
      "loss": 0.4964,
      "step": 7378
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.8412261127874674,
      "learning_rate": 5.03152831948438e-06,
      "loss": 0.437,
      "step": 7379
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.012927688114177,
      "learning_rate": 5.030402322208402e-06,
      "loss": 0.5,
      "step": 7380
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6160044829013348,
      "learning_rate": 5.029276323390515e-06,
      "loss": 0.436,
      "step": 7381
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.382252026469837,
      "learning_rate": 5.0281503230878304e-06,
      "loss": 0.5221,
      "step": 7382
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6162629169464937,
      "learning_rate": 5.027024321357452e-06,
      "loss": 0.4465,
      "step": 7383
    },
    {
      "epoch": 0.51,
      "grad_norm": 16.219978676066802,
      "learning_rate": 5.025898318256489e-06,
      "loss": 0.5025,
      "step": 7384
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.0692800781195286,
      "learning_rate": 5.024772313842047e-06,
      "loss": 0.4698,
      "step": 7385
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.558726009375278,
      "learning_rate": 5.023646308171234e-06,
      "loss": 0.5265,
      "step": 7386
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.675322644112354,
      "learning_rate": 5.022520301301157e-06,
      "loss": 0.5435,
      "step": 7387
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.7333750933207037,
      "learning_rate": 5.021394293288925e-06,
      "loss": 0.5532,
      "step": 7388
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6228127912205026,
      "learning_rate": 5.020268284191643e-06,
      "loss": 0.4518,
      "step": 7389
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.727343255574449,
      "learning_rate": 5.019142274066421e-06,
      "loss": 0.5254,
      "step": 7390
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.071896435635791,
      "learning_rate": 5.018016262970364e-06,
      "loss": 0.4955,
      "step": 7391
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.976988482733413,
      "learning_rate": 5.016890250960582e-06,
      "loss": 0.493,
      "step": 7392
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.767827755738224,
      "learning_rate": 5.01576423809418e-06,
      "loss": 0.4733,
      "step": 7393
    },
    {
      "epoch": 0.51,
      "grad_norm": 6.586908304788429,
      "learning_rate": 5.014638224428269e-06,
      "loss": 0.4696,
      "step": 7394
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.0057246239956403,
      "learning_rate": 5.013512210019954e-06,
      "loss": 0.566,
      "step": 7395
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.127756748066044,
      "learning_rate": 5.012386194926344e-06,
      "loss": 0.5121,
      "step": 7396
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.9249354134647323,
      "learning_rate": 5.011260179204546e-06,
      "loss": 0.5533,
      "step": 7397
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.7460751607156888,
      "learning_rate": 5.01013416291167e-06,
      "loss": 0.4928,
      "step": 7398
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.9671860055242374,
      "learning_rate": 5.00900814610482e-06,
      "loss": 0.5408,
      "step": 7399
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.311987181494198,
      "learning_rate": 5.0078821288411074e-06,
      "loss": 0.5118,
      "step": 7400
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.5807926675356503,
      "learning_rate": 5.006756111177639e-06,
      "loss": 0.4921,
      "step": 7401
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.8176458087036964,
      "learning_rate": 5.005630093171523e-06,
      "loss": 0.4788,
      "step": 7402
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.9454978940824117,
      "learning_rate": 5.004504074879867e-06,
      "loss": 0.4809,
      "step": 7403
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.0801305246521373,
      "learning_rate": 5.003378056359779e-06,
      "loss": 0.5238,
      "step": 7404
    },
    {
      "epoch": 0.51,
      "grad_norm": 4.16667267667988,
      "learning_rate": 5.002252037668366e-06,
      "loss": 0.499,
      "step": 7405
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.891870469082735,
      "learning_rate": 5.001126018862737e-06,
      "loss": 0.5217,
      "step": 7406
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.9366241593114168,
      "learning_rate": 5e-06,
      "loss": 0.5001,
      "step": 7407
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.970712549794403,
      "learning_rate": 4.998873981137265e-06,
      "loss": 0.5255,
      "step": 7408
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.162737123263428,
      "learning_rate": 4.997747962331634e-06,
      "loss": 0.462,
      "step": 7409
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.8697762267954772,
      "learning_rate": 4.9966219436402225e-06,
      "loss": 0.447,
      "step": 7410
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.8721270223099284,
      "learning_rate": 4.995495925120135e-06,
      "loss": 0.5274,
      "step": 7411
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.5109384489510258,
      "learning_rate": 4.994369906828479e-06,
      "loss": 0.4484,
      "step": 7412
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.8245732180763918,
      "learning_rate": 4.993243888822361e-06,
      "loss": 0.539,
      "step": 7413
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.8645863028076624,
      "learning_rate": 4.992117871158893e-06,
      "loss": 0.4984,
      "step": 7414
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.1616460609147743,
      "learning_rate": 4.990991853895182e-06,
      "loss": 0.4823,
      "step": 7415
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6398331410946733,
      "learning_rate": 4.989865837088334e-06,
      "loss": 0.4015,
      "step": 7416
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.8537386172262957,
      "learning_rate": 4.988739820795455e-06,
      "loss": 0.4894,
      "step": 7417
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.0060416814319777,
      "learning_rate": 4.9876138050736575e-06,
      "loss": 0.4826,
      "step": 7418
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.7014949696027806,
      "learning_rate": 4.986487789980048e-06,
      "loss": 0.4821,
      "step": 7419
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.5507393484242926,
      "learning_rate": 4.985361775571733e-06,
      "loss": 0.4751,
      "step": 7420
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.660033019074081,
      "learning_rate": 4.98423576190582e-06,
      "loss": 0.4381,
      "step": 7421
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.7721434387343586,
      "learning_rate": 4.9831097490394195e-06,
      "loss": 0.4881,
      "step": 7422
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.7470217513099804,
      "learning_rate": 4.981983737029637e-06,
      "loss": 0.5018,
      "step": 7423
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.4738555248764458,
      "learning_rate": 4.980857725933581e-06,
      "loss": 0.5204,
      "step": 7424
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.0745989392816577,
      "learning_rate": 4.979731715808357e-06,
      "loss": 0.4714,
      "step": 7425
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.0134128268669156,
      "learning_rate": 4.978605706711077e-06,
      "loss": 0.4699,
      "step": 7426
    },
    {
      "epoch": 0.52,
      "grad_norm": 5.734600874869975,
      "learning_rate": 4.9774796986988446e-06,
      "loss": 0.4853,
      "step": 7427
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.80983340807986,
      "learning_rate": 4.9763536918287685e-06,
      "loss": 0.5368,
      "step": 7428
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.6181176491039417,
      "learning_rate": 4.975227686157954e-06,
      "loss": 0.5144,
      "step": 7429
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.91575804703399,
      "learning_rate": 4.974101681743513e-06,
      "loss": 0.5334,
      "step": 7430
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.735501943044216,
      "learning_rate": 4.97297567864255e-06,
      "loss": 0.5056,
      "step": 7431
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.5821452014552011,
      "learning_rate": 4.971849676912172e-06,
      "loss": 0.4443,
      "step": 7432
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.193525511448712,
      "learning_rate": 4.9707236766094855e-06,
      "loss": 0.4555,
      "step": 7433
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.7193570589706155,
      "learning_rate": 4.9695976777915995e-06,
      "loss": 0.4935,
      "step": 7434
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.0063698466474937,
      "learning_rate": 4.968471680515622e-06,
      "loss": 0.4683,
      "step": 7435
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.7440502040153776,
      "learning_rate": 4.967345684838656e-06,
      "loss": 0.4638,
      "step": 7436
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.9063585583135783,
      "learning_rate": 4.96621969081781e-06,
      "loss": 0.53,
      "step": 7437
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.1215433674660598,
      "learning_rate": 4.965093698510192e-06,
      "loss": 0.497,
      "step": 7438
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.8321315256135973,
      "learning_rate": 4.963967707972909e-06,
      "loss": 0.4922,
      "step": 7439
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.9792640200124043,
      "learning_rate": 4.962841719263066e-06,
      "loss": 0.5288,
      "step": 7440
    },
    {
      "epoch": 0.52,
      "grad_norm": 3.0796875142627997,
      "learning_rate": 4.961715732437767e-06,
      "loss": 0.5346,
      "step": 7441
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.1988378867311855,
      "learning_rate": 4.9605897475541245e-06,
      "loss": 0.5484,
      "step": 7442
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.8430151202884875,
      "learning_rate": 4.959463764669241e-06,
      "loss": 0.5348,
      "step": 7443
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.559775874585259,
      "learning_rate": 4.958337783840223e-06,
      "loss": 0.4927,
      "step": 7444
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.882105893373532,
      "learning_rate": 4.957211805124175e-06,
      "loss": 0.5266,
      "step": 7445
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.333447972935315,
      "learning_rate": 4.956085828578207e-06,
      "loss": 0.474,
      "step": 7446
    },
    {
      "epoch": 0.52,
      "grad_norm": 3.3702528974194252,
      "learning_rate": 4.954959854259422e-06,
      "loss": 0.488,
      "step": 7447
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.9459866903432324,
      "learning_rate": 4.953833882224927e-06,
      "loss": 0.5141,
      "step": 7448
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.7393642487463672,
      "learning_rate": 4.952707912531824e-06,
      "loss": 0.5171,
      "step": 7449
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.8411155136384951,
      "learning_rate": 4.951581945237224e-06,
      "loss": 0.4683,
      "step": 7450
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.6393336144784816,
      "learning_rate": 4.95045598039823e-06,
      "loss": 0.5287,
      "step": 7451
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.2522368722018173,
      "learning_rate": 4.949330018071947e-06,
      "loss": 0.5635,
      "step": 7452
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.8281300781647292,
      "learning_rate": 4.948204058315478e-06,
      "loss": 0.502,
      "step": 7453
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.8135836242862728,
      "learning_rate": 4.947078101185933e-06,
      "loss": 0.4622,
      "step": 7454
    },
    {
      "epoch": 0.52,
      "grad_norm": 3.041593474686294,
      "learning_rate": 4.945952146740414e-06,
      "loss": 0.476,
      "step": 7455
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.552287233003716,
      "learning_rate": 4.944826195036025e-06,
      "loss": 0.4813,
      "step": 7456
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.0201024627253985,
      "learning_rate": 4.943700246129871e-06,
      "loss": 0.5558,
      "step": 7457
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.8447040018813585,
      "learning_rate": 4.942574300079058e-06,
      "loss": 0.5157,
      "step": 7458
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.731577488023566,
      "learning_rate": 4.9414483569406905e-06,
      "loss": 0.4995,
      "step": 7459
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.9468678308439684,
      "learning_rate": 4.94032241677187e-06,
      "loss": 0.4553,
      "step": 7460
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6428215572483498,
      "learning_rate": 4.9391964796297e-06,
      "loss": 0.4354,
      "step": 7461
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.9058542536500802,
      "learning_rate": 4.938070545571289e-06,
      "loss": 0.5063,
      "step": 7462
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.745242083671209,
      "learning_rate": 4.936944614653738e-06,
      "loss": 0.4541,
      "step": 7463
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6071615205745915,
      "learning_rate": 4.93581868693415e-06,
      "loss": 0.4508,
      "step": 7464
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.7338914770068048,
      "learning_rate": 4.9346927624696266e-06,
      "loss": 0.5407,
      "step": 7465
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.839025448899065,
      "learning_rate": 4.9335668413172765e-06,
      "loss": 0.5183,
      "step": 7466
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.622784615475183,
      "learning_rate": 4.932440923534199e-06,
      "loss": 0.5016,
      "step": 7467
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.7441440616938833,
      "learning_rate": 4.931315009177498e-06,
      "loss": 0.5188,
      "step": 7468
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.0872789045931035,
      "learning_rate": 4.9301890983042744e-06,
      "loss": 0.5251,
      "step": 7469
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.084144510755639,
      "learning_rate": 4.929063190971633e-06,
      "loss": 0.5153,
      "step": 7470
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.771743214006019,
      "learning_rate": 4.927937287236676e-06,
      "loss": 0.51,
      "step": 7471
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.839422396293327,
      "learning_rate": 4.926811387156502e-06,
      "loss": 0.5153,
      "step": 7472
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.8202982931898013,
      "learning_rate": 4.925685490788218e-06,
      "loss": 0.474,
      "step": 7473
    },
    {
      "epoch": 0.52,
      "grad_norm": 3.8757950317958416,
      "learning_rate": 4.924559598188924e-06,
      "loss": 0.5112,
      "step": 7474
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.706539759512523,
      "learning_rate": 4.923433709415722e-06,
      "loss": 0.5205,
      "step": 7475
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.9058905521391296,
      "learning_rate": 4.922307824525709e-06,
      "loss": 0.4721,
      "step": 7476
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.6757862995383594,
      "learning_rate": 4.921181943575992e-06,
      "loss": 0.5551,
      "step": 7477
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6102306427180373,
      "learning_rate": 4.920056066623671e-06,
      "loss": 0.4584,
      "step": 7478
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.5710341352544828,
      "learning_rate": 4.918930193725846e-06,
      "loss": 0.5168,
      "step": 7479
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.6579055444867574,
      "learning_rate": 4.917804324939614e-06,
      "loss": 0.4765,
      "step": 7480
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.8980519553908797,
      "learning_rate": 4.916678460322082e-06,
      "loss": 0.4808,
      "step": 7481
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.8064979962545922,
      "learning_rate": 4.915552599930345e-06,
      "loss": 0.4777,
      "step": 7482
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.72484610415666,
      "learning_rate": 4.914426743821507e-06,
      "loss": 0.5047,
      "step": 7483
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.620461895172082,
      "learning_rate": 4.913300892052661e-06,
      "loss": 0.5053,
      "step": 7484
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.967807000628144,
      "learning_rate": 4.912175044680914e-06,
      "loss": 0.4984,
      "step": 7485
    },
    {
      "epoch": 0.52,
      "grad_norm": 3.251555470823138,
      "learning_rate": 4.911049201763364e-06,
      "loss": 0.4954,
      "step": 7486
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.6725062607757468,
      "learning_rate": 4.909923363357107e-06,
      "loss": 0.5235,
      "step": 7487
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.6673742132777392,
      "learning_rate": 4.9087975295192415e-06,
      "loss": 0.4838,
      "step": 7488
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.8182692077223752,
      "learning_rate": 4.907671700306871e-06,
      "loss": 0.4615,
      "step": 7489
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.131755397147017,
      "learning_rate": 4.906545875777089e-06,
      "loss": 0.5137,
      "step": 7490
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.421140002737529,
      "learning_rate": 4.905420055986997e-06,
      "loss": 0.4919,
      "step": 7491
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.8443714984447726,
      "learning_rate": 4.904294240993689e-06,
      "loss": 0.4861,
      "step": 7492
    },
    {
      "epoch": 0.52,
      "grad_norm": 5.0907471806500855,
      "learning_rate": 4.903168430854267e-06,
      "loss": 0.499,
      "step": 7493
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.5825943681601,
      "learning_rate": 4.902042625625827e-06,
      "loss": 0.5381,
      "step": 7494
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.7235697379616788,
      "learning_rate": 4.9009168253654645e-06,
      "loss": 0.4995,
      "step": 7495
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.7454152441810216,
      "learning_rate": 4.899791030130276e-06,
      "loss": 0.4824,
      "step": 7496
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.5483005656342894,
      "learning_rate": 4.8986652399773625e-06,
      "loss": 0.4488,
      "step": 7497
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.9333698019336143,
      "learning_rate": 4.897539454963817e-06,
      "loss": 0.5355,
      "step": 7498
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.7634103117489741,
      "learning_rate": 4.896413675146737e-06,
      "loss": 0.5085,
      "step": 7499
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.811928191498372,
      "learning_rate": 4.895287900583216e-06,
      "loss": 0.5192,
      "step": 7500
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.136940739468724,
      "learning_rate": 4.894162131330353e-06,
      "loss": 0.4787,
      "step": 7501
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.514053288551149,
      "learning_rate": 4.893036367445239e-06,
      "loss": 0.4724,
      "step": 7502
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.3436264313395156,
      "learning_rate": 4.891910608984974e-06,
      "loss": 0.5243,
      "step": 7503
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.8486308821310617,
      "learning_rate": 4.890784856006649e-06,
      "loss": 0.479,
      "step": 7504
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.211081686997996,
      "learning_rate": 4.889659108567362e-06,
      "loss": 0.499,
      "step": 7505
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.134168814029696,
      "learning_rate": 4.888533366724204e-06,
      "loss": 0.505,
      "step": 7506
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.971018800861125,
      "learning_rate": 4.887407630534271e-06,
      "loss": 0.5071,
      "step": 7507
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.8851397569526969,
      "learning_rate": 4.886281900054653e-06,
      "loss": 0.5112,
      "step": 7508
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.6299954091494313,
      "learning_rate": 4.88515617534245e-06,
      "loss": 0.4828,
      "step": 7509
    },
    {
      "epoch": 0.52,
      "grad_norm": 5.802129680772829,
      "learning_rate": 4.8840304564547505e-06,
      "loss": 0.5012,
      "step": 7510
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.342612620698516,
      "learning_rate": 4.882904743448647e-06,
      "loss": 0.4885,
      "step": 7511
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.965431973802389,
      "learning_rate": 4.881779036381234e-06,
      "loss": 0.4594,
      "step": 7512
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.064563476213176,
      "learning_rate": 4.880653335309603e-06,
      "loss": 0.5183,
      "step": 7513
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.354271184749352,
      "learning_rate": 4.879527640290846e-06,
      "loss": 0.4891,
      "step": 7514
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.9868873888147138,
      "learning_rate": 4.878401951382054e-06,
      "loss": 0.5018,
      "step": 7515
    },
    {
      "epoch": 0.52,
      "grad_norm": 3.253667956401781,
      "learning_rate": 4.877276268640317e-06,
      "loss": 0.4912,
      "step": 7516
    },
    {
      "epoch": 0.52,
      "grad_norm": 3.199157234240323,
      "learning_rate": 4.8761505921227295e-06,
      "loss": 0.5024,
      "step": 7517
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.9946599759034935,
      "learning_rate": 4.87502492188638e-06,
      "loss": 0.5478,
      "step": 7518
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.1292066197709794,
      "learning_rate": 4.873899257988359e-06,
      "loss": 0.5509,
      "step": 7519
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.9734026843910508,
      "learning_rate": 4.872773600485754e-06,
      "loss": 0.51,
      "step": 7520
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.289726667699485,
      "learning_rate": 4.87164794943566e-06,
      "loss": 0.5367,
      "step": 7521
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.8279667439051799,
      "learning_rate": 4.870522304895164e-06,
      "loss": 0.5478,
      "step": 7522
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.9464375094166675,
      "learning_rate": 4.869396666921353e-06,
      "loss": 0.4581,
      "step": 7523
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.8398119004793125,
      "learning_rate": 4.8682710355713175e-06,
      "loss": 0.5282,
      "step": 7524
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.000750978801383,
      "learning_rate": 4.867145410902146e-06,
      "loss": 0.4793,
      "step": 7525
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.1264246186204954,
      "learning_rate": 4.866019792970926e-06,
      "loss": 0.4853,
      "step": 7526
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.8255347993756856,
      "learning_rate": 4.8648941818347465e-06,
      "loss": 0.4967,
      "step": 7527
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.4503518928593278,
      "learning_rate": 4.863768577550691e-06,
      "loss": 0.4938,
      "step": 7528
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.9404625101094186,
      "learning_rate": 4.86264298017585e-06,
      "loss": 0.4986,
      "step": 7529
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.801221720268092,
      "learning_rate": 4.8615173897673105e-06,
      "loss": 0.5065,
      "step": 7530
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6586073734774484,
      "learning_rate": 4.860391806382157e-06,
      "loss": 0.4281,
      "step": 7531
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.5217876943207573,
      "learning_rate": 4.859266230077474e-06,
      "loss": 0.4723,
      "step": 7532
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.6247853356682094,
      "learning_rate": 4.858140660910352e-06,
      "loss": 0.4802,
      "step": 7533
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.991471498556965,
      "learning_rate": 4.857015098937872e-06,
      "loss": 0.5122,
      "step": 7534
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.8329373868346048,
      "learning_rate": 4.855889544217119e-06,
      "loss": 0.4989,
      "step": 7535
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.7169266976746913,
      "learning_rate": 4.854763996805179e-06,
      "loss": 0.5225,
      "step": 7536
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.6103023844072712,
      "learning_rate": 4.853638456759137e-06,
      "loss": 0.5264,
      "step": 7537
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6695298643882834,
      "learning_rate": 4.8525129241360746e-06,
      "loss": 0.4593,
      "step": 7538
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.7314392932682987,
      "learning_rate": 4.851387398993073e-06,
      "loss": 0.5099,
      "step": 7539
    },
    {
      "epoch": 0.52,
      "grad_norm": 5.096225515800005,
      "learning_rate": 4.850261881387222e-06,
      "loss": 0.5102,
      "step": 7540
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.8314864846932486,
      "learning_rate": 4.849136371375599e-06,
      "loss": 0.471,
      "step": 7541
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.6140974359454145,
      "learning_rate": 4.848010869015288e-06,
      "loss": 0.4808,
      "step": 7542
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.5766070140329624,
      "learning_rate": 4.846885374363367e-06,
      "loss": 0.4923,
      "step": 7543
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.2463128702011854,
      "learning_rate": 4.845759887476924e-06,
      "loss": 0.5354,
      "step": 7544
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.0746190765602366,
      "learning_rate": 4.844634408413036e-06,
      "loss": 0.5579,
      "step": 7545
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.8141626381351406,
      "learning_rate": 4.8435089372287844e-06,
      "loss": 0.4984,
      "step": 7546
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.8058916850100661,
      "learning_rate": 4.842383473981248e-06,
      "loss": 0.4703,
      "step": 7547
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6911471848543226,
      "learning_rate": 4.8412580187275095e-06,
      "loss": 0.4727,
      "step": 7548
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.8695265570967674,
      "learning_rate": 4.840132571524646e-06,
      "loss": 0.5368,
      "step": 7549
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.8340426886546182,
      "learning_rate": 4.839007132429738e-06,
      "loss": 0.4783,
      "step": 7550
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.9788629303816934,
      "learning_rate": 4.837881701499861e-06,
      "loss": 0.5448,
      "step": 7551
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.9182479185178474,
      "learning_rate": 4.836756278792098e-06,
      "loss": 0.4934,
      "step": 7552
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.6531368525098915,
      "learning_rate": 4.835630864363524e-06,
      "loss": 0.4408,
      "step": 7553
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.7600610159023775,
      "learning_rate": 4.834505458271217e-06,
      "loss": 0.5202,
      "step": 7554
    },
    {
      "epoch": 0.53,
      "grad_norm": 4.645721934700436,
      "learning_rate": 4.833380060572251e-06,
      "loss": 0.5178,
      "step": 7555
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.9665401507547924,
      "learning_rate": 4.832254671323707e-06,
      "loss": 0.5013,
      "step": 7556
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.8694838307468635,
      "learning_rate": 4.83112929058266e-06,
      "loss": 0.5189,
      "step": 7557
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.0866542923278804,
      "learning_rate": 4.830003918406184e-06,
      "loss": 0.5082,
      "step": 7558
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.0864785672726116,
      "learning_rate": 4.828878554851355e-06,
      "loss": 0.514,
      "step": 7559
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.9940750964625795,
      "learning_rate": 4.827753199975248e-06,
      "loss": 0.4917,
      "step": 7560
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.2090954915290304,
      "learning_rate": 4.826627853834937e-06,
      "loss": 0.5386,
      "step": 7561
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.7127260330773646,
      "learning_rate": 4.825502516487497e-06,
      "loss": 0.5207,
      "step": 7562
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.3953247324813205,
      "learning_rate": 4.824377187989997e-06,
      "loss": 0.5454,
      "step": 7563
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.1438456437559865,
      "learning_rate": 4.823251868399517e-06,
      "loss": 0.5093,
      "step": 7564
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.8913679405041646,
      "learning_rate": 4.8221265577731256e-06,
      "loss": 0.4616,
      "step": 7565
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.6477090946768542,
      "learning_rate": 4.821001256167895e-06,
      "loss": 0.4721,
      "step": 7566
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.038390986479492,
      "learning_rate": 4.819875963640896e-06,
      "loss": 0.4707,
      "step": 7567
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.052057730270609,
      "learning_rate": 4.818750680249202e-06,
      "loss": 0.4508,
      "step": 7568
    },
    {
      "epoch": 0.53,
      "grad_norm": 3.0074972372185167,
      "learning_rate": 4.817625406049883e-06,
      "loss": 0.5442,
      "step": 7569
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.8427772479308406,
      "learning_rate": 4.8165001411000074e-06,
      "loss": 0.5147,
      "step": 7570
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.772526932329565,
      "learning_rate": 4.815374885456646e-06,
      "loss": 0.4663,
      "step": 7571
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.1970311393430326,
      "learning_rate": 4.81424963917687e-06,
      "loss": 0.5288,
      "step": 7572
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.714526193377763,
      "learning_rate": 4.813124402317747e-06,
      "loss": 0.4934,
      "step": 7573
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.9850779490021235,
      "learning_rate": 4.8119991749363445e-06,
      "loss": 0.4659,
      "step": 7574
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.1685002309214076,
      "learning_rate": 4.81087395708973e-06,
      "loss": 0.4991,
      "step": 7575
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.213505999675125,
      "learning_rate": 4.809748748834972e-06,
      "loss": 0.5124,
      "step": 7576
    },
    {
      "epoch": 0.53,
      "grad_norm": 3.031826096134805,
      "learning_rate": 4.808623550229139e-06,
      "loss": 0.4963,
      "step": 7577
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.7419347602880795,
      "learning_rate": 4.807498361329295e-06,
      "loss": 0.4966,
      "step": 7578
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.040491956585683,
      "learning_rate": 4.806373182192505e-06,
      "loss": 0.5065,
      "step": 7579
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6373458247933446,
      "learning_rate": 4.805248012875837e-06,
      "loss": 0.4395,
      "step": 7580
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.8386034297128553,
      "learning_rate": 4.804122853436355e-06,
      "loss": 0.5191,
      "step": 7581
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.975213242037115,
      "learning_rate": 4.802997703931124e-06,
      "loss": 0.466,
      "step": 7582
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.901223759456347,
      "learning_rate": 4.801872564417204e-06,
      "loss": 0.468,
      "step": 7583
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.1905583419603043,
      "learning_rate": 4.800747434951665e-06,
      "loss": 0.461,
      "step": 7584
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.6704873866743317,
      "learning_rate": 4.799622315591566e-06,
      "loss": 0.5134,
      "step": 7585
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.7884779590831454,
      "learning_rate": 4.798497206393969e-06,
      "loss": 0.4937,
      "step": 7586
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6151297568325503,
      "learning_rate": 4.797372107415935e-06,
      "loss": 0.4526,
      "step": 7587
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.5775599522589594,
      "learning_rate": 4.79624701871453e-06,
      "loss": 0.4824,
      "step": 7588
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.9300892391442284,
      "learning_rate": 4.795121940346811e-06,
      "loss": 0.471,
      "step": 7589
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.9613891725736643,
      "learning_rate": 4.79399687236984e-06,
      "loss": 0.4766,
      "step": 7590
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.8521914757449511,
      "learning_rate": 4.792871814840674e-06,
      "loss": 0.5014,
      "step": 7591
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.7373925665656438,
      "learning_rate": 4.7917467678163764e-06,
      "loss": 0.5155,
      "step": 7592
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.7509968235056825,
      "learning_rate": 4.7906217313540035e-06,
      "loss": 0.5121,
      "step": 7593
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.0578433477441793,
      "learning_rate": 4.789496705510613e-06,
      "loss": 0.5139,
      "step": 7594
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.1596778920449973,
      "learning_rate": 4.788371690343262e-06,
      "loss": 0.458,
      "step": 7595
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.2180840199571104,
      "learning_rate": 4.787246685909011e-06,
      "loss": 0.4701,
      "step": 7596
    },
    {
      "epoch": 0.53,
      "grad_norm": 5.720359684948156,
      "learning_rate": 4.786121692264915e-06,
      "loss": 0.4995,
      "step": 7597
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.193883928908538,
      "learning_rate": 4.784996709468029e-06,
      "loss": 0.5354,
      "step": 7598
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.0095167778272556,
      "learning_rate": 4.783871737575406e-06,
      "loss": 0.4725,
      "step": 7599
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.9859723958724964,
      "learning_rate": 4.782746776644107e-06,
      "loss": 0.4847,
      "step": 7600
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.3957540386100313,
      "learning_rate": 4.781621826731183e-06,
      "loss": 0.4444,
      "step": 7601
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.9308013736135314,
      "learning_rate": 4.780496887893686e-06,
      "loss": 0.4956,
      "step": 7602
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.9451974155633178,
      "learning_rate": 4.7793719601886735e-06,
      "loss": 0.4784,
      "step": 7603
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.7331326823940694,
      "learning_rate": 4.7782470436731954e-06,
      "loss": 0.4929,
      "step": 7604
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.484544956366274,
      "learning_rate": 4.777122138404304e-06,
      "loss": 0.4883,
      "step": 7605
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.7141721989055514,
      "learning_rate": 4.77599724443905e-06,
      "loss": 0.4628,
      "step": 7606
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.7941286656736117,
      "learning_rate": 4.7748723618344865e-06,
      "loss": 0.4724,
      "step": 7607
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.8607788408183024,
      "learning_rate": 4.773747490647663e-06,
      "loss": 0.4851,
      "step": 7608
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.89560424301965,
      "learning_rate": 4.772622630935629e-06,
      "loss": 0.5203,
      "step": 7609
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.9556794636052404,
      "learning_rate": 4.771497782755433e-06,
      "loss": 0.4903,
      "step": 7610
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6013523472940608,
      "learning_rate": 4.770372946164125e-06,
      "loss": 0.4606,
      "step": 7611
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.09700028025012,
      "learning_rate": 4.7692481212187534e-06,
      "loss": 0.4687,
      "step": 7612
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.4577888163358286,
      "learning_rate": 4.768123307976365e-06,
      "loss": 0.472,
      "step": 7613
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.958376817208246,
      "learning_rate": 4.766998506494005e-06,
      "loss": 0.4985,
      "step": 7614
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.6386160859183083,
      "learning_rate": 4.765873716828723e-06,
      "loss": 0.4562,
      "step": 7615
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.9178105215193328,
      "learning_rate": 4.764748939037562e-06,
      "loss": 0.5109,
      "step": 7616
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.8012779512479948,
      "learning_rate": 4.763624173177568e-06,
      "loss": 0.4494,
      "step": 7617
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.7190815454151955,
      "learning_rate": 4.7624994193057825e-06,
      "loss": 0.4905,
      "step": 7618
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.8867991285298524,
      "learning_rate": 4.761374677479255e-06,
      "loss": 0.5204,
      "step": 7619
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.2545835681897777,
      "learning_rate": 4.7602499477550255e-06,
      "loss": 0.5219,
      "step": 7620
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.0407900747769863,
      "learning_rate": 4.759125230190138e-06,
      "loss": 0.4891,
      "step": 7621
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.8018735572603632,
      "learning_rate": 4.758000524841632e-06,
      "loss": 0.4806,
      "step": 7622
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.9436913141461003,
      "learning_rate": 4.75687583176655e-06,
      "loss": 0.4915,
      "step": 7623
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.64628677268258,
      "learning_rate": 4.755751151021934e-06,
      "loss": 0.5561,
      "step": 7624
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.121620781646419,
      "learning_rate": 4.754626482664824e-06,
      "loss": 0.4932,
      "step": 7625
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.8819342582905452,
      "learning_rate": 4.7535018267522575e-06,
      "loss": 0.4527,
      "step": 7626
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.8006129507076039,
      "learning_rate": 4.752377183341276e-06,
      "loss": 0.5397,
      "step": 7627
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.8462187917391268,
      "learning_rate": 4.7512525524889154e-06,
      "loss": 0.5176,
      "step": 7628
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.7663185062747326,
      "learning_rate": 4.750127934252216e-06,
      "loss": 0.4783,
      "step": 7629
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.9254434124785038,
      "learning_rate": 4.74900332868821e-06,
      "loss": 0.4714,
      "step": 7630
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6266388795190414,
      "learning_rate": 4.747878735853939e-06,
      "loss": 0.4246,
      "step": 7631
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.8973471968401225,
      "learning_rate": 4.746754155806437e-06,
      "loss": 0.5305,
      "step": 7632
    },
    {
      "epoch": 0.53,
      "grad_norm": 4.29667724428791,
      "learning_rate": 4.745629588602739e-06,
      "loss": 0.5196,
      "step": 7633
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.5721155112295637,
      "learning_rate": 4.744505034299876e-06,
      "loss": 0.5208,
      "step": 7634
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.5795610185106888,
      "learning_rate": 4.743380492954888e-06,
      "loss": 0.4567,
      "step": 7635
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.4293055037580273,
      "learning_rate": 4.742255964624804e-06,
      "loss": 0.455,
      "step": 7636
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.094603615862239,
      "learning_rate": 4.741131449366657e-06,
      "loss": 0.5236,
      "step": 7637
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.2689755255090347,
      "learning_rate": 4.740006947237477e-06,
      "loss": 0.4981,
      "step": 7638
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.159381617966698,
      "learning_rate": 4.738882458294299e-06,
      "loss": 0.5098,
      "step": 7639
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.932891429868966,
      "learning_rate": 4.737757982594151e-06,
      "loss": 0.5129,
      "step": 7640
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.9924121438236033,
      "learning_rate": 4.736633520194064e-06,
      "loss": 0.5085,
      "step": 7641
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.7133996766096555,
      "learning_rate": 4.7355090711510635e-06,
      "loss": 0.4853,
      "step": 7642
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.6163854003179727,
      "learning_rate": 4.7343846355221825e-06,
      "loss": 0.5637,
      "step": 7643
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6236389473429695,
      "learning_rate": 4.733260213364447e-06,
      "loss": 0.4465,
      "step": 7644
    },
    {
      "epoch": 0.53,
      "grad_norm": 3.042892590781957,
      "learning_rate": 4.732135804734885e-06,
      "loss": 0.4395,
      "step": 7645
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.8491343693602975,
      "learning_rate": 4.731011409690519e-06,
      "loss": 0.5028,
      "step": 7646
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.862732029847814,
      "learning_rate": 4.729887028288379e-06,
      "loss": 0.4914,
      "step": 7647
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.9707868974265983,
      "learning_rate": 4.7287626605854895e-06,
      "loss": 0.5109,
      "step": 7648
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.942940360492384,
      "learning_rate": 4.727638306638872e-06,
      "loss": 0.5078,
      "step": 7649
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.6055966672187698,
      "learning_rate": 4.7265139665055495e-06,
      "loss": 0.5099,
      "step": 7650
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.9320755403638836,
      "learning_rate": 4.725389640242551e-06,
      "loss": 0.5185,
      "step": 7651
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.427160058786203,
      "learning_rate": 4.724265327906893e-06,
      "loss": 0.519,
      "step": 7652
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.999724782875642,
      "learning_rate": 4.723141029555599e-06,
      "loss": 0.5507,
      "step": 7653
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.5946201623114886,
      "learning_rate": 4.722016745245687e-06,
      "loss": 0.4803,
      "step": 7654
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.7984923125995866,
      "learning_rate": 4.720892475034181e-06,
      "loss": 0.5222,
      "step": 7655
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.6551601916015355,
      "learning_rate": 4.7197682189781e-06,
      "loss": 0.5381,
      "step": 7656
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.539056651846773,
      "learning_rate": 4.71864397713446e-06,
      "loss": 0.4895,
      "step": 7657
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.7858319704817802,
      "learning_rate": 4.717519749560281e-06,
      "loss": 0.5195,
      "step": 7658
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.6112063916869848,
      "learning_rate": 4.716395536312579e-06,
      "loss": 0.5391,
      "step": 7659
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.967063440144295,
      "learning_rate": 4.715271337448371e-06,
      "loss": 0.4669,
      "step": 7660
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.9962535516199784,
      "learning_rate": 4.714147153024672e-06,
      "loss": 0.5018,
      "step": 7661
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.7922517411097185,
      "learning_rate": 4.713022983098496e-06,
      "loss": 0.4945,
      "step": 7662
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.4469297372172165,
      "learning_rate": 4.711898827726862e-06,
      "loss": 0.4921,
      "step": 7663
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.9649188662751096,
      "learning_rate": 4.710774686966778e-06,
      "loss": 0.4727,
      "step": 7664
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.69750364373345,
      "learning_rate": 4.709650560875258e-06,
      "loss": 0.4556,
      "step": 7665
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.932523845431702,
      "learning_rate": 4.708526449509317e-06,
      "loss": 0.4545,
      "step": 7666
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.83917367606369,
      "learning_rate": 4.707402352925964e-06,
      "loss": 0.5029,
      "step": 7667
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.62985067322234,
      "learning_rate": 4.706278271182209e-06,
      "loss": 0.4917,
      "step": 7668
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.8825477607648213,
      "learning_rate": 4.705154204335063e-06,
      "loss": 0.5351,
      "step": 7669
    },
    {
      "epoch": 0.53,
      "grad_norm": 5.995810722033114,
      "learning_rate": 4.704030152441535e-06,
      "loss": 0.5102,
      "step": 7670
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.8039624174388653,
      "learning_rate": 4.702906115558632e-06,
      "loss": 0.4609,
      "step": 7671
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.962185286680135,
      "learning_rate": 4.7017820937433635e-06,
      "loss": 0.4931,
      "step": 7672
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.7897848709416935,
      "learning_rate": 4.700658087052733e-06,
      "loss": 0.5019,
      "step": 7673
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.275823929732064,
      "learning_rate": 4.699534095543749e-06,
      "loss": 0.47,
      "step": 7674
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.6769490823390988,
      "learning_rate": 4.698410119273417e-06,
      "loss": 0.4415,
      "step": 7675
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.8008428206625022,
      "learning_rate": 4.69728615829874e-06,
      "loss": 0.5002,
      "step": 7676
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.710258755565195,
      "learning_rate": 4.696162212676721e-06,
      "loss": 0.4747,
      "step": 7677
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.0286519583350255,
      "learning_rate": 4.695038282464365e-06,
      "loss": 0.4983,
      "step": 7678
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.0454942673345236,
      "learning_rate": 4.693914367718673e-06,
      "loss": 0.5173,
      "step": 7679
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.000490132784834,
      "learning_rate": 4.6927904684966475e-06,
      "loss": 0.5142,
      "step": 7680
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.693858528967425,
      "learning_rate": 4.691666584855286e-06,
      "loss": 0.4412,
      "step": 7681
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.002961732005054,
      "learning_rate": 4.6905427168515914e-06,
      "loss": 0.4747,
      "step": 7682
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.1928076156035874,
      "learning_rate": 4.689418864542561e-06,
      "loss": 0.5253,
      "step": 7683
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.8225348349397583,
      "learning_rate": 4.688295027985194e-06,
      "loss": 0.528,
      "step": 7684
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.7057634781619946,
      "learning_rate": 4.687171207236484e-06,
      "loss": 0.5375,
      "step": 7685
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.9300421902996803,
      "learning_rate": 4.686047402353433e-06,
      "loss": 0.4857,
      "step": 7686
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.602833339608673,
      "learning_rate": 4.684923613393035e-06,
      "loss": 0.4963,
      "step": 7687
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.9831598600852238,
      "learning_rate": 4.683799840412283e-06,
      "loss": 0.5346,
      "step": 7688
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.7414437355238446,
      "learning_rate": 4.682676083468172e-06,
      "loss": 0.5483,
      "step": 7689
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.8601462901154004,
      "learning_rate": 4.681552342617696e-06,
      "loss": 0.5076,
      "step": 7690
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.9320814123120993,
      "learning_rate": 4.680428617917846e-06,
      "loss": 0.5315,
      "step": 7691
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.9967642420335803,
      "learning_rate": 4.679304909425615e-06,
      "loss": 0.4605,
      "step": 7692
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.699227691423648,
      "learning_rate": 4.678181217197993e-06,
      "loss": 0.4866,
      "step": 7693
    },
    {
      "epoch": 0.53,
      "grad_norm": 5.964555695930435,
      "learning_rate": 4.677057541291972e-06,
      "loss": 0.499,
      "step": 7694
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.3217552263365553,
      "learning_rate": 4.6759338817645395e-06,
      "loss": 0.492,
      "step": 7695
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.4569268914365487,
      "learning_rate": 4.674810238672684e-06,
      "loss": 0.5303,
      "step": 7696
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.0994552147377834,
      "learning_rate": 4.67368661207339e-06,
      "loss": 0.513,
      "step": 7697
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.740891474467016,
      "learning_rate": 4.67256300202365e-06,
      "loss": 0.4923,
      "step": 7698
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.6386962628045334,
      "learning_rate": 4.671439408580447e-06,
      "loss": 0.4971,
      "step": 7699
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.9292153130036387,
      "learning_rate": 4.670315831800767e-06,
      "loss": 0.4492,
      "step": 7700
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.5914411661556949,
      "learning_rate": 4.669192271741591e-06,
      "loss": 0.5157,
      "step": 7701
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.0065652571847306,
      "learning_rate": 4.668068728459905e-06,
      "loss": 0.5022,
      "step": 7702
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.5523958474943658,
      "learning_rate": 4.6669452020126915e-06,
      "loss": 0.5136,
      "step": 7703
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.7621685694527087,
      "learning_rate": 4.6658216924569325e-06,
      "loss": 0.5535,
      "step": 7704
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.907930398032286,
      "learning_rate": 4.664698199849604e-06,
      "loss": 0.4727,
      "step": 7705
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.7165256632848713,
      "learning_rate": 4.663574724247693e-06,
      "loss": 0.5049,
      "step": 7706
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.8632041616754516,
      "learning_rate": 4.662451265708174e-06,
      "loss": 0.4843,
      "step": 7707
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.199661465138422,
      "learning_rate": 4.6613278242880275e-06,
      "loss": 0.4994,
      "step": 7708
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6493485844597613,
      "learning_rate": 4.660204400044227e-06,
      "loss": 0.4654,
      "step": 7709
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.5650681901838945,
      "learning_rate": 4.659080993033754e-06,
      "loss": 0.5087,
      "step": 7710
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.8090505777106465,
      "learning_rate": 4.6579576033135815e-06,
      "loss": 0.5179,
      "step": 7711
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.7164216030612376,
      "learning_rate": 4.656834230940684e-06,
      "loss": 0.4673,
      "step": 7712
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.65885146565802,
      "learning_rate": 4.655710875972035e-06,
      "loss": 0.469,
      "step": 7713
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.7320065152336463,
      "learning_rate": 4.6545875384646075e-06,
      "loss": 0.4833,
      "step": 7714
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.773150057861692,
      "learning_rate": 4.653464218475375e-06,
      "loss": 0.5644,
      "step": 7715
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.267342186409017,
      "learning_rate": 4.652340916061308e-06,
      "loss": 0.4908,
      "step": 7716
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.7507019904954262,
      "learning_rate": 4.651217631279374e-06,
      "loss": 0.5223,
      "step": 7717
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.6120935045387335,
      "learning_rate": 4.6500943641865455e-06,
      "loss": 0.4762,
      "step": 7718
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.244281962183086,
      "learning_rate": 4.648971114839792e-06,
      "loss": 0.4825,
      "step": 7719
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.0913947870550467,
      "learning_rate": 4.647847883296079e-06,
      "loss": 0.5291,
      "step": 7720
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.6460139740258664,
      "learning_rate": 4.646724669612369e-06,
      "loss": 0.5211,
      "step": 7721
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.6864127525654469,
      "learning_rate": 4.645601473845636e-06,
      "loss": 0.4855,
      "step": 7722
    },
    {
      "epoch": 0.54,
      "grad_norm": 3.057263615623801,
      "learning_rate": 4.64447829605284e-06,
      "loss": 0.4914,
      "step": 7723
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.672339335120809,
      "learning_rate": 4.643355136290946e-06,
      "loss": 0.4541,
      "step": 7724
    },
    {
      "epoch": 0.54,
      "grad_norm": 9.473629184795007,
      "learning_rate": 4.642231994616916e-06,
      "loss": 0.4692,
      "step": 7725
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.0143957784121658,
      "learning_rate": 4.641108871087714e-06,
      "loss": 0.5345,
      "step": 7726
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.0415922629002936,
      "learning_rate": 4.639985765760299e-06,
      "loss": 0.4852,
      "step": 7727
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.7703052205099934,
      "learning_rate": 4.638862678691631e-06,
      "loss": 0.514,
      "step": 7728
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.5837054822459677,
      "learning_rate": 4.637739609938673e-06,
      "loss": 0.4858,
      "step": 7729
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.8919688540407091,
      "learning_rate": 4.6366165595583805e-06,
      "loss": 0.5045,
      "step": 7730
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.9908196157783862,
      "learning_rate": 4.635493527607711e-06,
      "loss": 0.5094,
      "step": 7731
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.962693390839752,
      "learning_rate": 4.63437051414362e-06,
      "loss": 0.5181,
      "step": 7732
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.400030422150638,
      "learning_rate": 4.633247519223066e-06,
      "loss": 0.5062,
      "step": 7733
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.5254146333710032,
      "learning_rate": 4.632124542903003e-06,
      "loss": 0.5101,
      "step": 7734
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.6638635967213282,
      "learning_rate": 4.631001585240382e-06,
      "loss": 0.4841,
      "step": 7735
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.791833127623444,
      "learning_rate": 4.629878646292159e-06,
      "loss": 0.4811,
      "step": 7736
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.8241829449839404,
      "learning_rate": 4.628755726115284e-06,
      "loss": 0.4872,
      "step": 7737
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.5959402803610674,
      "learning_rate": 4.627632824766708e-06,
      "loss": 0.4734,
      "step": 7738
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.5369118500445493,
      "learning_rate": 4.626509942303382e-06,
      "loss": 0.5181,
      "step": 7739
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.951457186440706,
      "learning_rate": 4.625387078782252e-06,
      "loss": 0.5093,
      "step": 7740
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.8109224090500384,
      "learning_rate": 4.624264234260269e-06,
      "loss": 0.5234,
      "step": 7741
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.1538093548974415,
      "learning_rate": 4.62314140879438e-06,
      "loss": 0.4557,
      "step": 7742
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.8366438567689927,
      "learning_rate": 4.62201860244153e-06,
      "loss": 0.5141,
      "step": 7743
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.8732297707505392,
      "learning_rate": 4.620895815258662e-06,
      "loss": 0.4948,
      "step": 7744
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.8873557341091167,
      "learning_rate": 4.619773047302725e-06,
      "loss": 0.4503,
      "step": 7745
    },
    {
      "epoch": 0.54,
      "grad_norm": 3.509369684219352,
      "learning_rate": 4.618650298630658e-06,
      "loss": 0.5724,
      "step": 7746
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.813730568623831,
      "learning_rate": 4.617527569299406e-06,
      "loss": 0.537,
      "step": 7747
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.7944492047766756,
      "learning_rate": 4.6164048593659076e-06,
      "loss": 0.4772,
      "step": 7748
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.7817070214268382,
      "learning_rate": 4.615282168887104e-06,
      "loss": 0.5027,
      "step": 7749
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.4364114963421875,
      "learning_rate": 4.614159497919936e-06,
      "loss": 0.4875,
      "step": 7750
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.917566858670749,
      "learning_rate": 4.613036846521339e-06,
      "loss": 0.4954,
      "step": 7751
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.4144379521342207,
      "learning_rate": 4.61191421474825e-06,
      "loss": 0.5058,
      "step": 7752
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.9164521144757822,
      "learning_rate": 4.610791602657609e-06,
      "loss": 0.5251,
      "step": 7753
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.1616854486723187,
      "learning_rate": 4.609669010306349e-06,
      "loss": 0.5146,
      "step": 7754
    },
    {
      "epoch": 0.54,
      "grad_norm": 3.1867570853418576,
      "learning_rate": 4.608546437751404e-06,
      "loss": 0.5105,
      "step": 7755
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.8748678569017692,
      "learning_rate": 4.6074238850497076e-06,
      "loss": 0.5057,
      "step": 7756
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.8023353649856877,
      "learning_rate": 4.606301352258192e-06,
      "loss": 0.477,
      "step": 7757
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.227320479113617,
      "learning_rate": 4.605178839433788e-06,
      "loss": 0.4875,
      "step": 7758
    },
    {
      "epoch": 0.54,
      "grad_norm": 5.88512983094528,
      "learning_rate": 4.604056346633425e-06,
      "loss": 0.5164,
      "step": 7759
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.4959488249887958,
      "learning_rate": 4.602933873914034e-06,
      "loss": 0.5089,
      "step": 7760
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6307611382929933,
      "learning_rate": 4.601811421332543e-06,
      "loss": 0.4066,
      "step": 7761
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.99784308660331,
      "learning_rate": 4.6006889889458784e-06,
      "loss": 0.5147,
      "step": 7762
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.0586267107020335,
      "learning_rate": 4.599566576810966e-06,
      "loss": 0.4993,
      "step": 7763
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.9740074926503584,
      "learning_rate": 4.598444184984731e-06,
      "loss": 0.4853,
      "step": 7764
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.923991535153825,
      "learning_rate": 4.5973218135240985e-06,
      "loss": 0.5287,
      "step": 7765
    },
    {
      "epoch": 0.54,
      "grad_norm": 4.370109751683016,
      "learning_rate": 4.59619946248599e-06,
      "loss": 0.4475,
      "step": 7766
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.923911216292542,
      "learning_rate": 4.59507713192733e-06,
      "loss": 0.5161,
      "step": 7767
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.843707995837509,
      "learning_rate": 4.593954821905036e-06,
      "loss": 0.4666,
      "step": 7768
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.338190552760705,
      "learning_rate": 4.592832532476031e-06,
      "loss": 0.506,
      "step": 7769
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.9411214942740511,
      "learning_rate": 4.591710263697232e-06,
      "loss": 0.4749,
      "step": 7770
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.8467328196870585,
      "learning_rate": 4.5905880156255575e-06,
      "loss": 0.4967,
      "step": 7771
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.2123510577171657,
      "learning_rate": 4.589465788317923e-06,
      "loss": 0.5362,
      "step": 7772
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.9664108481860287,
      "learning_rate": 4.588343581831246e-06,
      "loss": 0.4741,
      "step": 7773
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5437425008032422,
      "learning_rate": 4.587221396222441e-06,
      "loss": 0.4459,
      "step": 7774
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.7917862613575057,
      "learning_rate": 4.586099231548421e-06,
      "loss": 0.4805,
      "step": 7775
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.7759173888859414,
      "learning_rate": 4.584977087866096e-06,
      "loss": 0.5047,
      "step": 7776
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.0066998832215925,
      "learning_rate": 4.583854965232383e-06,
      "loss": 0.5041,
      "step": 7777
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.8140116360892704,
      "learning_rate": 4.582732863704189e-06,
      "loss": 0.5082,
      "step": 7778
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.7195082585052759,
      "learning_rate": 4.581610783338424e-06,
      "loss": 0.5377,
      "step": 7779
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.9053535864774538,
      "learning_rate": 4.580488724191995e-06,
      "loss": 0.4609,
      "step": 7780
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.65168128443601,
      "learning_rate": 4.579366686321811e-06,
      "loss": 0.4387,
      "step": 7781
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.4019837240427018,
      "learning_rate": 4.5782446697847775e-06,
      "loss": 0.5237,
      "step": 7782
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.5512221499154424,
      "learning_rate": 4.5771226746377985e-06,
      "loss": 0.4746,
      "step": 7783
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5715474038130377,
      "learning_rate": 4.576000700937778e-06,
      "loss": 0.44,
      "step": 7784
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.9634034012826476,
      "learning_rate": 4.574878748741621e-06,
      "loss": 0.4943,
      "step": 7785
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.5781111304251032,
      "learning_rate": 4.573756818106228e-06,
      "loss": 0.4784,
      "step": 7786
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5413135837510259,
      "learning_rate": 4.5726349090885e-06,
      "loss": 0.4343,
      "step": 7787
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.024440995885246,
      "learning_rate": 4.571513021745334e-06,
      "loss": 0.5123,
      "step": 7788
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.5714548636001795,
      "learning_rate": 4.570391156133631e-06,
      "loss": 0.5071,
      "step": 7789
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.8724774700208522,
      "learning_rate": 4.56926931231029e-06,
      "loss": 0.534,
      "step": 7790
    },
    {
      "epoch": 0.54,
      "grad_norm": 115.73632425362004,
      "learning_rate": 4.568147490332203e-06,
      "loss": 0.5464,
      "step": 7791
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.6153520204167595,
      "learning_rate": 4.567025690256269e-06,
      "loss": 0.4978,
      "step": 7792
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6110690315031438,
      "learning_rate": 4.5659039121393805e-06,
      "loss": 0.4256,
      "step": 7793
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.7582709862311938,
      "learning_rate": 4.564782156038431e-06,
      "loss": 0.5279,
      "step": 7794
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.671516356060035,
      "learning_rate": 4.563660422010308e-06,
      "loss": 0.4557,
      "step": 7795
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.621374120394236,
      "learning_rate": 4.562538710111909e-06,
      "loss": 0.4134,
      "step": 7796
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.2371162666002857,
      "learning_rate": 4.561417020400119e-06,
      "loss": 0.4649,
      "step": 7797
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.7298628329214412,
      "learning_rate": 4.56029535293183e-06,
      "loss": 0.4909,
      "step": 7798
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.9715094585422115,
      "learning_rate": 4.559173707763924e-06,
      "loss": 0.5254,
      "step": 7799
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.9068602072234229,
      "learning_rate": 4.558052084953292e-06,
      "loss": 0.5208,
      "step": 7800
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.5988578816134418,
      "learning_rate": 4.556930484556818e-06,
      "loss": 0.5262,
      "step": 7801
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.7032047998735933,
      "learning_rate": 4.5558089066313855e-06,
      "loss": 0.4823,
      "step": 7802
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.5928965100997508,
      "learning_rate": 4.554687351233876e-06,
      "loss": 0.5093,
      "step": 7803
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.762494671538438,
      "learning_rate": 4.553565818421173e-06,
      "loss": 0.5235,
      "step": 7804
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.99409189703721,
      "learning_rate": 4.552444308250156e-06,
      "loss": 0.5509,
      "step": 7805
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.595150266363001,
      "learning_rate": 4.551322820777705e-06,
      "loss": 0.431,
      "step": 7806
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.8760416484035487,
      "learning_rate": 4.550201356060695e-06,
      "loss": 0.4469,
      "step": 7807
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.7507074170716461,
      "learning_rate": 4.549079914156009e-06,
      "loss": 0.5337,
      "step": 7808
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.982767476604193,
      "learning_rate": 4.5479584951205195e-06,
      "loss": 0.5185,
      "step": 7809
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.1319287513855634,
      "learning_rate": 4.546837099011101e-06,
      "loss": 0.501,
      "step": 7810
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.7510439690253747,
      "learning_rate": 4.545715725884625e-06,
      "loss": 0.5255,
      "step": 7811
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.2510649198266535,
      "learning_rate": 4.544594375797969e-06,
      "loss": 0.4826,
      "step": 7812
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.837781124258067,
      "learning_rate": 4.543473048808001e-06,
      "loss": 0.5044,
      "step": 7813
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.1124067107699243,
      "learning_rate": 4.542351744971592e-06,
      "loss": 0.4492,
      "step": 7814
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.8111242971449142,
      "learning_rate": 4.541230464345609e-06,
      "loss": 0.485,
      "step": 7815
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.042680207074821,
      "learning_rate": 4.540109206986923e-06,
      "loss": 0.5132,
      "step": 7816
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.080330705877619,
      "learning_rate": 4.538987972952398e-06,
      "loss": 0.4611,
      "step": 7817
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.0341950384921343,
      "learning_rate": 4.537866762298901e-06,
      "loss": 0.491,
      "step": 7818
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.861849574499071,
      "learning_rate": 4.536745575083291e-06,
      "loss": 0.5098,
      "step": 7819
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.222663210791851,
      "learning_rate": 4.5356244113624394e-06,
      "loss": 0.4857,
      "step": 7820
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.9002756518906667,
      "learning_rate": 4.534503271193202e-06,
      "loss": 0.4999,
      "step": 7821
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.566106189242374,
      "learning_rate": 4.533382154632442e-06,
      "loss": 0.5162,
      "step": 7822
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.5521387432824576,
      "learning_rate": 4.532261061737017e-06,
      "loss": 0.5084,
      "step": 7823
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.9447174914204974,
      "learning_rate": 4.531139992563788e-06,
      "loss": 0.535,
      "step": 7824
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.2497266218039,
      "learning_rate": 4.530018947169608e-06,
      "loss": 0.5192,
      "step": 7825
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.0254540023856498,
      "learning_rate": 4.528897925611335e-06,
      "loss": 0.4875,
      "step": 7826
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.2782086340551593,
      "learning_rate": 4.527776927945823e-06,
      "loss": 0.5413,
      "step": 7827
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.9537835324942743,
      "learning_rate": 4.526655954229926e-06,
      "loss": 0.5529,
      "step": 7828
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.7744460969117195,
      "learning_rate": 4.525535004520496e-06,
      "loss": 0.5123,
      "step": 7829
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5984099129075677,
      "learning_rate": 4.524414078874385e-06,
      "loss": 0.4403,
      "step": 7830
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.289785417504478,
      "learning_rate": 4.5232931773484385e-06,
      "loss": 0.5157,
      "step": 7831
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.8375085920224603,
      "learning_rate": 4.52217229999951e-06,
      "loss": 0.477,
      "step": 7832
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.7391907938871753,
      "learning_rate": 4.521051446884445e-06,
      "loss": 0.4777,
      "step": 7833
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.0915373536939206,
      "learning_rate": 4.519930618060088e-06,
      "loss": 0.4918,
      "step": 7834
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.7977325677298825,
      "learning_rate": 4.518809813583284e-06,
      "loss": 0.5076,
      "step": 7835
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.8710731811951413,
      "learning_rate": 4.517689033510881e-06,
      "loss": 0.5103,
      "step": 7836
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.325902168854332,
      "learning_rate": 4.516568277899715e-06,
      "loss": 0.4782,
      "step": 7837
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6514987672475898,
      "learning_rate": 4.5154475468066315e-06,
      "loss": 0.4417,
      "step": 7838
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.7029020559776429,
      "learning_rate": 4.514326840288466e-06,
      "loss": 0.4927,
      "step": 7839
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6341688259521256,
      "learning_rate": 4.513206158402061e-06,
      "loss": 0.4168,
      "step": 7840
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.7022127117150332,
      "learning_rate": 4.512085501204254e-06,
      "loss": 0.4623,
      "step": 7841
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.8937656077015579,
      "learning_rate": 4.510964868751879e-06,
      "loss": 0.5567,
      "step": 7842
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.3400127983661485,
      "learning_rate": 4.509844261101769e-06,
      "loss": 0.5138,
      "step": 7843
    },
    {
      "epoch": 0.55,
      "grad_norm": 6.664080695981853,
      "learning_rate": 4.508723678310763e-06,
      "loss": 0.4836,
      "step": 7844
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.9743360281913998,
      "learning_rate": 4.50760312043569e-06,
      "loss": 0.5455,
      "step": 7845
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.232337474449299,
      "learning_rate": 4.506482587533382e-06,
      "loss": 0.4657,
      "step": 7846
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.8870131896328162,
      "learning_rate": 4.5053620796606665e-06,
      "loss": 0.4831,
      "step": 7847
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.8806666853638951,
      "learning_rate": 4.504241596874375e-06,
      "loss": 0.4844,
      "step": 7848
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.7907802803447077,
      "learning_rate": 4.503121139231333e-06,
      "loss": 0.483,
      "step": 7849
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.5681398978569354,
      "learning_rate": 4.5020007067883675e-06,
      "loss": 0.5034,
      "step": 7850
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.188265451638499,
      "learning_rate": 4.500880299602301e-06,
      "loss": 0.5057,
      "step": 7851
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.7340413150309641,
      "learning_rate": 4.499759917729959e-06,
      "loss": 0.4796,
      "step": 7852
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.7909444486632353,
      "learning_rate": 4.498639561228164e-06,
      "loss": 0.4636,
      "step": 7853
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.1223338002929206,
      "learning_rate": 4.497519230153736e-06,
      "loss": 0.5187,
      "step": 7854
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.811738966281366,
      "learning_rate": 4.496398924563492e-06,
      "loss": 0.4741,
      "step": 7855
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.05600562514773,
      "learning_rate": 4.495278644514255e-06,
      "loss": 0.5316,
      "step": 7856
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.9212271009204196,
      "learning_rate": 4.49415839006284e-06,
      "loss": 0.4468,
      "step": 7857
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.7508345260117197,
      "learning_rate": 4.4930381612660605e-06,
      "loss": 0.5017,
      "step": 7858
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.628065146137538,
      "learning_rate": 4.491917958180734e-06,
      "loss": 0.4239,
      "step": 7859
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.9169337672229654,
      "learning_rate": 4.490797780863672e-06,
      "loss": 0.5122,
      "step": 7860
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.854379679971253,
      "learning_rate": 4.489677629371688e-06,
      "loss": 0.4504,
      "step": 7861
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.4686506822579317,
      "learning_rate": 4.488557503761588e-06,
      "loss": 0.4921,
      "step": 7862
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.7384931457583335,
      "learning_rate": 4.4874374040901855e-06,
      "loss": 0.4815,
      "step": 7863
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6402528186227323,
      "learning_rate": 4.486317330414287e-06,
      "loss": 0.4416,
      "step": 7864
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.0774858631223054,
      "learning_rate": 4.485197282790698e-06,
      "loss": 0.4732,
      "step": 7865
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.5148490301279087,
      "learning_rate": 4.484077261276224e-06,
      "loss": 0.4978,
      "step": 7866
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.7236434781515446,
      "learning_rate": 4.48295726592767e-06,
      "loss": 0.5127,
      "step": 7867
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.8330562630630656,
      "learning_rate": 4.481837296801839e-06,
      "loss": 0.4995,
      "step": 7868
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.2159719265793396,
      "learning_rate": 4.48071735395553e-06,
      "loss": 0.5229,
      "step": 7869
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.890535855573964,
      "learning_rate": 4.479597437445544e-06,
      "loss": 0.4777,
      "step": 7870
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.9699448754892734,
      "learning_rate": 4.47847754732868e-06,
      "loss": 0.4973,
      "step": 7871
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.6539842453541858,
      "learning_rate": 4.477357683661734e-06,
      "loss": 0.4991,
      "step": 7872
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.8225240632254374,
      "learning_rate": 4.476237846501502e-06,
      "loss": 0.5004,
      "step": 7873
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.7814745364544746,
      "learning_rate": 4.475118035904778e-06,
      "loss": 0.4832,
      "step": 7874
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.0912102310338603,
      "learning_rate": 4.473998251928357e-06,
      "loss": 0.5073,
      "step": 7875
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.491949473316509,
      "learning_rate": 4.4728784946290305e-06,
      "loss": 0.4918,
      "step": 7876
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5848500898676552,
      "learning_rate": 4.471758764063588e-06,
      "loss": 0.4199,
      "step": 7877
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.0622637976883444,
      "learning_rate": 4.470639060288818e-06,
      "loss": 0.5144,
      "step": 7878
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.6565127959535557,
      "learning_rate": 4.469519383361508e-06,
      "loss": 0.5288,
      "step": 7879
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.0427512943549972,
      "learning_rate": 4.468399733338447e-06,
      "loss": 0.5506,
      "step": 7880
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.1992913193641868,
      "learning_rate": 4.4672801102764195e-06,
      "loss": 0.508,
      "step": 7881
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.830141547310383,
      "learning_rate": 4.466160514232206e-06,
      "loss": 0.468,
      "step": 7882
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.7150379280743757,
      "learning_rate": 4.465040945262592e-06,
      "loss": 0.4791,
      "step": 7883
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.1439147753520977,
      "learning_rate": 4.463921403424357e-06,
      "loss": 0.4929,
      "step": 7884
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.7084816102456544,
      "learning_rate": 4.462801888774281e-06,
      "loss": 0.5285,
      "step": 7885
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.2815721962820663,
      "learning_rate": 4.4616824013691395e-06,
      "loss": 0.4744,
      "step": 7886
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.0261953489077644,
      "learning_rate": 4.4605629412657145e-06,
      "loss": 0.4758,
      "step": 7887
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.154721292001802,
      "learning_rate": 4.459443508520778e-06,
      "loss": 0.5275,
      "step": 7888
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.606743143364294,
      "learning_rate": 4.458324103191103e-06,
      "loss": 0.4267,
      "step": 7889
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.32359617738304,
      "learning_rate": 4.4572047253334645e-06,
      "loss": 0.4748,
      "step": 7890
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.7951124335490507,
      "learning_rate": 4.456085375004633e-06,
      "loss": 0.5223,
      "step": 7891
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.342072797301485,
      "learning_rate": 4.454966052261378e-06,
      "loss": 0.4737,
      "step": 7892
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.59839063333627,
      "learning_rate": 4.4538467571604676e-06,
      "loss": 0.4728,
      "step": 7893
    },
    {
      "epoch": 0.55,
      "grad_norm": 3.1630472704227284,
      "learning_rate": 4.452727489758668e-06,
      "loss": 0.5143,
      "step": 7894
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.1083151052044915,
      "learning_rate": 4.451608250112747e-06,
      "loss": 0.5224,
      "step": 7895
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.7505840553144199,
      "learning_rate": 4.450489038279468e-06,
      "loss": 0.5451,
      "step": 7896
    },
    {
      "epoch": 0.55,
      "grad_norm": 7.280681742513218,
      "learning_rate": 4.449369854315594e-06,
      "loss": 0.5049,
      "step": 7897
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.469067639445254,
      "learning_rate": 4.448250698277883e-06,
      "loss": 0.5348,
      "step": 7898
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.2416744035978344,
      "learning_rate": 4.447131570223099e-06,
      "loss": 0.56,
      "step": 7899
    },
    {
      "epoch": 0.55,
      "grad_norm": 4.519031663504196,
      "learning_rate": 4.446012470208001e-06,
      "loss": 0.4853,
      "step": 7900
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.9170707279473387,
      "learning_rate": 4.4448933982893435e-06,
      "loss": 0.5028,
      "step": 7901
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.543150821687197,
      "learning_rate": 4.443774354523883e-06,
      "loss": 0.4776,
      "step": 7902
    },
    {
      "epoch": 0.55,
      "grad_norm": 10.737001074466226,
      "learning_rate": 4.442655338968373e-06,
      "loss": 0.5028,
      "step": 7903
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.8313169475279143,
      "learning_rate": 4.441536351679569e-06,
      "loss": 0.4914,
      "step": 7904
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.8241288932793034,
      "learning_rate": 4.44041739271422e-06,
      "loss": 0.5129,
      "step": 7905
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.8807001296451993,
      "learning_rate": 4.439298462129074e-06,
      "loss": 0.5004,
      "step": 7906
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.6257510511296949,
      "learning_rate": 4.438179559980885e-06,
      "loss": 0.4691,
      "step": 7907
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.9404665828867387,
      "learning_rate": 4.437060686326397e-06,
      "loss": 0.4886,
      "step": 7908
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.3675965119848135,
      "learning_rate": 4.435941841222354e-06,
      "loss": 0.5044,
      "step": 7909
    },
    {
      "epoch": 0.55,
      "grad_norm": 20.534240824711222,
      "learning_rate": 4.4348230247255015e-06,
      "loss": 0.4629,
      "step": 7910
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.8465198311394089,
      "learning_rate": 4.433704236892584e-06,
      "loss": 0.469,
      "step": 7911
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.8421346738714055,
      "learning_rate": 4.432585477780342e-06,
      "loss": 0.5188,
      "step": 7912
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.074980475434834,
      "learning_rate": 4.431466747445514e-06,
      "loss": 0.4813,
      "step": 7913
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.8545817508080757,
      "learning_rate": 4.4303480459448384e-06,
      "loss": 0.5052,
      "step": 7914
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.210168035242641,
      "learning_rate": 4.429229373335054e-06,
      "loss": 0.4657,
      "step": 7915
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.531072622062595,
      "learning_rate": 4.428110729672894e-06,
      "loss": 0.4682,
      "step": 7916
    },
    {
      "epoch": 0.55,
      "grad_norm": 3.3834387966510904,
      "learning_rate": 4.426992115015094e-06,
      "loss": 0.4648,
      "step": 7917
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.9741341462875215,
      "learning_rate": 4.425873529418384e-06,
      "loss": 0.4998,
      "step": 7918
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.3176870987399054,
      "learning_rate": 4.424754972939498e-06,
      "loss": 0.4921,
      "step": 7919
    },
    {
      "epoch": 0.55,
      "grad_norm": 3.0550884296627325,
      "learning_rate": 4.423636445635165e-06,
      "loss": 0.5408,
      "step": 7920
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.678120785341099,
      "learning_rate": 4.42251794756211e-06,
      "loss": 0.4459,
      "step": 7921
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.110950338852139,
      "learning_rate": 4.421399478777064e-06,
      "loss": 0.459,
      "step": 7922
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.6605031255843037,
      "learning_rate": 4.420281039336751e-06,
      "loss": 0.4764,
      "step": 7923
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.9739740308389977,
      "learning_rate": 4.419162629297894e-06,
      "loss": 0.5145,
      "step": 7924
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.9882008708003616,
      "learning_rate": 4.418044248717212e-06,
      "loss": 0.4699,
      "step": 7925
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.966849743431367,
      "learning_rate": 4.41692589765143e-06,
      "loss": 0.4874,
      "step": 7926
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.5824145821225806,
      "learning_rate": 4.415807576157267e-06,
      "loss": 0.4894,
      "step": 7927
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.8954583676795753,
      "learning_rate": 4.414689284291438e-06,
      "loss": 0.5059,
      "step": 7928
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.2804036927986595,
      "learning_rate": 4.413571022110658e-06,
      "loss": 0.4649,
      "step": 7929
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.436710121539399,
      "learning_rate": 4.4124527896716466e-06,
      "loss": 0.5122,
      "step": 7930
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.229374258771052,
      "learning_rate": 4.411334587031113e-06,
      "loss": 0.485,
      "step": 7931
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.578350974557961,
      "learning_rate": 4.410216414245771e-06,
      "loss": 0.5369,
      "step": 7932
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.8228073503768103,
      "learning_rate": 4.409098271372328e-06,
      "loss": 0.5598,
      "step": 7933
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.8134740231662203,
      "learning_rate": 4.4079801584674955e-06,
      "loss": 0.4937,
      "step": 7934
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.1172089718781986,
      "learning_rate": 4.40686207558798e-06,
      "loss": 0.4812,
      "step": 7935
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.347490924533813,
      "learning_rate": 4.405744022790485e-06,
      "loss": 0.5308,
      "step": 7936
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.1274061104303224,
      "learning_rate": 4.404626000131716e-06,
      "loss": 0.4911,
      "step": 7937
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.9406489719739572,
      "learning_rate": 4.403508007668375e-06,
      "loss": 0.5413,
      "step": 7938
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.6539503932859052,
      "learning_rate": 4.402390045457165e-06,
      "loss": 0.5423,
      "step": 7939
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.264245485120108,
      "learning_rate": 4.401272113554782e-06,
      "loss": 0.4597,
      "step": 7940
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.9876128011914411,
      "learning_rate": 4.400154212017923e-06,
      "loss": 0.5271,
      "step": 7941
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.7060554941634765,
      "learning_rate": 4.39903634090329e-06,
      "loss": 0.503,
      "step": 7942
    },
    {
      "epoch": 0.55,
      "grad_norm": 3.6528377923434627,
      "learning_rate": 4.397918500267575e-06,
      "loss": 0.4566,
      "step": 7943
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.7100020661122621,
      "learning_rate": 4.39680069016747e-06,
      "loss": 0.5016,
      "step": 7944
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.844440455891037,
      "learning_rate": 4.395682910659666e-06,
      "loss": 0.5107,
      "step": 7945
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.8900369807401212,
      "learning_rate": 4.3945651618008565e-06,
      "loss": 0.493,
      "step": 7946
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.9917869820734186,
      "learning_rate": 4.393447443647726e-06,
      "loss": 0.5275,
      "step": 7947
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.7936214717301477,
      "learning_rate": 4.3923297562569655e-06,
      "loss": 0.5048,
      "step": 7948
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.003711645756866,
      "learning_rate": 4.391212099685258e-06,
      "loss": 0.5141,
      "step": 7949
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.81392208288795,
      "learning_rate": 4.390094473989288e-06,
      "loss": 0.4498,
      "step": 7950
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.5632699168799787,
      "learning_rate": 4.388976879225739e-06,
      "loss": 0.4662,
      "step": 7951
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.7290253197116732,
      "learning_rate": 4.38785931545129e-06,
      "loss": 0.4818,
      "step": 7952
    },
    {
      "epoch": 0.55,
      "grad_norm": 12.841416928861886,
      "learning_rate": 4.386741782722618e-06,
      "loss": 0.5307,
      "step": 7953
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.2391178540299843,
      "learning_rate": 4.385624281096407e-06,
      "loss": 0.5229,
      "step": 7954
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.6696770996086983,
      "learning_rate": 4.384506810629329e-06,
      "loss": 0.5064,
      "step": 7955
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.021963682802331,
      "learning_rate": 4.383389371378059e-06,
      "loss": 0.4725,
      "step": 7956
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.5950807842643733,
      "learning_rate": 4.382271963399268e-06,
      "loss": 0.46,
      "step": 7957
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.159002881665636,
      "learning_rate": 4.381154586749631e-06,
      "loss": 0.5389,
      "step": 7958
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.8607153353783359,
      "learning_rate": 4.380037241485815e-06,
      "loss": 0.4674,
      "step": 7959
    },
    {
      "epoch": 0.55,
      "grad_norm": 3.4084431391379004,
      "learning_rate": 4.37891992766449e-06,
      "loss": 0.4985,
      "step": 7960
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.03653404814129,
      "learning_rate": 4.377802645342318e-06,
      "loss": 0.4948,
      "step": 7961
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.5781522122342904,
      "learning_rate": 4.376685394575971e-06,
      "loss": 0.5338,
      "step": 7962
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.7721008898768333,
      "learning_rate": 4.375568175422108e-06,
      "loss": 0.5036,
      "step": 7963
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.8316263553145196,
      "learning_rate": 4.374450987937391e-06,
      "loss": 0.5068,
      "step": 7964
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.789032440134031,
      "learning_rate": 4.373333832178478e-06,
      "loss": 0.5262,
      "step": 7965
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.8003949736701583,
      "learning_rate": 4.372216708202034e-06,
      "loss": 0.5053,
      "step": 7966
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.7582702537243398,
      "learning_rate": 4.37109961606471e-06,
      "loss": 0.4568,
      "step": 7967
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.9555814940493148,
      "learning_rate": 4.3699825558231636e-06,
      "loss": 0.467,
      "step": 7968
    },
    {
      "epoch": 0.55,
      "grad_norm": 4.127007138272918,
      "learning_rate": 4.368865527534047e-06,
      "loss": 0.5366,
      "step": 7969
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.7298592235327641,
      "learning_rate": 4.367748531254015e-06,
      "loss": 0.4785,
      "step": 7970
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.572819555772298,
      "learning_rate": 4.366631567039715e-06,
      "loss": 0.417,
      "step": 7971
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.736568782908061,
      "learning_rate": 4.365514634947798e-06,
      "loss": 0.5122,
      "step": 7972
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.0638023020105356,
      "learning_rate": 4.364397735034908e-06,
      "loss": 0.4645,
      "step": 7973
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.185589263456468,
      "learning_rate": 4.363280867357694e-06,
      "loss": 0.4706,
      "step": 7974
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.295506748955258,
      "learning_rate": 4.362164031972799e-06,
      "loss": 0.4921,
      "step": 7975
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.6745602546928001,
      "learning_rate": 4.361047228936865e-06,
      "loss": 0.4474,
      "step": 7976
    },
    {
      "epoch": 0.55,
      "grad_norm": 3.274092510731135,
      "learning_rate": 4.35993045830653e-06,
      "loss": 0.4645,
      "step": 7977
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.7337685159894396,
      "learning_rate": 4.358813720138438e-06,
      "loss": 0.544,
      "step": 7978
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.116165986522326,
      "learning_rate": 4.3576970144892236e-06,
      "loss": 0.5212,
      "step": 7979
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.1091794788503426,
      "learning_rate": 4.356580341415522e-06,
      "loss": 0.5288,
      "step": 7980
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.1740885893607667,
      "learning_rate": 4.355463700973968e-06,
      "loss": 0.541,
      "step": 7981
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.8355795407652133,
      "learning_rate": 4.354347093221194e-06,
      "loss": 0.5225,
      "step": 7982
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.7647577578398694,
      "learning_rate": 4.35323051821383e-06,
      "loss": 0.5562,
      "step": 7983
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6990309589303548,
      "learning_rate": 4.352113976008504e-06,
      "loss": 0.4333,
      "step": 7984
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.9075075113382556,
      "learning_rate": 4.350997466661847e-06,
      "loss": 0.4965,
      "step": 7985
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.9263800514651763,
      "learning_rate": 4.349880990230483e-06,
      "loss": 0.4902,
      "step": 7986
    },
    {
      "epoch": 0.56,
      "grad_norm": 3.473791915220024,
      "learning_rate": 4.348764546771035e-06,
      "loss": 0.5175,
      "step": 7987
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.6483091707950666,
      "learning_rate": 4.347648136340124e-06,
      "loss": 0.5143,
      "step": 7988
    },
    {
      "epoch": 0.56,
      "grad_norm": 4.547883755723075,
      "learning_rate": 4.346531758994375e-06,
      "loss": 0.4985,
      "step": 7989
    },
    {
      "epoch": 0.56,
      "grad_norm": 5.187657526295934,
      "learning_rate": 4.345415414790405e-06,
      "loss": 0.5096,
      "step": 7990
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.6276666915336064,
      "learning_rate": 4.344299103784831e-06,
      "loss": 0.4824,
      "step": 7991
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.8648731814567625,
      "learning_rate": 4.343182826034268e-06,
      "loss": 0.5023,
      "step": 7992
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.0597301481979104,
      "learning_rate": 4.342066581595331e-06,
      "loss": 0.5078,
      "step": 7993
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.1598362964023146,
      "learning_rate": 4.3409503705246325e-06,
      "loss": 0.4914,
      "step": 7994
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.7628474068463755,
      "learning_rate": 4.339834192878782e-06,
      "loss": 0.4703,
      "step": 7995
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.0705063096300336,
      "learning_rate": 4.3387180487143875e-06,
      "loss": 0.5378,
      "step": 7996
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.5778064230268534,
      "learning_rate": 4.33760193808806e-06,
      "loss": 0.5416,
      "step": 7997
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.6869865043133727,
      "learning_rate": 4.336485861056402e-06,
      "loss": 0.4918,
      "step": 7998
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.2856351007347007,
      "learning_rate": 4.335369817676018e-06,
      "loss": 0.4926,
      "step": 7999
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.577750133767391,
      "learning_rate": 4.334253808003508e-06,
      "loss": 0.4332,
      "step": 8000
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.6589835258226104,
      "learning_rate": 4.333137832095477e-06,
      "loss": 0.4833,
      "step": 8001
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.6471844549417018,
      "learning_rate": 4.33202189000852e-06,
      "loss": 0.501,
      "step": 8002
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.9183200365452395,
      "learning_rate": 4.3309059817992365e-06,
      "loss": 0.5091,
      "step": 8003
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.0299612988902624,
      "learning_rate": 4.329790107524218e-06,
      "loss": 0.4997,
      "step": 8004
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.6710912323089553,
      "learning_rate": 4.3286742672400615e-06,
      "loss": 0.4839,
      "step": 8005
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.8108729786127318,
      "learning_rate": 4.3275584610033575e-06,
      "loss": 0.5122,
      "step": 8006
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.6823777585108186,
      "learning_rate": 4.326442688870697e-06,
      "loss": 0.4868,
      "step": 8007
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.0961586413422646,
      "learning_rate": 4.325326950898664e-06,
      "loss": 0.4944,
      "step": 8008
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.1032037599731486,
      "learning_rate": 4.3242112471438515e-06,
      "loss": 0.5021,
      "step": 8009
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.557346380576572,
      "learning_rate": 4.323095577662841e-06,
      "loss": 0.4457,
      "step": 8010
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.3442464412566566,
      "learning_rate": 4.321979942512216e-06,
      "loss": 0.4864,
      "step": 8011
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.7451778669839864,
      "learning_rate": 4.320864341748557e-06,
      "loss": 0.4815,
      "step": 8012
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.050735412138143,
      "learning_rate": 4.3197487754284444e-06,
      "loss": 0.4902,
      "step": 8013
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.8932985140224563,
      "learning_rate": 4.318633243608457e-06,
      "loss": 0.5056,
      "step": 8014
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.448217412462941,
      "learning_rate": 4.31751774634517e-06,
      "loss": 0.5434,
      "step": 8015
    },
    {
      "epoch": 0.56,
      "grad_norm": 8.115392674256213,
      "learning_rate": 4.316402283695156e-06,
      "loss": 0.5406,
      "step": 8016
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.028586451292692,
      "learning_rate": 4.315286855714992e-06,
      "loss": 0.4919,
      "step": 8017
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.957021826649403,
      "learning_rate": 4.314171462461246e-06,
      "loss": 0.5245,
      "step": 8018
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.349637735573736,
      "learning_rate": 4.313056103990487e-06,
      "loss": 0.5032,
      "step": 8019
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.996532847773788,
      "learning_rate": 4.311940780359281e-06,
      "loss": 0.4831,
      "step": 8020
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.7950410887719959,
      "learning_rate": 4.310825491624198e-06,
      "loss": 0.4702,
      "step": 8021
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.7464465510143803,
      "learning_rate": 4.3097102378417985e-06,
      "loss": 0.5022,
      "step": 8022
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.9356335996092473,
      "learning_rate": 4.308595019068646e-06,
      "loss": 0.4824,
      "step": 8023
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.8318350495315017,
      "learning_rate": 4.307479835361298e-06,
      "loss": 0.5185,
      "step": 8024
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.4592005639315078,
      "learning_rate": 4.3063646867763175e-06,
      "loss": 0.5485,
      "step": 8025
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.256912596550646,
      "learning_rate": 4.305249573370258e-06,
      "loss": 0.4815,
      "step": 8026
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.089448212456061,
      "learning_rate": 4.304134495199675e-06,
      "loss": 0.4782,
      "step": 8027
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.189112011635027,
      "learning_rate": 4.3030194523211195e-06,
      "loss": 0.5583,
      "step": 8028
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.1292591553459514,
      "learning_rate": 4.301904444791147e-06,
      "loss": 0.4697,
      "step": 8029
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.980025200868996,
      "learning_rate": 4.300789472666306e-06,
      "loss": 0.478,
      "step": 8030
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6051679251724095,
      "learning_rate": 4.299674536003142e-06,
      "loss": 0.4303,
      "step": 8031
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.788511997711796,
      "learning_rate": 4.298559634858202e-06,
      "loss": 0.4694,
      "step": 8032
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.7894939874926163,
      "learning_rate": 4.297444769288031e-06,
      "loss": 0.4966,
      "step": 8033
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.134342309934255,
      "learning_rate": 4.296329939349172e-06,
      "loss": 0.4657,
      "step": 8034
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.6414070267169587,
      "learning_rate": 4.295215145098164e-06,
      "loss": 0.4924,
      "step": 8035
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.6464646431122039,
      "learning_rate": 4.2941003865915445e-06,
      "loss": 0.55,
      "step": 8036
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5992508536003013,
      "learning_rate": 4.292985663885854e-06,
      "loss": 0.4338,
      "step": 8037
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.067963156183477,
      "learning_rate": 4.291870977037625e-06,
      "loss": 0.5557,
      "step": 8038
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.1144335290824197,
      "learning_rate": 4.290756326103392e-06,
      "loss": 0.4697,
      "step": 8039
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.9522301605960337,
      "learning_rate": 4.289641711139683e-06,
      "loss": 0.5214,
      "step": 8040
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.897869707215662,
      "learning_rate": 4.288527132203033e-06,
      "loss": 0.5352,
      "step": 8041
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.8665065164156016,
      "learning_rate": 4.287412589349967e-06,
      "loss": 0.507,
      "step": 8042
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.4370735909162833,
      "learning_rate": 4.286298082637012e-06,
      "loss": 0.5099,
      "step": 8043
    },
    {
      "epoch": 0.56,
      "grad_norm": 3.7323863538001167,
      "learning_rate": 4.285183612120689e-06,
      "loss": 0.5027,
      "step": 8044
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.183615291265198,
      "learning_rate": 4.284069177857525e-06,
      "loss": 0.4762,
      "step": 8045
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.7096065579200657,
      "learning_rate": 4.282954779904038e-06,
      "loss": 0.4747,
      "step": 8046
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.854265874644362,
      "learning_rate": 4.2818404183167455e-06,
      "loss": 0.514,
      "step": 8047
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.41345309680185,
      "learning_rate": 4.280726093152167e-06,
      "loss": 0.4609,
      "step": 8048
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.4242885903554128,
      "learning_rate": 4.2796118044668165e-06,
      "loss": 0.4829,
      "step": 8049
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.280642431136561,
      "learning_rate": 4.2784975523172064e-06,
      "loss": 0.4684,
      "step": 8050
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.0487265545707327,
      "learning_rate": 4.277383336759846e-06,
      "loss": 0.5005,
      "step": 8051
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.091476442934179,
      "learning_rate": 4.2762691578512485e-06,
      "loss": 0.4983,
      "step": 8052
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.8819204254015105,
      "learning_rate": 4.27515501564792e-06,
      "loss": 0.5191,
      "step": 8053
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.156411115898205,
      "learning_rate": 4.2740409102063665e-06,
      "loss": 0.4619,
      "step": 8054
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.9567972201577457,
      "learning_rate": 4.2729268415830895e-06,
      "loss": 0.5029,
      "step": 8055
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.26783086351168,
      "learning_rate": 4.271812809834594e-06,
      "loss": 0.456,
      "step": 8056
    },
    {
      "epoch": 0.56,
      "grad_norm": 3.7272124774888717,
      "learning_rate": 4.270698815017379e-06,
      "loss": 0.5427,
      "step": 8057
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6682061123020692,
      "learning_rate": 4.269584857187942e-06,
      "loss": 0.4305,
      "step": 8058
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.5435622452198365,
      "learning_rate": 4.26847093640278e-06,
      "loss": 0.4957,
      "step": 8059
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.7008070453234172,
      "learning_rate": 4.267357052718387e-06,
      "loss": 0.4328,
      "step": 8060
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.3923824549123136,
      "learning_rate": 4.266243206191256e-06,
      "loss": 0.4735,
      "step": 8061
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.7522265859283659,
      "learning_rate": 4.265129396877878e-06,
      "loss": 0.4342,
      "step": 8062
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.8252282050448292,
      "learning_rate": 4.264015624834738e-06,
      "loss": 0.4944,
      "step": 8063
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.4781514431096485,
      "learning_rate": 4.26290189011833e-06,
      "loss": 0.4831,
      "step": 8064
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.34669696647465,
      "learning_rate": 4.261788192785133e-06,
      "loss": 0.4737,
      "step": 8065
    },
    {
      "epoch": 0.56,
      "grad_norm": 3.1577666296566353,
      "learning_rate": 4.2606745328916335e-06,
      "loss": 0.5045,
      "step": 8066
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.0443557850144365,
      "learning_rate": 4.2595609104943095e-06,
      "loss": 0.5013,
      "step": 8067
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.9340226996155478,
      "learning_rate": 4.258447325649643e-06,
      "loss": 0.4847,
      "step": 8068
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.9868913108830577,
      "learning_rate": 4.25733377841411e-06,
      "loss": 0.4476,
      "step": 8069
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.9828304096206568,
      "learning_rate": 4.256220268844188e-06,
      "loss": 0.5315,
      "step": 8070
    },
    {
      "epoch": 0.56,
      "grad_norm": 3.300538867394782,
      "learning_rate": 4.255106796996348e-06,
      "loss": 0.4637,
      "step": 8071
    },
    {
      "epoch": 0.56,
      "grad_norm": 9.185981911989648,
      "learning_rate": 4.253993362927063e-06,
      "loss": 0.5107,
      "step": 8072
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.8393525159980548,
      "learning_rate": 4.2528799666928034e-06,
      "loss": 0.4597,
      "step": 8073
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.7475364656078267,
      "learning_rate": 4.251766608350035e-06,
      "loss": 0.4398,
      "step": 8074
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.310565745497033,
      "learning_rate": 4.250653287955224e-06,
      "loss": 0.4896,
      "step": 8075
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5624248961158318,
      "learning_rate": 4.249540005564837e-06,
      "loss": 0.4596,
      "step": 8076
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.6120257794720554,
      "learning_rate": 4.2484267612353335e-06,
      "loss": 0.4681,
      "step": 8077
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.140585175757615,
      "learning_rate": 4.247313555023175e-06,
      "loss": 0.5158,
      "step": 8078
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.8959462952323773,
      "learning_rate": 4.246200386984818e-06,
      "loss": 0.4612,
      "step": 8079
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.016341023183059,
      "learning_rate": 4.245087257176721e-06,
      "loss": 0.4595,
      "step": 8080
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.027144394516813,
      "learning_rate": 4.243974165655336e-06,
      "loss": 0.5057,
      "step": 8081
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.8641062006219293,
      "learning_rate": 4.2428611124771184e-06,
      "loss": 0.5241,
      "step": 8082
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5681318295407656,
      "learning_rate": 4.241748097698514e-06,
      "loss": 0.4158,
      "step": 8083
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.5971276784410362,
      "learning_rate": 4.240635121375975e-06,
      "loss": 0.4885,
      "step": 8084
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.005481419459282,
      "learning_rate": 4.239522183565949e-06,
      "loss": 0.523,
      "step": 8085
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.6544398893699253,
      "learning_rate": 4.238409284324877e-06,
      "loss": 0.5091,
      "step": 8086
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.48879295620817,
      "learning_rate": 4.2372964237092015e-06,
      "loss": 0.522,
      "step": 8087
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.0934721034374193,
      "learning_rate": 4.2361836017753675e-06,
      "loss": 0.4931,
      "step": 8088
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.44519506793349,
      "learning_rate": 4.23507081857981e-06,
      "loss": 0.559,
      "step": 8089
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.8936939037091944,
      "learning_rate": 4.233958074178968e-06,
      "loss": 0.46,
      "step": 8090
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.9506078177232986,
      "learning_rate": 4.232845368629273e-06,
      "loss": 0.4685,
      "step": 8091
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.5275602338366365,
      "learning_rate": 4.2317327019871614e-06,
      "loss": 0.4789,
      "step": 8092
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.7871522712224914,
      "learning_rate": 4.230620074309062e-06,
      "loss": 0.5135,
      "step": 8093
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.086854573798849,
      "learning_rate": 4.229507485651404e-06,
      "loss": 0.4559,
      "step": 8094
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.0621978646407864,
      "learning_rate": 4.228394936070613e-06,
      "loss": 0.4975,
      "step": 8095
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.8961299024586538,
      "learning_rate": 4.227282425623117e-06,
      "loss": 0.5157,
      "step": 8096
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.7763637511307244,
      "learning_rate": 4.226169954365337e-06,
      "loss": 0.4887,
      "step": 8097
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.6616966979429852,
      "learning_rate": 4.225057522353694e-06,
      "loss": 0.4695,
      "step": 8098
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.1624912944707093,
      "learning_rate": 4.223945129644606e-06,
      "loss": 0.4816,
      "step": 8099
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.7859859452196836,
      "learning_rate": 4.222832776294491e-06,
      "loss": 0.5078,
      "step": 8100
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.1871277218293823,
      "learning_rate": 4.221720462359765e-06,
      "loss": 0.4934,
      "step": 8101
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.6255189958753526,
      "learning_rate": 4.22060818789684e-06,
      "loss": 0.4836,
      "step": 8102
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.263829020426756,
      "learning_rate": 4.219495952962126e-06,
      "loss": 0.5299,
      "step": 8103
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.9464614043262403,
      "learning_rate": 4.218383757612033e-06,
      "loss": 0.5035,
      "step": 8104
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.3825716303270585,
      "learning_rate": 4.217271601902968e-06,
      "loss": 0.5059,
      "step": 8105
    },
    {
      "epoch": 0.56,
      "grad_norm": 3.5223484377745105,
      "learning_rate": 4.216159485891336e-06,
      "loss": 0.5044,
      "step": 8106
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.9334319755699343,
      "learning_rate": 4.2150474096335356e-06,
      "loss": 0.4839,
      "step": 8107
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.2113991802668465,
      "learning_rate": 4.213935373185975e-06,
      "loss": 0.5062,
      "step": 8108
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.6557382405626964,
      "learning_rate": 4.21282337660505e-06,
      "loss": 0.5438,
      "step": 8109
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.1000409170355017,
      "learning_rate": 4.211711419947156e-06,
      "loss": 0.4687,
      "step": 8110
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.6685977783254662,
      "learning_rate": 4.210599503268686e-06,
      "loss": 0.4561,
      "step": 8111
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.178740133494568,
      "learning_rate": 4.209487626626039e-06,
      "loss": 0.511,
      "step": 8112
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.8181356682282133,
      "learning_rate": 4.208375790075603e-06,
      "loss": 0.4833,
      "step": 8113
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.8900519698727178,
      "learning_rate": 4.2072639936737635e-06,
      "loss": 0.4965,
      "step": 8114
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.7016598547838262,
      "learning_rate": 4.206152237476912e-06,
      "loss": 0.521,
      "step": 8115
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.6924306660267272,
      "learning_rate": 4.20504052154143e-06,
      "loss": 0.4715,
      "step": 8116
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.6925912063042265,
      "learning_rate": 4.203928845923701e-06,
      "loss": 0.4555,
      "step": 8117
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.825167124461871,
      "learning_rate": 4.202817210680103e-06,
      "loss": 0.4716,
      "step": 8118
    },
    {
      "epoch": 0.56,
      "grad_norm": 7.515752542172968,
      "learning_rate": 4.201705615867021e-06,
      "loss": 0.5012,
      "step": 8119
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.175648407800248,
      "learning_rate": 4.200594061540827e-06,
      "loss": 0.4911,
      "step": 8120
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.7685515492406234,
      "learning_rate": 4.199482547757895e-06,
      "loss": 0.4924,
      "step": 8121
    },
    {
      "epoch": 0.56,
      "grad_norm": 3.272702385293702,
      "learning_rate": 4.198371074574597e-06,
      "loss": 0.5052,
      "step": 8122
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.185764560014124,
      "learning_rate": 4.197259642047306e-06,
      "loss": 0.5123,
      "step": 8123
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.4939802843407533,
      "learning_rate": 4.19614825023239e-06,
      "loss": 0.4827,
      "step": 8124
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.9527456880949405,
      "learning_rate": 4.195036899186213e-06,
      "loss": 0.4924,
      "step": 8125
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.8590160016275104,
      "learning_rate": 4.19392558896514e-06,
      "loss": 0.5121,
      "step": 8126
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.4118509155045214,
      "learning_rate": 4.192814319625534e-06,
      "loss": 0.4675,
      "step": 8127
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.88133012292411,
      "learning_rate": 4.191703091223753e-06,
      "loss": 0.492,
      "step": 8128
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.121850935306267,
      "learning_rate": 4.190591903816157e-06,
      "loss": 0.49,
      "step": 8129
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.4145979794816124,
      "learning_rate": 4.189480757459099e-06,
      "loss": 0.5193,
      "step": 8130
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.5933103434713136,
      "learning_rate": 4.188369652208936e-06,
      "loss": 0.4632,
      "step": 8131
    },
    {
      "epoch": 0.57,
      "grad_norm": 3.516613829970621,
      "learning_rate": 4.187258588122019e-06,
      "loss": 0.4701,
      "step": 8132
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.7690776351753166,
      "learning_rate": 4.186147565254696e-06,
      "loss": 0.5038,
      "step": 8133
    },
    {
      "epoch": 0.57,
      "grad_norm": 7.587690094244031,
      "learning_rate": 4.185036583663314e-06,
      "loss": 0.4987,
      "step": 8134
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.045995451735886,
      "learning_rate": 4.183925643404222e-06,
      "loss": 0.5034,
      "step": 8135
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.575838641112433,
      "learning_rate": 4.182814744533758e-06,
      "loss": 0.4391,
      "step": 8136
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.650586814963235,
      "learning_rate": 4.181703887108268e-06,
      "loss": 0.5367,
      "step": 8137
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.7871561865794519,
      "learning_rate": 4.180593071184087e-06,
      "loss": 0.4833,
      "step": 8138
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.6916424725369588,
      "learning_rate": 4.179482296817557e-06,
      "loss": 0.5107,
      "step": 8139
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.627186518388243,
      "learning_rate": 4.178371564065008e-06,
      "loss": 0.5403,
      "step": 8140
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.6353760016192032,
      "learning_rate": 4.177260872982774e-06,
      "loss": 0.5146,
      "step": 8141
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.2254379358927325,
      "learning_rate": 4.176150223627186e-06,
      "loss": 0.508,
      "step": 8142
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.6666569243602247,
      "learning_rate": 4.175039616054575e-06,
      "loss": 0.5323,
      "step": 8143
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.1904344769036115,
      "learning_rate": 4.173929050321264e-06,
      "loss": 0.4915,
      "step": 8144
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.313799540108573,
      "learning_rate": 4.1728185264835785e-06,
      "loss": 0.5201,
      "step": 8145
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.3040587770578336,
      "learning_rate": 4.1717080445978394e-06,
      "loss": 0.4956,
      "step": 8146
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.8343893893971575,
      "learning_rate": 4.17059760472037e-06,
      "loss": 0.4872,
      "step": 8147
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.9859044072703365,
      "learning_rate": 4.169487206907486e-06,
      "loss": 0.4984,
      "step": 8148
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.3365075565517124,
      "learning_rate": 4.168376851215502e-06,
      "loss": 0.4987,
      "step": 8149
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5791675977881672,
      "learning_rate": 4.167266537700732e-06,
      "loss": 0.4254,
      "step": 8150
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.9174825641943298,
      "learning_rate": 4.166156266419489e-06,
      "loss": 0.4701,
      "step": 8151
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.919515629208902,
      "learning_rate": 4.165046037428083e-06,
      "loss": 0.4932,
      "step": 8152
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.8996327762174265,
      "learning_rate": 4.163935850782819e-06,
      "loss": 0.4941,
      "step": 8153
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5759227536329681,
      "learning_rate": 4.162825706540001e-06,
      "loss": 0.4061,
      "step": 8154
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.200778008115881,
      "learning_rate": 4.161715604755937e-06,
      "loss": 0.4802,
      "step": 8155
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.5266139375033436,
      "learning_rate": 4.160605545486923e-06,
      "loss": 0.5043,
      "step": 8156
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.6442556782105266,
      "learning_rate": 4.15949552878926e-06,
      "loss": 0.5225,
      "step": 8157
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.6325140392850415,
      "learning_rate": 4.1583855547192425e-06,
      "loss": 0.5043,
      "step": 8158
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.785588684942306,
      "learning_rate": 4.157275623333167e-06,
      "loss": 0.4988,
      "step": 8159
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.9228800793292193,
      "learning_rate": 4.156165734687324e-06,
      "loss": 0.4647,
      "step": 8160
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.7855191295531274,
      "learning_rate": 4.155055888838005e-06,
      "loss": 0.5215,
      "step": 8161
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.9184174194288142,
      "learning_rate": 4.153946085841493e-06,
      "loss": 0.5052,
      "step": 8162
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.9922826627260368,
      "learning_rate": 4.15283632575408e-06,
      "loss": 0.4795,
      "step": 8163
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.2972519060360943,
      "learning_rate": 4.151726608632047e-06,
      "loss": 0.4684,
      "step": 8164
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.739946251989966,
      "learning_rate": 4.150616934531674e-06,
      "loss": 0.4637,
      "step": 8165
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.896584873968493,
      "learning_rate": 4.149507303509239e-06,
      "loss": 0.5094,
      "step": 8166
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.98218517476104,
      "learning_rate": 4.148397715621024e-06,
      "loss": 0.5206,
      "step": 8167
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.34115629993423,
      "learning_rate": 4.147288170923299e-06,
      "loss": 0.4643,
      "step": 8168
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5922198922109828,
      "learning_rate": 4.146178669472339e-06,
      "loss": 0.4541,
      "step": 8169
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.0160727316327853,
      "learning_rate": 4.145069211324412e-06,
      "loss": 0.4695,
      "step": 8170
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.0596535355334096,
      "learning_rate": 4.143959796535789e-06,
      "loss": 0.4973,
      "step": 8171
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.6542403196583895,
      "learning_rate": 4.1428504251627335e-06,
      "loss": 0.4912,
      "step": 8172
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.9350499640687637,
      "learning_rate": 4.1417410972615095e-06,
      "loss": 0.517,
      "step": 8173
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.7982244491722388,
      "learning_rate": 4.140631812888378e-06,
      "loss": 0.5669,
      "step": 8174
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.392990088938174,
      "learning_rate": 4.1395225720996e-06,
      "loss": 0.4683,
      "step": 8175
    },
    {
      "epoch": 0.57,
      "grad_norm": 7.615790236147617,
      "learning_rate": 4.138413374951434e-06,
      "loss": 0.4539,
      "step": 8176
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5858504499645902,
      "learning_rate": 4.137304221500128e-06,
      "loss": 0.4124,
      "step": 8177
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.988485861050756,
      "learning_rate": 4.136195111801943e-06,
      "loss": 0.5008,
      "step": 8178
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.7841974639993823,
      "learning_rate": 4.135086045913125e-06,
      "loss": 0.4953,
      "step": 8179
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.1309510243243692,
      "learning_rate": 4.133977023889923e-06,
      "loss": 0.4668,
      "step": 8180
    },
    {
      "epoch": 0.57,
      "grad_norm": 5.799384610278875,
      "learning_rate": 4.1328680457885825e-06,
      "loss": 0.532,
      "step": 8181
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.206932298941401,
      "learning_rate": 4.131759111665349e-06,
      "loss": 0.4716,
      "step": 8182
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.039730999762433,
      "learning_rate": 4.1306502215764625e-06,
      "loss": 0.5277,
      "step": 8183
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.7243957580054974,
      "learning_rate": 4.1295413755781625e-06,
      "loss": 0.4969,
      "step": 8184
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.7608473227487234,
      "learning_rate": 4.128432573726683e-06,
      "loss": 0.5145,
      "step": 8185
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.730902677696559,
      "learning_rate": 4.127323816078264e-06,
      "loss": 0.4839,
      "step": 8186
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.8993278285732311,
      "learning_rate": 4.126215102689137e-06,
      "loss": 0.4715,
      "step": 8187
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5234653497214491,
      "learning_rate": 4.125106433615532e-06,
      "loss": 0.3969,
      "step": 8188
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.8373153192527976,
      "learning_rate": 4.123997808913673e-06,
      "loss": 0.4929,
      "step": 8189
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.6675035482201013,
      "learning_rate": 4.122889228639791e-06,
      "loss": 0.491,
      "step": 8190
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.7378703350451707,
      "learning_rate": 4.1217806928501084e-06,
      "loss": 0.4949,
      "step": 8191
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.1522270871701394,
      "learning_rate": 4.120672201600846e-06,
      "loss": 0.49,
      "step": 8192
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.7026815883008986,
      "learning_rate": 4.119563754948221e-06,
      "loss": 0.4829,
      "step": 8193
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.8978626109061114,
      "learning_rate": 4.1184553529484536e-06,
      "loss": 0.4851,
      "step": 8194
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.57320780409686,
      "learning_rate": 4.117346995657757e-06,
      "loss": 0.4723,
      "step": 8195
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.1826614367300055,
      "learning_rate": 4.116238683132343e-06,
      "loss": 0.5681,
      "step": 8196
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.4173869785859745,
      "learning_rate": 4.11513041542842e-06,
      "loss": 0.4696,
      "step": 8197
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.068575986549795,
      "learning_rate": 4.114022192602198e-06,
      "loss": 0.4993,
      "step": 8198
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.8078322955836632,
      "learning_rate": 4.112914014709883e-06,
      "loss": 0.5223,
      "step": 8199
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.4543123517558656,
      "learning_rate": 4.111805881807678e-06,
      "loss": 0.4584,
      "step": 8200
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.1587620670795644,
      "learning_rate": 4.110697793951781e-06,
      "loss": 0.4993,
      "step": 8201
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.813661056686222,
      "learning_rate": 4.109589751198393e-06,
      "loss": 0.5229,
      "step": 8202
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.5887683516898012,
      "learning_rate": 4.108481753603712e-06,
      "loss": 0.4904,
      "step": 8203
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.12942954195055,
      "learning_rate": 4.107373801223927e-06,
      "loss": 0.5045,
      "step": 8204
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.45927305730968,
      "learning_rate": 4.106265894115233e-06,
      "loss": 0.4649,
      "step": 8205
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.7962514353467998,
      "learning_rate": 4.10515803233382e-06,
      "loss": 0.4324,
      "step": 8206
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.721261192132029,
      "learning_rate": 4.104050215935875e-06,
      "loss": 0.4707,
      "step": 8207
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.059388619418355,
      "learning_rate": 4.102942444977581e-06,
      "loss": 0.4982,
      "step": 8208
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.688829639774169,
      "learning_rate": 4.10183471951512e-06,
      "loss": 0.4961,
      "step": 8209
    },
    {
      "epoch": 0.57,
      "grad_norm": 4.377527097669442,
      "learning_rate": 4.100727039604676e-06,
      "loss": 0.5211,
      "step": 8210
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.3646621030683743,
      "learning_rate": 4.099619405302426e-06,
      "loss": 0.4806,
      "step": 8211
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.8474848967163313,
      "learning_rate": 4.0985118166645426e-06,
      "loss": 0.4759,
      "step": 8212
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.6474839644485806,
      "learning_rate": 4.0974042737472005e-06,
      "loss": 0.4877,
      "step": 8213
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.693916810681237,
      "learning_rate": 4.096296776606572e-06,
      "loss": 0.5438,
      "step": 8214
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.180129673187759,
      "learning_rate": 4.095189325298825e-06,
      "loss": 0.4926,
      "step": 8215
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.781775107415287,
      "learning_rate": 4.094081919880125e-06,
      "loss": 0.534,
      "step": 8216
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.0262051303045956,
      "learning_rate": 4.092974560406635e-06,
      "loss": 0.5671,
      "step": 8217
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.766156066157254,
      "learning_rate": 4.09186724693452e-06,
      "loss": 0.5169,
      "step": 8218
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.9753921778578305,
      "learning_rate": 4.090759979519937e-06,
      "loss": 0.5188,
      "step": 8219
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.81341806527168,
      "learning_rate": 4.089652758219045e-06,
      "loss": 0.4532,
      "step": 8220
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.1827713004285068,
      "learning_rate": 4.088545583087994e-06,
      "loss": 0.4955,
      "step": 8221
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.2306601504064334,
      "learning_rate": 4.087438454182942e-06,
      "loss": 0.5109,
      "step": 8222
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.868416637604661,
      "learning_rate": 4.086331371560036e-06,
      "loss": 0.4957,
      "step": 8223
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.9015169352739727,
      "learning_rate": 4.085224335275425e-06,
      "loss": 0.4909,
      "step": 8224
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.8220003870322918,
      "learning_rate": 4.084117345385252e-06,
      "loss": 0.5286,
      "step": 8225
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.240696134212489,
      "learning_rate": 4.083010401945662e-06,
      "loss": 0.5287,
      "step": 8226
    },
    {
      "epoch": 0.57,
      "grad_norm": 5.2982353233880914,
      "learning_rate": 4.081903505012795e-06,
      "loss": 0.5303,
      "step": 8227
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.6664484123177337,
      "learning_rate": 4.0807966546427895e-06,
      "loss": 0.5158,
      "step": 8228
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.9642067332951587,
      "learning_rate": 4.079689850891778e-06,
      "loss": 0.5076,
      "step": 8229
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.390382193247734,
      "learning_rate": 4.078583093815899e-06,
      "loss": 0.5303,
      "step": 8230
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.181920830798619,
      "learning_rate": 4.077476383471281e-06,
      "loss": 0.5153,
      "step": 8231
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.396259577621174,
      "learning_rate": 4.076369719914055e-06,
      "loss": 0.499,
      "step": 8232
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.9591189204004402,
      "learning_rate": 4.075263103200342e-06,
      "loss": 0.5265,
      "step": 8233
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.1039845246992,
      "learning_rate": 4.074156533386273e-06,
      "loss": 0.4884,
      "step": 8234
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.045559022483463,
      "learning_rate": 4.0730500105279655e-06,
      "loss": 0.4513,
      "step": 8235
    },
    {
      "epoch": 0.57,
      "grad_norm": 5.01767383382749,
      "learning_rate": 4.071943534681539e-06,
      "loss": 0.5372,
      "step": 8236
    },
    {
      "epoch": 0.57,
      "grad_norm": 3.6284750701546082,
      "learning_rate": 4.07083710590311e-06,
      "loss": 0.4977,
      "step": 8237
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.4609130780726636,
      "learning_rate": 4.069730724248795e-06,
      "loss": 0.4713,
      "step": 8238
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.9431074335381946,
      "learning_rate": 4.0686243897747045e-06,
      "loss": 0.5148,
      "step": 8239
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.8117721743034552,
      "learning_rate": 4.067518102536947e-06,
      "loss": 0.5053,
      "step": 8240
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.603859495901811,
      "learning_rate": 4.066411862591633e-06,
      "loss": 0.513,
      "step": 8241
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.7947750313156157,
      "learning_rate": 4.065305669994866e-06,
      "loss": 0.4698,
      "step": 8242
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.7383897600783977,
      "learning_rate": 4.064199524802748e-06,
      "loss": 0.5437,
      "step": 8243
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.8114782884159923,
      "learning_rate": 4.063093427071376e-06,
      "loss": 0.4827,
      "step": 8244
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.5427944351498173,
      "learning_rate": 4.0619873768568545e-06,
      "loss": 0.4889,
      "step": 8245
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.814901257255313,
      "learning_rate": 4.060881374215274e-06,
      "loss": 0.5565,
      "step": 8246
    },
    {
      "epoch": 0.57,
      "grad_norm": 15.202846273736915,
      "learning_rate": 4.059775419202729e-06,
      "loss": 0.5069,
      "step": 8247
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.8982505031548826,
      "learning_rate": 4.0586695118753084e-06,
      "loss": 0.4885,
      "step": 8248
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.9821765110585443,
      "learning_rate": 4.057563652289102e-06,
      "loss": 0.5201,
      "step": 8249
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.1164420069121093,
      "learning_rate": 4.056457840500195e-06,
      "loss": 0.505,
      "step": 8250
    },
    {
      "epoch": 0.57,
      "grad_norm": 3.6423324981238485,
      "learning_rate": 4.055352076564671e-06,
      "loss": 0.5132,
      "step": 8251
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.8215321148133237,
      "learning_rate": 4.054246360538607e-06,
      "loss": 0.5005,
      "step": 8252
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.0623342645764144,
      "learning_rate": 4.053140692478086e-06,
      "loss": 0.4844,
      "step": 8253
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.0692011774695187,
      "learning_rate": 4.052035072439183e-06,
      "loss": 0.4546,
      "step": 8254
    },
    {
      "epoch": 0.57,
      "grad_norm": 5.149108602657872,
      "learning_rate": 4.05092950047797e-06,
      "loss": 0.5175,
      "step": 8255
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.9551567612426375,
      "learning_rate": 4.049823976650517e-06,
      "loss": 0.522,
      "step": 8256
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.858036772704667,
      "learning_rate": 4.048718501012895e-06,
      "loss": 0.4643,
      "step": 8257
    },
    {
      "epoch": 0.57,
      "grad_norm": 3.0434907814719785,
      "learning_rate": 4.04761307362117e-06,
      "loss": 0.5048,
      "step": 8258
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.4062312464936744,
      "learning_rate": 4.046507694531405e-06,
      "loss": 0.4995,
      "step": 8259
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.286133569901578,
      "learning_rate": 4.0454023637996606e-06,
      "loss": 0.4584,
      "step": 8260
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.6693398941735595,
      "learning_rate": 4.044297081481997e-06,
      "loss": 0.4781,
      "step": 8261
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.5038400940372965,
      "learning_rate": 4.043191847634469e-06,
      "loss": 0.4674,
      "step": 8262
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.9573207443365688,
      "learning_rate": 4.042086662313132e-06,
      "loss": 0.4971,
      "step": 8263
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5707044976670671,
      "learning_rate": 4.040981525574034e-06,
      "loss": 0.4368,
      "step": 8264
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.9330007190499476,
      "learning_rate": 4.039876437473228e-06,
      "loss": 0.4764,
      "step": 8265
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.569357331788591,
      "learning_rate": 4.038771398066759e-06,
      "loss": 0.4487,
      "step": 8266
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.845925039561675,
      "learning_rate": 4.037666407410671e-06,
      "loss": 0.4952,
      "step": 8267
    },
    {
      "epoch": 0.57,
      "grad_norm": 3.3574871944328493,
      "learning_rate": 4.036561465561005e-06,
      "loss": 0.4595,
      "step": 8268
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.2091198671580177,
      "learning_rate": 4.0354565725738015e-06,
      "loss": 0.5291,
      "step": 8269
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6518036447755031,
      "learning_rate": 4.034351728505096e-06,
      "loss": 0.4205,
      "step": 8270
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.67870412829886,
      "learning_rate": 4.033246933410922e-06,
      "loss": 0.4878,
      "step": 8271
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.2404205816516902,
      "learning_rate": 4.0321421873473095e-06,
      "loss": 0.4988,
      "step": 8272
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.9883323105839283,
      "learning_rate": 4.0310374903702934e-06,
      "loss": 0.5011,
      "step": 8273
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.3096004189274226,
      "learning_rate": 4.029932842535895e-06,
      "loss": 0.4857,
      "step": 8274
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.1989840523332256,
      "learning_rate": 4.028828243900141e-06,
      "loss": 0.4569,
      "step": 8275
    },
    {
      "epoch": 0.58,
      "grad_norm": 3.222358874575691,
      "learning_rate": 4.027723694519051e-06,
      "loss": 0.4895,
      "step": 8276
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.482636811977756,
      "learning_rate": 4.026619194448647e-06,
      "loss": 0.5445,
      "step": 8277
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.043976658140686,
      "learning_rate": 4.025514743744943e-06,
      "loss": 0.5218,
      "step": 8278
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.2448281025892034,
      "learning_rate": 4.024410342463956e-06,
      "loss": 0.4724,
      "step": 8279
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.9853154299285822,
      "learning_rate": 4.023305990661694e-06,
      "loss": 0.453,
      "step": 8280
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.8862653770893123,
      "learning_rate": 4.022201688394168e-06,
      "loss": 0.5052,
      "step": 8281
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.906239555144936,
      "learning_rate": 4.021097435717386e-06,
      "loss": 0.4902,
      "step": 8282
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.9199554588719656,
      "learning_rate": 4.019993232687349e-06,
      "loss": 0.4935,
      "step": 8283
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.8142336492653501,
      "learning_rate": 4.018889079360059e-06,
      "loss": 0.466,
      "step": 8284
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.864917233405764,
      "learning_rate": 4.0177849757915185e-06,
      "loss": 0.4844,
      "step": 8285
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.5509663740435395,
      "learning_rate": 4.016680922037723e-06,
      "loss": 0.4837,
      "step": 8286
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.9107031685230176,
      "learning_rate": 4.015576918154664e-06,
      "loss": 0.5186,
      "step": 8287
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.9080395685790126,
      "learning_rate": 4.014472964198332e-06,
      "loss": 0.5011,
      "step": 8288
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.8292989725408562,
      "learning_rate": 4.013369060224721e-06,
      "loss": 0.495,
      "step": 8289
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.0031180924203493,
      "learning_rate": 4.012265206289814e-06,
      "loss": 0.4646,
      "step": 8290
    },
    {
      "epoch": 0.58,
      "grad_norm": 3.3274752448469758,
      "learning_rate": 4.011161402449596e-06,
      "loss": 0.5132,
      "step": 8291
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6736401045286985,
      "learning_rate": 4.0100576487600465e-06,
      "loss": 0.4413,
      "step": 8292
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.8613008860635416,
      "learning_rate": 4.008953945277148e-06,
      "loss": 0.5122,
      "step": 8293
    },
    {
      "epoch": 0.58,
      "grad_norm": 5.4524538850384685,
      "learning_rate": 4.007850292056873e-06,
      "loss": 0.4893,
      "step": 8294
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.69576655032205,
      "learning_rate": 4.006746689155196e-06,
      "loss": 0.5025,
      "step": 8295
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.7448403922957256,
      "learning_rate": 4.005643136628088e-06,
      "loss": 0.5176,
      "step": 8296
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.8916229616274978,
      "learning_rate": 4.00453963453152e-06,
      "loss": 0.4983,
      "step": 8297
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.7634164120841325,
      "learning_rate": 4.0034361829214565e-06,
      "loss": 0.5143,
      "step": 8298
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.8994431565285657,
      "learning_rate": 4.002332781853861e-06,
      "loss": 0.5004,
      "step": 8299
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.7942864903836906,
      "learning_rate": 4.0012294313846915e-06,
      "loss": 0.5012,
      "step": 8300
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.7248018333174469,
      "learning_rate": 4.000126131569912e-06,
      "loss": 0.4786,
      "step": 8301
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.1933166258250782,
      "learning_rate": 3.999022882465474e-06,
      "loss": 0.5531,
      "step": 8302
    },
    {
      "epoch": 0.58,
      "grad_norm": 3.0503202752917065,
      "learning_rate": 3.997919684127332e-06,
      "loss": 0.4997,
      "step": 8303
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.4119326341313516,
      "learning_rate": 3.996816536611438e-06,
      "loss": 0.5465,
      "step": 8304
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.073729437693834,
      "learning_rate": 3.995713439973738e-06,
      "loss": 0.4914,
      "step": 8305
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.6358252500510655,
      "learning_rate": 3.994610394270178e-06,
      "loss": 0.5198,
      "step": 8306
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.990477046072691,
      "learning_rate": 3.993507399556699e-06,
      "loss": 0.5012,
      "step": 8307
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.7202566080820856,
      "learning_rate": 3.992404455889246e-06,
      "loss": 0.5384,
      "step": 8308
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.7055031186544345,
      "learning_rate": 3.991301563323754e-06,
      "loss": 0.4498,
      "step": 8309
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.336796271770451,
      "learning_rate": 3.990198721916158e-06,
      "loss": 0.4822,
      "step": 8310
    },
    {
      "epoch": 0.58,
      "grad_norm": 5.466234889192558,
      "learning_rate": 3.989095931722388e-06,
      "loss": 0.5072,
      "step": 8311
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.7756256127102,
      "learning_rate": 3.98799319279838e-06,
      "loss": 0.5123,
      "step": 8312
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.8557909765931995,
      "learning_rate": 3.986890505200057e-06,
      "loss": 0.5384,
      "step": 8313
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.930507079261155,
      "learning_rate": 3.985787868983345e-06,
      "loss": 0.5128,
      "step": 8314
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.8784372699443437,
      "learning_rate": 3.984685284204164e-06,
      "loss": 0.5141,
      "step": 8315
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.9438735036924308,
      "learning_rate": 3.983582750918437e-06,
      "loss": 0.5037,
      "step": 8316
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.1195413604582316,
      "learning_rate": 3.982480269182079e-06,
      "loss": 0.4898,
      "step": 8317
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.8043778933357135,
      "learning_rate": 3.981377839051004e-06,
      "loss": 0.5007,
      "step": 8318
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.7985197187185848,
      "learning_rate": 3.980275460581122e-06,
      "loss": 0.4841,
      "step": 8319
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.4772397909656,
      "learning_rate": 3.979173133828347e-06,
      "loss": 0.5121,
      "step": 8320
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.9164189065609176,
      "learning_rate": 3.978070858848583e-06,
      "loss": 0.4947,
      "step": 8321
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.007688273782101,
      "learning_rate": 3.976968635697732e-06,
      "loss": 0.4901,
      "step": 8322
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.8787175288658124,
      "learning_rate": 3.975866464431696e-06,
      "loss": 0.4849,
      "step": 8323
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.8100507760246602,
      "learning_rate": 3.974764345106376e-06,
      "loss": 0.5107,
      "step": 8324
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.5984764940800806,
      "learning_rate": 3.9736622777776635e-06,
      "loss": 0.5003,
      "step": 8325
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.26371194252331,
      "learning_rate": 3.972560262501456e-06,
      "loss": 0.4897,
      "step": 8326
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.8428638975256477,
      "learning_rate": 3.971458299333641e-06,
      "loss": 0.5104,
      "step": 8327
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.155220219786157,
      "learning_rate": 3.970356388330109e-06,
      "loss": 0.4717,
      "step": 8328
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.9648889023615248,
      "learning_rate": 3.9692545295467445e-06,
      "loss": 0.4984,
      "step": 8329
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.688065339220705,
      "learning_rate": 3.968152723039429e-06,
      "loss": 0.5005,
      "step": 8330
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.7161181640734955,
      "learning_rate": 3.967050968864042e-06,
      "loss": 0.5278,
      "step": 8331
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.6202274572727988,
      "learning_rate": 3.965949267076465e-06,
      "loss": 0.5522,
      "step": 8332
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.0814373258132695,
      "learning_rate": 3.964847617732568e-06,
      "loss": 0.4908,
      "step": 8333
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6520731870664814,
      "learning_rate": 3.963746020888226e-06,
      "loss": 0.422,
      "step": 8334
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.9350275713510445,
      "learning_rate": 3.962644476599306e-06,
      "loss": 0.5286,
      "step": 8335
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.7296620416438753,
      "learning_rate": 3.961542984921679e-06,
      "loss": 0.476,
      "step": 8336
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.58988041958057,
      "learning_rate": 3.960441545911205e-06,
      "loss": 0.5241,
      "step": 8337
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.889219291170716,
      "learning_rate": 3.959340159623747e-06,
      "loss": 0.5207,
      "step": 8338
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.464586766341375,
      "learning_rate": 3.9582388261151606e-06,
      "loss": 0.4555,
      "step": 8339
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.700633743177234,
      "learning_rate": 3.957137545441307e-06,
      "loss": 0.5183,
      "step": 8340
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.201789583741958,
      "learning_rate": 3.956036317658037e-06,
      "loss": 0.4488,
      "step": 8341
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.8930439904079754,
      "learning_rate": 3.954935142821202e-06,
      "loss": 0.466,
      "step": 8342
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.7632229887093978,
      "learning_rate": 3.953834020986646e-06,
      "loss": 0.4631,
      "step": 8343
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.2153135730946927,
      "learning_rate": 3.952732952210221e-06,
      "loss": 0.5019,
      "step": 8344
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.9104637425223912,
      "learning_rate": 3.951631936547766e-06,
      "loss": 0.491,
      "step": 8345
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.7725550903827418,
      "learning_rate": 3.950530974055122e-06,
      "loss": 0.4861,
      "step": 8346
    },
    {
      "epoch": 0.58,
      "grad_norm": 7.542020685978895,
      "learning_rate": 3.949430064788124e-06,
      "loss": 0.4708,
      "step": 8347
    },
    {
      "epoch": 0.58,
      "grad_norm": 4.566273053534987,
      "learning_rate": 3.948329208802609e-06,
      "loss": 0.5307,
      "step": 8348
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.825189194045319,
      "learning_rate": 3.947228406154408e-06,
      "loss": 0.4706,
      "step": 8349
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.8385724626661517,
      "learning_rate": 3.94612765689935e-06,
      "loss": 0.5014,
      "step": 8350
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.761973588150071,
      "learning_rate": 3.945026961093259e-06,
      "loss": 0.4631,
      "step": 8351
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.8933771493960065,
      "learning_rate": 3.9439263187919635e-06,
      "loss": 0.5093,
      "step": 8352
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.8330892266132415,
      "learning_rate": 3.9428257300512825e-06,
      "loss": 0.482,
      "step": 8353
    },
    {
      "epoch": 0.58,
      "grad_norm": 4.949380188911669,
      "learning_rate": 3.941725194927034e-06,
      "loss": 0.4795,
      "step": 8354
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.9070127347643415,
      "learning_rate": 3.940624713475031e-06,
      "loss": 0.53,
      "step": 8355
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.9939247003806777,
      "learning_rate": 3.93952428575109e-06,
      "loss": 0.5457,
      "step": 8356
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.7945970395427602,
      "learning_rate": 3.938423911811021e-06,
      "loss": 0.4771,
      "step": 8357
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.558378732668194,
      "learning_rate": 3.937323591710629e-06,
      "loss": 0.4583,
      "step": 8358
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.1971180023361425,
      "learning_rate": 3.9362233255057205e-06,
      "loss": 0.4847,
      "step": 8359
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.906902877209928,
      "learning_rate": 3.935123113252097e-06,
      "loss": 0.5202,
      "step": 8360
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.266576027949524,
      "learning_rate": 3.934022955005558e-06,
      "loss": 0.4714,
      "step": 8361
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.0938007761159514,
      "learning_rate": 3.932922850821899e-06,
      "loss": 0.5109,
      "step": 8362
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.1756705557760276,
      "learning_rate": 3.931822800756911e-06,
      "loss": 0.5106,
      "step": 8363
    },
    {
      "epoch": 0.58,
      "grad_norm": 3.2282309348116076,
      "learning_rate": 3.9307228048663915e-06,
      "loss": 0.4746,
      "step": 8364
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6191332711784167,
      "learning_rate": 3.929622863206125e-06,
      "loss": 0.4332,
      "step": 8365
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.9656239456029878,
      "learning_rate": 3.928522975831898e-06,
      "loss": 0.4732,
      "step": 8366
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.918252042892598,
      "learning_rate": 3.927423142799489e-06,
      "loss": 0.5379,
      "step": 8367
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.926905536502093,
      "learning_rate": 3.926323364164684e-06,
      "loss": 0.4757,
      "step": 8368
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.275157818062137,
      "learning_rate": 3.925223639983258e-06,
      "loss": 0.492,
      "step": 8369
    },
    {
      "epoch": 0.58,
      "grad_norm": 3.1603953938190332,
      "learning_rate": 3.924123970310984e-06,
      "loss": 0.5022,
      "step": 8370
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.7453307496924377,
      "learning_rate": 3.923024355203635e-06,
      "loss": 0.5195,
      "step": 8371
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.8865065266749477,
      "learning_rate": 3.92192479471698e-06,
      "loss": 0.4673,
      "step": 8372
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.829082948327762,
      "learning_rate": 3.920825288906784e-06,
      "loss": 0.5676,
      "step": 8373
    },
    {
      "epoch": 0.58,
      "grad_norm": 3.1566246374739735,
      "learning_rate": 3.91972583782881e-06,
      "loss": 0.4806,
      "step": 8374
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.6527182048174487,
      "learning_rate": 3.918626441538821e-06,
      "loss": 0.5121,
      "step": 8375
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.223629928123046,
      "learning_rate": 3.917527100092574e-06,
      "loss": 0.6156,
      "step": 8376
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.0212823944618052,
      "learning_rate": 3.916427813545823e-06,
      "loss": 0.5488,
      "step": 8377
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.9243485419858533,
      "learning_rate": 3.915328581954319e-06,
      "loss": 0.4742,
      "step": 8378
    },
    {
      "epoch": 0.58,
      "grad_norm": 3.817751100326164,
      "learning_rate": 3.914229405373815e-06,
      "loss": 0.4542,
      "step": 8379
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.178266286602982,
      "learning_rate": 3.913130283860056e-06,
      "loss": 0.5212,
      "step": 8380
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.6895763724942663,
      "learning_rate": 3.9120312174687845e-06,
      "loss": 0.4751,
      "step": 8381
    },
    {
      "epoch": 0.58,
      "grad_norm": 4.278245456924338,
      "learning_rate": 3.910932206255742e-06,
      "loss": 0.5196,
      "step": 8382
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.557462087727341,
      "learning_rate": 3.909833250276669e-06,
      "loss": 0.5061,
      "step": 8383
    },
    {
      "epoch": 0.58,
      "grad_norm": 4.329528425792211,
      "learning_rate": 3.908734349587299e-06,
      "loss": 0.4894,
      "step": 8384
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.7803811477110365,
      "learning_rate": 3.907635504243366e-06,
      "loss": 0.5033,
      "step": 8385
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.931644859588464,
      "learning_rate": 3.906536714300596e-06,
      "loss": 0.5034,
      "step": 8386
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.21296625775757,
      "learning_rate": 3.905437979814721e-06,
      "loss": 0.4887,
      "step": 8387
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.3370941808594345,
      "learning_rate": 3.904339300841464e-06,
      "loss": 0.4541,
      "step": 8388
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.3090133736069167,
      "learning_rate": 3.903240677436544e-06,
      "loss": 0.5024,
      "step": 8389
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.2928899958548383,
      "learning_rate": 3.902142109655681e-06,
      "loss": 0.5045,
      "step": 8390
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.4676782685838132,
      "learning_rate": 3.901043597554592e-06,
      "loss": 0.4707,
      "step": 8391
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.6627442795116663,
      "learning_rate": 3.899945141188989e-06,
      "loss": 0.4973,
      "step": 8392
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.7978593087227788,
      "learning_rate": 3.898846740614581e-06,
      "loss": 0.4991,
      "step": 8393
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.9498875752341678,
      "learning_rate": 3.897748395887077e-06,
      "loss": 0.5086,
      "step": 8394
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.648479203731631,
      "learning_rate": 3.8966501070621805e-06,
      "loss": 0.5168,
      "step": 8395
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.220344861392992,
      "learning_rate": 3.8955518741955945e-06,
      "loss": 0.5102,
      "step": 8396
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.840652122703511,
      "learning_rate": 3.894453697343016e-06,
      "loss": 0.4844,
      "step": 8397
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.0978813851271934,
      "learning_rate": 3.893355576560141e-06,
      "loss": 0.4961,
      "step": 8398
    },
    {
      "epoch": 0.58,
      "grad_norm": 4.650801893228245,
      "learning_rate": 3.892257511902664e-06,
      "loss": 0.5196,
      "step": 8399
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.6766203632687966,
      "learning_rate": 3.891159503426275e-06,
      "loss": 0.5008,
      "step": 8400
    },
    {
      "epoch": 0.58,
      "grad_norm": 4.015861175853301,
      "learning_rate": 3.890061551186661e-06,
      "loss": 0.5079,
      "step": 8401
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.023778206071335,
      "learning_rate": 3.888963655239505e-06,
      "loss": 0.513,
      "step": 8402
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.8976625395298368,
      "learning_rate": 3.8878658156404914e-06,
      "loss": 0.4914,
      "step": 8403
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.6976731745638394,
      "learning_rate": 3.886768032445299e-06,
      "loss": 0.5214,
      "step": 8404
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.9571452537975949,
      "learning_rate": 3.885670305709601e-06,
      "loss": 0.4734,
      "step": 8405
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.3835193687184346,
      "learning_rate": 3.884572635489071e-06,
      "loss": 0.4751,
      "step": 8406
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.1386740681868903,
      "learning_rate": 3.883475021839382e-06,
      "loss": 0.5119,
      "step": 8407
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.8387356408456677,
      "learning_rate": 3.882377464816201e-06,
      "loss": 0.4866,
      "step": 8408
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.8673315197816949,
      "learning_rate": 3.88127996447519e-06,
      "loss": 0.4744,
      "step": 8409
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.550659656640479,
      "learning_rate": 3.88018252087201e-06,
      "loss": 0.4774,
      "step": 8410
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6075042857823376,
      "learning_rate": 3.879085134062324e-06,
      "loss": 0.4319,
      "step": 8411
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.7087856621458768,
      "learning_rate": 3.877987804101786e-06,
      "loss": 0.4752,
      "step": 8412
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.673622256276242,
      "learning_rate": 3.876890531046048e-06,
      "loss": 0.4656,
      "step": 8413
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.454680951765687,
      "learning_rate": 3.87579331495076e-06,
      "loss": 0.495,
      "step": 8414
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.108279344845115,
      "learning_rate": 3.8746961558715716e-06,
      "loss": 0.4781,
      "step": 8415
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.6398775285656426,
      "learning_rate": 3.873599053864125e-06,
      "loss": 0.515,
      "step": 8416
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.96169472361365,
      "learning_rate": 3.872502008984061e-06,
      "loss": 0.5126,
      "step": 8417
    },
    {
      "epoch": 0.59,
      "grad_norm": 11.177202899931089,
      "learning_rate": 3.871405021287019e-06,
      "loss": 0.465,
      "step": 8418
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.8142076457602316,
      "learning_rate": 3.870308090828636e-06,
      "loss": 0.4724,
      "step": 8419
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.8814705262198714,
      "learning_rate": 3.869211217664544e-06,
      "loss": 0.501,
      "step": 8420
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.172823687365351,
      "learning_rate": 3.868114401850372e-06,
      "loss": 0.4914,
      "step": 8421
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.591794271780275,
      "learning_rate": 3.867017643441746e-06,
      "loss": 0.4976,
      "step": 8422
    },
    {
      "epoch": 0.59,
      "grad_norm": 3.6722199233015926,
      "learning_rate": 3.8659209424942925e-06,
      "loss": 0.4933,
      "step": 8423
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.6239373011807468,
      "learning_rate": 3.864824299063632e-06,
      "loss": 0.4701,
      "step": 8424
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.604816136723875,
      "learning_rate": 3.863727713205382e-06,
      "loss": 0.4838,
      "step": 8425
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5467737167305377,
      "learning_rate": 3.862631184975157e-06,
      "loss": 0.4328,
      "step": 8426
    },
    {
      "epoch": 0.59,
      "grad_norm": 3.1275547301700435,
      "learning_rate": 3.861534714428571e-06,
      "loss": 0.5355,
      "step": 8427
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.8595442757481182,
      "learning_rate": 3.860438301621233e-06,
      "loss": 0.4885,
      "step": 8428
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.801037212953833,
      "learning_rate": 3.85934194660875e-06,
      "loss": 0.4752,
      "step": 8429
    },
    {
      "epoch": 0.59,
      "grad_norm": 4.7923416514436425,
      "learning_rate": 3.8582456494467214e-06,
      "loss": 0.5168,
      "step": 8430
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.3389718577558662,
      "learning_rate": 3.857149410190754e-06,
      "loss": 0.5453,
      "step": 8431
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.679721280369387,
      "learning_rate": 3.856053228896442e-06,
      "loss": 0.5051,
      "step": 8432
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.0507052853968526,
      "learning_rate": 3.8549571056193785e-06,
      "loss": 0.4687,
      "step": 8433
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.2491784129605987,
      "learning_rate": 3.85386104041516e-06,
      "loss": 0.4694,
      "step": 8434
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.8312147503164213,
      "learning_rate": 3.8527650333393725e-06,
      "loss": 0.5321,
      "step": 8435
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5976135781163741,
      "learning_rate": 3.8516690844476035e-06,
      "loss": 0.4408,
      "step": 8436
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5902306155160574,
      "learning_rate": 3.850573193795433e-06,
      "loss": 0.4329,
      "step": 8437
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.7072938031821256,
      "learning_rate": 3.849477361438443e-06,
      "loss": 0.5193,
      "step": 8438
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.016996032683443,
      "learning_rate": 3.848381587432212e-06,
      "loss": 0.5313,
      "step": 8439
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.900619989077069,
      "learning_rate": 3.847285871832311e-06,
      "loss": 0.4687,
      "step": 8440
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5645656956760191,
      "learning_rate": 3.846190214694311e-06,
      "loss": 0.413,
      "step": 8441
    },
    {
      "epoch": 0.59,
      "grad_norm": 4.623225999073312,
      "learning_rate": 3.845094616073783e-06,
      "loss": 0.4696,
      "step": 8442
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.0273143699016876,
      "learning_rate": 3.843999076026292e-06,
      "loss": 0.4735,
      "step": 8443
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.1053127215372163,
      "learning_rate": 3.842903594607399e-06,
      "loss": 0.4696,
      "step": 8444
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.771893613876272,
      "learning_rate": 3.841808171872661e-06,
      "loss": 0.4817,
      "step": 8445
    },
    {
      "epoch": 0.59,
      "grad_norm": 5.010283541264849,
      "learning_rate": 3.840712807877638e-06,
      "loss": 0.5197,
      "step": 8446
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.328703205355475,
      "learning_rate": 3.839617502677883e-06,
      "loss": 0.5271,
      "step": 8447
    },
    {
      "epoch": 0.59,
      "grad_norm": 3.35037364115112,
      "learning_rate": 3.838522256328944e-06,
      "loss": 0.4641,
      "step": 8448
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.798372309885741,
      "learning_rate": 3.837427068886369e-06,
      "loss": 0.5424,
      "step": 8449
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.389036707105256,
      "learning_rate": 3.8363319404057045e-06,
      "loss": 0.4975,
      "step": 8450
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.9623681963019612,
      "learning_rate": 3.83523687094249e-06,
      "loss": 0.5411,
      "step": 8451
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.301062797085049,
      "learning_rate": 3.834141860552263e-06,
      "loss": 0.5601,
      "step": 8452
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.532399742188136,
      "learning_rate": 3.833046909290559e-06,
      "loss": 0.468,
      "step": 8453
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.4998882700614615,
      "learning_rate": 3.8319520172129125e-06,
      "loss": 0.4717,
      "step": 8454
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5526499069939912,
      "learning_rate": 3.8308571843748525e-06,
      "loss": 0.4478,
      "step": 8455
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.8390420221394634,
      "learning_rate": 3.829762410831904e-06,
      "loss": 0.4934,
      "step": 8456
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.6438635771499617,
      "learning_rate": 3.8286676966395895e-06,
      "loss": 0.5156,
      "step": 8457
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.8098218139020492,
      "learning_rate": 3.827573041853433e-06,
      "loss": 0.4642,
      "step": 8458
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.373338481886455,
      "learning_rate": 3.826478446528948e-06,
      "loss": 0.5012,
      "step": 8459
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.316104582539395,
      "learning_rate": 3.825383910721651e-06,
      "loss": 0.5127,
      "step": 8460
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.249670292412652,
      "learning_rate": 3.82428943448705e-06,
      "loss": 0.5513,
      "step": 8461
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.4713389494579796,
      "learning_rate": 3.823195017880659e-06,
      "loss": 0.4703,
      "step": 8462
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.9567725779983196,
      "learning_rate": 3.822100660957979e-06,
      "loss": 0.4847,
      "step": 8463
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.8123404015745854,
      "learning_rate": 3.821006363774513e-06,
      "loss": 0.4542,
      "step": 8464
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.336146411780194,
      "learning_rate": 3.819912126385759e-06,
      "loss": 0.4861,
      "step": 8465
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.8558869904581616,
      "learning_rate": 3.818817948847217e-06,
      "loss": 0.5188,
      "step": 8466
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.8840266847784188,
      "learning_rate": 3.817723831214378e-06,
      "loss": 0.4872,
      "step": 8467
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.7937461404509214,
      "learning_rate": 3.816629773542731e-06,
      "loss": 0.474,
      "step": 8468
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.325112232576953,
      "learning_rate": 3.815535775887763e-06,
      "loss": 0.4626,
      "step": 8469
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.264826703230541,
      "learning_rate": 3.8144418383049604e-06,
      "loss": 0.5625,
      "step": 8470
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.1538099560125876,
      "learning_rate": 3.8133479608498026e-06,
      "loss": 0.4634,
      "step": 8471
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.7409609182118255,
      "learning_rate": 3.812254143577767e-06,
      "loss": 0.4874,
      "step": 8472
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.8342449015632527,
      "learning_rate": 3.8111603865443268e-06,
      "loss": 0.5042,
      "step": 8473
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.0441474788228153,
      "learning_rate": 3.8100666898049586e-06,
      "loss": 0.4717,
      "step": 8474
    },
    {
      "epoch": 0.59,
      "grad_norm": 13.707457533518426,
      "learning_rate": 3.8089730534151286e-06,
      "loss": 0.5129,
      "step": 8475
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.671524779216178,
      "learning_rate": 3.807879477430302e-06,
      "loss": 0.4584,
      "step": 8476
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.5338735510650094,
      "learning_rate": 3.8067859619059398e-06,
      "loss": 0.493,
      "step": 8477
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.8302827158088912,
      "learning_rate": 3.8056925068975055e-06,
      "loss": 0.5019,
      "step": 8478
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.350487234357913,
      "learning_rate": 3.8045991124604536e-06,
      "loss": 0.495,
      "step": 8479
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.863580847826592,
      "learning_rate": 3.803505778650237e-06,
      "loss": 0.5018,
      "step": 8480
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.770959109718992,
      "learning_rate": 3.802412505522306e-06,
      "loss": 0.5268,
      "step": 8481
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.1253619343275076,
      "learning_rate": 3.8013192931321095e-06,
      "loss": 0.5291,
      "step": 8482
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.1938790173645653,
      "learning_rate": 3.8002261415350905e-06,
      "loss": 0.4978,
      "step": 8483
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.1074239751229196,
      "learning_rate": 3.7991330507866903e-06,
      "loss": 0.4834,
      "step": 8484
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.2234180646706445,
      "learning_rate": 3.798040020942344e-06,
      "loss": 0.4695,
      "step": 8485
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5936537341091741,
      "learning_rate": 3.796947052057492e-06,
      "loss": 0.4327,
      "step": 8486
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.5349938563158325,
      "learning_rate": 3.7958541441875628e-06,
      "loss": 0.5256,
      "step": 8487
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.7645516402443935,
      "learning_rate": 3.7947612973879853e-06,
      "loss": 0.507,
      "step": 8488
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.4783132622798365,
      "learning_rate": 3.7936685117141847e-06,
      "loss": 0.4721,
      "step": 8489
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.474585362457512,
      "learning_rate": 3.792575787221585e-06,
      "loss": 0.5422,
      "step": 8490
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.9649097014044974,
      "learning_rate": 3.7914831239656056e-06,
      "loss": 0.4789,
      "step": 8491
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.9284003570669397,
      "learning_rate": 3.790390522001662e-06,
      "loss": 0.5014,
      "step": 8492
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.78507575381131,
      "learning_rate": 3.789297981385167e-06,
      "loss": 0.4557,
      "step": 8493
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.1671021408040274,
      "learning_rate": 3.7882055021715325e-06,
      "loss": 0.4842,
      "step": 8494
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.9998436027994904,
      "learning_rate": 3.7871130844161635e-06,
      "loss": 0.4674,
      "step": 8495
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.9176328470540493,
      "learning_rate": 3.7860207281744626e-06,
      "loss": 0.4459,
      "step": 8496
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.04681200161772,
      "learning_rate": 3.784928433501835e-06,
      "loss": 0.4902,
      "step": 8497
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.8278763965727236,
      "learning_rate": 3.7838362004536756e-06,
      "loss": 0.543,
      "step": 8498
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6392456910360744,
      "learning_rate": 3.7827440290853794e-06,
      "loss": 0.4372,
      "step": 8499
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.7173899524973406,
      "learning_rate": 3.7816519194523354e-06,
      "loss": 0.4876,
      "step": 8500
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.0168086491609913,
      "learning_rate": 3.7805598716099362e-06,
      "loss": 0.4395,
      "step": 8501
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.208779321552781,
      "learning_rate": 3.7794678856135647e-06,
      "loss": 0.5392,
      "step": 8502
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.7945236655053527,
      "learning_rate": 3.7783759615186027e-06,
      "loss": 0.5123,
      "step": 8503
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.5875703678913706,
      "learning_rate": 3.777284099380428e-06,
      "loss": 0.498,
      "step": 8504
    },
    {
      "epoch": 0.59,
      "grad_norm": 4.827630610391664,
      "learning_rate": 3.7761922992544187e-06,
      "loss": 0.4529,
      "step": 8505
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.8542624272352777,
      "learning_rate": 3.775100561195946e-06,
      "loss": 0.5056,
      "step": 8506
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.0506988422598154,
      "learning_rate": 3.77400888526038e-06,
      "loss": 0.4978,
      "step": 8507
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.4137742246351706,
      "learning_rate": 3.7729172715030838e-06,
      "loss": 0.5345,
      "step": 8508
    },
    {
      "epoch": 0.59,
      "grad_norm": 5.738978673123436,
      "learning_rate": 3.7718257199794257e-06,
      "loss": 0.5392,
      "step": 8509
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.0043550797681173,
      "learning_rate": 3.7707342307447626e-06,
      "loss": 0.4558,
      "step": 8510
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.003045800569248,
      "learning_rate": 3.7696428038544515e-06,
      "loss": 0.4769,
      "step": 8511
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.8979286755970317,
      "learning_rate": 3.7685514393638455e-06,
      "loss": 0.4814,
      "step": 8512
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.716712992239802,
      "learning_rate": 3.767460137328295e-06,
      "loss": 0.4674,
      "step": 8513
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.9626714440611164,
      "learning_rate": 3.7663688978031496e-06,
      "loss": 0.4768,
      "step": 8514
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.8607717955855856,
      "learning_rate": 3.7652777208437522e-06,
      "loss": 0.4545,
      "step": 8515
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.1640808577644406,
      "learning_rate": 3.764186606505442e-06,
      "loss": 0.4755,
      "step": 8516
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.048788024770505,
      "learning_rate": 3.7630955548435595e-06,
      "loss": 0.464,
      "step": 8517
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.242080340682806,
      "learning_rate": 3.7620045659134375e-06,
      "loss": 0.4928,
      "step": 8518
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.7697362381439299,
      "learning_rate": 3.7609136397704077e-06,
      "loss": 0.5259,
      "step": 8519
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5929103605346445,
      "learning_rate": 3.759822776469797e-06,
      "loss": 0.419,
      "step": 8520
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.0672039815233645,
      "learning_rate": 3.7587319760669335e-06,
      "loss": 0.4837,
      "step": 8521
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.006591288514905,
      "learning_rate": 3.757641238617137e-06,
      "loss": 0.5221,
      "step": 8522
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.8700350671545787,
      "learning_rate": 3.756550564175727e-06,
      "loss": 0.4908,
      "step": 8523
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.797469878945946,
      "learning_rate": 3.755459952798017e-06,
      "loss": 0.4878,
      "step": 8524
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.0527123596682246,
      "learning_rate": 3.7543694045393232e-06,
      "loss": 0.5024,
      "step": 8525
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.1442953290028552,
      "learning_rate": 3.753278919454951e-06,
      "loss": 0.5191,
      "step": 8526
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.9247521623836437,
      "learning_rate": 3.7521884976002075e-06,
      "loss": 0.4912,
      "step": 8527
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.2804777214616627,
      "learning_rate": 3.7510981390303938e-06,
      "loss": 0.4904,
      "step": 8528
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.8211143355000843,
      "learning_rate": 3.7500078438008123e-06,
      "loss": 0.525,
      "step": 8529
    },
    {
      "epoch": 0.59,
      "grad_norm": 7.398121314321056,
      "learning_rate": 3.748917611966758e-06,
      "loss": 0.4443,
      "step": 8530
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.8804600820717694,
      "learning_rate": 3.7478274435835236e-06,
      "loss": 0.5146,
      "step": 8531
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.7428022931299807,
      "learning_rate": 3.7467373387063973e-06,
      "loss": 0.4902,
      "step": 8532
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.4428667486957925,
      "learning_rate": 3.7456472973906687e-06,
      "loss": 0.4693,
      "step": 8533
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.3420399864612027,
      "learning_rate": 3.74455731969162e-06,
      "loss": 0.5058,
      "step": 8534
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.6346123031053312,
      "learning_rate": 3.7434674056645313e-06,
      "loss": 0.4748,
      "step": 8535
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.0565859089087724,
      "learning_rate": 3.742377555364678e-06,
      "loss": 0.5026,
      "step": 8536
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.9947651681114298,
      "learning_rate": 3.741287768847336e-06,
      "loss": 0.5456,
      "step": 8537
    },
    {
      "epoch": 0.59,
      "grad_norm": 3.320445885528173,
      "learning_rate": 3.740198046167775e-06,
      "loss": 0.4962,
      "step": 8538
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.8833917444564314,
      "learning_rate": 3.7391083873812618e-06,
      "loss": 0.4555,
      "step": 8539
    },
    {
      "epoch": 0.59,
      "grad_norm": 8.975678687404072,
      "learning_rate": 3.7380187925430583e-06,
      "loss": 0.4886,
      "step": 8540
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.8933095862453706,
      "learning_rate": 3.7369292617084295e-06,
      "loss": 0.5395,
      "step": 8541
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.7064674744987547,
      "learning_rate": 3.7358397949326307e-06,
      "loss": 0.4502,
      "step": 8542
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.0511219635528186,
      "learning_rate": 3.734750392270916e-06,
      "loss": 0.5483,
      "step": 8543
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.548991386626882,
      "learning_rate": 3.7336610537785347e-06,
      "loss": 0.4639,
      "step": 8544
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.223434329378358,
      "learning_rate": 3.7325717795107374e-06,
      "loss": 0.4987,
      "step": 8545
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.7756527720959197,
      "learning_rate": 3.7314825695227684e-06,
      "loss": 0.4921,
      "step": 8546
    },
    {
      "epoch": 0.59,
      "grad_norm": 7.0725833234222355,
      "learning_rate": 3.7303934238698675e-06,
      "loss": 0.5054,
      "step": 8547
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.450642050756276,
      "learning_rate": 3.7293043426072717e-06,
      "loss": 0.5492,
      "step": 8548
    },
    {
      "epoch": 0.59,
      "grad_norm": 3.69253725322938,
      "learning_rate": 3.728215325790219e-06,
      "loss": 0.5184,
      "step": 8549
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.4463913666674992,
      "learning_rate": 3.727126373473937e-06,
      "loss": 0.5013,
      "step": 8550
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.2599151707793093,
      "learning_rate": 3.7260374857136574e-06,
      "loss": 0.5275,
      "step": 8551
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.6686119251319234,
      "learning_rate": 3.7249486625645994e-06,
      "loss": 0.4754,
      "step": 8552
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.859896561416148,
      "learning_rate": 3.723859904081991e-06,
      "loss": 0.4899,
      "step": 8553
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.9356364092346205,
      "learning_rate": 3.7227712103210485e-06,
      "loss": 0.5241,
      "step": 8554
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.6666710666032065,
      "learning_rate": 3.7216825813369854e-06,
      "loss": 0.4601,
      "step": 8555
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.7139046391654376,
      "learning_rate": 3.7205940171850125e-06,
      "loss": 0.4941,
      "step": 8556
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.8900325017186859,
      "learning_rate": 3.719505517920342e-06,
      "loss": 0.4987,
      "step": 8557
    },
    {
      "epoch": 0.6,
      "grad_norm": 3.4979593998129297,
      "learning_rate": 3.718417083598177e-06,
      "loss": 0.5402,
      "step": 8558
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.9244013907400852,
      "learning_rate": 3.717328714273718e-06,
      "loss": 0.474,
      "step": 8559
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.3765995630852794,
      "learning_rate": 3.7162404100021666e-06,
      "loss": 0.4936,
      "step": 8560
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.8016877544472798,
      "learning_rate": 3.7151521708387155e-06,
      "loss": 0.46,
      "step": 8561
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.9172855000122655,
      "learning_rate": 3.714063996838558e-06,
      "loss": 0.4845,
      "step": 8562
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.9649778249124692,
      "learning_rate": 3.7129758880568796e-06,
      "loss": 0.4975,
      "step": 8563
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.905747113481611,
      "learning_rate": 3.7118878445488705e-06,
      "loss": 0.5059,
      "step": 8564
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.5280315455678037,
      "learning_rate": 3.710799866369711e-06,
      "loss": 0.515,
      "step": 8565
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.0838950503554776,
      "learning_rate": 3.7097119535745783e-06,
      "loss": 0.5354,
      "step": 8566
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.7561951471721926,
      "learning_rate": 3.7086241062186467e-06,
      "loss": 0.5079,
      "step": 8567
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.7248490818956725,
      "learning_rate": 3.707536324357093e-06,
      "loss": 0.495,
      "step": 8568
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5912342303753395,
      "learning_rate": 3.7064486080450833e-06,
      "loss": 0.4232,
      "step": 8569
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.1390455787260807,
      "learning_rate": 3.7053609573377826e-06,
      "loss": 0.5169,
      "step": 8570
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.223177746087121,
      "learning_rate": 3.7042733722903525e-06,
      "loss": 0.5225,
      "step": 8571
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.2838335259174616,
      "learning_rate": 3.7031858529579535e-06,
      "loss": 0.5117,
      "step": 8572
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.943393950769858,
      "learning_rate": 3.7020983993957405e-06,
      "loss": 0.4805,
      "step": 8573
    },
    {
      "epoch": 0.6,
      "grad_norm": 3.442217591661844,
      "learning_rate": 3.701011011658865e-06,
      "loss": 0.4737,
      "step": 8574
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.851683272259725,
      "learning_rate": 3.699923689802474e-06,
      "loss": 0.5063,
      "step": 8575
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.3343316185597964,
      "learning_rate": 3.6988364338817172e-06,
      "loss": 0.5061,
      "step": 8576
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.7817282736504465,
      "learning_rate": 3.697749243951735e-06,
      "loss": 0.4776,
      "step": 8577
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.325642221521359,
      "learning_rate": 3.6966621200676643e-06,
      "loss": 0.4543,
      "step": 8578
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.748301033249324,
      "learning_rate": 3.6955750622846414e-06,
      "loss": 0.4533,
      "step": 8579
    },
    {
      "epoch": 0.6,
      "grad_norm": 5.522400883124642,
      "learning_rate": 3.6944880706578e-06,
      "loss": 0.5213,
      "step": 8580
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.343663524085748,
      "learning_rate": 3.6934011452422657e-06,
      "loss": 0.5205,
      "step": 8581
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.4087287773961465,
      "learning_rate": 3.692314286093167e-06,
      "loss": 0.5033,
      "step": 8582
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.8411805709102114,
      "learning_rate": 3.691227493265623e-06,
      "loss": 0.4984,
      "step": 8583
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.3957469044974253,
      "learning_rate": 3.6901407668147554e-06,
      "loss": 0.5254,
      "step": 8584
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.1742868026757494,
      "learning_rate": 3.6890541067956775e-06,
      "loss": 0.4975,
      "step": 8585
    },
    {
      "epoch": 0.6,
      "grad_norm": 3.0611188738644453,
      "learning_rate": 3.6879675132635012e-06,
      "loss": 0.4562,
      "step": 8586
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.9538006316483778,
      "learning_rate": 3.686880986273333e-06,
      "loss": 0.5105,
      "step": 8587
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.9638889845707586,
      "learning_rate": 3.6857945258802822e-06,
      "loss": 0.5188,
      "step": 8588
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.338062378449086,
      "learning_rate": 3.6847081321394486e-06,
      "loss": 0.4966,
      "step": 8589
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6050459445644235,
      "learning_rate": 3.6836218051059308e-06,
      "loss": 0.466,
      "step": 8590
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.7312443743452746,
      "learning_rate": 3.682535544834822e-06,
      "loss": 0.5103,
      "step": 8591
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.1594680986260206,
      "learning_rate": 3.6814493513812165e-06,
      "loss": 0.5259,
      "step": 8592
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.0896540026550467,
      "learning_rate": 3.680363224800201e-06,
      "loss": 0.5093,
      "step": 8593
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.8313913620055926,
      "learning_rate": 3.67927716514686e-06,
      "loss": 0.4867,
      "step": 8594
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.8558664507588467,
      "learning_rate": 3.6781911724762743e-06,
      "loss": 0.5162,
      "step": 8595
    },
    {
      "epoch": 0.6,
      "grad_norm": 4.468245493052323,
      "learning_rate": 3.677105246843524e-06,
      "loss": 0.461,
      "step": 8596
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.019964170911279,
      "learning_rate": 3.6760193883036834e-06,
      "loss": 0.5182,
      "step": 8597
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.1552999095016707,
      "learning_rate": 3.6749335969118226e-06,
      "loss": 0.5031,
      "step": 8598
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.8278511709380445,
      "learning_rate": 3.6738478727230077e-06,
      "loss": 0.4991,
      "step": 8599
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.6847008696217753,
      "learning_rate": 3.6727622157923075e-06,
      "loss": 0.5251,
      "step": 8600
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.768184961817614,
      "learning_rate": 3.6716766261747806e-06,
      "loss": 0.4841,
      "step": 8601
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.2395917940007113,
      "learning_rate": 3.670591103925485e-06,
      "loss": 0.5238,
      "step": 8602
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.7651127853124555,
      "learning_rate": 3.669505649099473e-06,
      "loss": 0.5243,
      "step": 8603
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.3558460098575242,
      "learning_rate": 3.6684202617517985e-06,
      "loss": 0.498,
      "step": 8604
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.4377430028530744,
      "learning_rate": 3.667334941937506e-06,
      "loss": 0.5278,
      "step": 8605
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.001933028853913,
      "learning_rate": 3.666249689711642e-06,
      "loss": 0.4615,
      "step": 8606
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6149947359050287,
      "learning_rate": 3.6651645051292415e-06,
      "loss": 0.4311,
      "step": 8607
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.824202360903042,
      "learning_rate": 3.6640793882453486e-06,
      "loss": 0.4997,
      "step": 8608
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.8390319933977035,
      "learning_rate": 3.6629943391149943e-06,
      "loss": 0.4739,
      "step": 8609
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.6835762066144613,
      "learning_rate": 3.6619093577932074e-06,
      "loss": 0.4732,
      "step": 8610
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.2098082227149303,
      "learning_rate": 3.6608244443350137e-06,
      "loss": 0.5099,
      "step": 8611
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.053497053575364,
      "learning_rate": 3.65973959879544e-06,
      "loss": 0.5327,
      "step": 8612
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.0265638073224097,
      "learning_rate": 3.658654821229505e-06,
      "loss": 0.5558,
      "step": 8613
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.754141169969269,
      "learning_rate": 3.6575701116922237e-06,
      "loss": 0.4705,
      "step": 8614
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.9186576074914865,
      "learning_rate": 3.656485470238609e-06,
      "loss": 0.487,
      "step": 8615
    },
    {
      "epoch": 0.6,
      "grad_norm": 4.968721019957902,
      "learning_rate": 3.655400896923672e-06,
      "loss": 0.5057,
      "step": 8616
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.0447075091812663,
      "learning_rate": 3.654316391802418e-06,
      "loss": 0.5047,
      "step": 8617
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6188919228374286,
      "learning_rate": 3.65323195492985e-06,
      "loss": 0.441,
      "step": 8618
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.9271978755350256,
      "learning_rate": 3.652147586360964e-06,
      "loss": 0.5222,
      "step": 8619
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.1105126141642563,
      "learning_rate": 3.65106328615076e-06,
      "loss": 0.4901,
      "step": 8620
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.572348990487894,
      "learning_rate": 3.649979054354229e-06,
      "loss": 0.4462,
      "step": 8621
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.7046416081005482,
      "learning_rate": 3.648894891026358e-06,
      "loss": 0.4758,
      "step": 8622
    },
    {
      "epoch": 0.6,
      "grad_norm": 3.197717533799034,
      "learning_rate": 3.647810796222132e-06,
      "loss": 0.4614,
      "step": 8623
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.5946131737324716,
      "learning_rate": 3.6467267699965357e-06,
      "loss": 0.4656,
      "step": 8624
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.8153642471041547,
      "learning_rate": 3.645642812404546e-06,
      "loss": 0.486,
      "step": 8625
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.846861967105965,
      "learning_rate": 3.6445589235011364e-06,
      "loss": 0.5057,
      "step": 8626
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.9253673360458237,
      "learning_rate": 3.64347510334128e-06,
      "loss": 0.4669,
      "step": 8627
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.8437512633848983,
      "learning_rate": 3.6423913519799444e-06,
      "loss": 0.4723,
      "step": 8628
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.641428609664995,
      "learning_rate": 3.641307669472093e-06,
      "loss": 0.421,
      "step": 8629
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.9839287627568616,
      "learning_rate": 3.640224055872684e-06,
      "loss": 0.5261,
      "step": 8630
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.8298861030823335,
      "learning_rate": 3.639140511236681e-06,
      "loss": 0.4847,
      "step": 8631
    },
    {
      "epoch": 0.6,
      "grad_norm": 3.853048548030516,
      "learning_rate": 3.6380570356190346e-06,
      "loss": 0.4779,
      "step": 8632
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.1152580949503297,
      "learning_rate": 3.6369736290746948e-06,
      "loss": 0.4473,
      "step": 8633
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.7400666716755802,
      "learning_rate": 3.635890291658607e-06,
      "loss": 0.464,
      "step": 8634
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.3910562268883204,
      "learning_rate": 3.6348070234257184e-06,
      "loss": 0.5359,
      "step": 8635
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.2041912779392865,
      "learning_rate": 3.6337238244309658e-06,
      "loss": 0.5019,
      "step": 8636
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.283953228862062,
      "learning_rate": 3.6326406947292875e-06,
      "loss": 0.4886,
      "step": 8637
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.4963356340974294,
      "learning_rate": 3.631557634375614e-06,
      "loss": 0.5507,
      "step": 8638
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.7045539941568524,
      "learning_rate": 3.630474643424877e-06,
      "loss": 0.4676,
      "step": 8639
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.7199219454819303,
      "learning_rate": 3.6293917219320012e-06,
      "loss": 0.4807,
      "step": 8640
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.8970293294332743,
      "learning_rate": 3.6283088699519087e-06,
      "loss": 0.4664,
      "step": 8641
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.712367196827286,
      "learning_rate": 3.6272260875395173e-06,
      "loss": 0.507,
      "step": 8642
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5655551099525311,
      "learning_rate": 3.626143374749744e-06,
      "loss": 0.4262,
      "step": 8643
    },
    {
      "epoch": 0.6,
      "grad_norm": 3.182823088622967,
      "learning_rate": 3.6250607316374996e-06,
      "loss": 0.4935,
      "step": 8644
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.589080212865829,
      "learning_rate": 3.6239781582576934e-06,
      "loss": 0.5039,
      "step": 8645
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.9756612973730743,
      "learning_rate": 3.6228956546652273e-06,
      "loss": 0.5033,
      "step": 8646
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.4797826017262725,
      "learning_rate": 3.6218132209150047e-06,
      "loss": 0.4929,
      "step": 8647
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.0495754484126913,
      "learning_rate": 3.6207308570619227e-06,
      "loss": 0.5354,
      "step": 8648
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.818162546509502,
      "learning_rate": 3.6196485631608746e-06,
      "loss": 0.4633,
      "step": 8649
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.8706553161400772,
      "learning_rate": 3.61856633926675e-06,
      "loss": 0.5029,
      "step": 8650
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.673613127882503,
      "learning_rate": 3.6174841854344388e-06,
      "loss": 0.4661,
      "step": 8651
    },
    {
      "epoch": 0.6,
      "grad_norm": 5.042556849567688,
      "learning_rate": 3.6164021017188223e-06,
      "loss": 0.4727,
      "step": 8652
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.9307283487055291,
      "learning_rate": 3.6153200881747797e-06,
      "loss": 0.4853,
      "step": 8653
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.033294282000024,
      "learning_rate": 3.6142381448571867e-06,
      "loss": 0.4951,
      "step": 8654
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.7467001650987584,
      "learning_rate": 3.613156271820919e-06,
      "loss": 0.5282,
      "step": 8655
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.9935872355874786,
      "learning_rate": 3.612074469120844e-06,
      "loss": 0.4863,
      "step": 8656
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.0435491231982295,
      "learning_rate": 3.610992736811827e-06,
      "loss": 0.5008,
      "step": 8657
    },
    {
      "epoch": 0.6,
      "grad_norm": 4.091822594244747,
      "learning_rate": 3.6099110749487282e-06,
      "loss": 0.5092,
      "step": 8658
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.9914190791015745,
      "learning_rate": 3.608829483586409e-06,
      "loss": 0.5127,
      "step": 8659
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.179685910591286,
      "learning_rate": 3.6077479627797234e-06,
      "loss": 0.4713,
      "step": 8660
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.1186237920684183,
      "learning_rate": 3.606666512583522e-06,
      "loss": 0.5077,
      "step": 8661
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.086060967775617,
      "learning_rate": 3.6055851330526503e-06,
      "loss": 0.4747,
      "step": 8662
    },
    {
      "epoch": 0.6,
      "grad_norm": 19.59165925354859,
      "learning_rate": 3.6045038242419574e-06,
      "loss": 0.5049,
      "step": 8663
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.104984589913248,
      "learning_rate": 3.60342258620628e-06,
      "loss": 0.4871,
      "step": 8664
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.8587330416692889,
      "learning_rate": 3.602341419000456e-06,
      "loss": 0.461,
      "step": 8665
    },
    {
      "epoch": 0.6,
      "grad_norm": 3.1709460132241687,
      "learning_rate": 3.601260322679317e-06,
      "loss": 0.5271,
      "step": 8666
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.6164771364983004,
      "learning_rate": 3.6001792972976957e-06,
      "loss": 0.4944,
      "step": 8667
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.8921322263121323,
      "learning_rate": 3.599098342910418e-06,
      "loss": 0.503,
      "step": 8668
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.9112924257192134,
      "learning_rate": 3.5980174595723038e-06,
      "loss": 0.5084,
      "step": 8669
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.822158757609923,
      "learning_rate": 3.5969366473381727e-06,
      "loss": 0.4863,
      "step": 8670
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.9279688416999092,
      "learning_rate": 3.5958559062628416e-06,
      "loss": 0.489,
      "step": 8671
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.6343567002916217,
      "learning_rate": 3.5947752364011216e-06,
      "loss": 0.461,
      "step": 8672
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.126449821154109,
      "learning_rate": 3.5936946378078203e-06,
      "loss": 0.4445,
      "step": 8673
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.1673879083776653,
      "learning_rate": 3.59261411053774e-06,
      "loss": 0.4352,
      "step": 8674
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.8675686021667461,
      "learning_rate": 3.5915336546456853e-06,
      "loss": 0.455,
      "step": 8675
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.443607416376508,
      "learning_rate": 3.590453270186452e-06,
      "loss": 0.5074,
      "step": 8676
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.8671948190998728,
      "learning_rate": 3.5893729572148333e-06,
      "loss": 0.5444,
      "step": 8677
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.721769692256059,
      "learning_rate": 3.5882927157856175e-06,
      "loss": 0.5327,
      "step": 8678
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.4678878034011835,
      "learning_rate": 3.5872125459535946e-06,
      "loss": 0.4691,
      "step": 8679
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.7942409737935836,
      "learning_rate": 3.586132447773546e-06,
      "loss": 0.4528,
      "step": 8680
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6138876584448307,
      "learning_rate": 3.585052421300249e-06,
      "loss": 0.4326,
      "step": 8681
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.082319620274823,
      "learning_rate": 3.58397246658848e-06,
      "loss": 0.4659,
      "step": 8682
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.9296484196979597,
      "learning_rate": 3.5828925836930118e-06,
      "loss": 0.546,
      "step": 8683
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.7084464993832884,
      "learning_rate": 3.5818127726686126e-06,
      "loss": 0.486,
      "step": 8684
    },
    {
      "epoch": 0.6,
      "grad_norm": 6.273619501473166,
      "learning_rate": 3.5807330335700444e-06,
      "loss": 0.4898,
      "step": 8685
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.6970609099542806,
      "learning_rate": 3.579653366452068e-06,
      "loss": 0.4768,
      "step": 8686
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6271802631445197,
      "learning_rate": 3.578573771369446e-06,
      "loss": 0.4273,
      "step": 8687
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.8089995149686364,
      "learning_rate": 3.5774942483769266e-06,
      "loss": 0.5215,
      "step": 8688
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.912317187614787,
      "learning_rate": 3.5764147975292596e-06,
      "loss": 0.487,
      "step": 8689
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.752699657790632,
      "learning_rate": 3.5753354188811945e-06,
      "loss": 0.477,
      "step": 8690
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.9523372705623563,
      "learning_rate": 3.5742561124874732e-06,
      "loss": 0.5091,
      "step": 8691
    },
    {
      "epoch": 0.6,
      "grad_norm": 9.67967797365203,
      "learning_rate": 3.573176878402833e-06,
      "loss": 0.4549,
      "step": 8692
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.5899773259777668,
      "learning_rate": 3.572097716682009e-06,
      "loss": 0.4698,
      "step": 8693
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.856369904768287,
      "learning_rate": 3.5710186273797343e-06,
      "loss": 0.5229,
      "step": 8694
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.4623722791097182,
      "learning_rate": 3.569939610550737e-06,
      "loss": 0.4804,
      "step": 8695
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.608624476101871,
      "learning_rate": 3.5688606662497393e-06,
      "loss": 0.4888,
      "step": 8696
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.8653612133126203,
      "learning_rate": 3.567781794531461e-06,
      "loss": 0.5117,
      "step": 8697
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.0656576452552655,
      "learning_rate": 3.5667029954506233e-06,
      "loss": 0.4622,
      "step": 8698
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.4586506947571363,
      "learning_rate": 3.565624269061937e-06,
      "loss": 0.5069,
      "step": 8699
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.0685490929622494,
      "learning_rate": 3.564545615420111e-06,
      "loss": 0.4198,
      "step": 8700
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.207455007656064,
      "learning_rate": 3.56346703457985e-06,
      "loss": 0.5638,
      "step": 8701
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.195472715725206,
      "learning_rate": 3.562388526595858e-06,
      "loss": 0.4777,
      "step": 8702
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.133486996306947,
      "learning_rate": 3.561310091522835e-06,
      "loss": 0.5215,
      "step": 8703
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.9191998765863327,
      "learning_rate": 3.5602317294154727e-06,
      "loss": 0.4733,
      "step": 8704
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.23787895906521,
      "learning_rate": 3.5591534403284623e-06,
      "loss": 0.4471,
      "step": 8705
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.9519037582465522,
      "learning_rate": 3.558075224316493e-06,
      "loss": 0.4822,
      "step": 8706
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.3996846072663223,
      "learning_rate": 3.556997081434248e-06,
      "loss": 0.4847,
      "step": 8707
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.2334624028919254,
      "learning_rate": 3.5559190117364064e-06,
      "loss": 0.5456,
      "step": 8708
    },
    {
      "epoch": 0.61,
      "grad_norm": 5.229674052080303,
      "learning_rate": 3.5548410152776414e-06,
      "loss": 0.5163,
      "step": 8709
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.06307329112393,
      "learning_rate": 3.5537630921126322e-06,
      "loss": 0.4824,
      "step": 8710
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.7797579599460052,
      "learning_rate": 3.552685242296043e-06,
      "loss": 0.4774,
      "step": 8711
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.176238513166013,
      "learning_rate": 3.55160746588254e-06,
      "loss": 0.5009,
      "step": 8712
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.904392620282068,
      "learning_rate": 3.550529762926783e-06,
      "loss": 0.5589,
      "step": 8713
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.9859007645377453,
      "learning_rate": 3.5494521334834326e-06,
      "loss": 0.4613,
      "step": 8714
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.3933126509772586,
      "learning_rate": 3.5483745776071403e-06,
      "loss": 0.4352,
      "step": 8715
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.7529975593077187,
      "learning_rate": 3.5472970953525576e-06,
      "loss": 0.4826,
      "step": 8716
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.5565776164806504,
      "learning_rate": 3.546219686774327e-06,
      "loss": 0.4802,
      "step": 8717
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.8945135421868127,
      "learning_rate": 3.545142351927097e-06,
      "loss": 0.4752,
      "step": 8718
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.1835620651326004,
      "learning_rate": 3.544065090865504e-06,
      "loss": 0.4764,
      "step": 8719
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.9405647987013668,
      "learning_rate": 3.5429879036441826e-06,
      "loss": 0.5356,
      "step": 8720
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.1175439988263465,
      "learning_rate": 3.541910790317763e-06,
      "loss": 0.4825,
      "step": 8721
    },
    {
      "epoch": 0.61,
      "grad_norm": 3.6205056621595273,
      "learning_rate": 3.5408337509408764e-06,
      "loss": 0.5053,
      "step": 8722
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.8062437059171046,
      "learning_rate": 3.539756785568144e-06,
      "loss": 0.4865,
      "step": 8723
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.6507819280732148,
      "learning_rate": 3.5386798942541876e-06,
      "loss": 0.4469,
      "step": 8724
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.168048224533879,
      "learning_rate": 3.5376030770536213e-06,
      "loss": 0.5057,
      "step": 8725
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.562437027783778,
      "learning_rate": 3.536526334021061e-06,
      "loss": 0.4961,
      "step": 8726
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.8922766816401773,
      "learning_rate": 3.5354496652111125e-06,
      "loss": 0.4984,
      "step": 8727
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.3041396493986492,
      "learning_rate": 3.5343730706783835e-06,
      "loss": 0.5418,
      "step": 8728
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.3665938309036534,
      "learning_rate": 3.5332965504774717e-06,
      "loss": 0.5076,
      "step": 8729
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.9846114361323117,
      "learning_rate": 3.532220104662979e-06,
      "loss": 0.5254,
      "step": 8730
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.989767476723469,
      "learning_rate": 3.5311437332894977e-06,
      "loss": 0.4714,
      "step": 8731
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.8803159926697783,
      "learning_rate": 3.5300674364116173e-06,
      "loss": 0.5329,
      "step": 8732
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.9012052479146782,
      "learning_rate": 3.528991214083922e-06,
      "loss": 0.4758,
      "step": 8733
    },
    {
      "epoch": 0.61,
      "grad_norm": 3.301365579674432,
      "learning_rate": 3.527915066360999e-06,
      "loss": 0.5203,
      "step": 8734
    },
    {
      "epoch": 0.61,
      "grad_norm": 4.812748610216327,
      "learning_rate": 3.5268389932974243e-06,
      "loss": 0.5149,
      "step": 8735
    },
    {
      "epoch": 0.61,
      "grad_norm": 3.254844798482161,
      "learning_rate": 3.5257629949477735e-06,
      "loss": 0.4855,
      "step": 8736
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.9400200447330078,
      "learning_rate": 3.524687071366616e-06,
      "loss": 0.5377,
      "step": 8737
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.8214286026391397,
      "learning_rate": 3.523611222608521e-06,
      "loss": 0.4705,
      "step": 8738
    },
    {
      "epoch": 0.61,
      "grad_norm": 3.6486786391802806,
      "learning_rate": 3.5225354487280523e-06,
      "loss": 0.4962,
      "step": 8739
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.574246096188104,
      "learning_rate": 3.521459749779769e-06,
      "loss": 0.4272,
      "step": 8740
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.748607371430046,
      "learning_rate": 3.5203841258182238e-06,
      "loss": 0.4597,
      "step": 8741
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.0884990186278096,
      "learning_rate": 3.519308576897974e-06,
      "loss": 0.4712,
      "step": 8742
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.351119477351499,
      "learning_rate": 3.518233103073566e-06,
      "loss": 0.4986,
      "step": 8743
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.2194007585631086,
      "learning_rate": 3.5171577043995453e-06,
      "loss": 0.4719,
      "step": 8744
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.2068355603362066,
      "learning_rate": 3.516082380930448e-06,
      "loss": 0.4767,
      "step": 8745
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.4418734857727746,
      "learning_rate": 3.5150071327208173e-06,
      "loss": 0.511,
      "step": 8746
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.990405766892547,
      "learning_rate": 3.5139319598251832e-06,
      "loss": 0.4816,
      "step": 8747
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.178919420650684,
      "learning_rate": 3.5128568622980754e-06,
      "loss": 0.4491,
      "step": 8748
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.1522596920471995,
      "learning_rate": 3.5117818401940186e-06,
      "loss": 0.5026,
      "step": 8749
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.924907282298407,
      "learning_rate": 3.510706893567535e-06,
      "loss": 0.536,
      "step": 8750
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.9059183826358224,
      "learning_rate": 3.509632022473143e-06,
      "loss": 0.4728,
      "step": 8751
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.965823614855208,
      "learning_rate": 3.5085572269653535e-06,
      "loss": 0.5269,
      "step": 8752
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.75911954646349,
      "learning_rate": 3.507482507098682e-06,
      "loss": 0.507,
      "step": 8753
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.131520424982387,
      "learning_rate": 3.506407862927631e-06,
      "loss": 0.4978,
      "step": 8754
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.380848628268017,
      "learning_rate": 3.5053332945067044e-06,
      "loss": 0.4852,
      "step": 8755
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5757967501331926,
      "learning_rate": 3.5042588018903972e-06,
      "loss": 0.4273,
      "step": 8756
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.2323662679670457,
      "learning_rate": 3.5031843851332105e-06,
      "loss": 0.5067,
      "step": 8757
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.0258300946322287,
      "learning_rate": 3.5021100442896305e-06,
      "loss": 0.4883,
      "step": 8758
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.7499287424751295,
      "learning_rate": 3.501035779414147e-06,
      "loss": 0.5062,
      "step": 8759
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.036058683585671,
      "learning_rate": 3.49996159056124e-06,
      "loss": 0.4969,
      "step": 8760
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.9468409238106958,
      "learning_rate": 3.498887477785392e-06,
      "loss": 0.4752,
      "step": 8761
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5282614014502104,
      "learning_rate": 3.497813441141077e-06,
      "loss": 0.4193,
      "step": 8762
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.7714882940589372,
      "learning_rate": 3.496739480682767e-06,
      "loss": 0.4421,
      "step": 8763
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.4764107407743894,
      "learning_rate": 3.495665596464928e-06,
      "loss": 0.4927,
      "step": 8764
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.3654921931416553,
      "learning_rate": 3.494591788542027e-06,
      "loss": 0.4566,
      "step": 8765
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.8463773821730125,
      "learning_rate": 3.4935180569685224e-06,
      "loss": 0.5358,
      "step": 8766
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.570792904112061,
      "learning_rate": 3.4924444017988713e-06,
      "loss": 0.4659,
      "step": 8767
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.1317592092601405,
      "learning_rate": 3.4913708230875238e-06,
      "loss": 0.4749,
      "step": 8768
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.0310837844406366,
      "learning_rate": 3.490297320888931e-06,
      "loss": 0.5051,
      "step": 8769
    },
    {
      "epoch": 0.61,
      "grad_norm": 3.8451880611534888,
      "learning_rate": 3.489223895257535e-06,
      "loss": 0.51,
      "step": 8770
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.6885564945262475,
      "learning_rate": 3.488150546247778e-06,
      "loss": 0.4857,
      "step": 8771
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.260661034338405,
      "learning_rate": 3.4870772739140956e-06,
      "loss": 0.4879,
      "step": 8772
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.568548433656158,
      "learning_rate": 3.4860040783109233e-06,
      "loss": 0.5057,
      "step": 8773
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.4166584312886275,
      "learning_rate": 3.4849309594926878e-06,
      "loss": 0.4826,
      "step": 8774
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.115571671754306,
      "learning_rate": 3.4838579175138143e-06,
      "loss": 0.4927,
      "step": 8775
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.8156957964400275,
      "learning_rate": 3.4827849524287227e-06,
      "loss": 0.4791,
      "step": 8776
    },
    {
      "epoch": 0.61,
      "grad_norm": 5.404963684402209,
      "learning_rate": 3.481712064291834e-06,
      "loss": 0.5071,
      "step": 8777
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.5941193545916326,
      "learning_rate": 3.4806392531575593e-06,
      "loss": 0.5101,
      "step": 8778
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.9258668176741145,
      "learning_rate": 3.479566519080308e-06,
      "loss": 0.4853,
      "step": 8779
    },
    {
      "epoch": 0.61,
      "grad_norm": 7.919125946824574,
      "learning_rate": 3.478493862114485e-06,
      "loss": 0.5004,
      "step": 8780
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.9212210690066103,
      "learning_rate": 3.4774212823144947e-06,
      "loss": 0.4584,
      "step": 8781
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.2366337841532613,
      "learning_rate": 3.476348779734732e-06,
      "loss": 0.526,
      "step": 8782
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.9336451823172394,
      "learning_rate": 3.4752763544295926e-06,
      "loss": 0.5146,
      "step": 8783
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.3928805723874627,
      "learning_rate": 3.4742040064534634e-06,
      "loss": 0.4975,
      "step": 8784
    },
    {
      "epoch": 0.61,
      "grad_norm": 3.122583433523553,
      "learning_rate": 3.473131735860734e-06,
      "loss": 0.5001,
      "step": 8785
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.765816942492644,
      "learning_rate": 3.4720595427057857e-06,
      "loss": 0.5073,
      "step": 8786
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.8712257732305828,
      "learning_rate": 3.4709874270429968e-06,
      "loss": 0.507,
      "step": 8787
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.8415626954378688,
      "learning_rate": 3.4699153889267374e-06,
      "loss": 0.5084,
      "step": 8788
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5997363418250261,
      "learning_rate": 3.4688434284113837e-06,
      "loss": 0.4112,
      "step": 8789
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.9210874212776132,
      "learning_rate": 3.4677715455512995e-06,
      "loss": 0.4694,
      "step": 8790
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.3843894479801344,
      "learning_rate": 3.466699740400846e-06,
      "loss": 0.4685,
      "step": 8791
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.154164601181218,
      "learning_rate": 3.4656280130143837e-06,
      "loss": 0.5022,
      "step": 8792
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.7965491875062494,
      "learning_rate": 3.4645563634462665e-06,
      "loss": 0.5144,
      "step": 8793
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.7625742545723162,
      "learning_rate": 3.4634847917508443e-06,
      "loss": 0.4931,
      "step": 8794
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.9687107617080009,
      "learning_rate": 3.462413297982464e-06,
      "loss": 0.468,
      "step": 8795
    },
    {
      "epoch": 0.61,
      "grad_norm": 34.725674405533354,
      "learning_rate": 3.461341882195467e-06,
      "loss": 0.4952,
      "step": 8796
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.9496236448138,
      "learning_rate": 3.460270544444195e-06,
      "loss": 0.5396,
      "step": 8797
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.770461973364542,
      "learning_rate": 3.4591992847829814e-06,
      "loss": 0.4852,
      "step": 8798
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.009357752724449,
      "learning_rate": 3.458128103266157e-06,
      "loss": 0.4961,
      "step": 8799
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.180335413671654,
      "learning_rate": 3.457056999948046e-06,
      "loss": 0.4836,
      "step": 8800
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.188799697266294,
      "learning_rate": 3.455985974882976e-06,
      "loss": 0.4954,
      "step": 8801
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.0208266499595275,
      "learning_rate": 3.4549150281252635e-06,
      "loss": 0.4954,
      "step": 8802
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.9484179579043257,
      "learning_rate": 3.453844159729224e-06,
      "loss": 0.4663,
      "step": 8803
    },
    {
      "epoch": 0.61,
      "grad_norm": 8.022666859432563,
      "learning_rate": 3.452773369749166e-06,
      "loss": 0.4921,
      "step": 8804
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.324649211159589,
      "learning_rate": 3.4517026582394e-06,
      "loss": 0.5113,
      "step": 8805
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.5635798585196449,
      "learning_rate": 3.450632025254227e-06,
      "loss": 0.4358,
      "step": 8806
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.6628352035020626,
      "learning_rate": 3.449561470847947e-06,
      "loss": 0.515,
      "step": 8807
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.9191076121379815,
      "learning_rate": 3.448490995074852e-06,
      "loss": 0.4839,
      "step": 8808
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.474461424474086,
      "learning_rate": 3.447420597989238e-06,
      "loss": 0.5538,
      "step": 8809
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.322786982065853,
      "learning_rate": 3.446350279645389e-06,
      "loss": 0.5019,
      "step": 8810
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.8428969217718385,
      "learning_rate": 3.445280040097589e-06,
      "loss": 0.5152,
      "step": 8811
    },
    {
      "epoch": 0.61,
      "grad_norm": 5.635705160733635,
      "learning_rate": 3.4442098794001146e-06,
      "loss": 0.4853,
      "step": 8812
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.6470856315101707,
      "learning_rate": 3.443139797607245e-06,
      "loss": 0.5133,
      "step": 8813
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.886944640258704,
      "learning_rate": 3.442069794773249e-06,
      "loss": 0.4798,
      "step": 8814
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.8620330987153646,
      "learning_rate": 3.4409998709523927e-06,
      "loss": 0.474,
      "step": 8815
    },
    {
      "epoch": 0.61,
      "grad_norm": 4.087330271083543,
      "learning_rate": 3.439930026198942e-06,
      "loss": 0.4738,
      "step": 8816
    },
    {
      "epoch": 0.61,
      "grad_norm": 5.592735252957989,
      "learning_rate": 3.438860260567154e-06,
      "loss": 0.5149,
      "step": 8817
    },
    {
      "epoch": 0.61,
      "grad_norm": 3.7486647482653677,
      "learning_rate": 3.437790574111284e-06,
      "loss": 0.4936,
      "step": 8818
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.331789822497334,
      "learning_rate": 3.4367209668855807e-06,
      "loss": 0.517,
      "step": 8819
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.4650382625425893,
      "learning_rate": 3.435651438944295e-06,
      "loss": 0.5063,
      "step": 8820
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.224309590398428,
      "learning_rate": 3.4345819903416696e-06,
      "loss": 0.5467,
      "step": 8821
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.552078386850463,
      "learning_rate": 3.4335126211319412e-06,
      "loss": 0.5063,
      "step": 8822
    },
    {
      "epoch": 0.61,
      "grad_norm": 3.5354961287132958,
      "learning_rate": 3.4324433313693437e-06,
      "loss": 0.476,
      "step": 8823
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.6275576290916898,
      "learning_rate": 3.431374121108112e-06,
      "loss": 0.5131,
      "step": 8824
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.3428152074927175,
      "learning_rate": 3.4303049904024704e-06,
      "loss": 0.5083,
      "step": 8825
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.868107679929676,
      "learning_rate": 3.4292359393066426e-06,
      "loss": 0.4622,
      "step": 8826
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.6353099485484646,
      "learning_rate": 3.4281669678748463e-06,
      "loss": 0.5033,
      "step": 8827
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.6799355190531098,
      "learning_rate": 3.427098076161297e-06,
      "loss": 0.4013,
      "step": 8828
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.5162670001714056,
      "learning_rate": 3.4260292642202063e-06,
      "loss": 0.4815,
      "step": 8829
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.1124620631585684,
      "learning_rate": 3.4249605321057794e-06,
      "loss": 0.4825,
      "step": 8830
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.225725369469777,
      "learning_rate": 3.4238918798722176e-06,
      "loss": 0.491,
      "step": 8831
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.3272973964142265,
      "learning_rate": 3.4228233075737225e-06,
      "loss": 0.4452,
      "step": 8832
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.071905791268582,
      "learning_rate": 3.4217548152644887e-06,
      "loss": 0.5324,
      "step": 8833
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.1978946274373965,
      "learning_rate": 3.420686402998704e-06,
      "loss": 0.5078,
      "step": 8834
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.5481747512673545,
      "learning_rate": 3.419618070830556e-06,
      "loss": 0.4997,
      "step": 8835
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.8850304542070344,
      "learning_rate": 3.4185498188142274e-06,
      "loss": 0.5043,
      "step": 8836
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.317825804273937,
      "learning_rate": 3.4174816470038963e-06,
      "loss": 0.493,
      "step": 8837
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.924059184274865,
      "learning_rate": 3.416413555453736e-06,
      "loss": 0.4849,
      "step": 8838
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.0763071937047504,
      "learning_rate": 3.415345544217917e-06,
      "loss": 0.5231,
      "step": 8839
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.5854059255264894,
      "learning_rate": 3.4142776133506073e-06,
      "loss": 0.5312,
      "step": 8840
    },
    {
      "epoch": 0.61,
      "grad_norm": 4.690836959563443,
      "learning_rate": 3.4132097629059668e-06,
      "loss": 0.529,
      "step": 8841
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.6089229909627812,
      "learning_rate": 3.412141992938155e-06,
      "loss": 0.4129,
      "step": 8842
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.4528669440864177,
      "learning_rate": 3.4110743035013214e-06,
      "loss": 0.5235,
      "step": 8843
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.8251130154345028,
      "learning_rate": 3.4100066946496212e-06,
      "loss": 0.4862,
      "step": 8844
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.059253405592506,
      "learning_rate": 3.4089391664371974e-06,
      "loss": 0.4849,
      "step": 8845
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5812540431518138,
      "learning_rate": 3.407871718918193e-06,
      "loss": 0.4325,
      "step": 8846
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.0494996841434903,
      "learning_rate": 3.4068043521467424e-06,
      "loss": 0.4971,
      "step": 8847
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.1479778075333282,
      "learning_rate": 3.4057370661769823e-06,
      "loss": 0.4999,
      "step": 8848
    },
    {
      "epoch": 0.62,
      "grad_norm": 3.3996523993823113,
      "learning_rate": 3.404669861063041e-06,
      "loss": 0.5312,
      "step": 8849
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5689590721554117,
      "learning_rate": 3.4036027368590423e-06,
      "loss": 0.4425,
      "step": 8850
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.8542528211004818,
      "learning_rate": 3.4025356936191068e-06,
      "loss": 0.456,
      "step": 8851
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.3944904629665813,
      "learning_rate": 3.4014687313973547e-06,
      "loss": 0.481,
      "step": 8852
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5970675989136678,
      "learning_rate": 3.4004018502478976e-06,
      "loss": 0.4217,
      "step": 8853
    },
    {
      "epoch": 0.62,
      "grad_norm": 4.986013295900373,
      "learning_rate": 3.3993350502248433e-06,
      "loss": 0.464,
      "step": 8854
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.6538638630156082,
      "learning_rate": 3.398268331382295e-06,
      "loss": 0.5166,
      "step": 8855
    },
    {
      "epoch": 0.62,
      "grad_norm": 3.493234321628137,
      "learning_rate": 3.3972016937743566e-06,
      "loss": 0.492,
      "step": 8856
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.392435762738397,
      "learning_rate": 3.3961351374551234e-06,
      "loss": 0.5064,
      "step": 8857
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.063935971885017,
      "learning_rate": 3.3950686624786866e-06,
      "loss": 0.5051,
      "step": 8858
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.8962049378395769,
      "learning_rate": 3.3940022688991337e-06,
      "loss": 0.4958,
      "step": 8859
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.4852547091623185,
      "learning_rate": 3.392935956770551e-06,
      "loss": 0.4593,
      "step": 8860
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.3154171033503426,
      "learning_rate": 3.391869726147018e-06,
      "loss": 0.443,
      "step": 8861
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.2298768023184303,
      "learning_rate": 3.3908035770826085e-06,
      "loss": 0.4827,
      "step": 8862
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.853599150656625,
      "learning_rate": 3.389737509631394e-06,
      "loss": 0.4718,
      "step": 8863
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.564413266471292,
      "learning_rate": 3.3886715238474454e-06,
      "loss": 0.4827,
      "step": 8864
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.3279211440696685,
      "learning_rate": 3.3876056197848236e-06,
      "loss": 0.5262,
      "step": 8865
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5920109997241098,
      "learning_rate": 3.3865397974975878e-06,
      "loss": 0.4297,
      "step": 8866
    },
    {
      "epoch": 0.62,
      "grad_norm": 5.9748594258868435,
      "learning_rate": 3.3854740570397913e-06,
      "loss": 0.4952,
      "step": 8867
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.8057959118102553,
      "learning_rate": 3.38440839846549e-06,
      "loss": 0.492,
      "step": 8868
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.8943772687119238,
      "learning_rate": 3.383342821828727e-06,
      "loss": 0.4864,
      "step": 8869
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.775315773691536,
      "learning_rate": 3.3822773271835446e-06,
      "loss": 0.4986,
      "step": 8870
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.0382887857601335,
      "learning_rate": 3.3812119145839815e-06,
      "loss": 0.4752,
      "step": 8871
    },
    {
      "epoch": 0.62,
      "grad_norm": 7.660116501391881,
      "learning_rate": 3.380146584084074e-06,
      "loss": 0.5005,
      "step": 8872
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.6095040294378933,
      "learning_rate": 3.3790813357378505e-06,
      "loss": 0.5256,
      "step": 8873
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.906474894395328,
      "learning_rate": 3.3780161695993374e-06,
      "loss": 0.4515,
      "step": 8874
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.134173564118845,
      "learning_rate": 3.376951085722554e-06,
      "loss": 0.4746,
      "step": 8875
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.9693402821030683,
      "learning_rate": 3.375886084161522e-06,
      "loss": 0.5367,
      "step": 8876
    },
    {
      "epoch": 0.62,
      "grad_norm": 3.1803618752734932,
      "learning_rate": 3.3748211649702533e-06,
      "loss": 0.4768,
      "step": 8877
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.9057100725656198,
      "learning_rate": 3.373756328202756e-06,
      "loss": 0.522,
      "step": 8878
    },
    {
      "epoch": 0.62,
      "grad_norm": 4.730213094707779,
      "learning_rate": 3.3726915739130343e-06,
      "loss": 0.5162,
      "step": 8879
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.7893837147252665,
      "learning_rate": 3.371626902155093e-06,
      "loss": 0.492,
      "step": 8880
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.1001633749649353,
      "learning_rate": 3.370562312982926e-06,
      "loss": 0.5279,
      "step": 8881
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.3164227324246607,
      "learning_rate": 3.3694978064505258e-06,
      "loss": 0.484,
      "step": 8882
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.211836512098253,
      "learning_rate": 3.368433382611881e-06,
      "loss": 0.4645,
      "step": 8883
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.768735817974339,
      "learning_rate": 3.3673690415209765e-06,
      "loss": 0.4913,
      "step": 8884
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.9282393849245205,
      "learning_rate": 3.3663047832317918e-06,
      "loss": 0.4952,
      "step": 8885
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.809550673638019,
      "learning_rate": 3.3652406077982998e-06,
      "loss": 0.4842,
      "step": 8886
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.2426536373293597,
      "learning_rate": 3.3641765152744763e-06,
      "loss": 0.4641,
      "step": 8887
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.0322287546335986,
      "learning_rate": 3.3631125057142876e-06,
      "loss": 0.5138,
      "step": 8888
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.1330530127522604,
      "learning_rate": 3.362048579171696e-06,
      "loss": 0.4622,
      "step": 8889
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.1278639860842787,
      "learning_rate": 3.3609847357006588e-06,
      "loss": 0.5047,
      "step": 8890
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.9141743076508873,
      "learning_rate": 3.359920975355133e-06,
      "loss": 0.4535,
      "step": 8891
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.565143932212838,
      "learning_rate": 3.358857298189069e-06,
      "loss": 0.511,
      "step": 8892
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.6717170407498299,
      "learning_rate": 3.3577937042564124e-06,
      "loss": 0.4787,
      "step": 8893
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.6050973771285925,
      "learning_rate": 3.356730193611104e-06,
      "loss": 0.4324,
      "step": 8894
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.8519202560389252,
      "learning_rate": 3.355666766307084e-06,
      "loss": 0.4875,
      "step": 8895
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.8078290577546423,
      "learning_rate": 3.354603422398285e-06,
      "loss": 0.458,
      "step": 8896
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5957377890441637,
      "learning_rate": 3.3535401619386366e-06,
      "loss": 0.4107,
      "step": 8897
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.9281740651044383,
      "learning_rate": 3.3524769849820606e-06,
      "loss": 0.4945,
      "step": 8898
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.7235429483595137,
      "learning_rate": 3.3514138915824824e-06,
      "loss": 0.4958,
      "step": 8899
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.20377636754361,
      "learning_rate": 3.350350881793818e-06,
      "loss": 0.4602,
      "step": 8900
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.987326233471446,
      "learning_rate": 3.3492879556699775e-06,
      "loss": 0.5336,
      "step": 8901
    },
    {
      "epoch": 0.62,
      "grad_norm": 3.0188586183404142,
      "learning_rate": 3.34822511326487e-06,
      "loss": 0.5461,
      "step": 8902
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.6505639026257692,
      "learning_rate": 3.3471623546324007e-06,
      "loss": 0.4794,
      "step": 8903
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.2569119784564475,
      "learning_rate": 3.3460996798264677e-06,
      "loss": 0.4959,
      "step": 8904
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.642442079427836,
      "learning_rate": 3.3450370889009674e-06,
      "loss": 0.4224,
      "step": 8905
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.853542214413279,
      "learning_rate": 3.3439745819097884e-06,
      "loss": 0.5093,
      "step": 8906
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.8184054267229766,
      "learning_rate": 3.3429121589068213e-06,
      "loss": 0.5024,
      "step": 8907
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.926845032294818,
      "learning_rate": 3.3418498199459477e-06,
      "loss": 0.5162,
      "step": 8908
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.8398124267901366,
      "learning_rate": 3.340787565081045e-06,
      "loss": 0.4996,
      "step": 8909
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5880470823772501,
      "learning_rate": 3.3397253943659855e-06,
      "loss": 0.4107,
      "step": 8910
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.859063525717027,
      "learning_rate": 3.338663307854644e-06,
      "loss": 0.5057,
      "step": 8911
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.104222762452133,
      "learning_rate": 3.337601305600882e-06,
      "loss": 0.5079,
      "step": 8912
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.9025836058480945,
      "learning_rate": 3.3365393876585626e-06,
      "loss": 0.4638,
      "step": 8913
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.6582868192073619,
      "learning_rate": 3.3354775540815415e-06,
      "loss": 0.483,
      "step": 8914
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.2637797176836663,
      "learning_rate": 3.334415804923673e-06,
      "loss": 0.5117,
      "step": 8915
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.059083715040581,
      "learning_rate": 3.3333541402388046e-06,
      "loss": 0.507,
      "step": 8916
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.5936613150670852,
      "learning_rate": 3.332292560080781e-06,
      "loss": 0.4312,
      "step": 8917
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.3219814574300965,
      "learning_rate": 3.3312310645034395e-06,
      "loss": 0.52,
      "step": 8918
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.578785550101263,
      "learning_rate": 3.33016965356062e-06,
      "loss": 0.526,
      "step": 8919
    },
    {
      "epoch": 0.62,
      "grad_norm": 3.225790503456611,
      "learning_rate": 3.329108327306152e-06,
      "loss": 0.4917,
      "step": 8920
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.42001429292719,
      "learning_rate": 3.328047085793862e-06,
      "loss": 0.4761,
      "step": 8921
    },
    {
      "epoch": 0.62,
      "grad_norm": 7.071763573716744,
      "learning_rate": 3.32698592907757e-06,
      "loss": 0.4455,
      "step": 8922
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.050548131848828,
      "learning_rate": 3.3259248572111e-06,
      "loss": 0.5077,
      "step": 8923
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.708243662674518,
      "learning_rate": 3.324863870248264e-06,
      "loss": 0.5095,
      "step": 8924
    },
    {
      "epoch": 0.62,
      "grad_norm": 3.209930034084598,
      "learning_rate": 3.3238029682428706e-06,
      "loss": 0.5192,
      "step": 8925
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.366625630419231,
      "learning_rate": 3.322742151248726e-06,
      "loss": 0.5354,
      "step": 8926
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.410251389486204,
      "learning_rate": 3.321681419319631e-06,
      "loss": 0.4798,
      "step": 8927
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.4458036925561277,
      "learning_rate": 3.320620772509383e-06,
      "loss": 0.5084,
      "step": 8928
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.580302272474173,
      "learning_rate": 3.319560210871775e-06,
      "loss": 0.4424,
      "step": 8929
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.1322463039683663,
      "learning_rate": 3.3184997344605917e-06,
      "loss": 0.5142,
      "step": 8930
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.5996627451862926,
      "learning_rate": 3.3174393433296228e-06,
      "loss": 0.4474,
      "step": 8931
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.8012038502053198,
      "learning_rate": 3.316379037532644e-06,
      "loss": 0.4508,
      "step": 8932
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.8811253562423178,
      "learning_rate": 3.315318817123432e-06,
      "loss": 0.5071,
      "step": 8933
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.082239312802852,
      "learning_rate": 3.3142586821557554e-06,
      "loss": 0.5049,
      "step": 8934
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.990049254040218,
      "learning_rate": 3.313198632683384e-06,
      "loss": 0.4611,
      "step": 8935
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.174935888940203,
      "learning_rate": 3.3121386687600788e-06,
      "loss": 0.506,
      "step": 8936
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.168749324777895,
      "learning_rate": 3.311078790439598e-06,
      "loss": 0.498,
      "step": 8937
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.8454856275269749,
      "learning_rate": 3.3100189977756936e-06,
      "loss": 0.4986,
      "step": 8938
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.970555285946365,
      "learning_rate": 3.308959290822117e-06,
      "loss": 0.463,
      "step": 8939
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.19995183576267,
      "learning_rate": 3.307899669632612e-06,
      "loss": 0.5069,
      "step": 8940
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.927925182357444,
      "learning_rate": 3.306840134260919e-06,
      "loss": 0.4536,
      "step": 8941
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.7688304642993922,
      "learning_rate": 3.305780684760773e-06,
      "loss": 0.4448,
      "step": 8942
    },
    {
      "epoch": 0.62,
      "grad_norm": 3.3070631126537315,
      "learning_rate": 3.3047213211859085e-06,
      "loss": 0.5172,
      "step": 8943
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.7131605311993771,
      "learning_rate": 3.303662043590052e-06,
      "loss": 0.4524,
      "step": 8944
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.976579050722712,
      "learning_rate": 3.302602852026924e-06,
      "loss": 0.4426,
      "step": 8945
    },
    {
      "epoch": 0.62,
      "grad_norm": 44.778472746398776,
      "learning_rate": 3.3015437465502476e-06,
      "loss": 0.5195,
      "step": 8946
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.8379620202157967,
      "learning_rate": 3.3004847272137354e-06,
      "loss": 0.5096,
      "step": 8947
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.5422798696883684,
      "learning_rate": 3.2994257940710964e-06,
      "loss": 0.4628,
      "step": 8948
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.6016939245117136,
      "learning_rate": 3.2983669471760373e-06,
      "loss": 0.4214,
      "step": 8949
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.248743239508728,
      "learning_rate": 3.2973081865822585e-06,
      "loss": 0.5378,
      "step": 8950
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.7482443244797854,
      "learning_rate": 3.296249512343458e-06,
      "loss": 0.4969,
      "step": 8951
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.7852598361535506,
      "learning_rate": 3.2951909245133277e-06,
      "loss": 0.477,
      "step": 8952
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.6934665668739162,
      "learning_rate": 3.294132423145554e-06,
      "loss": 0.494,
      "step": 8953
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.4484299909196388,
      "learning_rate": 3.293074008293824e-06,
      "loss": 0.455,
      "step": 8954
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.9959223255969267,
      "learning_rate": 3.2920156800118154e-06,
      "loss": 0.4962,
      "step": 8955
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.7426535494096862,
      "learning_rate": 3.290957438353203e-06,
      "loss": 0.4761,
      "step": 8956
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.5011364387755015,
      "learning_rate": 3.289899283371657e-06,
      "loss": 0.5125,
      "step": 8957
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.97629351742626,
      "learning_rate": 3.2888412151208448e-06,
      "loss": 0.5343,
      "step": 8958
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.9440055448367484,
      "learning_rate": 3.2877832336544263e-06,
      "loss": 0.4629,
      "step": 8959
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.4021592506421925,
      "learning_rate": 3.286725339026061e-06,
      "loss": 0.4272,
      "step": 8960
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.0888430259816073,
      "learning_rate": 3.2856675312894005e-06,
      "loss": 0.4572,
      "step": 8961
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.7977025559164461,
      "learning_rate": 3.284609810498094e-06,
      "loss": 0.482,
      "step": 8962
    },
    {
      "epoch": 0.62,
      "grad_norm": 3.1053192262099443,
      "learning_rate": 3.283552176705786e-06,
      "loss": 0.4779,
      "step": 8963
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.314230764848401,
      "learning_rate": 3.2824946299661154e-06,
      "loss": 0.5264,
      "step": 8964
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.901723844180573,
      "learning_rate": 3.2814371703327162e-06,
      "loss": 0.5283,
      "step": 8965
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.2152116681731857,
      "learning_rate": 3.280379797859222e-06,
      "loss": 0.4552,
      "step": 8966
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.3079112488382245,
      "learning_rate": 3.279322512599259e-06,
      "loss": 0.4805,
      "step": 8967
    },
    {
      "epoch": 0.62,
      "grad_norm": 3.501926318907734,
      "learning_rate": 3.278265314606448e-06,
      "loss": 0.4628,
      "step": 8968
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.0773135388547344,
      "learning_rate": 3.2772082039344065e-06,
      "loss": 0.4889,
      "step": 8969
    },
    {
      "epoch": 0.62,
      "grad_norm": 3.8267528596941656,
      "learning_rate": 3.276151180636749e-06,
      "loss": 0.4826,
      "step": 8970
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.2001244284454495,
      "learning_rate": 3.2750942447670837e-06,
      "loss": 0.4572,
      "step": 8971
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.471327745148195,
      "learning_rate": 3.2740373963790147e-06,
      "loss": 0.5031,
      "step": 8972
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.879038735234859,
      "learning_rate": 3.2729806355261396e-06,
      "loss": 0.5173,
      "step": 8973
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.129889548648009,
      "learning_rate": 3.2719239622620587e-06,
      "loss": 0.4934,
      "step": 8974
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.765948991024323,
      "learning_rate": 3.2708673766403604e-06,
      "loss": 0.4533,
      "step": 8975
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.8887544966668817,
      "learning_rate": 3.2698108787146314e-06,
      "loss": 0.501,
      "step": 8976
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.17101367148897,
      "learning_rate": 3.268754468538452e-06,
      "loss": 0.5046,
      "step": 8977
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.7348622862106986,
      "learning_rate": 3.267698146165404e-06,
      "loss": 0.4194,
      "step": 8978
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.9849874794076334,
      "learning_rate": 3.266641911649058e-06,
      "loss": 0.5012,
      "step": 8979
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.742235415465633,
      "learning_rate": 3.2655857650429836e-06,
      "loss": 0.5146,
      "step": 8980
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.8752522775013056,
      "learning_rate": 3.264529706400743e-06,
      "loss": 0.4687,
      "step": 8981
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.7744817048343136,
      "learning_rate": 3.2634737357758994e-06,
      "loss": 0.5273,
      "step": 8982
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.5528769048333841,
      "learning_rate": 3.2624178532220062e-06,
      "loss": 0.473,
      "step": 8983
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.2369713733054475,
      "learning_rate": 3.261362058792615e-06,
      "loss": 0.4579,
      "step": 8984
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.0468757631426677,
      "learning_rate": 3.2603063525412694e-06,
      "loss": 0.5423,
      "step": 8985
    },
    {
      "epoch": 0.62,
      "grad_norm": 3.467215916882893,
      "learning_rate": 3.259250734521516e-06,
      "loss": 0.4927,
      "step": 8986
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.8695767679926145,
      "learning_rate": 3.25819520478689e-06,
      "loss": 0.4997,
      "step": 8987
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.0375210680800144,
      "learning_rate": 3.2571397633909252e-06,
      "loss": 0.4716,
      "step": 8988
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.6683799087583122,
      "learning_rate": 3.256084410387147e-06,
      "loss": 0.509,
      "step": 8989
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.5932590270683193,
      "learning_rate": 3.2550291458290847e-06,
      "loss": 0.5474,
      "step": 8990
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6485682504689886,
      "learning_rate": 3.2539739697702545e-06,
      "loss": 0.4194,
      "step": 8991
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.9964241522141728,
      "learning_rate": 3.252918882264172e-06,
      "loss": 0.4773,
      "step": 8992
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.732620991534495,
      "learning_rate": 3.251863883364348e-06,
      "loss": 0.5009,
      "step": 8993
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.550822142803209,
      "learning_rate": 3.2508089731242886e-06,
      "loss": 0.4234,
      "step": 8994
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.9820965648830056,
      "learning_rate": 3.249754151597496e-06,
      "loss": 0.4234,
      "step": 8995
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.07339565667327,
      "learning_rate": 3.2486994188374667e-06,
      "loss": 0.4696,
      "step": 8996
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.9136114047364121,
      "learning_rate": 3.2476447748976906e-06,
      "loss": 0.5299,
      "step": 8997
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.9276044988709062,
      "learning_rate": 3.246590219831661e-06,
      "loss": 0.479,
      "step": 8998
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.432282277368746,
      "learning_rate": 3.245535753692859e-06,
      "loss": 0.4768,
      "step": 8999
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.74246176117082,
      "learning_rate": 3.244481376534764e-06,
      "loss": 0.5178,
      "step": 9000
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.8665030721703666,
      "learning_rate": 3.2434270884108476e-06,
      "loss": 0.5287,
      "step": 9001
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.253517846273964,
      "learning_rate": 3.2423728893745854e-06,
      "loss": 0.4914,
      "step": 9002
    },
    {
      "epoch": 0.63,
      "grad_norm": 10.845344471894308,
      "learning_rate": 3.2413187794794387e-06,
      "loss": 0.4931,
      "step": 9003
    },
    {
      "epoch": 0.63,
      "grad_norm": 3.238853245186963,
      "learning_rate": 3.240264758778871e-06,
      "loss": 0.4642,
      "step": 9004
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.008069240573479,
      "learning_rate": 3.2392108273263366e-06,
      "loss": 0.5024,
      "step": 9005
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.8000954469868569,
      "learning_rate": 3.238156985175289e-06,
      "loss": 0.4527,
      "step": 9006
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.7425756031542636,
      "learning_rate": 3.2371032323791757e-06,
      "loss": 0.5014,
      "step": 9007
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.7660220647338063,
      "learning_rate": 3.2360495689914367e-06,
      "loss": 0.4823,
      "step": 9008
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.5672566671108683,
      "learning_rate": 3.2349959950655154e-06,
      "loss": 0.4369,
      "step": 9009
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.1260424545586503,
      "learning_rate": 3.2339425106548423e-06,
      "loss": 0.4884,
      "step": 9010
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.0674408912446296,
      "learning_rate": 3.232889115812847e-06,
      "loss": 0.4884,
      "step": 9011
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.675514389447559,
      "learning_rate": 3.2318358105929538e-06,
      "loss": 0.4928,
      "step": 9012
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.1448677426156895,
      "learning_rate": 3.230782595048585e-06,
      "loss": 0.476,
      "step": 9013
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.347679887192834,
      "learning_rate": 3.229729469233155e-06,
      "loss": 0.5585,
      "step": 9014
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.1751959177595057,
      "learning_rate": 3.228676433200075e-06,
      "loss": 0.4862,
      "step": 9015
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.8272225394554618,
      "learning_rate": 3.2276234870027507e-06,
      "loss": 0.5311,
      "step": 9016
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.074259492087273,
      "learning_rate": 3.2265706306945854e-06,
      "loss": 0.5258,
      "step": 9017
    },
    {
      "epoch": 0.63,
      "grad_norm": 3.0606237001057965,
      "learning_rate": 3.2255178643289765e-06,
      "loss": 0.4757,
      "step": 9018
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.6619768482622637,
      "learning_rate": 3.224465187959316e-06,
      "loss": 0.4511,
      "step": 9019
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.661597643005493,
      "learning_rate": 3.223412601638991e-06,
      "loss": 0.4823,
      "step": 9020
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.8890296992040367,
      "learning_rate": 3.222360105421388e-06,
      "loss": 0.4591,
      "step": 9021
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.061048752203025,
      "learning_rate": 3.2213076993598857e-06,
      "loss": 0.4672,
      "step": 9022
    },
    {
      "epoch": 0.63,
      "grad_norm": 15.239175673557254,
      "learning_rate": 3.220255383507858e-06,
      "loss": 0.4366,
      "step": 9023
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.7255813256423387,
      "learning_rate": 3.219203157918674e-06,
      "loss": 0.4944,
      "step": 9024
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6112914572311983,
      "learning_rate": 3.2181510226457012e-06,
      "loss": 0.4362,
      "step": 9025
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.045236712160113,
      "learning_rate": 3.217098977742299e-06,
      "loss": 0.4787,
      "step": 9026
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.662768860541795,
      "learning_rate": 3.2160470232618228e-06,
      "loss": 0.4877,
      "step": 9027
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.095237080031303,
      "learning_rate": 3.2149951592576264e-06,
      "loss": 0.5236,
      "step": 9028
    },
    {
      "epoch": 0.63,
      "grad_norm": 3.837087410637192,
      "learning_rate": 3.213943385783056e-06,
      "loss": 0.5195,
      "step": 9029
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.6592570095684172,
      "learning_rate": 3.212891702891455e-06,
      "loss": 0.5053,
      "step": 9030
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.579627789352061,
      "learning_rate": 3.2118401106361606e-06,
      "loss": 0.4978,
      "step": 9031
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.9642585564590742,
      "learning_rate": 3.2107886090705035e-06,
      "loss": 0.5203,
      "step": 9032
    },
    {
      "epoch": 0.63,
      "grad_norm": 4.487464870274357,
      "learning_rate": 3.2097371982478177e-06,
      "loss": 0.4697,
      "step": 9033
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.7928431713165607,
      "learning_rate": 3.208685878221424e-06,
      "loss": 0.4557,
      "step": 9034
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.93710383726494,
      "learning_rate": 3.2076346490446427e-06,
      "loss": 0.4938,
      "step": 9035
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.8248345701139408,
      "learning_rate": 3.2065835107707877e-06,
      "loss": 0.5096,
      "step": 9036
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.9645956309419899,
      "learning_rate": 3.2055324634531704e-06,
      "loss": 0.5332,
      "step": 9037
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.8268519053204095,
      "learning_rate": 3.2044815071450975e-06,
      "loss": 0.4766,
      "step": 9038
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.5959030718036011,
      "learning_rate": 3.2034306418998677e-06,
      "loss": 0.4725,
      "step": 9039
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.886520646486374,
      "learning_rate": 3.2023798677707775e-06,
      "loss": 0.4772,
      "step": 9040
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.7526052155604945,
      "learning_rate": 3.2013291848111214e-06,
      "loss": 0.4756,
      "step": 9041
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.8455598080277245,
      "learning_rate": 3.2002785930741855e-06,
      "loss": 0.4899,
      "step": 9042
    },
    {
      "epoch": 0.63,
      "grad_norm": 3.3649701415033806,
      "learning_rate": 3.1992280926132515e-06,
      "loss": 0.4967,
      "step": 9043
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.074965660619277,
      "learning_rate": 3.198177683481595e-06,
      "loss": 0.4738,
      "step": 9044
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.079922820743972,
      "learning_rate": 3.1971273657324954e-06,
      "loss": 0.5104,
      "step": 9045
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.5784535597028995,
      "learning_rate": 3.196077139419217e-06,
      "loss": 0.4717,
      "step": 9046
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.346450909388157,
      "learning_rate": 3.195027004595026e-06,
      "loss": 0.4952,
      "step": 9047
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.3864176610012313,
      "learning_rate": 3.193976961313179e-06,
      "loss": 0.4852,
      "step": 9048
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.63215273541427,
      "learning_rate": 3.192927009626934e-06,
      "loss": 0.4695,
      "step": 9049
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.8960420061826924,
      "learning_rate": 3.1918771495895395e-06,
      "loss": 0.4997,
      "step": 9050
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.33411118030614,
      "learning_rate": 3.1908273812542413e-06,
      "loss": 0.4874,
      "step": 9051
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.7573330596629506,
      "learning_rate": 3.1897777046742784e-06,
      "loss": 0.4728,
      "step": 9052
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.067683914928945,
      "learning_rate": 3.18872811990289e-06,
      "loss": 0.5269,
      "step": 9053
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.9044959135022779,
      "learning_rate": 3.187678626993307e-06,
      "loss": 0.4828,
      "step": 9054
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.517188944219129,
      "learning_rate": 3.1866292259987545e-06,
      "loss": 0.5061,
      "step": 9055
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.72365666324147,
      "learning_rate": 3.1855799169724544e-06,
      "loss": 0.5,
      "step": 9056
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.241703690364942,
      "learning_rate": 3.1845306999676274e-06,
      "loss": 0.4622,
      "step": 9057
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.5232513910108834,
      "learning_rate": 3.183481575037485e-06,
      "loss": 0.4643,
      "step": 9058
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.184469584444013,
      "learning_rate": 3.182432542235234e-06,
      "loss": 0.4966,
      "step": 9059
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.346897471300082,
      "learning_rate": 3.181383601614079e-06,
      "loss": 0.4635,
      "step": 9060
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.1829050684630786,
      "learning_rate": 3.1803347532272187e-06,
      "loss": 0.47,
      "step": 9061
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.8102021306402283,
      "learning_rate": 3.179285997127848e-06,
      "loss": 0.5335,
      "step": 9062
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.807628780705546,
      "learning_rate": 3.1782373333691545e-06,
      "loss": 0.4913,
      "step": 9063
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.7684847013740064,
      "learning_rate": 3.1771887620043228e-06,
      "loss": 0.4625,
      "step": 9064
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.6826802743765332,
      "learning_rate": 3.1761402830865368e-06,
      "loss": 0.5187,
      "step": 9065
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.9763148473295917,
      "learning_rate": 3.1750918966689694e-06,
      "loss": 0.5077,
      "step": 9066
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.2548107972941245,
      "learning_rate": 3.174043602804791e-06,
      "loss": 0.5036,
      "step": 9067
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.8159726321809506,
      "learning_rate": 3.1729954015471664e-06,
      "loss": 0.5057,
      "step": 9068
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5825115976181179,
      "learning_rate": 3.171947292949261e-06,
      "loss": 0.4013,
      "step": 9069
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.9000432615514222,
      "learning_rate": 3.170899277064229e-06,
      "loss": 0.4827,
      "step": 9070
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.925088931779471,
      "learning_rate": 3.169851353945221e-06,
      "loss": 0.5048,
      "step": 9071
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.990212492804663,
      "learning_rate": 3.168803523645387e-06,
      "loss": 0.4565,
      "step": 9072
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5807459232924408,
      "learning_rate": 3.1677557862178678e-06,
      "loss": 0.4333,
      "step": 9073
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.054563529876183,
      "learning_rate": 3.166708141715802e-06,
      "loss": 0.4679,
      "step": 9074
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.5354599936917794,
      "learning_rate": 3.1656605901923205e-06,
      "loss": 0.4625,
      "step": 9075
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.7975270700626118,
      "learning_rate": 3.1646131317005556e-06,
      "loss": 0.5089,
      "step": 9076
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.104858883309556,
      "learning_rate": 3.163565766293629e-06,
      "loss": 0.506,
      "step": 9077
    },
    {
      "epoch": 0.63,
      "grad_norm": 3.5234951349694863,
      "learning_rate": 3.162518494024659e-06,
      "loss": 0.4899,
      "step": 9078
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.7986088206656325,
      "learning_rate": 3.16147131494676e-06,
      "loss": 0.4916,
      "step": 9079
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.7820635148181967,
      "learning_rate": 3.1604242291130416e-06,
      "loss": 0.4468,
      "step": 9080
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.216304462200322,
      "learning_rate": 3.1593772365766107e-06,
      "loss": 0.4795,
      "step": 9081
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.7022389733332595,
      "learning_rate": 3.158330337390565e-06,
      "loss": 0.461,
      "step": 9082
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.7164494038292977,
      "learning_rate": 3.1572835316079993e-06,
      "loss": 0.4778,
      "step": 9083
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.0781173493718095,
      "learning_rate": 3.1562368192820063e-06,
      "loss": 0.5128,
      "step": 9084
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.9918390056801507,
      "learning_rate": 3.155190200465671e-06,
      "loss": 0.4385,
      "step": 9085
    },
    {
      "epoch": 0.63,
      "grad_norm": 6.9469858147121615,
      "learning_rate": 3.1541436752120748e-06,
      "loss": 0.5029,
      "step": 9086
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.1611532259615034,
      "learning_rate": 3.1530972435742902e-06,
      "loss": 0.5129,
      "step": 9087
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.9882139282654732,
      "learning_rate": 3.152050905605395e-06,
      "loss": 0.536,
      "step": 9088
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6262553153363182,
      "learning_rate": 3.151004661358453e-06,
      "loss": 0.417,
      "step": 9089
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.499883674149491,
      "learning_rate": 3.149958510886527e-06,
      "loss": 0.5461,
      "step": 9090
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.0472965688616083,
      "learning_rate": 3.148912454242673e-06,
      "loss": 0.4913,
      "step": 9091
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.319388924919317,
      "learning_rate": 3.147866491479945e-06,
      "loss": 0.5127,
      "step": 9092
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.8789358710151438,
      "learning_rate": 3.1468206226513897e-06,
      "loss": 0.454,
      "step": 9093
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.993712439962212,
      "learning_rate": 3.1457748478100514e-06,
      "loss": 0.4679,
      "step": 9094
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6150457278666914,
      "learning_rate": 3.144729167008965e-06,
      "loss": 0.4268,
      "step": 9095
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.9884470578422393,
      "learning_rate": 3.14368358030117e-06,
      "loss": 0.4796,
      "step": 9096
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.328319143156868,
      "learning_rate": 3.142638087739691e-06,
      "loss": 0.4795,
      "step": 9097
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.3016761881484578,
      "learning_rate": 3.141592689377553e-06,
      "loss": 0.4601,
      "step": 9098
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.8470650310816898,
      "learning_rate": 3.1405473852677726e-06,
      "loss": 0.5344,
      "step": 9099
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.8844904395994433,
      "learning_rate": 3.139502175463369e-06,
      "loss": 0.5001,
      "step": 9100
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.035961077509886,
      "learning_rate": 3.1384570600173495e-06,
      "loss": 0.4467,
      "step": 9101
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.796962541717954,
      "learning_rate": 3.137412038982719e-06,
      "loss": 0.4906,
      "step": 9102
    },
    {
      "epoch": 0.63,
      "grad_norm": 3.95941607841844,
      "learning_rate": 3.1363671124124765e-06,
      "loss": 0.4762,
      "step": 9103
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.998937081143174,
      "learning_rate": 3.1353222803596195e-06,
      "loss": 0.4885,
      "step": 9104
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.713253481612714,
      "learning_rate": 3.1342775428771368e-06,
      "loss": 0.5226,
      "step": 9105
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.2397484572087936,
      "learning_rate": 3.133232900018015e-06,
      "loss": 0.4822,
      "step": 9106
    },
    {
      "epoch": 0.63,
      "grad_norm": 3.4175217837159755,
      "learning_rate": 3.132188351835232e-06,
      "loss": 0.4763,
      "step": 9107
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.9253139086047548,
      "learning_rate": 3.131143898381769e-06,
      "loss": 0.4573,
      "step": 9108
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.9602445377997142,
      "learning_rate": 3.1300995397105938e-06,
      "loss": 0.5091,
      "step": 9109
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.2037375071859016,
      "learning_rate": 3.129055275874674e-06,
      "loss": 0.5098,
      "step": 9110
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.080659392195486,
      "learning_rate": 3.1280111069269694e-06,
      "loss": 0.5229,
      "step": 9111
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.8378131408399159,
      "learning_rate": 3.12696703292044e-06,
      "loss": 0.4878,
      "step": 9112
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.7376207990440247,
      "learning_rate": 3.1259230539080364e-06,
      "loss": 0.5187,
      "step": 9113
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.5481621026169586,
      "learning_rate": 3.1248791699427054e-06,
      "loss": 0.4413,
      "step": 9114
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.127307444884369,
      "learning_rate": 3.123835381077389e-06,
      "loss": 0.4879,
      "step": 9115
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.121618846160816,
      "learning_rate": 3.1227916873650267e-06,
      "loss": 0.5383,
      "step": 9116
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.960706260759995,
      "learning_rate": 3.1217480888585493e-06,
      "loss": 0.4988,
      "step": 9117
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.2030776272172785,
      "learning_rate": 3.1207045856108857e-06,
      "loss": 0.5071,
      "step": 9118
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.6386674988136476,
      "learning_rate": 3.119661177674956e-06,
      "loss": 0.5295,
      "step": 9119
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.485981641514111,
      "learning_rate": 3.118617865103685e-06,
      "loss": 0.4995,
      "step": 9120
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.28381295788614,
      "learning_rate": 3.11757464794998e-06,
      "loss": 0.4956,
      "step": 9121
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.086934171750475,
      "learning_rate": 3.1165315262667535e-06,
      "loss": 0.4678,
      "step": 9122
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.7653318956828452,
      "learning_rate": 3.1154885001069047e-06,
      "loss": 0.4886,
      "step": 9123
    },
    {
      "epoch": 0.63,
      "grad_norm": 3.5977049927090934,
      "learning_rate": 3.1144455695233374e-06,
      "loss": 0.4794,
      "step": 9124
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.8300533964467054,
      "learning_rate": 3.1134027345689432e-06,
      "loss": 0.4894,
      "step": 9125
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.8448997714617676,
      "learning_rate": 3.112359995296612e-06,
      "loss": 0.455,
      "step": 9126
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.6076346292204944,
      "learning_rate": 3.111317351759227e-06,
      "loss": 0.5012,
      "step": 9127
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.8901499775422501,
      "learning_rate": 3.110274804009669e-06,
      "loss": 0.4736,
      "step": 9128
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.7364919304297337,
      "learning_rate": 3.109232352100813e-06,
      "loss": 0.4661,
      "step": 9129
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.793367470728232,
      "learning_rate": 3.1081899960855265e-06,
      "loss": 0.4994,
      "step": 9130
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.879059952938688,
      "learning_rate": 3.1071477360166745e-06,
      "loss": 0.4832,
      "step": 9131
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.1792624390806643,
      "learning_rate": 3.10610557194712e-06,
      "loss": 0.4713,
      "step": 9132
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.7704097452269727,
      "learning_rate": 3.1050635039297173e-06,
      "loss": 0.454,
      "step": 9133
    },
    {
      "epoch": 0.64,
      "grad_norm": 4.031761334479387,
      "learning_rate": 3.104021532017315e-06,
      "loss": 0.468,
      "step": 9134
    },
    {
      "epoch": 0.64,
      "grad_norm": 3.759229823569705,
      "learning_rate": 3.1029796562627573e-06,
      "loss": 0.4835,
      "step": 9135
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.677361743814375,
      "learning_rate": 3.1019378767188892e-06,
      "loss": 0.5111,
      "step": 9136
    },
    {
      "epoch": 0.64,
      "grad_norm": 3.672314347607985,
      "learning_rate": 3.100896193438544e-06,
      "loss": 0.5198,
      "step": 9137
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.7533327078941523,
      "learning_rate": 3.0998546064745507e-06,
      "loss": 0.5039,
      "step": 9138
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.8287116590173826,
      "learning_rate": 3.0988131158797387e-06,
      "loss": 0.4707,
      "step": 9139
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.8053631680220388,
      "learning_rate": 3.097771721706927e-06,
      "loss": 0.5086,
      "step": 9140
    },
    {
      "epoch": 0.64,
      "grad_norm": 5.125947135061971,
      "learning_rate": 3.0967304240089317e-06,
      "loss": 0.5025,
      "step": 9141
    },
    {
      "epoch": 0.64,
      "grad_norm": 4.31946147806286,
      "learning_rate": 3.0956892228385626e-06,
      "loss": 0.4916,
      "step": 9142
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.0972397924778927,
      "learning_rate": 3.09464811824863e-06,
      "loss": 0.5175,
      "step": 9143
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.8808116134223134,
      "learning_rate": 3.0936071102919325e-06,
      "loss": 0.5088,
      "step": 9144
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.21056376591764,
      "learning_rate": 3.0925661990212674e-06,
      "loss": 0.4286,
      "step": 9145
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.642303290118443,
      "learning_rate": 3.0915253844894242e-06,
      "loss": 0.485,
      "step": 9146
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.567131093812623,
      "learning_rate": 3.090484666749193e-06,
      "loss": 0.5087,
      "step": 9147
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.338700681270843,
      "learning_rate": 3.0894440458533544e-06,
      "loss": 0.4778,
      "step": 9148
    },
    {
      "epoch": 0.64,
      "grad_norm": 3.8772948884090597,
      "learning_rate": 3.088403521854685e-06,
      "loss": 0.5206,
      "step": 9149
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.6673049188332703,
      "learning_rate": 3.0873630948059557e-06,
      "loss": 0.4799,
      "step": 9150
    },
    {
      "epoch": 0.64,
      "grad_norm": 3.5838601369180156,
      "learning_rate": 3.086322764759936e-06,
      "loss": 0.4977,
      "step": 9151
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5463413443577853,
      "learning_rate": 3.085282531769387e-06,
      "loss": 0.4342,
      "step": 9152
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.900944312549002,
      "learning_rate": 3.0842423958870648e-06,
      "loss": 0.5395,
      "step": 9153
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.6356119070124309,
      "learning_rate": 3.083202357165721e-06,
      "loss": 0.476,
      "step": 9154
    },
    {
      "epoch": 0.64,
      "grad_norm": 3.2221944910923255,
      "learning_rate": 3.0821624156581065e-06,
      "loss": 0.4576,
      "step": 9155
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5912485113378576,
      "learning_rate": 3.081122571416962e-06,
      "loss": 0.4014,
      "step": 9156
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.4202273092535953,
      "learning_rate": 3.080082824495024e-06,
      "loss": 0.523,
      "step": 9157
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.4643232051313673,
      "learning_rate": 3.0790431749450255e-06,
      "loss": 0.4971,
      "step": 9158
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.737333486512029,
      "learning_rate": 3.078003622819695e-06,
      "loss": 0.5015,
      "step": 9159
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.7831099727302662,
      "learning_rate": 3.0769641681717554e-06,
      "loss": 0.4975,
      "step": 9160
    },
    {
      "epoch": 0.64,
      "grad_norm": 3.711668023221394,
      "learning_rate": 3.0759248110539238e-06,
      "loss": 0.5068,
      "step": 9161
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.3150732441216695,
      "learning_rate": 3.0748855515189104e-06,
      "loss": 0.5193,
      "step": 9162
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.680162226715018,
      "learning_rate": 3.0738463896194277e-06,
      "loss": 0.4989,
      "step": 9163
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.3266101515781,
      "learning_rate": 3.072807325408177e-06,
      "loss": 0.4712,
      "step": 9164
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.6048568147156372,
      "learning_rate": 3.071768358937855e-06,
      "loss": 0.4671,
      "step": 9165
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.233281758449697,
      "learning_rate": 3.070729490261154e-06,
      "loss": 0.4967,
      "step": 9166
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.8238985443129951,
      "learning_rate": 3.0696907194307645e-06,
      "loss": 0.5427,
      "step": 9167
    },
    {
      "epoch": 0.64,
      "grad_norm": 3.01415689398089,
      "learning_rate": 3.06865204649937e-06,
      "loss": 0.4946,
      "step": 9168
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.9676884761737803,
      "learning_rate": 3.0676134715196457e-06,
      "loss": 0.4983,
      "step": 9169
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.4983022274024718,
      "learning_rate": 3.066574994544266e-06,
      "loss": 0.4884,
      "step": 9170
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.7431078812990337,
      "learning_rate": 3.0655366156259002e-06,
      "loss": 0.5449,
      "step": 9171
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.6504672429715708,
      "learning_rate": 3.0644983348172108e-06,
      "loss": 0.5018,
      "step": 9172
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.6853619372950461,
      "learning_rate": 3.0634601521708553e-06,
      "loss": 0.4746,
      "step": 9173
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.8773719727681553,
      "learning_rate": 3.0624220677394854e-06,
      "loss": 0.5199,
      "step": 9174
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.754809751064926,
      "learning_rate": 3.0613840815757535e-06,
      "loss": 0.5095,
      "step": 9175
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.7671956680042287,
      "learning_rate": 3.0603461937323005e-06,
      "loss": 0.4492,
      "step": 9176
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.9511983300529145,
      "learning_rate": 3.059308404261765e-06,
      "loss": 0.516,
      "step": 9177
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.9925711762617753,
      "learning_rate": 3.058270713216778e-06,
      "loss": 0.519,
      "step": 9178
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.8559539030118961,
      "learning_rate": 3.057233120649973e-06,
      "loss": 0.5394,
      "step": 9179
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.418314413615365,
      "learning_rate": 3.0561956266139694e-06,
      "loss": 0.4953,
      "step": 9180
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.9565493308905006,
      "learning_rate": 3.055158231161387e-06,
      "loss": 0.5224,
      "step": 9181
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.2580557546453286,
      "learning_rate": 3.0541209343448373e-06,
      "loss": 0.5087,
      "step": 9182
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.476996363449025,
      "learning_rate": 3.053083736216931e-06,
      "loss": 0.5005,
      "step": 9183
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.9036963333654693,
      "learning_rate": 3.0520466368302697e-06,
      "loss": 0.4611,
      "step": 9184
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.894689786477125,
      "learning_rate": 3.051009636237453e-06,
      "loss": 0.485,
      "step": 9185
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.903519785978984,
      "learning_rate": 3.049972734491071e-06,
      "loss": 0.5427,
      "step": 9186
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.1226033054413485,
      "learning_rate": 3.0489359316437172e-06,
      "loss": 0.4932,
      "step": 9187
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.8869430578153943,
      "learning_rate": 3.0478992277479715e-06,
      "loss": 0.4743,
      "step": 9188
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.943862266057318,
      "learning_rate": 3.0468626228564123e-06,
      "loss": 0.4951,
      "step": 9189
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.9575357155189688,
      "learning_rate": 3.045826117021612e-06,
      "loss": 0.5082,
      "step": 9190
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6029537385269653,
      "learning_rate": 3.044789710296142e-06,
      "loss": 0.4385,
      "step": 9191
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.7297672006053015,
      "learning_rate": 3.0437534027325634e-06,
      "loss": 0.4765,
      "step": 9192
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.0208897072795353,
      "learning_rate": 3.0427171943834345e-06,
      "loss": 0.4992,
      "step": 9193
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.5678779455635772,
      "learning_rate": 3.0416810853013078e-06,
      "loss": 0.55,
      "step": 9194
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.7261357048367294,
      "learning_rate": 3.0406450755387323e-06,
      "loss": 0.4565,
      "step": 9195
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.1843996447543783,
      "learning_rate": 3.0396091651482513e-06,
      "loss": 0.4324,
      "step": 9196
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.5379861052634816,
      "learning_rate": 3.0385733541824015e-06,
      "loss": 0.4826,
      "step": 9197
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.9055831954660676,
      "learning_rate": 3.0375376426937154e-06,
      "loss": 0.4961,
      "step": 9198
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.9742911330644013,
      "learning_rate": 3.0365020307347236e-06,
      "loss": 0.5212,
      "step": 9199
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.110428447551087,
      "learning_rate": 3.0354665183579467e-06,
      "loss": 0.4737,
      "step": 9200
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.95907409765063,
      "learning_rate": 3.0344311056159024e-06,
      "loss": 0.4813,
      "step": 9201
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.9984737958185663,
      "learning_rate": 3.0333957925611056e-06,
      "loss": 0.4693,
      "step": 9202
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.8253118903820802,
      "learning_rate": 3.0323605792460633e-06,
      "loss": 0.451,
      "step": 9203
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.3119917862963244,
      "learning_rate": 3.0313254657232772e-06,
      "loss": 0.487,
      "step": 9204
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.2629192065530743,
      "learning_rate": 3.030290452045245e-06,
      "loss": 0.5704,
      "step": 9205
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.8010881254438362,
      "learning_rate": 3.0292555382644596e-06,
      "loss": 0.4871,
      "step": 9206
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6011689452046401,
      "learning_rate": 3.0282207244334084e-06,
      "loss": 0.4258,
      "step": 9207
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.8855180146574013,
      "learning_rate": 3.0271860106045734e-06,
      "loss": 0.5343,
      "step": 9208
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.0321322923086256,
      "learning_rate": 3.02615139683043e-06,
      "loss": 0.4467,
      "step": 9209
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.0859024047914647,
      "learning_rate": 3.0251168831634558e-06,
      "loss": 0.5229,
      "step": 9210
    },
    {
      "epoch": 0.64,
      "grad_norm": 3.3195057706477593,
      "learning_rate": 3.0240824696561136e-06,
      "loss": 0.5032,
      "step": 9211
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5883614519746356,
      "learning_rate": 3.0230481563608673e-06,
      "loss": 0.4358,
      "step": 9212
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.6840784805101467,
      "learning_rate": 3.022013943330172e-06,
      "loss": 0.5017,
      "step": 9213
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.9570123329569644,
      "learning_rate": 3.0209798306164827e-06,
      "loss": 0.4809,
      "step": 9214
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.5725441541322955,
      "learning_rate": 3.019945818272243e-06,
      "loss": 0.4677,
      "step": 9215
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.6333914256050104,
      "learning_rate": 3.018911906349896e-06,
      "loss": 0.4846,
      "step": 9216
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.8805019778606478,
      "learning_rate": 3.0178780949018786e-06,
      "loss": 0.4944,
      "step": 9217
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.8952770728142547,
      "learning_rate": 3.0168443839806226e-06,
      "loss": 0.4655,
      "step": 9218
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.9880802801729764,
      "learning_rate": 3.0158107736385544e-06,
      "loss": 0.5433,
      "step": 9219
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.6203521043653544,
      "learning_rate": 3.014777263928095e-06,
      "loss": 0.5288,
      "step": 9220
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.7301887991166616,
      "learning_rate": 3.0137438549016578e-06,
      "loss": 0.4636,
      "step": 9221
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.2729780066121115,
      "learning_rate": 3.012710546611659e-06,
      "loss": 0.5589,
      "step": 9222
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.9066911861618254,
      "learning_rate": 3.0116773391105026e-06,
      "loss": 0.4767,
      "step": 9223
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.061437934502441,
      "learning_rate": 3.0106442324505893e-06,
      "loss": 0.5056,
      "step": 9224
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.9123423651000624,
      "learning_rate": 3.0096112266843135e-06,
      "loss": 0.477,
      "step": 9225
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.7667322985514036,
      "learning_rate": 3.0085783218640692e-06,
      "loss": 0.5141,
      "step": 9226
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.7157896650263642,
      "learning_rate": 3.007545518042239e-06,
      "loss": 0.4814,
      "step": 9227
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.7419687182170172,
      "learning_rate": 3.0065128152712046e-06,
      "loss": 0.4934,
      "step": 9228
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.026831997244008,
      "learning_rate": 3.005480213603339e-06,
      "loss": 0.5,
      "step": 9229
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.24431344536443,
      "learning_rate": 3.0044477130910164e-06,
      "loss": 0.5068,
      "step": 9230
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.6731982863362735,
      "learning_rate": 3.003415313786601e-06,
      "loss": 0.4859,
      "step": 9231
    },
    {
      "epoch": 0.64,
      "grad_norm": 12.936222543885671,
      "learning_rate": 3.0023830157424504e-06,
      "loss": 0.4944,
      "step": 9232
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.7134536940943064,
      "learning_rate": 3.0013508190109184e-06,
      "loss": 0.4854,
      "step": 9233
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.0440311137143565,
      "learning_rate": 3.0003187236443597e-06,
      "loss": 0.4943,
      "step": 9234
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.3304921587247622,
      "learning_rate": 2.9992867296951157e-06,
      "loss": 0.5147,
      "step": 9235
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.5027102122366858,
      "learning_rate": 2.9982548372155264e-06,
      "loss": 0.4911,
      "step": 9236
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.8159673077163374,
      "learning_rate": 2.9972230462579243e-06,
      "loss": 0.4904,
      "step": 9237
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.0066692273828135,
      "learning_rate": 2.996191356874641e-06,
      "loss": 0.5173,
      "step": 9238
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.0956710167762895,
      "learning_rate": 2.995159769117999e-06,
      "loss": 0.4616,
      "step": 9239
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.6750816363950642,
      "learning_rate": 2.994128283040318e-06,
      "loss": 0.4952,
      "step": 9240
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.676988288000348,
      "learning_rate": 2.9930968986939078e-06,
      "loss": 0.4693,
      "step": 9241
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.2603175254905805,
      "learning_rate": 2.9920656161310833e-06,
      "loss": 0.4761,
      "step": 9242
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5208762937871697,
      "learning_rate": 2.9910344354041443e-06,
      "loss": 0.4095,
      "step": 9243
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.3570609491427854,
      "learning_rate": 2.9900033565653886e-06,
      "loss": 0.4948,
      "step": 9244
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.8719393919272143,
      "learning_rate": 2.988972379667108e-06,
      "loss": 0.4747,
      "step": 9245
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.9084335249288054,
      "learning_rate": 2.987941504761594e-06,
      "loss": 0.5423,
      "step": 9246
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.0760736745877004,
      "learning_rate": 2.986910731901127e-06,
      "loss": 0.5001,
      "step": 9247
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.7335362432795571,
      "learning_rate": 2.9858800611379847e-06,
      "loss": 0.5204,
      "step": 9248
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.8920649449253004,
      "learning_rate": 2.9848494925244385e-06,
      "loss": 0.4977,
      "step": 9249
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.086560774403786,
      "learning_rate": 2.983819026112757e-06,
      "loss": 0.5059,
      "step": 9250
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.7887495558103403,
      "learning_rate": 2.9827886619552015e-06,
      "loss": 0.4856,
      "step": 9251
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.392388534241152,
      "learning_rate": 2.981758400104028e-06,
      "loss": 0.5147,
      "step": 9252
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.1982461230699264,
      "learning_rate": 2.980728240611488e-06,
      "loss": 0.4906,
      "step": 9253
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6076129621221429,
      "learning_rate": 2.9796981835298288e-06,
      "loss": 0.424,
      "step": 9254
    },
    {
      "epoch": 0.64,
      "grad_norm": 6.565800291709266,
      "learning_rate": 2.978668228911292e-06,
      "loss": 0.4613,
      "step": 9255
    },
    {
      "epoch": 0.64,
      "grad_norm": 3.8121922144177716,
      "learning_rate": 2.977638376808113e-06,
      "loss": 0.5065,
      "step": 9256
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.7948642446501653,
      "learning_rate": 2.97660862727252e-06,
      "loss": 0.4681,
      "step": 9257
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.5937367943757605,
      "learning_rate": 2.9755789803567427e-06,
      "loss": 0.5094,
      "step": 9258
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.8823176003301396,
      "learning_rate": 2.974549436112999e-06,
      "loss": 0.534,
      "step": 9259
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.3260035455680166,
      "learning_rate": 2.9735199945935057e-06,
      "loss": 0.4487,
      "step": 9260
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.8014543704404848,
      "learning_rate": 2.9724906558504698e-06,
      "loss": 0.5066,
      "step": 9261
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.124786072320598,
      "learning_rate": 2.971461419936099e-06,
      "loss": 0.4936,
      "step": 9262
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.7827604329592344,
      "learning_rate": 2.9704322869025915e-06,
      "loss": 0.4744,
      "step": 9263
    },
    {
      "epoch": 0.64,
      "grad_norm": 4.4354161140070545,
      "learning_rate": 2.969403256802139e-06,
      "loss": 0.4645,
      "step": 9264
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.5251078142237984,
      "learning_rate": 2.968374329686936e-06,
      "loss": 0.4701,
      "step": 9265
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.357580691754207,
      "learning_rate": 2.967345505609164e-06,
      "loss": 0.4759,
      "step": 9266
    },
    {
      "epoch": 0.64,
      "grad_norm": 4.0361123459493005,
      "learning_rate": 2.966316784621e-06,
      "loss": 0.4757,
      "step": 9267
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.664480084807028,
      "learning_rate": 2.965288166774617e-06,
      "loss": 0.5023,
      "step": 9268
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.1615843675822775,
      "learning_rate": 2.9642596521221865e-06,
      "loss": 0.506,
      "step": 9269
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.27590937134373,
      "learning_rate": 2.963231240715869e-06,
      "loss": 0.4852,
      "step": 9270
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.8936445318987045,
      "learning_rate": 2.962202932607824e-06,
      "loss": 0.5554,
      "step": 9271
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.9765918537045166,
      "learning_rate": 2.9611747278502013e-06,
      "loss": 0.4649,
      "step": 9272
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.6665432989593922,
      "learning_rate": 2.9601466264951494e-06,
      "loss": 0.5058,
      "step": 9273
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.3819764044467253,
      "learning_rate": 2.9591186285948115e-06,
      "loss": 0.5105,
      "step": 9274
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.7033553172379499,
      "learning_rate": 2.9580907342013225e-06,
      "loss": 0.4695,
      "step": 9275
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.9382549875032913,
      "learning_rate": 2.957062943366813e-06,
      "loss": 0.5335,
      "step": 9276
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.8779762658446986,
      "learning_rate": 2.9560352561434117e-06,
      "loss": 0.4951,
      "step": 9277
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.025523403301065,
      "learning_rate": 2.9550076725832393e-06,
      "loss": 0.5011,
      "step": 9278
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.749772094447997,
      "learning_rate": 2.9539801927384104e-06,
      "loss": 0.5015,
      "step": 9279
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.8235368744876161,
      "learning_rate": 2.952952816661035e-06,
      "loss": 0.5006,
      "step": 9280
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.686218055825919,
      "learning_rate": 2.95192554440322e-06,
      "loss": 0.4819,
      "step": 9281
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.2269504391967128,
      "learning_rate": 2.950898376017064e-06,
      "loss": 0.4832,
      "step": 9282
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.9821402115440894,
      "learning_rate": 2.9498713115546606e-06,
      "loss": 0.5108,
      "step": 9283
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.6434151845279819,
      "learning_rate": 2.9488443510681007e-06,
      "loss": 0.4983,
      "step": 9284
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.62307819648822,
      "learning_rate": 2.9478174946094695e-06,
      "loss": 0.5066,
      "step": 9285
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.1418450815090644,
      "learning_rate": 2.946790742230844e-06,
      "loss": 0.5121,
      "step": 9286
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.03583787001741,
      "learning_rate": 2.9457640939842983e-06,
      "loss": 0.5022,
      "step": 9287
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.7761267949100554,
      "learning_rate": 2.944737549921899e-06,
      "loss": 0.538,
      "step": 9288
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.6877505894207214,
      "learning_rate": 2.9437111100957128e-06,
      "loss": 0.5048,
      "step": 9289
    },
    {
      "epoch": 0.65,
      "grad_norm": 3.190801698488611,
      "learning_rate": 2.9426847745577947e-06,
      "loss": 0.4778,
      "step": 9290
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.8870987992442618,
      "learning_rate": 2.9416585433601976e-06,
      "loss": 0.5092,
      "step": 9291
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.839322014586221,
      "learning_rate": 2.9406324165549672e-06,
      "loss": 0.4741,
      "step": 9292
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.7423618298716341,
      "learning_rate": 2.9396063941941483e-06,
      "loss": 0.4865,
      "step": 9293
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.0224536188660247,
      "learning_rate": 2.9385804763297754e-06,
      "loss": 0.5023,
      "step": 9294
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.713239475705361,
      "learning_rate": 2.9375546630138808e-06,
      "loss": 0.5092,
      "step": 9295
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.2378100386323303,
      "learning_rate": 2.9365289542984876e-06,
      "loss": 0.4779,
      "step": 9296
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.1940340089428347,
      "learning_rate": 2.93550335023562e-06,
      "loss": 0.4928,
      "step": 9297
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.8804308534096037,
      "learning_rate": 2.934477850877292e-06,
      "loss": 0.4722,
      "step": 9298
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.240241804826749,
      "learning_rate": 2.9334524562755134e-06,
      "loss": 0.5201,
      "step": 9299
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.8576568239583344,
      "learning_rate": 2.932427166482287e-06,
      "loss": 0.4873,
      "step": 9300
    },
    {
      "epoch": 0.65,
      "grad_norm": 5.0793426127162835,
      "learning_rate": 2.9314019815496163e-06,
      "loss": 0.4933,
      "step": 9301
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.003866514693117,
      "learning_rate": 2.9303769015294925e-06,
      "loss": 0.546,
      "step": 9302
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.9116367365020135,
      "learning_rate": 2.9293519264739058e-06,
      "loss": 0.4599,
      "step": 9303
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.8444590959127716,
      "learning_rate": 2.9283270564348365e-06,
      "loss": 0.4767,
      "step": 9304
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.2707094079775487,
      "learning_rate": 2.9273022914642667e-06,
      "loss": 0.4307,
      "step": 9305
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.997382363393958,
      "learning_rate": 2.926277631614167e-06,
      "loss": 0.4883,
      "step": 9306
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.0777833040258473,
      "learning_rate": 2.9252530769365053e-06,
      "loss": 0.4934,
      "step": 9307
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.9626771606902116,
      "learning_rate": 2.924228627483241e-06,
      "loss": 0.4625,
      "step": 9308
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.3093067922219004,
      "learning_rate": 2.9232042833063356e-06,
      "loss": 0.5092,
      "step": 9309
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.397044574937991,
      "learning_rate": 2.9221800444577385e-06,
      "loss": 0.5008,
      "step": 9310
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.0160974930302906,
      "learning_rate": 2.921155910989395e-06,
      "loss": 0.5061,
      "step": 9311
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.9545655672599214,
      "learning_rate": 2.920131882953245e-06,
      "loss": 0.4572,
      "step": 9312
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.9693159709748385,
      "learning_rate": 2.9191079604012274e-06,
      "loss": 0.4876,
      "step": 9313
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.013187895098551,
      "learning_rate": 2.918084143385268e-06,
      "loss": 0.472,
      "step": 9314
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.708366646237631,
      "learning_rate": 2.917060431957296e-06,
      "loss": 0.4521,
      "step": 9315
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.8783135618217224,
      "learning_rate": 2.9160368261692233e-06,
      "loss": 0.4858,
      "step": 9316
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.2455819140849766,
      "learning_rate": 2.9150133260729735e-06,
      "loss": 0.4856,
      "step": 9317
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.6380242817248045,
      "learning_rate": 2.9139899317204477e-06,
      "loss": 0.507,
      "step": 9318
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.7197424762754099,
      "learning_rate": 2.912966643163554e-06,
      "loss": 0.4882,
      "step": 9319
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.7949853383899355,
      "learning_rate": 2.9119434604541864e-06,
      "loss": 0.5407,
      "step": 9320
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.561937156894218,
      "learning_rate": 2.9109203836442383e-06,
      "loss": 0.4383,
      "step": 9321
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.038214489378282,
      "learning_rate": 2.9098974127856e-06,
      "loss": 0.5352,
      "step": 9322
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.538034261287298,
      "learning_rate": 2.908874547930149e-06,
      "loss": 0.5021,
      "step": 9323
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.1222085528098256,
      "learning_rate": 2.907851789129763e-06,
      "loss": 0.4986,
      "step": 9324
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.4291294004392974,
      "learning_rate": 2.906829136436313e-06,
      "loss": 0.518,
      "step": 9325
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.223746031179238,
      "learning_rate": 2.9058065899016685e-06,
      "loss": 0.4781,
      "step": 9326
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.7800365684072386,
      "learning_rate": 2.9047841495776812e-06,
      "loss": 0.4931,
      "step": 9327
    },
    {
      "epoch": 0.65,
      "grad_norm": 3.4939040733377995,
      "learning_rate": 2.9037618155162155e-06,
      "loss": 0.5354,
      "step": 9328
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.6888881375310547,
      "learning_rate": 2.9027395877691143e-06,
      "loss": 0.4735,
      "step": 9329
    },
    {
      "epoch": 0.65,
      "grad_norm": 5.063708433417321,
      "learning_rate": 2.901717466388226e-06,
      "loss": 0.5383,
      "step": 9330
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.7569079328583082,
      "learning_rate": 2.9006954514253843e-06,
      "loss": 0.5069,
      "step": 9331
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.31483317614295,
      "learning_rate": 2.8996735429324256e-06,
      "loss": 0.486,
      "step": 9332
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.1883492234729154,
      "learning_rate": 2.8986517409611793e-06,
      "loss": 0.4589,
      "step": 9333
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.8156904800468103,
      "learning_rate": 2.897630045563464e-06,
      "loss": 0.5,
      "step": 9334
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.0065070126652276,
      "learning_rate": 2.8966084567910992e-06,
      "loss": 0.4953,
      "step": 9335
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.9293451094156078,
      "learning_rate": 2.895586974695895e-06,
      "loss": 0.512,
      "step": 9336
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.3879665279440507,
      "learning_rate": 2.8945655993296606e-06,
      "loss": 0.4958,
      "step": 9337
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5585610488732953,
      "learning_rate": 2.8935443307441934e-06,
      "loss": 0.4243,
      "step": 9338
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.557736594808056,
      "learning_rate": 2.8925231689912903e-06,
      "loss": 0.4148,
      "step": 9339
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.3676056130806886,
      "learning_rate": 2.891502114122742e-06,
      "loss": 0.476,
      "step": 9340
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.9575647356927037,
      "learning_rate": 2.890481166190333e-06,
      "loss": 0.5154,
      "step": 9341
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.9082338236714187,
      "learning_rate": 2.8894603252458407e-06,
      "loss": 0.4837,
      "step": 9342
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.9976090045194352,
      "learning_rate": 2.88843959134104e-06,
      "loss": 0.5116,
      "step": 9343
    },
    {
      "epoch": 0.65,
      "grad_norm": 3.296022643640081,
      "learning_rate": 2.8874189645277005e-06,
      "loss": 0.5047,
      "step": 9344
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.6007613023251974,
      "learning_rate": 2.886398444857582e-06,
      "loss": 0.5117,
      "step": 9345
    },
    {
      "epoch": 0.65,
      "grad_norm": 3.294825480337243,
      "learning_rate": 2.885378032382446e-06,
      "loss": 0.5018,
      "step": 9346
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.044366536991737,
      "learning_rate": 2.884357727154038e-06,
      "loss": 0.5037,
      "step": 9347
    },
    {
      "epoch": 0.65,
      "grad_norm": 6.570508495612279,
      "learning_rate": 2.8833375292241123e-06,
      "loss": 0.4619,
      "step": 9348
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.4838850170523505,
      "learning_rate": 2.8823174386444047e-06,
      "loss": 0.5022,
      "step": 9349
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.604766302242142,
      "learning_rate": 2.8812974554666546e-06,
      "loss": 0.4832,
      "step": 9350
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5757367524960493,
      "learning_rate": 2.8802775797425864e-06,
      "loss": 0.437,
      "step": 9351
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.3943728677458185,
      "learning_rate": 2.8792578115239323e-06,
      "loss": 0.4621,
      "step": 9352
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.5730633703091863,
      "learning_rate": 2.8782381508624057e-06,
      "loss": 0.4615,
      "step": 9353
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5880227112119053,
      "learning_rate": 2.877218597809725e-06,
      "loss": 0.4304,
      "step": 9354
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.911112962750632,
      "learning_rate": 2.876199152417595e-06,
      "loss": 0.514,
      "step": 9355
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.0453956460939415,
      "learning_rate": 2.875179814737719e-06,
      "loss": 0.5302,
      "step": 9356
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.0551315511022175,
      "learning_rate": 2.874160584821798e-06,
      "loss": 0.4652,
      "step": 9357
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.0080933285667255,
      "learning_rate": 2.873141462721519e-06,
      "loss": 0.4896,
      "step": 9358
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.7413738848364368,
      "learning_rate": 2.8721224484885717e-06,
      "loss": 0.4842,
      "step": 9359
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.9341553345504514,
      "learning_rate": 2.871103542174637e-06,
      "loss": 0.4487,
      "step": 9360
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.7133092296918366,
      "learning_rate": 2.8700847438313905e-06,
      "loss": 0.4508,
      "step": 9361
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.5268210775695237,
      "learning_rate": 2.869066053510501e-06,
      "loss": 0.4502,
      "step": 9362
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.7540980394382089,
      "learning_rate": 2.868047471263634e-06,
      "loss": 0.4616,
      "step": 9363
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.03778949077013,
      "learning_rate": 2.867028997142448e-06,
      "loss": 0.4851,
      "step": 9364
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.0760901630119326,
      "learning_rate": 2.8660106311986003e-06,
      "loss": 0.4601,
      "step": 9365
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.3089955508730844,
      "learning_rate": 2.8649923734837336e-06,
      "loss": 0.5299,
      "step": 9366
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.8206626229810117,
      "learning_rate": 2.8639742240494935e-06,
      "loss": 0.4984,
      "step": 9367
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.7784710159735277,
      "learning_rate": 2.862956182947518e-06,
      "loss": 0.4921,
      "step": 9368
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.3065268406293273,
      "learning_rate": 2.861938250229437e-06,
      "loss": 0.4867,
      "step": 9369
    },
    {
      "epoch": 0.65,
      "grad_norm": 3.0520509168031653,
      "learning_rate": 2.8609204259468794e-06,
      "loss": 0.4966,
      "step": 9370
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.652717983835779,
      "learning_rate": 2.8599027101514586e-06,
      "loss": 0.4993,
      "step": 9371
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.954840926687152,
      "learning_rate": 2.8588851028948008e-06,
      "loss": 0.4998,
      "step": 9372
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.0368944574665138,
      "learning_rate": 2.857867604228507e-06,
      "loss": 0.4928,
      "step": 9373
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.7391563624251463,
      "learning_rate": 2.8568502142041876e-06,
      "loss": 0.5095,
      "step": 9374
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.1832625676126303,
      "learning_rate": 2.8558329328734357e-06,
      "loss": 0.4525,
      "step": 9375
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.7595312306722657,
      "learning_rate": 2.854815760287847e-06,
      "loss": 0.5013,
      "step": 9376
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.748464797245759,
      "learning_rate": 2.8537986964990113e-06,
      "loss": 0.4659,
      "step": 9377
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.0683938318284985,
      "learning_rate": 2.852781741558507e-06,
      "loss": 0.4746,
      "step": 9378
    },
    {
      "epoch": 0.65,
      "grad_norm": 3.389891602428655,
      "learning_rate": 2.8517648955179117e-06,
      "loss": 0.4796,
      "step": 9379
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.8272872056563296,
      "learning_rate": 2.850748158428798e-06,
      "loss": 0.5311,
      "step": 9380
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.2617832062876153,
      "learning_rate": 2.849731530342732e-06,
      "loss": 0.4505,
      "step": 9381
    },
    {
      "epoch": 0.65,
      "grad_norm": 3.036447181606492,
      "learning_rate": 2.848715011311271e-06,
      "loss": 0.5147,
      "step": 9382
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.6021643906229215,
      "learning_rate": 2.847698601385971e-06,
      "loss": 0.5013,
      "step": 9383
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.9432084686742477,
      "learning_rate": 2.846682300618381e-06,
      "loss": 0.4451,
      "step": 9384
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.6557639082708886,
      "learning_rate": 2.845666109060046e-06,
      "loss": 0.4796,
      "step": 9385
    },
    {
      "epoch": 0.65,
      "grad_norm": 6.226805939298641,
      "learning_rate": 2.844650026762501e-06,
      "loss": 0.4982,
      "step": 9386
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.177005954889441,
      "learning_rate": 2.84363405377728e-06,
      "loss": 0.4471,
      "step": 9387
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.037842679870671,
      "learning_rate": 2.8426181901559115e-06,
      "loss": 0.4608,
      "step": 9388
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.8458595198042085,
      "learning_rate": 2.841602435949913e-06,
      "loss": 0.4882,
      "step": 9389
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.378532922947089,
      "learning_rate": 2.8405867912108032e-06,
      "loss": 0.4313,
      "step": 9390
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.6024265947182816,
      "learning_rate": 2.839571255990088e-06,
      "loss": 0.4881,
      "step": 9391
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.556924403491925,
      "learning_rate": 2.8385558303392798e-06,
      "loss": 0.4819,
      "step": 9392
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5478488946773793,
      "learning_rate": 2.83754051430987e-06,
      "loss": 0.4356,
      "step": 9393
    },
    {
      "epoch": 0.65,
      "grad_norm": 3.259177272933163,
      "learning_rate": 2.836525307953356e-06,
      "loss": 0.4497,
      "step": 9394
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.275368934763251,
      "learning_rate": 2.835510211321225e-06,
      "loss": 0.5136,
      "step": 9395
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.1706131349321214,
      "learning_rate": 2.8344952244649615e-06,
      "loss": 0.5393,
      "step": 9396
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.343180541048802,
      "learning_rate": 2.833480347436038e-06,
      "loss": 0.4904,
      "step": 9397
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.503699180809027,
      "learning_rate": 2.8324655802859287e-06,
      "loss": 0.5042,
      "step": 9398
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.803776883726698,
      "learning_rate": 2.8314509230661e-06,
      "loss": 0.5318,
      "step": 9399
    },
    {
      "epoch": 0.65,
      "grad_norm": 3.6733661723857214,
      "learning_rate": 2.8304363758280085e-06,
      "loss": 0.5091,
      "step": 9400
    },
    {
      "epoch": 0.65,
      "grad_norm": 10.18387830256448,
      "learning_rate": 2.8294219386231136e-06,
      "loss": 0.4463,
      "step": 9401
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.0625702890667017,
      "learning_rate": 2.828407611502857e-06,
      "loss": 0.4646,
      "step": 9402
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.9193685648353824,
      "learning_rate": 2.8273933945186906e-06,
      "loss": 0.4657,
      "step": 9403
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.8061503952324576,
      "learning_rate": 2.8263792877220453e-06,
      "loss": 0.4473,
      "step": 9404
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.8664466767289964,
      "learning_rate": 2.825365291164359e-06,
      "loss": 0.4793,
      "step": 9405
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.8059134033940982,
      "learning_rate": 2.824351404897051e-06,
      "loss": 0.4862,
      "step": 9406
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.7487147835818595,
      "learning_rate": 2.823337628971551e-06,
      "loss": 0.4948,
      "step": 9407
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.7178508647542854,
      "learning_rate": 2.8223239634392686e-06,
      "loss": 0.4846,
      "step": 9408
    },
    {
      "epoch": 0.65,
      "grad_norm": 4.182575198010213,
      "learning_rate": 2.821310408351616e-06,
      "loss": 0.4924,
      "step": 9409
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.935565599269667,
      "learning_rate": 2.8202969637599952e-06,
      "loss": 0.4454,
      "step": 9410
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.04292091029107,
      "learning_rate": 2.8192836297158064e-06,
      "loss": 0.5028,
      "step": 9411
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.137402409822293,
      "learning_rate": 2.8182704062704443e-06,
      "loss": 0.5079,
      "step": 9412
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.9608087716606493,
      "learning_rate": 2.817257293475292e-06,
      "loss": 0.5237,
      "step": 9413
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.8004338529930517,
      "learning_rate": 2.8162442913817333e-06,
      "loss": 0.4826,
      "step": 9414
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.209437956976129,
      "learning_rate": 2.8152314000411456e-06,
      "loss": 0.4939,
      "step": 9415
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.3284052091940373,
      "learning_rate": 2.8142186195049002e-06,
      "loss": 0.4908,
      "step": 9416
    },
    {
      "epoch": 0.65,
      "grad_norm": 2.2711493685438584,
      "learning_rate": 2.813205949824358e-06,
      "loss": 0.4911,
      "step": 9417
    },
    {
      "epoch": 0.65,
      "grad_norm": 3.133839234048121,
      "learning_rate": 2.8121933910508815e-06,
      "loss": 0.4715,
      "step": 9418
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.9921965865120395,
      "learning_rate": 2.8111809432358227e-06,
      "loss": 0.5017,
      "step": 9419
    },
    {
      "epoch": 0.65,
      "grad_norm": 3.6879581730543425,
      "learning_rate": 2.810168606430532e-06,
      "loss": 0.4836,
      "step": 9420
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.907944506819805,
      "learning_rate": 2.80915638068635e-06,
      "loss": 0.5042,
      "step": 9421
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.11566113175111,
      "learning_rate": 2.8081442660546126e-06,
      "loss": 0.5016,
      "step": 9422
    },
    {
      "epoch": 0.66,
      "grad_norm": 4.724915112050747,
      "learning_rate": 2.8071322625866547e-06,
      "loss": 0.429,
      "step": 9423
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.819407669279222,
      "learning_rate": 2.8061203703337967e-06,
      "loss": 0.5402,
      "step": 9424
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.6565818392561287,
      "learning_rate": 2.8051085893473633e-06,
      "loss": 0.4929,
      "step": 9425
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.3426960614494168,
      "learning_rate": 2.8040969196786626e-06,
      "loss": 0.456,
      "step": 9426
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.11688110238636,
      "learning_rate": 2.803085361379011e-06,
      "loss": 0.4932,
      "step": 9427
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.975748995456845,
      "learning_rate": 2.8020739144997057e-06,
      "loss": 0.533,
      "step": 9428
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.991360714155263,
      "learning_rate": 2.8010625790920475e-06,
      "loss": 0.4997,
      "step": 9429
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.8748967766605167,
      "learning_rate": 2.8000513552073248e-06,
      "loss": 0.4629,
      "step": 9430
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.002525917809807,
      "learning_rate": 2.799040242896825e-06,
      "loss": 0.4962,
      "step": 9431
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.111484722887583,
      "learning_rate": 2.7980292422118282e-06,
      "loss": 0.4827,
      "step": 9432
    },
    {
      "epoch": 0.66,
      "grad_norm": 6.075815481874259,
      "learning_rate": 2.7970183532036115e-06,
      "loss": 0.5537,
      "step": 9433
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.8314271527659574,
      "learning_rate": 2.79600757592344e-06,
      "loss": 0.501,
      "step": 9434
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.1986006476962157,
      "learning_rate": 2.7949969104225787e-06,
      "loss": 0.4887,
      "step": 9435
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.188884782185455,
      "learning_rate": 2.7939863567522876e-06,
      "loss": 0.454,
      "step": 9436
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.68151125183871,
      "learning_rate": 2.792975914963814e-06,
      "loss": 0.4582,
      "step": 9437
    },
    {
      "epoch": 0.66,
      "grad_norm": 3.323842898008405,
      "learning_rate": 2.791965585108407e-06,
      "loss": 0.4854,
      "step": 9438
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.2356086589745523,
      "learning_rate": 2.790955367237307e-06,
      "loss": 0.5126,
      "step": 9439
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.5774354556366172,
      "learning_rate": 2.7899452614017506e-06,
      "loss": 0.4955,
      "step": 9440
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.914022607087998,
      "learning_rate": 2.7889352676529635e-06,
      "loss": 0.4695,
      "step": 9441
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.6671313328634056,
      "learning_rate": 2.7879253860421712e-06,
      "loss": 0.4763,
      "step": 9442
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.0587072655816834,
      "learning_rate": 2.7869156166205934e-06,
      "loss": 0.4991,
      "step": 9443
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.6573036761316307,
      "learning_rate": 2.785905959439439e-06,
      "loss": 0.4327,
      "step": 9444
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.969873658189405,
      "learning_rate": 2.784896414549917e-06,
      "loss": 0.477,
      "step": 9445
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.0300286168747976,
      "learning_rate": 2.783886982003223e-06,
      "loss": 0.5091,
      "step": 9446
    },
    {
      "epoch": 0.66,
      "grad_norm": 7.13878247536128,
      "learning_rate": 2.7828776618505615e-06,
      "loss": 0.5136,
      "step": 9447
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.89370800202839,
      "learning_rate": 2.781868454143114e-06,
      "loss": 0.5029,
      "step": 9448
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.085770243819066,
      "learning_rate": 2.7808593589320696e-06,
      "loss": 0.5191,
      "step": 9449
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.709100190019125,
      "learning_rate": 2.779850376268599e-06,
      "loss": 0.4771,
      "step": 9450
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.621123555521919,
      "learning_rate": 2.778841506203884e-06,
      "loss": 0.4749,
      "step": 9451
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.8527035382978798,
      "learning_rate": 2.7778327487890837e-06,
      "loss": 0.4667,
      "step": 9452
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.9602326991387675,
      "learning_rate": 2.776824104075364e-06,
      "loss": 0.5037,
      "step": 9453
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5990403843847649,
      "learning_rate": 2.775815572113876e-06,
      "loss": 0.4349,
      "step": 9454
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.0035016496252536,
      "learning_rate": 2.7748071529557706e-06,
      "loss": 0.4683,
      "step": 9455
    },
    {
      "epoch": 0.66,
      "grad_norm": 3.299535194442321,
      "learning_rate": 2.7737988466521936e-06,
      "loss": 0.4784,
      "step": 9456
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.2074768926285446,
      "learning_rate": 2.7727906532542783e-06,
      "loss": 0.5302,
      "step": 9457
    },
    {
      "epoch": 0.66,
      "grad_norm": 3.011782437328033,
      "learning_rate": 2.7717825728131632e-06,
      "loss": 0.4815,
      "step": 9458
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.335728713133311,
      "learning_rate": 2.7707746053799696e-06,
      "loss": 0.509,
      "step": 9459
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.9152337988650245,
      "learning_rate": 2.7697667510058224e-06,
      "loss": 0.4894,
      "step": 9460
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.9545659059823404,
      "learning_rate": 2.7687590097418305e-06,
      "loss": 0.4666,
      "step": 9461
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.3589363941449477,
      "learning_rate": 2.767751381639111e-06,
      "loss": 0.5302,
      "step": 9462
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.040079583064414,
      "learning_rate": 2.766743866748762e-06,
      "loss": 0.5306,
      "step": 9463
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.6165915568389992,
      "learning_rate": 2.765736465121886e-06,
      "loss": 0.4798,
      "step": 9464
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.1749559392004127,
      "learning_rate": 2.7647291768095695e-06,
      "loss": 0.5104,
      "step": 9465
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.6693001845110642,
      "learning_rate": 2.763722001862903e-06,
      "loss": 0.4536,
      "step": 9466
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.246868086968968,
      "learning_rate": 2.7627149403329668e-06,
      "loss": 0.4901,
      "step": 9467
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.3225888986028456,
      "learning_rate": 2.7617079922708332e-06,
      "loss": 0.4668,
      "step": 9468
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.5209031974814744,
      "learning_rate": 2.760701157727573e-06,
      "loss": 0.5073,
      "step": 9469
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.865198345686972,
      "learning_rate": 2.7596944367542487e-06,
      "loss": 0.4915,
      "step": 9470
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.9065398062956143,
      "learning_rate": 2.758687829401922e-06,
      "loss": 0.5093,
      "step": 9471
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.0059030497012476,
      "learning_rate": 2.757681335721639e-06,
      "loss": 0.5209,
      "step": 9472
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.9384202543517934,
      "learning_rate": 2.7566749557644478e-06,
      "loss": 0.4601,
      "step": 9473
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.047221711275444,
      "learning_rate": 2.75566868958139e-06,
      "loss": 0.5259,
      "step": 9474
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.1060879870413625,
      "learning_rate": 2.7546625372235015e-06,
      "loss": 0.5063,
      "step": 9475
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.8040987436275238,
      "learning_rate": 2.7536564987418056e-06,
      "loss": 0.5043,
      "step": 9476
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.6748196600974437,
      "learning_rate": 2.75265057418733e-06,
      "loss": 0.5419,
      "step": 9477
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.7405239342785537,
      "learning_rate": 2.7516447636110914e-06,
      "loss": 0.4916,
      "step": 9478
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.6734160214541867,
      "learning_rate": 2.750639067064099e-06,
      "loss": 0.4597,
      "step": 9479
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.1708529609447647,
      "learning_rate": 2.7496334845973618e-06,
      "loss": 0.5407,
      "step": 9480
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.699278975245383,
      "learning_rate": 2.7486280162618727e-06,
      "loss": 0.4642,
      "step": 9481
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.258899675440349,
      "learning_rate": 2.7476226621086354e-06,
      "loss": 0.545,
      "step": 9482
    },
    {
      "epoch": 0.66,
      "grad_norm": 3.147589484751852,
      "learning_rate": 2.746617422188632e-06,
      "loss": 0.5402,
      "step": 9483
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.064654291644532,
      "learning_rate": 2.7456122965528475e-06,
      "loss": 0.5111,
      "step": 9484
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.336743473002745,
      "learning_rate": 2.7446072852522545e-06,
      "loss": 0.5464,
      "step": 9485
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.6042432435335369,
      "learning_rate": 2.7436023883378303e-06,
      "loss": 0.4352,
      "step": 9486
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.4513275741300307,
      "learning_rate": 2.7425976058605354e-06,
      "loss": 0.5151,
      "step": 9487
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.8733879347161726,
      "learning_rate": 2.741592937871332e-06,
      "loss": 0.496,
      "step": 9488
    },
    {
      "epoch": 0.66,
      "grad_norm": 3.101502088026144,
      "learning_rate": 2.74058838442117e-06,
      "loss": 0.4676,
      "step": 9489
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.1873549023311596,
      "learning_rate": 2.7395839455609985e-06,
      "loss": 0.5079,
      "step": 9490
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.812295875110186,
      "learning_rate": 2.7385796213417626e-06,
      "loss": 0.4521,
      "step": 9491
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.0937967678093408,
      "learning_rate": 2.737575411814393e-06,
      "loss": 0.475,
      "step": 9492
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.621800906152545,
      "learning_rate": 2.7365713170298234e-06,
      "loss": 0.4545,
      "step": 9493
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.36025030341266,
      "learning_rate": 2.7355673370389768e-06,
      "loss": 0.478,
      "step": 9494
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.9046649230461516,
      "learning_rate": 2.734563471892775e-06,
      "loss": 0.4451,
      "step": 9495
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.667037226409103,
      "learning_rate": 2.733559721642125e-06,
      "loss": 0.5324,
      "step": 9496
    },
    {
      "epoch": 0.66,
      "grad_norm": 3.050362262364045,
      "learning_rate": 2.732556086337938e-06,
      "loss": 0.4665,
      "step": 9497
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.204324061503465,
      "learning_rate": 2.7315525660311135e-06,
      "loss": 0.4878,
      "step": 9498
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.7972276708352073,
      "learning_rate": 2.73054916077255e-06,
      "loss": 0.4762,
      "step": 9499
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.46018128951151,
      "learning_rate": 2.7295458706131316e-06,
      "loss": 0.4626,
      "step": 9500
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.630075174844536,
      "learning_rate": 2.728542695603744e-06,
      "loss": 0.4858,
      "step": 9501
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.0244701602679633,
      "learning_rate": 2.7275396357952683e-06,
      "loss": 0.468,
      "step": 9502
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.7128808020813677,
      "learning_rate": 2.7265366912385718e-06,
      "loss": 0.4863,
      "step": 9503
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.301747829433767,
      "learning_rate": 2.725533861984524e-06,
      "loss": 0.4933,
      "step": 9504
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.3957090438368356,
      "learning_rate": 2.7245311480839793e-06,
      "loss": 0.4787,
      "step": 9505
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.4941966211727156,
      "learning_rate": 2.7235285495878006e-06,
      "loss": 0.5325,
      "step": 9506
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.099518607433916,
      "learning_rate": 2.72252606654683e-06,
      "loss": 0.5223,
      "step": 9507
    },
    {
      "epoch": 0.66,
      "grad_norm": 3.093556639264639,
      "learning_rate": 2.721523699011914e-06,
      "loss": 0.5376,
      "step": 9508
    },
    {
      "epoch": 0.66,
      "grad_norm": 3.4053186821966843,
      "learning_rate": 2.720521447033887e-06,
      "loss": 0.5207,
      "step": 9509
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.0902617943877737,
      "learning_rate": 2.71951931066358e-06,
      "loss": 0.4915,
      "step": 9510
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.6288608355759666,
      "learning_rate": 2.7185172899518196e-06,
      "loss": 0.4885,
      "step": 9511
    },
    {
      "epoch": 0.66,
      "grad_norm": 3.182924383654476,
      "learning_rate": 2.717515384949424e-06,
      "loss": 0.5419,
      "step": 9512
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.8695544767860923,
      "learning_rate": 2.716513595707205e-06,
      "loss": 0.4894,
      "step": 9513
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.166279942883333,
      "learning_rate": 2.7155119222759734e-06,
      "loss": 0.5013,
      "step": 9514
    },
    {
      "epoch": 0.66,
      "grad_norm": 3.172011458639317,
      "learning_rate": 2.714510364706531e-06,
      "loss": 0.5025,
      "step": 9515
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.8048798896649132,
      "learning_rate": 2.713508923049669e-06,
      "loss": 0.4819,
      "step": 9516
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.4490222359092897,
      "learning_rate": 2.712507597356181e-06,
      "loss": 0.4585,
      "step": 9517
    },
    {
      "epoch": 0.66,
      "grad_norm": 14.451641574982528,
      "learning_rate": 2.711506387676849e-06,
      "loss": 0.509,
      "step": 9518
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.7278128048465686,
      "learning_rate": 2.7105052940624544e-06,
      "loss": 0.4636,
      "step": 9519
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.6981298581126731,
      "learning_rate": 2.7095043165637657e-06,
      "loss": 0.4815,
      "step": 9520
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.714441086249741,
      "learning_rate": 2.70850345523155e-06,
      "loss": 0.5192,
      "step": 9521
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.6905495826547248,
      "learning_rate": 2.7075027101165706e-06,
      "loss": 0.5465,
      "step": 9522
    },
    {
      "epoch": 0.66,
      "grad_norm": 7.9697083879299955,
      "learning_rate": 2.7065020812695776e-06,
      "loss": 0.5077,
      "step": 9523
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.07663572511816,
      "learning_rate": 2.7055015687413215e-06,
      "loss": 0.4827,
      "step": 9524
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.479016309382318,
      "learning_rate": 2.7045011725825458e-06,
      "loss": 0.4635,
      "step": 9525
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.768990190972574,
      "learning_rate": 2.7035008928439886e-06,
      "loss": 0.5076,
      "step": 9526
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.9965348072980469,
      "learning_rate": 2.702500729576377e-06,
      "loss": 0.4922,
      "step": 9527
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.711032891425308,
      "learning_rate": 2.701500682830439e-06,
      "loss": 0.4706,
      "step": 9528
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.241477771607394,
      "learning_rate": 2.7005007526568923e-06,
      "loss": 0.5186,
      "step": 9529
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.8822032742718178,
      "learning_rate": 2.6995009391064524e-06,
      "loss": 0.4973,
      "step": 9530
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.9822574729604714,
      "learning_rate": 2.698501242229823e-06,
      "loss": 0.5567,
      "step": 9531
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.294291579653301,
      "learning_rate": 2.697501662077707e-06,
      "loss": 0.5016,
      "step": 9532
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.6527518076840182,
      "learning_rate": 2.696502198700803e-06,
      "loss": 0.4969,
      "step": 9533
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.371701472944526,
      "learning_rate": 2.695502852149795e-06,
      "loss": 0.5039,
      "step": 9534
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.584004439267094,
      "learning_rate": 2.6945036224753706e-06,
      "loss": 0.4588,
      "step": 9535
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.524136577834115,
      "learning_rate": 2.693504509728203e-06,
      "loss": 0.4506,
      "step": 9536
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.903643810527321,
      "learning_rate": 2.6925055139589705e-06,
      "loss": 0.4265,
      "step": 9537
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.090472268664876,
      "learning_rate": 2.6915066352183346e-06,
      "loss": 0.4826,
      "step": 9538
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.7903099603294095,
      "learning_rate": 2.6905078735569568e-06,
      "loss": 0.4786,
      "step": 9539
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.9364812608577402,
      "learning_rate": 2.689509229025487e-06,
      "loss": 0.4437,
      "step": 9540
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.3063173629737,
      "learning_rate": 2.6885107016745804e-06,
      "loss": 0.535,
      "step": 9541
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.9437585316237853,
      "learning_rate": 2.6875122915548726e-06,
      "loss": 0.4964,
      "step": 9542
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.0164381219635774,
      "learning_rate": 2.6865139987170047e-06,
      "loss": 0.5319,
      "step": 9543
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.8641087587863379,
      "learning_rate": 2.685515823211602e-06,
      "loss": 0.4758,
      "step": 9544
    },
    {
      "epoch": 0.66,
      "grad_norm": 3.0583013018868623,
      "learning_rate": 2.684517765089292e-06,
      "loss": 0.4941,
      "step": 9545
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.0951873895030033,
      "learning_rate": 2.683519824400693e-06,
      "loss": 0.5286,
      "step": 9546
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.8479009052917483,
      "learning_rate": 2.682522001196415e-06,
      "loss": 0.4442,
      "step": 9547
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.825333934869235,
      "learning_rate": 2.6815242955270648e-06,
      "loss": 0.4836,
      "step": 9548
    },
    {
      "epoch": 0.66,
      "grad_norm": 3.8724499163827466,
      "learning_rate": 2.6805267074432443e-06,
      "loss": 0.4763,
      "step": 9549
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.8560331448838645,
      "learning_rate": 2.6795292369955493e-06,
      "loss": 0.4583,
      "step": 9550
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.6202554627253895,
      "learning_rate": 2.678531884234564e-06,
      "loss": 0.4295,
      "step": 9551
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.7697605658168718,
      "learning_rate": 2.6775346492108735e-06,
      "loss": 0.4742,
      "step": 9552
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.9343964370619626,
      "learning_rate": 2.6765375319750544e-06,
      "loss": 0.5072,
      "step": 9553
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.34709638634836,
      "learning_rate": 2.6755405325776774e-06,
      "loss": 0.5155,
      "step": 9554
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.9258025113336548,
      "learning_rate": 2.674543651069305e-06,
      "loss": 0.4702,
      "step": 9555
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.5677739870716425,
      "learning_rate": 2.6735468875004976e-06,
      "loss": 0.5145,
      "step": 9556
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.228784516855698,
      "learning_rate": 2.6725502419218084e-06,
      "loss": 0.5045,
      "step": 9557
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.6749102023576382,
      "learning_rate": 2.671553714383782e-06,
      "loss": 0.4322,
      "step": 9558
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.5953983560212945,
      "learning_rate": 2.670557304936962e-06,
      "loss": 0.4362,
      "step": 9559
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.9514210784067172,
      "learning_rate": 2.6695610136318766e-06,
      "loss": 0.4961,
      "step": 9560
    },
    {
      "epoch": 0.66,
      "grad_norm": 3.821133895207697,
      "learning_rate": 2.6685648405190636e-06,
      "loss": 0.5028,
      "step": 9561
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.131492243465272,
      "learning_rate": 2.6675687856490384e-06,
      "loss": 0.4936,
      "step": 9562
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.150994896769807,
      "learning_rate": 2.666572849072322e-06,
      "loss": 0.4759,
      "step": 9563
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.0192635499758107,
      "learning_rate": 2.6655770308394213e-06,
      "loss": 0.484,
      "step": 9564
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.8892995860319683,
      "learning_rate": 2.664581331000844e-06,
      "loss": 0.4612,
      "step": 9565
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.8917323498132257,
      "learning_rate": 2.663585749607087e-06,
      "loss": 0.4487,
      "step": 9566
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.8532545430310032,
      "learning_rate": 2.662590286708645e-06,
      "loss": 0.4203,
      "step": 9567
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.15943166025615,
      "learning_rate": 2.6615949423560017e-06,
      "loss": 0.5177,
      "step": 9568
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.9908897972287125,
      "learning_rate": 2.66059971659964e-06,
      "loss": 0.4434,
      "step": 9569
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5625157356356163,
      "learning_rate": 2.6596046094900353e-06,
      "loss": 0.4557,
      "step": 9570
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.4031741707048164,
      "learning_rate": 2.6586096210776525e-06,
      "loss": 0.4963,
      "step": 9571
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.1100090153654665,
      "learning_rate": 2.6576147514129557e-06,
      "loss": 0.498,
      "step": 9572
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.9025580244604061,
      "learning_rate": 2.6566200005464034e-06,
      "loss": 0.53,
      "step": 9573
    },
    {
      "epoch": 0.67,
      "grad_norm": 5.6724738121104785,
      "learning_rate": 2.6556253685284462e-06,
      "loss": 0.4962,
      "step": 9574
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.00246024420223,
      "learning_rate": 2.654630855409525e-06,
      "loss": 0.516,
      "step": 9575
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.6958427212785985,
      "learning_rate": 2.6536364612400812e-06,
      "loss": 0.5095,
      "step": 9576
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.0723631466172963,
      "learning_rate": 2.6526421860705474e-06,
      "loss": 0.4867,
      "step": 9577
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.35884793865129,
      "learning_rate": 2.6516480299513482e-06,
      "loss": 0.4546,
      "step": 9578
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.925609719534743,
      "learning_rate": 2.6506539929329063e-06,
      "loss": 0.5005,
      "step": 9579
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.0601385042559155,
      "learning_rate": 2.6496600750656306e-06,
      "loss": 0.4942,
      "step": 9580
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.025555240777181,
      "learning_rate": 2.648666276399937e-06,
      "loss": 0.4308,
      "step": 9581
    },
    {
      "epoch": 0.67,
      "grad_norm": 4.112558144949257,
      "learning_rate": 2.6476725969862227e-06,
      "loss": 0.4838,
      "step": 9582
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.072596123725695,
      "learning_rate": 2.6466790368748853e-06,
      "loss": 0.4966,
      "step": 9583
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.133710117530602,
      "learning_rate": 2.6456855961163143e-06,
      "loss": 0.4827,
      "step": 9584
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5687995146371623,
      "learning_rate": 2.6446922747608965e-06,
      "loss": 0.4098,
      "step": 9585
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6071333914664491,
      "learning_rate": 2.643699072859006e-06,
      "loss": 0.4168,
      "step": 9586
    },
    {
      "epoch": 0.67,
      "grad_norm": 4.118500391660978,
      "learning_rate": 2.6427059904610164e-06,
      "loss": 0.5179,
      "step": 9587
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.927648547883817,
      "learning_rate": 2.641713027617296e-06,
      "loss": 0.4871,
      "step": 9588
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.878436228860443,
      "learning_rate": 2.6407201843782006e-06,
      "loss": 0.5119,
      "step": 9589
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.5958459876572517,
      "learning_rate": 2.639727460794087e-06,
      "loss": 0.5092,
      "step": 9590
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.7213445231002276,
      "learning_rate": 2.6387348569152984e-06,
      "loss": 0.4952,
      "step": 9591
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.8884634393564705,
      "learning_rate": 2.6377423727921826e-06,
      "loss": 0.5013,
      "step": 9592
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.9206847423078126,
      "learning_rate": 2.636750008475071e-06,
      "loss": 0.5241,
      "step": 9593
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.1278961011546262,
      "learning_rate": 2.635757764014296e-06,
      "loss": 0.528,
      "step": 9594
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.2475924414395108,
      "learning_rate": 2.634765639460176e-06,
      "loss": 0.4179,
      "step": 9595
    },
    {
      "epoch": 0.67,
      "grad_norm": 3.0305978967273854,
      "learning_rate": 2.633773634863035e-06,
      "loss": 0.4936,
      "step": 9596
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.7004168277808562,
      "learning_rate": 2.632781750273179e-06,
      "loss": 0.4497,
      "step": 9597
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6085095229339265,
      "learning_rate": 2.631789985740918e-06,
      "loss": 0.4135,
      "step": 9598
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6234802531991843,
      "learning_rate": 2.6307983413165448e-06,
      "loss": 0.4371,
      "step": 9599
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.0767510731524044,
      "learning_rate": 2.6298068170503564e-06,
      "loss": 0.505,
      "step": 9600
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.873597848746854,
      "learning_rate": 2.6288154129926406e-06,
      "loss": 0.5055,
      "step": 9601
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.566752100387114,
      "learning_rate": 2.6278241291936747e-06,
      "loss": 0.5092,
      "step": 9602
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.2578499179250224,
      "learning_rate": 2.626832965703735e-06,
      "loss": 0.4976,
      "step": 9603
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.7242265083373907,
      "learning_rate": 2.6258419225730912e-06,
      "loss": 0.5016,
      "step": 9604
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.7449060043443159,
      "learning_rate": 2.624850999852006e-06,
      "loss": 0.4893,
      "step": 9605
    },
    {
      "epoch": 0.67,
      "grad_norm": 3.72256731675973,
      "learning_rate": 2.623860197590733e-06,
      "loss": 0.5086,
      "step": 9606
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.0691230093323454,
      "learning_rate": 2.622869515839524e-06,
      "loss": 0.4987,
      "step": 9607
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.2180850325219863,
      "learning_rate": 2.6218789546486235e-06,
      "loss": 0.4658,
      "step": 9608
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.112917029009208,
      "learning_rate": 2.6208885140682707e-06,
      "loss": 0.4179,
      "step": 9609
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.6774834583146367,
      "learning_rate": 2.6198981941486946e-06,
      "loss": 0.5088,
      "step": 9610
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.556833871038379,
      "learning_rate": 2.6189079949401223e-06,
      "loss": 0.4948,
      "step": 9611
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.7346440509984398,
      "learning_rate": 2.617917916492776e-06,
      "loss": 0.4648,
      "step": 9612
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.0056518548427498,
      "learning_rate": 2.6169279588568647e-06,
      "loss": 0.4433,
      "step": 9613
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.8605014900893915,
      "learning_rate": 2.6159381220826004e-06,
      "loss": 0.4722,
      "step": 9614
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.869525901102715,
      "learning_rate": 2.614948406220178e-06,
      "loss": 0.4822,
      "step": 9615
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.163090604185385,
      "learning_rate": 2.6139588113198e-06,
      "loss": 0.5003,
      "step": 9616
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.91472513572242,
      "learning_rate": 2.6129693374316512e-06,
      "loss": 0.4718,
      "step": 9617
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.9800706753957424,
      "learning_rate": 2.611979984605917e-06,
      "loss": 0.5097,
      "step": 9618
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.7177750160369387,
      "learning_rate": 2.610990752892768e-06,
      "loss": 0.5435,
      "step": 9619
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.388245188628054,
      "learning_rate": 2.6100016423423837e-06,
      "loss": 0.4752,
      "step": 9620
    },
    {
      "epoch": 0.67,
      "grad_norm": 3.406118033312803,
      "learning_rate": 2.6090126530049225e-06,
      "loss": 0.4742,
      "step": 9621
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.0497581372454063,
      "learning_rate": 2.6080237849305467e-06,
      "loss": 0.4492,
      "step": 9622
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.819559983140478,
      "learning_rate": 2.6070350381694037e-06,
      "loss": 0.4643,
      "step": 9623
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.948275992637231,
      "learning_rate": 2.6060464127716423e-06,
      "loss": 0.4653,
      "step": 9624
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.9528158786610597,
      "learning_rate": 2.605057908787404e-06,
      "loss": 0.4788,
      "step": 9625
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.1539340038296704,
      "learning_rate": 2.604069526266819e-06,
      "loss": 0.4934,
      "step": 9626
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.433516950107082,
      "learning_rate": 2.6030812652600156e-06,
      "loss": 0.4724,
      "step": 9627
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.853332388088881,
      "learning_rate": 2.6020931258171166e-06,
      "loss": 0.47,
      "step": 9628
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.7822978734053565,
      "learning_rate": 2.601105107988239e-06,
      "loss": 0.4768,
      "step": 9629
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.6735311296458897,
      "learning_rate": 2.6001172118234873e-06,
      "loss": 0.5396,
      "step": 9630
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.9846670563182374,
      "learning_rate": 2.5991294373729657e-06,
      "loss": 0.4925,
      "step": 9631
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5665405049504472,
      "learning_rate": 2.5981417846867753e-06,
      "loss": 0.4241,
      "step": 9632
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.0756965495418873,
      "learning_rate": 2.5971542538149997e-06,
      "loss": 0.4923,
      "step": 9633
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.7619948904401888,
      "learning_rate": 2.596166844807727e-06,
      "loss": 0.4622,
      "step": 9634
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.4958615222116993,
      "learning_rate": 2.595179557715035e-06,
      "loss": 0.4428,
      "step": 9635
    },
    {
      "epoch": 0.67,
      "grad_norm": 6.1546617117222775,
      "learning_rate": 2.5941923925869977e-06,
      "loss": 0.5158,
      "step": 9636
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.201322121266196,
      "learning_rate": 2.593205349473677e-06,
      "loss": 0.4963,
      "step": 9637
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.576601754048238,
      "learning_rate": 2.5922184284251363e-06,
      "loss": 0.4098,
      "step": 9638
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.2038255671604685,
      "learning_rate": 2.5912316294914232e-06,
      "loss": 0.499,
      "step": 9639
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.3021857781036412,
      "learning_rate": 2.5902449527225926e-06,
      "loss": 0.4939,
      "step": 9640
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.1690362126382747,
      "learning_rate": 2.58925839816868e-06,
      "loss": 0.5187,
      "step": 9641
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.8657966255879879,
      "learning_rate": 2.5882719658797235e-06,
      "loss": 0.4891,
      "step": 9642
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.1473118504194058,
      "learning_rate": 2.5872856559057484e-06,
      "loss": 0.4345,
      "step": 9643
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.7524305617933076,
      "learning_rate": 2.586299468296779e-06,
      "loss": 0.4847,
      "step": 9644
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.112294034016889,
      "learning_rate": 2.5853134031028337e-06,
      "loss": 0.4809,
      "step": 9645
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.6757661776692143,
      "learning_rate": 2.5843274603739177e-06,
      "loss": 0.4811,
      "step": 9646
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5813996355125112,
      "learning_rate": 2.5833416401600377e-06,
      "loss": 0.4102,
      "step": 9647
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6223948330312337,
      "learning_rate": 2.582355942511191e-06,
      "loss": 0.4267,
      "step": 9648
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.2885779877198233,
      "learning_rate": 2.581370367477371e-06,
      "loss": 0.4699,
      "step": 9649
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5114738286597408,
      "learning_rate": 2.580384915108557e-06,
      "loss": 0.4094,
      "step": 9650
    },
    {
      "epoch": 0.67,
      "grad_norm": 5.077547622365236,
      "learning_rate": 2.579399585454735e-06,
      "loss": 0.4685,
      "step": 9651
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.9073985261563022,
      "learning_rate": 2.578414378565873e-06,
      "loss": 0.5326,
      "step": 9652
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.810358750375752,
      "learning_rate": 2.5774292944919405e-06,
      "loss": 0.5366,
      "step": 9653
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.0584884955347733,
      "learning_rate": 2.5764443332828944e-06,
      "loss": 0.4358,
      "step": 9654
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.9428338802920586,
      "learning_rate": 2.5754594949886903e-06,
      "loss": 0.5334,
      "step": 9655
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.5943923760092216,
      "learning_rate": 2.5744747796592785e-06,
      "loss": 0.4789,
      "step": 9656
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.5821887607197795,
      "learning_rate": 2.573490187344596e-06,
      "loss": 0.4783,
      "step": 9657
    },
    {
      "epoch": 0.67,
      "grad_norm": 3.757850489236025,
      "learning_rate": 2.5725057180945803e-06,
      "loss": 0.4859,
      "step": 9658
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.652523666323466,
      "learning_rate": 2.57152137195916e-06,
      "loss": 0.4898,
      "step": 9659
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.5903456360692734,
      "learning_rate": 2.570537148988261e-06,
      "loss": 0.4822,
      "step": 9660
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.021583352915363,
      "learning_rate": 2.5695530492317954e-06,
      "loss": 0.5159,
      "step": 9661
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.2290189889638627,
      "learning_rate": 2.5685690727396752e-06,
      "loss": 0.5272,
      "step": 9662
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.92233712919305,
      "learning_rate": 2.5675852195618044e-06,
      "loss": 0.4571,
      "step": 9663
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.9927060341438516,
      "learning_rate": 2.566601489748084e-06,
      "loss": 0.5263,
      "step": 9664
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.8705384366169562,
      "learning_rate": 2.5656178833484e-06,
      "loss": 0.4528,
      "step": 9665
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.6133497796028936,
      "learning_rate": 2.5646344004126404e-06,
      "loss": 0.4276,
      "step": 9666
    },
    {
      "epoch": 0.67,
      "grad_norm": 3.281872027219586,
      "learning_rate": 2.5636510409906867e-06,
      "loss": 0.4734,
      "step": 9667
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.858368892935418,
      "learning_rate": 2.5626678051324074e-06,
      "loss": 0.4905,
      "step": 9668
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.3690093688983853,
      "learning_rate": 2.5616846928876714e-06,
      "loss": 0.4855,
      "step": 9669
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.8526778748449217,
      "learning_rate": 2.560701704306336e-06,
      "loss": 0.4814,
      "step": 9670
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.8804143902444819,
      "learning_rate": 2.559718839438261e-06,
      "loss": 0.5411,
      "step": 9671
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.5900919115854992,
      "learning_rate": 2.558736098333289e-06,
      "loss": 0.5415,
      "step": 9672
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.0063335506057145,
      "learning_rate": 2.5577534810412645e-06,
      "loss": 0.4734,
      "step": 9673
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.9695030013070942,
      "learning_rate": 2.556770987612018e-06,
      "loss": 0.4789,
      "step": 9674
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.1653448184048756,
      "learning_rate": 2.555788618095385e-06,
      "loss": 0.4666,
      "step": 9675
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.89849149767028,
      "learning_rate": 2.5548063725411832e-06,
      "loss": 0.4318,
      "step": 9676
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.90725240991237,
      "learning_rate": 2.5538242509992317e-06,
      "loss": 0.4941,
      "step": 9677
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.041711207551746,
      "learning_rate": 2.5528422535193377e-06,
      "loss": 0.4889,
      "step": 9678
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.49516052573904,
      "learning_rate": 2.5518603801513063e-06,
      "loss": 0.4365,
      "step": 9679
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.782732905508542,
      "learning_rate": 2.5508786309449375e-06,
      "loss": 0.4957,
      "step": 9680
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.8370544857586895,
      "learning_rate": 2.5498970059500173e-06,
      "loss": 0.4671,
      "step": 9681
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.7502985470864316,
      "learning_rate": 2.548915505216333e-06,
      "loss": 0.4731,
      "step": 9682
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.2515097886549182,
      "learning_rate": 2.5479341287936643e-06,
      "loss": 0.4392,
      "step": 9683
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.944931892459553,
      "learning_rate": 2.5469528767317836e-06,
      "loss": 0.5283,
      "step": 9684
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.1181672830884186,
      "learning_rate": 2.5459717490804535e-06,
      "loss": 0.499,
      "step": 9685
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.645082526910538,
      "learning_rate": 2.5449907458894362e-06,
      "loss": 0.4788,
      "step": 9686
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.946812974451465,
      "learning_rate": 2.5440098672084845e-06,
      "loss": 0.4644,
      "step": 9687
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.7970552917600344,
      "learning_rate": 2.5430291130873466e-06,
      "loss": 0.4637,
      "step": 9688
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.081421368781097,
      "learning_rate": 2.5420484835757607e-06,
      "loss": 0.4977,
      "step": 9689
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.4452997384621185,
      "learning_rate": 2.5410679787234616e-06,
      "loss": 0.4993,
      "step": 9690
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.7539690889530244,
      "learning_rate": 2.540087598580181e-06,
      "loss": 0.4699,
      "step": 9691
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.1252736135262675,
      "learning_rate": 2.539107343195635e-06,
      "loss": 0.4806,
      "step": 9692
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.5997517987131644,
      "learning_rate": 2.538127212619543e-06,
      "loss": 0.5005,
      "step": 9693
    },
    {
      "epoch": 0.67,
      "grad_norm": 6.227078767600627,
      "learning_rate": 2.53714720690161e-06,
      "loss": 0.4867,
      "step": 9694
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.6918927093951734,
      "learning_rate": 2.536167326091544e-06,
      "loss": 0.4397,
      "step": 9695
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.9285354131975099,
      "learning_rate": 2.5351875702390373e-06,
      "loss": 0.4885,
      "step": 9696
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.03882279694698,
      "learning_rate": 2.5342079393937834e-06,
      "loss": 0.4645,
      "step": 9697
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.403747144632206,
      "learning_rate": 2.5332284336054615e-06,
      "loss": 0.5037,
      "step": 9698
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.3659040708801706,
      "learning_rate": 2.532249052923752e-06,
      "loss": 0.4948,
      "step": 9699
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.9120766816544856,
      "learning_rate": 2.5312697973983264e-06,
      "loss": 0.513,
      "step": 9700
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.4910304380262347,
      "learning_rate": 2.5302906670788463e-06,
      "loss": 0.4597,
      "step": 9701
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.5794235842004514,
      "learning_rate": 2.529311662014972e-06,
      "loss": 0.496,
      "step": 9702
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.9067995755880214,
      "learning_rate": 2.528332782256355e-06,
      "loss": 0.5089,
      "step": 9703
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.0424849367664333,
      "learning_rate": 2.5273540278526445e-06,
      "loss": 0.4933,
      "step": 9704
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.6598813579979208,
      "learning_rate": 2.526375398853473e-06,
      "loss": 0.5226,
      "step": 9705
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.7081077588060842,
      "learning_rate": 2.5253968953084774e-06,
      "loss": 0.4808,
      "step": 9706
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.3278076970970853,
      "learning_rate": 2.524418517267283e-06,
      "loss": 0.525,
      "step": 9707
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.132987358582752,
      "learning_rate": 2.523440264779513e-06,
      "loss": 0.522,
      "step": 9708
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.594956624058578,
      "learning_rate": 2.5224621378947766e-06,
      "loss": 0.3989,
      "step": 9709
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.3324541773556806,
      "learning_rate": 2.5214841366626834e-06,
      "loss": 0.4944,
      "step": 9710
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.1777820900248255,
      "learning_rate": 2.5205062611328364e-06,
      "loss": 0.485,
      "step": 9711
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.8713479772963413,
      "learning_rate": 2.5195285113548263e-06,
      "loss": 0.5394,
      "step": 9712
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.3748442280824325,
      "learning_rate": 2.5185508873782427e-06,
      "loss": 0.4864,
      "step": 9713
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.6285894936678067,
      "learning_rate": 2.517573389252669e-06,
      "loss": 0.4719,
      "step": 9714
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.312160158741263,
      "learning_rate": 2.5165960170276815e-06,
      "loss": 0.4757,
      "step": 9715
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.1587779842723953,
      "learning_rate": 2.5156187707528456e-06,
      "loss": 0.4935,
      "step": 9716
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.4944242518676973,
      "learning_rate": 2.514641650477726e-06,
      "loss": 0.4803,
      "step": 9717
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.9847886328609057,
      "learning_rate": 2.513664656251879e-06,
      "loss": 0.4798,
      "step": 9718
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.459717597590836,
      "learning_rate": 2.5126877881248567e-06,
      "loss": 0.4817,
      "step": 9719
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.961664236633031,
      "learning_rate": 2.5117110461461992e-06,
      "loss": 0.5011,
      "step": 9720
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.9326705337970718,
      "learning_rate": 2.5107344303654444e-06,
      "loss": 0.4879,
      "step": 9721
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.4281062923806958,
      "learning_rate": 2.5097579408321264e-06,
      "loss": 0.4719,
      "step": 9722
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.946284871450304,
      "learning_rate": 2.508781577595765e-06,
      "loss": 0.4634,
      "step": 9723
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.13520532701581,
      "learning_rate": 2.5078053407058824e-06,
      "loss": 0.4814,
      "step": 9724
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.1198491298470796,
      "learning_rate": 2.5068292302119834e-06,
      "loss": 0.4598,
      "step": 9725
    },
    {
      "epoch": 0.68,
      "grad_norm": 3.0144432416414535,
      "learning_rate": 2.5058532461635816e-06,
      "loss": 0.5336,
      "step": 9726
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.242366967093622,
      "learning_rate": 2.5048773886101696e-06,
      "loss": 0.4593,
      "step": 9727
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.6875183960296614,
      "learning_rate": 2.503901657601244e-06,
      "loss": 0.5151,
      "step": 9728
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.948253665719136,
      "learning_rate": 2.502926053186285e-06,
      "loss": 0.4651,
      "step": 9729
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.2999642128000444,
      "learning_rate": 2.50195057541478e-06,
      "loss": 0.4812,
      "step": 9730
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.667165373042311,
      "learning_rate": 2.500975224336195e-06,
      "loss": 0.4758,
      "step": 9731
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.890398152817186,
      "learning_rate": 2.5000000000000015e-06,
      "loss": 0.4792,
      "step": 9732
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.8585007692108704,
      "learning_rate": 2.499024902455655e-06,
      "loss": 0.497,
      "step": 9733
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.0729780625817784,
      "learning_rate": 2.4980499317526125e-06,
      "loss": 0.4688,
      "step": 9734
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.936839031627593,
      "learning_rate": 2.4970750879403223e-06,
      "loss": 0.4663,
      "step": 9735
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.7844140917625886,
      "learning_rate": 2.496100371068222e-06,
      "loss": 0.475,
      "step": 9736
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.1915516655335554,
      "learning_rate": 2.495125781185747e-06,
      "loss": 0.4558,
      "step": 9737
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.313643467398228,
      "learning_rate": 2.494151318342327e-06,
      "loss": 0.544,
      "step": 9738
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.806571318274908,
      "learning_rate": 2.493176982587384e-06,
      "loss": 0.4568,
      "step": 9739
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.7731543851755882,
      "learning_rate": 2.49220277397033e-06,
      "loss": 0.5074,
      "step": 9740
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.8954752337379244,
      "learning_rate": 2.491228692540575e-06,
      "loss": 0.508,
      "step": 9741
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.461023910517023,
      "learning_rate": 2.4902547383475216e-06,
      "loss": 0.4954,
      "step": 9742
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.5336583191133952,
      "learning_rate": 2.489280911440568e-06,
      "loss": 0.4788,
      "step": 9743
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.510728118320468,
      "learning_rate": 2.4883072118690994e-06,
      "loss": 0.4794,
      "step": 9744
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.568217727945281,
      "learning_rate": 2.4873336396825e-06,
      "loss": 0.4867,
      "step": 9745
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.141691383971812,
      "learning_rate": 2.4863601949301487e-06,
      "loss": 0.4989,
      "step": 9746
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.8312542576192652,
      "learning_rate": 2.4853868776614117e-06,
      "loss": 0.5127,
      "step": 9747
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.990325399873506,
      "learning_rate": 2.4844136879256555e-06,
      "loss": 0.4877,
      "step": 9748
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.0301560815246735,
      "learning_rate": 2.483440625772232e-06,
      "loss": 0.4807,
      "step": 9749
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.343602130811426,
      "learning_rate": 2.4824676912504996e-06,
      "loss": 0.5025,
      "step": 9750
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.4258506782299474,
      "learning_rate": 2.481494884409796e-06,
      "loss": 0.4817,
      "step": 9751
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.9590994970596285,
      "learning_rate": 2.4805222052994636e-06,
      "loss": 0.5064,
      "step": 9752
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.5871954527814076,
      "learning_rate": 2.4795496539688292e-06,
      "loss": 0.4598,
      "step": 9753
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.6050803359905158,
      "learning_rate": 2.4785772304672184e-06,
      "loss": 0.3998,
      "step": 9754
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.873604295733841,
      "learning_rate": 2.4776049348439507e-06,
      "loss": 0.4807,
      "step": 9755
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.2827044329462285,
      "learning_rate": 2.476632767148339e-06,
      "loss": 0.5006,
      "step": 9756
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.738411584290123,
      "learning_rate": 2.4756607274296844e-06,
      "loss": 0.4645,
      "step": 9757
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.1854303716674433,
      "learning_rate": 2.4746888157372884e-06,
      "loss": 0.5157,
      "step": 9758
    },
    {
      "epoch": 0.68,
      "grad_norm": 5.661706458598637,
      "learning_rate": 2.4737170321204444e-06,
      "loss": 0.4428,
      "step": 9759
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.8079008873322495,
      "learning_rate": 2.4727453766284344e-06,
      "loss": 0.472,
      "step": 9760
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.799169299052152,
      "learning_rate": 2.4717738493105397e-06,
      "loss": 0.4712,
      "step": 9761
    },
    {
      "epoch": 0.68,
      "grad_norm": 3.2932656374477403,
      "learning_rate": 2.4708024502160327e-06,
      "loss": 0.5091,
      "step": 9762
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.2374825755378613,
      "learning_rate": 2.469831179394182e-06,
      "loss": 0.5173,
      "step": 9763
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.141882408792536,
      "learning_rate": 2.468860036894243e-06,
      "loss": 0.5724,
      "step": 9764
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.227576217714144,
      "learning_rate": 2.467889022765471e-06,
      "loss": 0.4968,
      "step": 9765
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.316370461270086,
      "learning_rate": 2.4669181370571142e-06,
      "loss": 0.4799,
      "step": 9766
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.6698553829508445,
      "learning_rate": 2.4659473798184096e-06,
      "loss": 0.4471,
      "step": 9767
    },
    {
      "epoch": 0.68,
      "grad_norm": 3.27707056365941,
      "learning_rate": 2.4649767510985944e-06,
      "loss": 0.4895,
      "step": 9768
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.560070086652248,
      "learning_rate": 2.4640062509468893e-06,
      "loss": 0.4374,
      "step": 9769
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.026149713272954,
      "learning_rate": 2.4630358794125235e-06,
      "loss": 0.5202,
      "step": 9770
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.268528590871472,
      "learning_rate": 2.4620656365447053e-06,
      "loss": 0.4944,
      "step": 9771
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.3254673335266496,
      "learning_rate": 2.461095522392646e-06,
      "loss": 0.498,
      "step": 9772
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.0192907533205644,
      "learning_rate": 2.4601255370055398e-06,
      "loss": 0.49,
      "step": 9773
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.9375410567470974,
      "learning_rate": 2.45915568043259e-06,
      "loss": 0.4955,
      "step": 9774
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.87308151106135,
      "learning_rate": 2.458185952722979e-06,
      "loss": 0.4465,
      "step": 9775
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.5729207977600721,
      "learning_rate": 2.457216353925889e-06,
      "loss": 0.4632,
      "step": 9776
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.815345165175046,
      "learning_rate": 2.456246884090498e-06,
      "loss": 0.5065,
      "step": 9777
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.7917800615460318,
      "learning_rate": 2.4552775432659696e-06,
      "loss": 0.5057,
      "step": 9778
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.6532211908011893,
      "learning_rate": 2.4543083315014704e-06,
      "loss": 0.5057,
      "step": 9779
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.770284854984147,
      "learning_rate": 2.4533392488461494e-06,
      "loss": 0.5153,
      "step": 9780
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.5623405530013401,
      "learning_rate": 2.452370295349162e-06,
      "loss": 0.4215,
      "step": 9781
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.9470260222349864,
      "learning_rate": 2.4514014710596467e-06,
      "loss": 0.4857,
      "step": 9782
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.161711931439108,
      "learning_rate": 2.4504327760267414e-06,
      "loss": 0.4523,
      "step": 9783
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.9507355433228182,
      "learning_rate": 2.4494642102995697e-06,
      "loss": 0.4583,
      "step": 9784
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.01333960395699,
      "learning_rate": 2.448495773927262e-06,
      "loss": 0.4988,
      "step": 9785
    },
    {
      "epoch": 0.68,
      "grad_norm": 3.9426827061675027,
      "learning_rate": 2.447527466958928e-06,
      "loss": 0.4793,
      "step": 9786
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.0856191811446467,
      "learning_rate": 2.4465592894436814e-06,
      "loss": 0.4859,
      "step": 9787
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.8952051623944262,
      "learning_rate": 2.445591241430621e-06,
      "loss": 0.5078,
      "step": 9788
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.0508333505392824,
      "learning_rate": 2.4446233229688456e-06,
      "loss": 0.4884,
      "step": 9789
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.361196548907067,
      "learning_rate": 2.443655534107445e-06,
      "loss": 0.4892,
      "step": 9790
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.7197776333947135,
      "learning_rate": 2.442687874895501e-06,
      "loss": 0.4794,
      "step": 9791
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.512500038565997,
      "learning_rate": 2.4417203453820892e-06,
      "loss": 0.5047,
      "step": 9792
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.8542258561123934,
      "learning_rate": 2.440752945616282e-06,
      "loss": 0.4485,
      "step": 9793
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.481325968434558,
      "learning_rate": 2.4397856756471435e-06,
      "loss": 0.4602,
      "step": 9794
    },
    {
      "epoch": 0.68,
      "grad_norm": 3.136365061930923,
      "learning_rate": 2.4388185355237267e-06,
      "loss": 0.5034,
      "step": 9795
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.679216030332264,
      "learning_rate": 2.437851525295084e-06,
      "loss": 0.5055,
      "step": 9796
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.196439873048817,
      "learning_rate": 2.4368846450102584e-06,
      "loss": 0.5237,
      "step": 9797
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.9130287951993223,
      "learning_rate": 2.43591789471829e-06,
      "loss": 0.4917,
      "step": 9798
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.9256458581692781,
      "learning_rate": 2.4349512744682043e-06,
      "loss": 0.5272,
      "step": 9799
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.95342762414601,
      "learning_rate": 2.4339847843090275e-06,
      "loss": 0.5169,
      "step": 9800
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.9402349154029728,
      "learning_rate": 2.4330184242897786e-06,
      "loss": 0.5051,
      "step": 9801
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.974940156609332,
      "learning_rate": 2.4320521944594645e-06,
      "loss": 0.4819,
      "step": 9802
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.2012703208745443,
      "learning_rate": 2.431086094867093e-06,
      "loss": 0.5086,
      "step": 9803
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.651929067778787,
      "learning_rate": 2.4301201255616556e-06,
      "loss": 0.4505,
      "step": 9804
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.1596898385083962,
      "learning_rate": 2.4291542865921514e-06,
      "loss": 0.5571,
      "step": 9805
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.1350872354951917,
      "learning_rate": 2.4281885780075583e-06,
      "loss": 0.506,
      "step": 9806
    },
    {
      "epoch": 0.68,
      "grad_norm": 5.961611447298915,
      "learning_rate": 2.4272229998568576e-06,
      "loss": 0.4634,
      "step": 9807
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.3502071999119054,
      "learning_rate": 2.4262575521890147e-06,
      "loss": 0.5037,
      "step": 9808
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.6427391051681797,
      "learning_rate": 2.4252922350530024e-06,
      "loss": 0.4974,
      "step": 9809
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.000497243510602,
      "learning_rate": 2.424327048497771e-06,
      "loss": 0.4758,
      "step": 9810
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.224005587319741,
      "learning_rate": 2.423361992572277e-06,
      "loss": 0.5493,
      "step": 9811
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.123954838739019,
      "learning_rate": 2.4223970673254605e-06,
      "loss": 0.4608,
      "step": 9812
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.89644393001959,
      "learning_rate": 2.421432272806261e-06,
      "loss": 0.4579,
      "step": 9813
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.8898902584268358,
      "learning_rate": 2.4204676090636127e-06,
      "loss": 0.4594,
      "step": 9814
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.9119717069299658,
      "learning_rate": 2.419503076146435e-06,
      "loss": 0.4799,
      "step": 9815
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.0159592285888057,
      "learning_rate": 2.418538674103648e-06,
      "loss": 0.4865,
      "step": 9816
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.3507577354469906,
      "learning_rate": 2.4175744029841642e-06,
      "loss": 0.4746,
      "step": 9817
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.150194930206841,
      "learning_rate": 2.4166102628368893e-06,
      "loss": 0.4896,
      "step": 9818
    },
    {
      "epoch": 0.68,
      "grad_norm": 7.731323046288718,
      "learning_rate": 2.415646253710717e-06,
      "loss": 0.5131,
      "step": 9819
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.08462389256033,
      "learning_rate": 2.414682375654542e-06,
      "loss": 0.4987,
      "step": 9820
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.07199402184845,
      "learning_rate": 2.4137186287172494e-06,
      "loss": 0.4565,
      "step": 9821
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.4542107736000083,
      "learning_rate": 2.4127550129477145e-06,
      "loss": 0.4845,
      "step": 9822
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.6045875260051488,
      "learning_rate": 2.4117915283948106e-06,
      "loss": 0.5312,
      "step": 9823
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.3766249400878303,
      "learning_rate": 2.4108281751074026e-06,
      "loss": 0.4459,
      "step": 9824
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.227878762982493,
      "learning_rate": 2.40986495313435e-06,
      "loss": 0.4725,
      "step": 9825
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.6761836034787079,
      "learning_rate": 2.4089018625245007e-06,
      "loss": 0.5035,
      "step": 9826
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.5779806045290034,
      "learning_rate": 2.4079389033267036e-06,
      "loss": 0.4161,
      "step": 9827
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.0378736998306533,
      "learning_rate": 2.406976075589791e-06,
      "loss": 0.5207,
      "step": 9828
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.00304511261869,
      "learning_rate": 2.406013379362601e-06,
      "loss": 0.5378,
      "step": 9829
    },
    {
      "epoch": 0.68,
      "grad_norm": 3.0093249073152175,
      "learning_rate": 2.4050508146939543e-06,
      "loss": 0.4897,
      "step": 9830
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.112984242794389,
      "learning_rate": 2.4040883816326727e-06,
      "loss": 0.5012,
      "step": 9831
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.0847089094129143,
      "learning_rate": 2.4031260802275623e-06,
      "loss": 0.4664,
      "step": 9832
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.166992782190694,
      "learning_rate": 2.4021639105274315e-06,
      "loss": 0.4774,
      "step": 9833
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.69454510533416,
      "learning_rate": 2.4012018725810794e-06,
      "loss": 0.4794,
      "step": 9834
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.9142013702297098,
      "learning_rate": 2.4002399664372937e-06,
      "loss": 0.5194,
      "step": 9835
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.0883306748253747,
      "learning_rate": 2.3992781921448614e-06,
      "loss": 0.5023,
      "step": 9836
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.6914811269970622,
      "learning_rate": 2.39831654975256e-06,
      "loss": 0.4898,
      "step": 9837
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.800121526422639,
      "learning_rate": 2.397355039309164e-06,
      "loss": 0.4815,
      "step": 9838
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.6610187522232713,
      "learning_rate": 2.396393660863431e-06,
      "loss": 0.4681,
      "step": 9839
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.8540589946845438,
      "learning_rate": 2.3954324144641266e-06,
      "loss": 0.4593,
      "step": 9840
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.6889771591275107,
      "learning_rate": 2.394471300159997e-06,
      "loss": 0.4659,
      "step": 9841
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.1470452386821646,
      "learning_rate": 2.3935103179997908e-06,
      "loss": 0.5071,
      "step": 9842
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.0929203807981707,
      "learning_rate": 2.392549468032242e-06,
      "loss": 0.4661,
      "step": 9843
    },
    {
      "epoch": 0.68,
      "grad_norm": 3.0403238567775643,
      "learning_rate": 2.391588750306083e-06,
      "loss": 0.4903,
      "step": 9844
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.7210438805683916,
      "learning_rate": 2.3906281648700406e-06,
      "loss": 0.4769,
      "step": 9845
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.82105103510445,
      "learning_rate": 2.389667711772829e-06,
      "loss": 0.476,
      "step": 9846
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.014497766700057,
      "learning_rate": 2.38870739106316e-06,
      "loss": 0.4753,
      "step": 9847
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.0960192855933855,
      "learning_rate": 2.3877472027897396e-06,
      "loss": 0.5682,
      "step": 9848
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.087163192381553,
      "learning_rate": 2.3867871470012666e-06,
      "loss": 0.5133,
      "step": 9849
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.587997370533442,
      "learning_rate": 2.385827223746428e-06,
      "loss": 0.4063,
      "step": 9850
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.5571418233534369,
      "learning_rate": 2.3848674330739097e-06,
      "loss": 0.4814,
      "step": 9851
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.4264047540582157,
      "learning_rate": 2.383907775032389e-06,
      "loss": 0.4997,
      "step": 9852
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.7823323614047708,
      "learning_rate": 2.3829482496705398e-06,
      "loss": 0.4735,
      "step": 9853
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.3003408062499986,
      "learning_rate": 2.3819888570370208e-06,
      "loss": 0.5208,
      "step": 9854
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.013962709429893,
      "learning_rate": 2.381029597180492e-06,
      "loss": 0.4861,
      "step": 9855
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.7827903778796068,
      "learning_rate": 2.380070470149605e-06,
      "loss": 0.4726,
      "step": 9856
    },
    {
      "epoch": 0.69,
      "grad_norm": 3.2301968267112957,
      "learning_rate": 2.3791114759930013e-06,
      "loss": 0.4885,
      "step": 9857
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.984385981692817,
      "learning_rate": 2.3781526147593204e-06,
      "loss": 0.5435,
      "step": 9858
    },
    {
      "epoch": 0.69,
      "grad_norm": 5.22472892718846,
      "learning_rate": 2.377193886497187e-06,
      "loss": 0.4658,
      "step": 9859
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.797921029651783,
      "learning_rate": 2.3762352912552335e-06,
      "loss": 0.4967,
      "step": 9860
    },
    {
      "epoch": 0.69,
      "grad_norm": 8.899221639072257,
      "learning_rate": 2.3752768290820695e-06,
      "loss": 0.4806,
      "step": 9861
    },
    {
      "epoch": 0.69,
      "grad_norm": 5.178166298751946,
      "learning_rate": 2.3743185000263097e-06,
      "loss": 0.4954,
      "step": 9862
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.0933990282908224,
      "learning_rate": 2.3733603041365515e-06,
      "loss": 0.4929,
      "step": 9863
    },
    {
      "epoch": 0.69,
      "grad_norm": 7.783128707704011,
      "learning_rate": 2.3724022414613995e-06,
      "loss": 0.4676,
      "step": 9864
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.0962711761567117,
      "learning_rate": 2.3714443120494367e-06,
      "loss": 0.5417,
      "step": 9865
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5411946075367594,
      "learning_rate": 2.370486515949251e-06,
      "loss": 0.3989,
      "step": 9866
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.5000584472443337,
      "learning_rate": 2.3695288532094152e-06,
      "loss": 0.4433,
      "step": 9867
    },
    {
      "epoch": 0.69,
      "grad_norm": 8.911158425632191,
      "learning_rate": 2.3685713238784997e-06,
      "loss": 0.4776,
      "step": 9868
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.1906001514152185,
      "learning_rate": 2.3676139280050696e-06,
      "loss": 0.4894,
      "step": 9869
    },
    {
      "epoch": 0.69,
      "grad_norm": 7.892905938987253,
      "learning_rate": 2.3666566656376773e-06,
      "loss": 0.5313,
      "step": 9870
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.5584969693679447,
      "learning_rate": 2.365699536824874e-06,
      "loss": 0.4988,
      "step": 9871
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.1968550953804353,
      "learning_rate": 2.364742541615201e-06,
      "loss": 0.4522,
      "step": 9872
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.0233484400251283,
      "learning_rate": 2.3637856800571975e-06,
      "loss": 0.5454,
      "step": 9873
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.339015069600712,
      "learning_rate": 2.3628289521993874e-06,
      "loss": 0.5063,
      "step": 9874
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.919327325595954,
      "learning_rate": 2.361872358090295e-06,
      "loss": 0.4985,
      "step": 9875
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.07862301830875,
      "learning_rate": 2.3609158977784365e-06,
      "loss": 0.5075,
      "step": 9876
    },
    {
      "epoch": 0.69,
      "grad_norm": 4.345703588894008,
      "learning_rate": 2.3599595713123212e-06,
      "loss": 0.4466,
      "step": 9877
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.8480511718528494,
      "learning_rate": 2.3590033787404478e-06,
      "loss": 0.4915,
      "step": 9878
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.9277880697444565,
      "learning_rate": 2.3580473201113122e-06,
      "loss": 0.4743,
      "step": 9879
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.0490229331894336,
      "learning_rate": 2.357091395473406e-06,
      "loss": 0.4787,
      "step": 9880
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.7365595176262987,
      "learning_rate": 2.3561356048752054e-06,
      "loss": 0.5289,
      "step": 9881
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.6442588304716548,
      "learning_rate": 2.3551799483651894e-06,
      "loss": 0.4656,
      "step": 9882
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.583611579100451,
      "learning_rate": 2.35422442599182e-06,
      "loss": 0.4768,
      "step": 9883
    },
    {
      "epoch": 0.69,
      "grad_norm": 3.023403409386279,
      "learning_rate": 2.353269037803566e-06,
      "loss": 0.4814,
      "step": 9884
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.8814657031708903,
      "learning_rate": 2.3523137838488757e-06,
      "loss": 0.4975,
      "step": 9885
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.597524588853266,
      "learning_rate": 2.3513586641762002e-06,
      "loss": 0.5206,
      "step": 9886
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.181156041186279,
      "learning_rate": 2.3504036788339763e-06,
      "loss": 0.4815,
      "step": 9887
    },
    {
      "epoch": 0.69,
      "grad_norm": 4.2612387698744305,
      "learning_rate": 2.3494488278706394e-06,
      "loss": 0.4794,
      "step": 9888
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.397626901559488,
      "learning_rate": 2.3484941113346186e-06,
      "loss": 0.5061,
      "step": 9889
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.2900507442147098,
      "learning_rate": 2.3475395292743304e-06,
      "loss": 0.4738,
      "step": 9890
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.7736340764794896,
      "learning_rate": 2.3465850817381897e-06,
      "loss": 0.4818,
      "step": 9891
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.2992527977584047,
      "learning_rate": 2.3456307687746026e-06,
      "loss": 0.4767,
      "step": 9892
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.151883821699926,
      "learning_rate": 2.3446765904319717e-06,
      "loss": 0.4488,
      "step": 9893
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.263644513477137,
      "learning_rate": 2.343722546758685e-06,
      "loss": 0.497,
      "step": 9894
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.3248644537260064,
      "learning_rate": 2.3427686378031307e-06,
      "loss": 0.5322,
      "step": 9895
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.895792854761114,
      "learning_rate": 2.3418148636136885e-06,
      "loss": 0.4459,
      "step": 9896
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5987278116638375,
      "learning_rate": 2.340861224238732e-06,
      "loss": 0.4244,
      "step": 9897
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.8314016034462233,
      "learning_rate": 2.3399077197266225e-06,
      "loss": 0.4731,
      "step": 9898
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.829774036005873,
      "learning_rate": 2.338954350125721e-06,
      "loss": 0.4295,
      "step": 9899
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.7088002125387187,
      "learning_rate": 2.338001115484382e-06,
      "loss": 0.4869,
      "step": 9900
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.065231498473689,
      "learning_rate": 2.337048015850946e-06,
      "loss": 0.5178,
      "step": 9901
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.3379456013382938,
      "learning_rate": 2.336095051273754e-06,
      "loss": 0.4937,
      "step": 9902
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.843910374262041,
      "learning_rate": 2.3351422218011327e-06,
      "loss": 0.4936,
      "step": 9903
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.4285616851661787,
      "learning_rate": 2.3341895274814136e-06,
      "loss": 0.4753,
      "step": 9904
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.4109733884300404,
      "learning_rate": 2.333236968362909e-06,
      "loss": 0.464,
      "step": 9905
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.716838419645066,
      "learning_rate": 2.332284544493931e-06,
      "loss": 0.4903,
      "step": 9906
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.912045934878263,
      "learning_rate": 2.331332255922784e-06,
      "loss": 0.4694,
      "step": 9907
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.8302388463909633,
      "learning_rate": 2.3303801026977665e-06,
      "loss": 0.5316,
      "step": 9908
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.7964045672400857,
      "learning_rate": 2.3294280848671643e-06,
      "loss": 0.5037,
      "step": 9909
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.587749631091044,
      "learning_rate": 2.3284762024792636e-06,
      "loss": 0.426,
      "step": 9910
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.7107214645187538,
      "learning_rate": 2.3275244555823415e-06,
      "loss": 0.4845,
      "step": 9911
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.148296194171934,
      "learning_rate": 2.326572844224665e-06,
      "loss": 0.4931,
      "step": 9912
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.067708272874269,
      "learning_rate": 2.3256213684545e-06,
      "loss": 0.4721,
      "step": 9913
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.8741846179842456,
      "learning_rate": 2.3246700283200955e-06,
      "loss": 0.4896,
      "step": 9914
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.360999207955088,
      "learning_rate": 2.3237188238697094e-06,
      "loss": 0.5558,
      "step": 9915
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.1432006298233572,
      "learning_rate": 2.3227677551515783e-06,
      "loss": 0.5196,
      "step": 9916
    },
    {
      "epoch": 0.69,
      "grad_norm": 4.137357140074561,
      "learning_rate": 2.321816822213939e-06,
      "loss": 0.5084,
      "step": 9917
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.105232597472931,
      "learning_rate": 2.320866025105016e-06,
      "loss": 0.4903,
      "step": 9918
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.0647735278898356,
      "learning_rate": 2.3199153638730372e-06,
      "loss": 0.4847,
      "step": 9919
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.1181437305973616,
      "learning_rate": 2.3189648385662118e-06,
      "loss": 0.4754,
      "step": 9920
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.9905278150185564,
      "learning_rate": 2.318014449232751e-06,
      "loss": 0.4758,
      "step": 9921
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.1831763368904213,
      "learning_rate": 2.317064195920852e-06,
      "loss": 0.4793,
      "step": 9922
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.017858890958373,
      "learning_rate": 2.3161140786787095e-06,
      "loss": 0.4919,
      "step": 9923
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.767790082034792,
      "learning_rate": 2.315164097554513e-06,
      "loss": 0.4617,
      "step": 9924
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.654278953349151,
      "learning_rate": 2.314214252596439e-06,
      "loss": 0.4852,
      "step": 9925
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.102520566727728,
      "learning_rate": 2.3132645438526612e-06,
      "loss": 0.5012,
      "step": 9926
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.8224619844407002,
      "learning_rate": 2.3123149713713474e-06,
      "loss": 0.4898,
      "step": 9927
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.0129517635975267,
      "learning_rate": 2.311365535200657e-06,
      "loss": 0.4952,
      "step": 9928
    },
    {
      "epoch": 0.69,
      "grad_norm": 3.484988196754843,
      "learning_rate": 2.3104162353887395e-06,
      "loss": 0.5217,
      "step": 9929
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.8959479778473043,
      "learning_rate": 2.309467071983742e-06,
      "loss": 0.4435,
      "step": 9930
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.916806655729542,
      "learning_rate": 2.308518045033803e-06,
      "loss": 0.5545,
      "step": 9931
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.0383198283458044,
      "learning_rate": 2.307569154587056e-06,
      "loss": 0.4639,
      "step": 9932
    },
    {
      "epoch": 0.69,
      "grad_norm": 4.370780919374625,
      "learning_rate": 2.3066204006916223e-06,
      "loss": 0.5281,
      "step": 9933
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.458243763078365,
      "learning_rate": 2.30567178339562e-06,
      "loss": 0.4512,
      "step": 9934
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.9900448361890948,
      "learning_rate": 2.304723302747163e-06,
      "loss": 0.4857,
      "step": 9935
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.8315367558645885,
      "learning_rate": 2.3037749587943508e-06,
      "loss": 0.4864,
      "step": 9936
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.1354440892456092,
      "learning_rate": 2.302826751585285e-06,
      "loss": 0.5349,
      "step": 9937
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.8590560683431419,
      "learning_rate": 2.3018786811680492e-06,
      "loss": 0.4843,
      "step": 9938
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.8702502255628284,
      "learning_rate": 2.300930747590734e-06,
      "loss": 0.484,
      "step": 9939
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.155802624318997,
      "learning_rate": 2.2999829509014097e-06,
      "loss": 0.503,
      "step": 9940
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.857904488171927,
      "learning_rate": 2.2990352911481496e-06,
      "loss": 0.5001,
      "step": 9941
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.374061973729685,
      "learning_rate": 2.298087768379012e-06,
      "loss": 0.5261,
      "step": 9942
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.3932742861632152,
      "learning_rate": 2.297140382642054e-06,
      "loss": 0.4451,
      "step": 9943
    },
    {
      "epoch": 0.69,
      "grad_norm": 6.4377211169494855,
      "learning_rate": 2.296193133985324e-06,
      "loss": 0.5114,
      "step": 9944
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.042981944395278,
      "learning_rate": 2.295246022456865e-06,
      "loss": 0.5024,
      "step": 9945
    },
    {
      "epoch": 0.69,
      "grad_norm": 6.491122960899703,
      "learning_rate": 2.2942990481047082e-06,
      "loss": 0.4948,
      "step": 9946
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.0550950184890047,
      "learning_rate": 2.2933522109768823e-06,
      "loss": 0.525,
      "step": 9947
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.23643170016778,
      "learning_rate": 2.2924055111214104e-06,
      "loss": 0.4989,
      "step": 9948
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.7735135559159043,
      "learning_rate": 2.2914589485863015e-06,
      "loss": 0.5291,
      "step": 9949
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.0363233395331504,
      "learning_rate": 2.2905125234195648e-06,
      "loss": 0.4863,
      "step": 9950
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.3267310894959055,
      "learning_rate": 2.289566235669199e-06,
      "loss": 0.4795,
      "step": 9951
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.8034717169170553,
      "learning_rate": 2.2886200853831993e-06,
      "loss": 0.5226,
      "step": 9952
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.9206601108473682,
      "learning_rate": 2.287674072609547e-06,
      "loss": 0.4853,
      "step": 9953
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.7297053298270373,
      "learning_rate": 2.286728197396223e-06,
      "loss": 0.4651,
      "step": 9954
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.752724073120187,
      "learning_rate": 2.2857824597912014e-06,
      "loss": 0.4676,
      "step": 9955
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.1601465705004377,
      "learning_rate": 2.2848368598424426e-06,
      "loss": 0.5067,
      "step": 9956
    },
    {
      "epoch": 0.69,
      "grad_norm": 4.05774222557555,
      "learning_rate": 2.283891397597908e-06,
      "loss": 0.5307,
      "step": 9957
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.9915208874034063,
      "learning_rate": 2.282946073105543e-06,
      "loss": 0.5043,
      "step": 9958
    },
    {
      "epoch": 0.69,
      "grad_norm": 3.203481706443972,
      "learning_rate": 2.282000886413299e-06,
      "loss": 0.5086,
      "step": 9959
    },
    {
      "epoch": 0.69,
      "grad_norm": 3.1302978188657153,
      "learning_rate": 2.2810558375691073e-06,
      "loss": 0.4683,
      "step": 9960
    },
    {
      "epoch": 0.69,
      "grad_norm": 3.198525901705066,
      "learning_rate": 2.2801109266209006e-06,
      "loss": 0.5245,
      "step": 9961
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.2225971924354426,
      "learning_rate": 2.2791661536165964e-06,
      "loss": 0.4951,
      "step": 9962
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.086966216959213,
      "learning_rate": 2.278221518604119e-06,
      "loss": 0.4813,
      "step": 9963
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.9597364020101267,
      "learning_rate": 2.27727702163137e-06,
      "loss": 0.4317,
      "step": 9964
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.202156468669087,
      "learning_rate": 2.276332662746256e-06,
      "loss": 0.5,
      "step": 9965
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.9856763152869477,
      "learning_rate": 2.2753884419966683e-06,
      "loss": 0.5113,
      "step": 9966
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.58434419494454,
      "learning_rate": 2.2744443594304955e-06,
      "loss": 0.4655,
      "step": 9967
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.122947939779071,
      "learning_rate": 2.273500415095621e-06,
      "loss": 0.5223,
      "step": 9968
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.7950380530063457,
      "learning_rate": 2.2725566090399127e-06,
      "loss": 0.4428,
      "step": 9969
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.3273235495167373,
      "learning_rate": 2.2716129413112455e-06,
      "loss": 0.5084,
      "step": 9970
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.069538399772346,
      "learning_rate": 2.2706694119574723e-06,
      "loss": 0.5077,
      "step": 9971
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5996731659113597,
      "learning_rate": 2.2697260210264506e-06,
      "loss": 0.4125,
      "step": 9972
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.1635620757111353,
      "learning_rate": 2.2687827685660195e-06,
      "loss": 0.4775,
      "step": 9973
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.1802288785937347,
      "learning_rate": 2.2678396546240267e-06,
      "loss": 0.5165,
      "step": 9974
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.7451098853159828,
      "learning_rate": 2.2668966792482973e-06,
      "loss": 0.4521,
      "step": 9975
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.6416453052995323,
      "learning_rate": 2.2659538424866594e-06,
      "loss": 0.4925,
      "step": 9976
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.1479751669551557,
      "learning_rate": 2.2650111443869277e-06,
      "loss": 0.4891,
      "step": 9977
    },
    {
      "epoch": 0.69,
      "grad_norm": 5.624113639391662,
      "learning_rate": 2.2640685849969133e-06,
      "loss": 0.4825,
      "step": 9978
    },
    {
      "epoch": 0.69,
      "grad_norm": 3.1687143356617056,
      "learning_rate": 2.2631261643644237e-06,
      "loss": 0.4745,
      "step": 9979
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.810617304668214,
      "learning_rate": 2.2621838825372496e-06,
      "loss": 0.5492,
      "step": 9980
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.832951152333718,
      "learning_rate": 2.2612417395631837e-06,
      "loss": 0.4591,
      "step": 9981
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.7857390881151134,
      "learning_rate": 2.2602997354900075e-06,
      "loss": 0.4713,
      "step": 9982
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.053649037020694,
      "learning_rate": 2.2593578703654987e-06,
      "loss": 0.5019,
      "step": 9983
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.8429954016517753,
      "learning_rate": 2.258416144237422e-06,
      "loss": 0.4964,
      "step": 9984
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.8876511113764955,
      "learning_rate": 2.25747455715354e-06,
      "loss": 0.4871,
      "step": 9985
    },
    {
      "epoch": 0.69,
      "grad_norm": 10.077398008505103,
      "learning_rate": 2.2565331091616076e-06,
      "loss": 0.472,
      "step": 9986
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.432122720315491,
      "learning_rate": 2.2555918003093737e-06,
      "loss": 0.504,
      "step": 9987
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.601408219801205,
      "learning_rate": 2.2546506306445748e-06,
      "loss": 0.452,
      "step": 9988
    },
    {
      "epoch": 0.69,
      "grad_norm": 4.880920403592789,
      "learning_rate": 2.253709600214945e-06,
      "loss": 0.4912,
      "step": 9989
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.220954779026602,
      "learning_rate": 2.2527687090682126e-06,
      "loss": 0.4984,
      "step": 9990
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.508566544923929,
      "learning_rate": 2.2518279572520934e-06,
      "loss": 0.4812,
      "step": 9991
    },
    {
      "epoch": 0.69,
      "grad_norm": 3.1949801594091483,
      "learning_rate": 2.2508873448143025e-06,
      "loss": 0.4914,
      "step": 9992
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.1314193361496816,
      "learning_rate": 2.2499468718025384e-06,
      "loss": 0.4805,
      "step": 9993
    },
    {
      "epoch": 0.69,
      "grad_norm": 3.1760913288500605,
      "learning_rate": 2.2490065382645083e-06,
      "loss": 0.4481,
      "step": 9994
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.5539724682125945,
      "learning_rate": 2.2480663442478952e-06,
      "loss": 0.4148,
      "step": 9995
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.3495716444509576,
      "learning_rate": 2.247126289800387e-06,
      "loss": 0.537,
      "step": 9996
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.0623858972214544,
      "learning_rate": 2.246186374969655e-06,
      "loss": 0.4985,
      "step": 9997
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.9787732658798562,
      "learning_rate": 2.245246599803376e-06,
      "loss": 0.4716,
      "step": 9998
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.917783328160719,
      "learning_rate": 2.244306964349206e-06,
      "loss": 0.491,
      "step": 9999
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.295253980337545,
      "learning_rate": 2.2433674686548053e-06,
      "loss": 0.4878,
      "step": 10000
    },
    {
      "epoch": 0.7,
      "grad_norm": 5.28230802616477,
      "learning_rate": 2.2424281127678166e-06,
      "loss": 0.4859,
      "step": 10001
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.684160252357245,
      "learning_rate": 2.2414888967358844e-06,
      "loss": 0.4624,
      "step": 10002
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.9245474331089187,
      "learning_rate": 2.240549820606644e-06,
      "loss": 0.4388,
      "step": 10003
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.73664844232005,
      "learning_rate": 2.239610884427719e-06,
      "loss": 0.46,
      "step": 10004
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.3735828509179657,
      "learning_rate": 2.23867208824673e-06,
      "loss": 0.4607,
      "step": 10005
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.89746791787398,
      "learning_rate": 2.2377334321112903e-06,
      "loss": 0.4652,
      "step": 10006
    },
    {
      "epoch": 0.7,
      "grad_norm": 4.298780940655808,
      "learning_rate": 2.236794916069007e-06,
      "loss": 0.5146,
      "step": 10007
    },
    {
      "epoch": 0.7,
      "grad_norm": 4.505322278147085,
      "learning_rate": 2.2358565401674753e-06,
      "loss": 0.4684,
      "step": 10008
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.3650987333696514,
      "learning_rate": 2.2349183044542882e-06,
      "loss": 0.5231,
      "step": 10009
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.8007712532759241,
      "learning_rate": 2.2339802089770325e-06,
      "loss": 0.557,
      "step": 10010
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.8918763775393117,
      "learning_rate": 2.23304225378328e-06,
      "loss": 0.4797,
      "step": 10011
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.6611989597648493,
      "learning_rate": 2.232104438920604e-06,
      "loss": 0.4271,
      "step": 10012
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.6027693008015377,
      "learning_rate": 2.2311667644365676e-06,
      "loss": 0.3957,
      "step": 10013
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.9634420536756,
      "learning_rate": 2.2302292303787277e-06,
      "loss": 0.5043,
      "step": 10014
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.1572949134635113,
      "learning_rate": 2.2292918367946287e-06,
      "loss": 0.4894,
      "step": 10015
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.7564895419131168,
      "learning_rate": 2.2283545837318172e-06,
      "loss": 0.5294,
      "step": 10016
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.8113756185579517,
      "learning_rate": 2.227417471237821e-06,
      "loss": 0.4872,
      "step": 10017
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.5525543246066196,
      "learning_rate": 2.2264804993601752e-06,
      "loss": 0.4143,
      "step": 10018
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.7909392170952014,
      "learning_rate": 2.225543668146395e-06,
      "loss": 0.483,
      "step": 10019
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.7891873915254393,
      "learning_rate": 2.224606977643996e-06,
      "loss": 0.5031,
      "step": 10020
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.8658898013322276,
      "learning_rate": 2.223670427900481e-06,
      "loss": 0.5102,
      "step": 10021
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.3125226212024432,
      "learning_rate": 2.2227340189633508e-06,
      "loss": 0.4729,
      "step": 10022
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.107860903365291,
      "learning_rate": 2.2217977508800987e-06,
      "loss": 0.4776,
      "step": 10023
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.015604140922189,
      "learning_rate": 2.220861623698205e-06,
      "loss": 0.5344,
      "step": 10024
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.8946396478706742,
      "learning_rate": 2.219925637465149e-06,
      "loss": 0.4995,
      "step": 10025
    },
    {
      "epoch": 0.7,
      "grad_norm": 5.624200087878183,
      "learning_rate": 2.2189897922284017e-06,
      "loss": 0.4957,
      "step": 10026
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.6770284342427793,
      "learning_rate": 2.2180540880354275e-06,
      "loss": 0.4561,
      "step": 10027
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.867014587809545,
      "learning_rate": 2.2171185249336774e-06,
      "loss": 0.5729,
      "step": 10028
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.6574282788752632,
      "learning_rate": 2.216183102970604e-06,
      "loss": 0.5126,
      "step": 10029
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.5951867352652958,
      "learning_rate": 2.2152478221936474e-06,
      "loss": 0.4844,
      "step": 10030
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.7925212170161506,
      "learning_rate": 2.214312682650244e-06,
      "loss": 0.4678,
      "step": 10031
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.921838820609647,
      "learning_rate": 2.2133776843878185e-06,
      "loss": 0.4554,
      "step": 10032
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.032970788484965,
      "learning_rate": 2.2124428274537914e-06,
      "loss": 0.502,
      "step": 10033
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.46485108055079,
      "learning_rate": 2.2115081118955783e-06,
      "loss": 0.5129,
      "step": 10034
    },
    {
      "epoch": 0.7,
      "grad_norm": 3.973055622641219,
      "learning_rate": 2.21057353776058e-06,
      "loss": 0.4579,
      "step": 10035
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.551174322427191,
      "learning_rate": 2.209639105096199e-06,
      "loss": 0.5571,
      "step": 10036
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.5884022735624903,
      "learning_rate": 2.208704813949825e-06,
      "loss": 0.4735,
      "step": 10037
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.8743543158095135,
      "learning_rate": 2.2077706643688445e-06,
      "loss": 0.4779,
      "step": 10038
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.099429047550439,
      "learning_rate": 2.206836656400631e-06,
      "loss": 0.5084,
      "step": 10039
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.7472762555342092,
      "learning_rate": 2.205902790092556e-06,
      "loss": 0.4743,
      "step": 10040
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.1629511755092348,
      "learning_rate": 2.204969065491982e-06,
      "loss": 0.4668,
      "step": 10041
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.7779981620810692,
      "learning_rate": 2.204035482646267e-06,
      "loss": 0.4374,
      "step": 10042
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.9183430358571805,
      "learning_rate": 2.2031020416027544e-06,
      "loss": 0.5064,
      "step": 10043
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.320964151157491,
      "learning_rate": 2.2021687424087884e-06,
      "loss": 0.5029,
      "step": 10044
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.640568364518802,
      "learning_rate": 2.201235585111704e-06,
      "loss": 0.5178,
      "step": 10045
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.7667048678064703,
      "learning_rate": 2.2003025697588244e-06,
      "loss": 0.4707,
      "step": 10046
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.621228528811901,
      "learning_rate": 2.1993696963974726e-06,
      "loss": 0.5077,
      "step": 10047
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.122402306925906,
      "learning_rate": 2.1984369650749554e-06,
      "loss": 0.4285,
      "step": 10048
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.0535744467636325,
      "learning_rate": 2.1975043758385855e-06,
      "loss": 0.4503,
      "step": 10049
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.856532802935505,
      "learning_rate": 2.196571928735656e-06,
      "loss": 0.5339,
      "step": 10050
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.024229650635625,
      "learning_rate": 2.195639623813459e-06,
      "loss": 0.5147,
      "step": 10051
    },
    {
      "epoch": 0.7,
      "grad_norm": 3.0023411701450704,
      "learning_rate": 2.1947074611192747e-06,
      "loss": 0.4642,
      "step": 10052
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.6724922462068028,
      "learning_rate": 2.193775440700386e-06,
      "loss": 0.5088,
      "step": 10053
    },
    {
      "epoch": 0.7,
      "grad_norm": 4.528292847860334,
      "learning_rate": 2.1928435626040563e-06,
      "loss": 0.459,
      "step": 10054
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.2943966857018436,
      "learning_rate": 2.1919118268775503e-06,
      "loss": 0.5161,
      "step": 10055
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.890226212475954,
      "learning_rate": 2.1909802335681203e-06,
      "loss": 0.479,
      "step": 10056
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.3689770467200226,
      "learning_rate": 2.190048782723015e-06,
      "loss": 0.512,
      "step": 10057
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.10506000182218,
      "learning_rate": 2.189117474389476e-06,
      "loss": 0.4938,
      "step": 10058
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.6785272724802986,
      "learning_rate": 2.1881863086147333e-06,
      "loss": 0.4961,
      "step": 10059
    },
    {
      "epoch": 0.7,
      "grad_norm": 3.061560773478131,
      "learning_rate": 2.1872552854460138e-06,
      "loss": 0.47,
      "step": 10060
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.8912371238632413,
      "learning_rate": 2.186324404930536e-06,
      "loss": 0.5056,
      "step": 10061
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.5929182859822169,
      "learning_rate": 2.185393667115513e-06,
      "loss": 0.4153,
      "step": 10062
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.696116416572036,
      "learning_rate": 2.1844630720481452e-06,
      "loss": 0.4856,
      "step": 10063
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.869032861328969,
      "learning_rate": 2.1835326197756317e-06,
      "loss": 0.5205,
      "step": 10064
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.9722558532635623,
      "learning_rate": 2.182602310345161e-06,
      "loss": 0.4819,
      "step": 10065
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.9147439553069296,
      "learning_rate": 2.1816721438039178e-06,
      "loss": 0.4545,
      "step": 10066
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.4580036789692477,
      "learning_rate": 2.1807421201990735e-06,
      "loss": 0.4725,
      "step": 10067
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.3448369216965506,
      "learning_rate": 2.1798122395777975e-06,
      "loss": 0.5009,
      "step": 10068
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.8474245201393389,
      "learning_rate": 2.1788825019872524e-06,
      "loss": 0.4864,
      "step": 10069
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.720791291799827,
      "learning_rate": 2.1779529074745876e-06,
      "loss": 0.4989,
      "step": 10070
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.5365963652843817,
      "learning_rate": 2.1770234560869526e-06,
      "loss": 0.4867,
      "step": 10071
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.5895638124624796,
      "learning_rate": 2.1760941478714807e-06,
      "loss": 0.435,
      "step": 10072
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.152659879129782,
      "learning_rate": 2.175164982875311e-06,
      "loss": 0.5171,
      "step": 10073
    },
    {
      "epoch": 0.7,
      "grad_norm": 5.468131139904164,
      "learning_rate": 2.174235961145562e-06,
      "loss": 0.4487,
      "step": 10074
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.8107606508693879,
      "learning_rate": 2.1733070827293547e-06,
      "loss": 0.4829,
      "step": 10075
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.007455465019234,
      "learning_rate": 2.172378347673794e-06,
      "loss": 0.4978,
      "step": 10076
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.747896310792198,
      "learning_rate": 2.1714497560259854e-06,
      "loss": 0.4999,
      "step": 10077
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.674526047463061,
      "learning_rate": 2.1705213078330253e-06,
      "loss": 0.4707,
      "step": 10078
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.2204864548408096,
      "learning_rate": 2.169593003141998e-06,
      "loss": 0.528,
      "step": 10079
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.999565245674657,
      "learning_rate": 2.1686648419999863e-06,
      "loss": 0.4765,
      "step": 10080
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.0420147611032817,
      "learning_rate": 2.1677368244540624e-06,
      "loss": 0.5084,
      "step": 10081
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.463380997836328,
      "learning_rate": 2.166808950551296e-06,
      "loss": 0.4628,
      "step": 10082
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.9958862780891493,
      "learning_rate": 2.16588122033874e-06,
      "loss": 0.5133,
      "step": 10083
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.883379263594223,
      "learning_rate": 2.164953633863449e-06,
      "loss": 0.5447,
      "step": 10084
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.485689046651817,
      "learning_rate": 2.164026191172467e-06,
      "loss": 0.4543,
      "step": 10085
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.9937142360495839,
      "learning_rate": 2.1630988923128324e-06,
      "loss": 0.5223,
      "step": 10086
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.0819014943229353,
      "learning_rate": 2.1621717373315716e-06,
      "loss": 0.4946,
      "step": 10087
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.5365888432992882,
      "learning_rate": 2.1612447262757088e-06,
      "loss": 0.4841,
      "step": 10088
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.655891030494252,
      "learning_rate": 2.1603178591922595e-06,
      "loss": 0.4704,
      "step": 10089
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.1206945228906315,
      "learning_rate": 2.1593911361282294e-06,
      "loss": 0.5098,
      "step": 10090
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.4587625540811184,
      "learning_rate": 2.158464557130621e-06,
      "loss": 0.5383,
      "step": 10091
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.756541354303348,
      "learning_rate": 2.1575381222464236e-06,
      "loss": 0.505,
      "step": 10092
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.9747899603037222,
      "learning_rate": 2.156611831522629e-06,
      "loss": 0.475,
      "step": 10093
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.7716532606336313,
      "learning_rate": 2.15568568500621e-06,
      "loss": 0.467,
      "step": 10094
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.057483852090311,
      "learning_rate": 2.1547596827441406e-06,
      "loss": 0.4952,
      "step": 10095
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.7650665633348983,
      "learning_rate": 2.1538338247833847e-06,
      "loss": 0.5376,
      "step": 10096
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.6751618541097715,
      "learning_rate": 2.1529081111708987e-06,
      "loss": 0.5301,
      "step": 10097
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.7588508591150631,
      "learning_rate": 2.1519825419536303e-06,
      "loss": 0.4933,
      "step": 10098
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.7718351426937886,
      "learning_rate": 2.151057117178522e-06,
      "loss": 0.5035,
      "step": 10099
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.6030261724754538,
      "learning_rate": 2.1501318368925104e-06,
      "loss": 0.4951,
      "step": 10100
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.526923142107655,
      "learning_rate": 2.1492067011425194e-06,
      "loss": 0.4981,
      "step": 10101
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.8068895051669807,
      "learning_rate": 2.1482817099754714e-06,
      "loss": 0.4484,
      "step": 10102
    },
    {
      "epoch": 0.7,
      "grad_norm": 6.567660913176713,
      "learning_rate": 2.147356863438275e-06,
      "loss": 0.4835,
      "step": 10103
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.0132648518943834,
      "learning_rate": 2.146432161577842e-06,
      "loss": 0.5079,
      "step": 10104
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.7046004247840671,
      "learning_rate": 2.145507604441065e-06,
      "loss": 0.4961,
      "step": 10105
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.5866347052448033,
      "learning_rate": 2.1445831920748373e-06,
      "loss": 0.4149,
      "step": 10106
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.5969884483090682,
      "learning_rate": 2.1436589245260375e-06,
      "loss": 0.4041,
      "step": 10107
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.7196089609636724,
      "learning_rate": 2.142734801841549e-06,
      "loss": 0.4718,
      "step": 10108
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.426421813796009,
      "learning_rate": 2.1418108240682334e-06,
      "loss": 0.4906,
      "step": 10109
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.758183364147307,
      "learning_rate": 2.1408869912529567e-06,
      "loss": 0.4636,
      "step": 10110
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.750140470815865,
      "learning_rate": 2.1399633034425694e-06,
      "loss": 0.4945,
      "step": 10111
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.7567388385434928,
      "learning_rate": 2.139039760683918e-06,
      "loss": 0.5417,
      "step": 10112
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.9922867044837478,
      "learning_rate": 2.1381163630238453e-06,
      "loss": 0.474,
      "step": 10113
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.8477306289849755,
      "learning_rate": 2.137193110509178e-06,
      "loss": 0.463,
      "step": 10114
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.77307737559168,
      "learning_rate": 2.1362700031867436e-06,
      "loss": 0.4799,
      "step": 10115
    },
    {
      "epoch": 0.7,
      "grad_norm": 3.362554884774759,
      "learning_rate": 2.135347041103358e-06,
      "loss": 0.5135,
      "step": 10116
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.9551245638051775,
      "learning_rate": 2.1344242243058327e-06,
      "loss": 0.4911,
      "step": 10117
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.9733372858493123,
      "learning_rate": 2.133501552840967e-06,
      "loss": 0.509,
      "step": 10118
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.047326076772191,
      "learning_rate": 2.132579026755557e-06,
      "loss": 0.4792,
      "step": 10119
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.8202948449811565,
      "learning_rate": 2.1316566460963906e-06,
      "loss": 0.5107,
      "step": 10120
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.352718119632534,
      "learning_rate": 2.130734410910249e-06,
      "loss": 0.4728,
      "step": 10121
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.4861666848815402,
      "learning_rate": 2.1298123212439028e-06,
      "loss": 0.4645,
      "step": 10122
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.9803051810186392,
      "learning_rate": 2.1288903771441178e-06,
      "loss": 0.4694,
      "step": 10123
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.228132269193705,
      "learning_rate": 2.127968578657654e-06,
      "loss": 0.4866,
      "step": 10124
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.752749274356849,
      "learning_rate": 2.127046925831259e-06,
      "loss": 0.4644,
      "step": 10125
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.716643469187416,
      "learning_rate": 2.1261254187116796e-06,
      "loss": 0.443,
      "step": 10126
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.9979149837557957,
      "learning_rate": 2.125204057345646e-06,
      "loss": 0.4944,
      "step": 10127
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.3065811674640835,
      "learning_rate": 2.1242828417798938e-06,
      "loss": 0.4686,
      "step": 10128
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.7669644251449712,
      "learning_rate": 2.123361772061139e-06,
      "loss": 0.4756,
      "step": 10129
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.1071148212321025,
      "learning_rate": 2.122440848236098e-06,
      "loss": 0.484,
      "step": 10130
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.8267728591603976,
      "learning_rate": 2.121520070351474e-06,
      "loss": 0.5151,
      "step": 10131
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.9614601470591722,
      "learning_rate": 2.120599438453968e-06,
      "loss": 0.5152,
      "step": 10132
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.574806046599324,
      "learning_rate": 2.1196789525902707e-06,
      "loss": 0.5428,
      "step": 10133
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.6099658327048759,
      "learning_rate": 2.118758612807069e-06,
      "loss": 0.4169,
      "step": 10134
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.476091735635176,
      "learning_rate": 2.1178384191510344e-06,
      "loss": 0.5116,
      "step": 10135
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.8987718965982006,
      "learning_rate": 2.116918371668839e-06,
      "loss": 0.5021,
      "step": 10136
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.9156631619861415,
      "learning_rate": 2.1159984704071466e-06,
      "loss": 0.4974,
      "step": 10137
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.6958939878582115,
      "learning_rate": 2.1150787154126074e-06,
      "loss": 0.4342,
      "step": 10138
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.0363185354621103,
      "learning_rate": 2.11415910673187e-06,
      "loss": 0.4851,
      "step": 10139
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.9058036748199385,
      "learning_rate": 2.1132396444115748e-06,
      "loss": 0.4842,
      "step": 10140
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.588204840779346,
      "learning_rate": 2.112320328498355e-06,
      "loss": 0.4862,
      "step": 10141
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.9965363558627631,
      "learning_rate": 2.111401159038832e-06,
      "loss": 0.5733,
      "step": 10142
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.9398786364559413,
      "learning_rate": 2.1104821360796253e-06,
      "loss": 0.4885,
      "step": 10143
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.9820645232659335,
      "learning_rate": 2.109563259667346e-06,
      "loss": 0.4578,
      "step": 10144
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.7880922039032239,
      "learning_rate": 2.1086445298485924e-06,
      "loss": 0.4562,
      "step": 10145
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.8265528648506384,
      "learning_rate": 2.107725946669964e-06,
      "loss": 0.4754,
      "step": 10146
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.908293803840032,
      "learning_rate": 2.1068075101780427e-06,
      "loss": 0.4974,
      "step": 10147
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.7390566413853599,
      "learning_rate": 2.105889220419416e-06,
      "loss": 0.4941,
      "step": 10148
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.0896578068157496,
      "learning_rate": 2.104971077440651e-06,
      "loss": 0.4843,
      "step": 10149
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.2551933613100505,
      "learning_rate": 2.1040530812883155e-06,
      "loss": 0.463,
      "step": 10150
    },
    {
      "epoch": 0.71,
      "grad_norm": 3.210547216377064,
      "learning_rate": 2.103135232008963e-06,
      "loss": 0.5053,
      "step": 10151
    },
    {
      "epoch": 0.71,
      "grad_norm": 3.698781759936782,
      "learning_rate": 2.1022175296491516e-06,
      "loss": 0.5085,
      "step": 10152
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.7889216845539093,
      "learning_rate": 2.101299974255417e-06,
      "loss": 0.4868,
      "step": 10153
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.7564480660652277,
      "learning_rate": 2.1003825658743e-06,
      "loss": 0.4719,
      "step": 10154
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.3094498042177523,
      "learning_rate": 2.099465304552324e-06,
      "loss": 0.4873,
      "step": 10155
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.6775785393469564,
      "learning_rate": 2.098548190336011e-06,
      "loss": 0.5137,
      "step": 10156
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.400181709803018,
      "learning_rate": 2.0976312232718763e-06,
      "loss": 0.4323,
      "step": 10157
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.9951750300174806,
      "learning_rate": 2.0967144034064225e-06,
      "loss": 0.5095,
      "step": 10158
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.618243200457048,
      "learning_rate": 2.095797730786149e-06,
      "loss": 0.4728,
      "step": 10159
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.9851864903511551,
      "learning_rate": 2.0948812054575456e-06,
      "loss": 0.4991,
      "step": 10160
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.6669081408866888,
      "learning_rate": 2.093964827467098e-06,
      "loss": 0.5205,
      "step": 10161
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.9968599764689023,
      "learning_rate": 2.0930485968612773e-06,
      "loss": 0.5156,
      "step": 10162
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.8950760509049822,
      "learning_rate": 2.092132513686558e-06,
      "loss": 0.4748,
      "step": 10163
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.0972643237661415,
      "learning_rate": 2.091216577989395e-06,
      "loss": 0.5071,
      "step": 10164
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.7886370670565501,
      "learning_rate": 2.0903007898162466e-06,
      "loss": 0.4646,
      "step": 10165
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.9876834987814955,
      "learning_rate": 2.0893851492135536e-06,
      "loss": 0.4934,
      "step": 10166
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.6227531604986298,
      "learning_rate": 2.0884696562277566e-06,
      "loss": 0.457,
      "step": 10167
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.0913831811156656,
      "learning_rate": 2.0875543109052887e-06,
      "loss": 0.4883,
      "step": 10168
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.960526450870056,
      "learning_rate": 2.086639113292569e-06,
      "loss": 0.4831,
      "step": 10169
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.6544475907755243,
      "learning_rate": 2.0857240634360152e-06,
      "loss": 0.4675,
      "step": 10170
    },
    {
      "epoch": 0.71,
      "grad_norm": 3.049720714120986,
      "learning_rate": 2.0848091613820364e-06,
      "loss": 0.4596,
      "step": 10171
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.43372710777201,
      "learning_rate": 2.0838944071770343e-06,
      "loss": 0.4643,
      "step": 10172
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.170801884729791,
      "learning_rate": 2.0829798008673992e-06,
      "loss": 0.483,
      "step": 10173
    },
    {
      "epoch": 0.71,
      "grad_norm": 3.558374577297885,
      "learning_rate": 2.082065342499518e-06,
      "loss": 0.4688,
      "step": 10174
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.530132000433372,
      "learning_rate": 2.0811510321197704e-06,
      "loss": 0.5071,
      "step": 10175
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.0073650938783913,
      "learning_rate": 2.080236869774528e-06,
      "loss": 0.467,
      "step": 10176
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.0188684430944956,
      "learning_rate": 2.0793228555101503e-06,
      "loss": 0.4852,
      "step": 10177
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.083208215154636,
      "learning_rate": 2.078408989372996e-06,
      "loss": 0.5375,
      "step": 10178
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.738575020068093,
      "learning_rate": 2.077495271409414e-06,
      "loss": 0.4237,
      "step": 10179
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.9307225384648052,
      "learning_rate": 2.076581701665743e-06,
      "loss": 0.441,
      "step": 10180
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.6207741422180884,
      "learning_rate": 2.0756682801883183e-06,
      "loss": 0.4848,
      "step": 10181
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.49791440399648,
      "learning_rate": 2.074755007023461e-06,
      "loss": 0.4488,
      "step": 10182
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.8138637799443862,
      "learning_rate": 2.0738418822174974e-06,
      "loss": 0.505,
      "step": 10183
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.997603641553672,
      "learning_rate": 2.0729289058167306e-06,
      "loss": 0.469,
      "step": 10184
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.885956326075385,
      "learning_rate": 2.0720160778674693e-06,
      "loss": 0.4917,
      "step": 10185
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.364032950230536,
      "learning_rate": 2.0711033984160035e-06,
      "loss": 0.4745,
      "step": 10186
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.8397184512855205,
      "learning_rate": 2.0701908675086273e-06,
      "loss": 0.5103,
      "step": 10187
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.5094731022211536,
      "learning_rate": 2.0692784851916175e-06,
      "loss": 0.4878,
      "step": 10188
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.6436465904627635,
      "learning_rate": 2.06836625151125e-06,
      "loss": 0.494,
      "step": 10189
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.1897706891436455,
      "learning_rate": 2.0674541665137865e-06,
      "loss": 0.4756,
      "step": 10190
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.530027804259016,
      "learning_rate": 2.0665422302454868e-06,
      "loss": 0.5158,
      "step": 10191
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.6436596956369878,
      "learning_rate": 2.0656304427526043e-06,
      "loss": 0.4923,
      "step": 10192
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.9099279587955118,
      "learning_rate": 2.0647188040813765e-06,
      "loss": 0.5102,
      "step": 10193
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.7528972141997898,
      "learning_rate": 2.0638073142780412e-06,
      "loss": 0.5154,
      "step": 10194
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.8093754635174029,
      "learning_rate": 2.062895973388827e-06,
      "loss": 0.4783,
      "step": 10195
    },
    {
      "epoch": 0.71,
      "grad_norm": 3.4167509269441756,
      "learning_rate": 2.0619847814599555e-06,
      "loss": 0.4881,
      "step": 10196
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.307653882256444,
      "learning_rate": 2.061073738537635e-06,
      "loss": 0.4976,
      "step": 10197
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.539281857724726,
      "learning_rate": 2.060162844668073e-06,
      "loss": 0.5001,
      "step": 10198
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.0684172628713697,
      "learning_rate": 2.059252099897469e-06,
      "loss": 0.4962,
      "step": 10199
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.308511261049621,
      "learning_rate": 2.0583415042720094e-06,
      "loss": 0.5013,
      "step": 10200
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.5611344140268577,
      "learning_rate": 2.0574310578378785e-06,
      "loss": 0.5045,
      "step": 10201
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.9301710461108441,
      "learning_rate": 2.0565207606412514e-06,
      "loss": 0.459,
      "step": 10202
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.245619913237911,
      "learning_rate": 2.055610612728296e-06,
      "loss": 0.4762,
      "step": 10203
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.426354153599022,
      "learning_rate": 2.05470061414517e-06,
      "loss": 0.4415,
      "step": 10204
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.6029659162727251,
      "learning_rate": 2.0537907649380277e-06,
      "loss": 0.4166,
      "step": 10205
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.461688528551511,
      "learning_rate": 2.052881065153009e-06,
      "loss": 0.4811,
      "step": 10206
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.059794386615098,
      "learning_rate": 2.0519715148362585e-06,
      "loss": 0.446,
      "step": 10207
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.0283300571541356,
      "learning_rate": 2.0510621140338997e-06,
      "loss": 0.4947,
      "step": 10208
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.4370334903129125,
      "learning_rate": 2.0501528627920586e-06,
      "loss": 0.4339,
      "step": 10209
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.67800451324627,
      "learning_rate": 2.049243761156845e-06,
      "loss": 0.444,
      "step": 10210
    },
    {
      "epoch": 0.71,
      "grad_norm": 5.048251893744878,
      "learning_rate": 2.0483348091743684e-06,
      "loss": 0.5419,
      "step": 10211
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.8550366980664301,
      "learning_rate": 2.047426006890728e-06,
      "loss": 0.5183,
      "step": 10212
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.8937805422927447,
      "learning_rate": 2.046517354352013e-06,
      "loss": 0.4714,
      "step": 10213
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.844006581429341,
      "learning_rate": 2.0456088516043097e-06,
      "loss": 0.5025,
      "step": 10214
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.600236838120265,
      "learning_rate": 2.0447004986936937e-06,
      "loss": 0.4893,
      "step": 10215
    },
    {
      "epoch": 0.71,
      "grad_norm": 3.6561104156610478,
      "learning_rate": 2.043792295666234e-06,
      "loss": 0.504,
      "step": 10216
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.9226471673197585,
      "learning_rate": 2.042884242567991e-06,
      "loss": 0.5038,
      "step": 10217
    },
    {
      "epoch": 0.71,
      "grad_norm": 3.0847188970623844,
      "learning_rate": 2.0419763394450175e-06,
      "loss": 0.4551,
      "step": 10218
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.9298095795249979,
      "learning_rate": 2.041068586343361e-06,
      "loss": 0.4647,
      "step": 10219
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.7472976711414954,
      "learning_rate": 2.0401609833090603e-06,
      "loss": 0.4882,
      "step": 10220
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.00688901410347,
      "learning_rate": 2.0392535303881434e-06,
      "loss": 0.5217,
      "step": 10221
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.8259315020991724,
      "learning_rate": 2.0383462276266347e-06,
      "loss": 0.4833,
      "step": 10222
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.9132974017347253,
      "learning_rate": 2.037439075070552e-06,
      "loss": 0.4937,
      "step": 10223
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.4921329455180037,
      "learning_rate": 2.036532072765899e-06,
      "loss": 0.4945,
      "step": 10224
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.833203612416093,
      "learning_rate": 2.0356252207586773e-06,
      "loss": 0.518,
      "step": 10225
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.4172757362025745,
      "learning_rate": 2.0347185190948805e-06,
      "loss": 0.4957,
      "step": 10226
    },
    {
      "epoch": 0.71,
      "grad_norm": 8.73270091744793,
      "learning_rate": 2.0338119678204944e-06,
      "loss": 0.4686,
      "step": 10227
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.9308976248012717,
      "learning_rate": 2.0329055669814936e-06,
      "loss": 0.4726,
      "step": 10228
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.8966636291531,
      "learning_rate": 2.031999316623849e-06,
      "loss": 0.508,
      "step": 10229
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.976292804967163,
      "learning_rate": 2.0310932167935228e-06,
      "loss": 0.5034,
      "step": 10230
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.2829608080377897,
      "learning_rate": 2.030187267536471e-06,
      "loss": 0.5362,
      "step": 10231
    },
    {
      "epoch": 0.71,
      "grad_norm": 7.405257376307066,
      "learning_rate": 2.0292814688986375e-06,
      "loss": 0.5363,
      "step": 10232
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.6034488835732029,
      "learning_rate": 2.0283758209259623e-06,
      "loss": 0.4272,
      "step": 10233
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.4167923914613243,
      "learning_rate": 2.0274703236643793e-06,
      "loss": 0.4938,
      "step": 10234
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.8391945264266103,
      "learning_rate": 2.026564977159809e-06,
      "loss": 0.5131,
      "step": 10235
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.252273279766353,
      "learning_rate": 2.0256597814581708e-06,
      "loss": 0.4668,
      "step": 10236
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.9906364175915077,
      "learning_rate": 2.0247547366053683e-06,
      "loss": 0.4759,
      "step": 10237
    },
    {
      "epoch": 0.71,
      "grad_norm": 4.363845696812147,
      "learning_rate": 2.0238498426473087e-06,
      "loss": 0.5278,
      "step": 10238
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.6634851045611037,
      "learning_rate": 2.0229450996298803e-06,
      "loss": 0.4806,
      "step": 10239
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.0486766264822647,
      "learning_rate": 2.0220405075989734e-06,
      "loss": 0.4789,
      "step": 10240
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.0039162068201035,
      "learning_rate": 2.0211360666004593e-06,
      "loss": 0.4961,
      "step": 10241
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.49450075139346,
      "learning_rate": 2.0202317766802155e-06,
      "loss": 0.4283,
      "step": 10242
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.0048223742837203,
      "learning_rate": 2.0193276378840996e-06,
      "loss": 0.5043,
      "step": 10243
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.188339581882882,
      "learning_rate": 2.0184236502579707e-06,
      "loss": 0.4875,
      "step": 10244
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.8821439625559346,
      "learning_rate": 2.0175198138476715e-06,
      "loss": 0.5065,
      "step": 10245
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.6488319311279198,
      "learning_rate": 2.016616128699044e-06,
      "loss": 0.3992,
      "step": 10246
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.133895497270385,
      "learning_rate": 2.015712594857922e-06,
      "loss": 0.5004,
      "step": 10247
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.6581069024314807,
      "learning_rate": 2.0148092123701256e-06,
      "loss": 0.4809,
      "step": 10248
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.3456623616803043,
      "learning_rate": 2.0139059812814744e-06,
      "loss": 0.5045,
      "step": 10249
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.238582143949938,
      "learning_rate": 2.0130029016377763e-06,
      "loss": 0.4905,
      "step": 10250
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.2756506177436133,
      "learning_rate": 2.012099973484834e-06,
      "loss": 0.4736,
      "step": 10251
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.760121842425182,
      "learning_rate": 2.011197196868439e-06,
      "loss": 0.4791,
      "step": 10252
    },
    {
      "epoch": 0.71,
      "grad_norm": 5.4357651882079026,
      "learning_rate": 2.0102945718343774e-06,
      "loss": 0.4457,
      "step": 10253
    },
    {
      "epoch": 0.71,
      "grad_norm": 3.3028204447065823,
      "learning_rate": 2.009392098428429e-06,
      "loss": 0.4992,
      "step": 10254
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.83374614380207,
      "learning_rate": 2.0084897766963645e-06,
      "loss": 0.4547,
      "step": 10255
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.369237380149982,
      "learning_rate": 2.0075876066839437e-06,
      "loss": 0.4528,
      "step": 10256
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.7845753549384447,
      "learning_rate": 2.0066855884369246e-06,
      "loss": 0.5008,
      "step": 10257
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.938745916254877,
      "learning_rate": 2.0057837220010545e-06,
      "loss": 0.4662,
      "step": 10258
    },
    {
      "epoch": 0.71,
      "grad_norm": 6.914019985696445,
      "learning_rate": 2.0048820074220716e-06,
      "loss": 0.4685,
      "step": 10259
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.8925946247004604,
      "learning_rate": 2.0039804447457096e-06,
      "loss": 0.4785,
      "step": 10260
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.6317311450980245,
      "learning_rate": 2.003079034017688e-06,
      "loss": 0.4885,
      "step": 10261
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.179708800178127,
      "learning_rate": 2.002177775283732e-06,
      "loss": 0.4814,
      "step": 10262
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.0098210642468084,
      "learning_rate": 2.001276668589543e-06,
      "loss": 0.4511,
      "step": 10263
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.3429685256351975,
      "learning_rate": 2.000375713980827e-06,
      "loss": 0.4877,
      "step": 10264
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.8050847358115845,
      "learning_rate": 1.9994749115032738e-06,
      "loss": 0.5112,
      "step": 10265
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.4974300463236476,
      "learning_rate": 1.9985742612025704e-06,
      "loss": 0.5337,
      "step": 10266
    },
    {
      "epoch": 0.71,
      "grad_norm": 4.889469939020953,
      "learning_rate": 1.9976737631243975e-06,
      "loss": 0.4888,
      "step": 10267
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.367698317688143,
      "learning_rate": 1.9967734173144217e-06,
      "loss": 0.4943,
      "step": 10268
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.1718459135003916,
      "learning_rate": 1.9958732238183064e-06,
      "loss": 0.5003,
      "step": 10269
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.1133859803700394,
      "learning_rate": 1.9949731826817077e-06,
      "loss": 0.4621,
      "step": 10270
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.851825303873107,
      "learning_rate": 1.9940732939502732e-06,
      "loss": 0.5055,
      "step": 10271
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.1451819639970693,
      "learning_rate": 1.9931735576696405e-06,
      "loss": 0.4639,
      "step": 10272
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.2702503408037993,
      "learning_rate": 1.992273973885441e-06,
      "loss": 0.4913,
      "step": 10273
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.341640705134428,
      "learning_rate": 1.991374542643301e-06,
      "loss": 0.4819,
      "step": 10274
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.370146283081305,
      "learning_rate": 1.990475263988837e-06,
      "loss": 0.4839,
      "step": 10275
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.8604306771665904,
      "learning_rate": 1.9895761379676544e-06,
      "loss": 0.4802,
      "step": 10276
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.842800125867025,
      "learning_rate": 1.988677164625355e-06,
      "loss": 0.4834,
      "step": 10277
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.118658054575395,
      "learning_rate": 1.9877783440075344e-06,
      "loss": 0.4593,
      "step": 10278
    },
    {
      "epoch": 0.71,
      "grad_norm": 3.530262316447127,
      "learning_rate": 1.9868796761597737e-06,
      "loss": 0.5169,
      "step": 10279
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.9263646491562163,
      "learning_rate": 1.985981161127654e-06,
      "loss": 0.4547,
      "step": 10280
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.915473404555088,
      "learning_rate": 1.9850827989567406e-06,
      "loss": 0.5154,
      "step": 10281
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.7394479686466997,
      "learning_rate": 1.9841845896926022e-06,
      "loss": 0.4798,
      "step": 10282
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.1340380284381286,
      "learning_rate": 1.983286533380787e-06,
      "loss": 0.4801,
      "step": 10283
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.250039582345497,
      "learning_rate": 1.982388630066846e-06,
      "loss": 0.4754,
      "step": 10284
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.8926403023224718,
      "learning_rate": 1.981490879796312e-06,
      "loss": 0.4749,
      "step": 10285
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.7591384687702527,
      "learning_rate": 1.980593282614723e-06,
      "loss": 0.5011,
      "step": 10286
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.8986069153085319,
      "learning_rate": 1.979695838567597e-06,
      "loss": 0.5105,
      "step": 10287
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.319987067231883,
      "learning_rate": 1.9787985477004513e-06,
      "loss": 0.4685,
      "step": 10288
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.4980780782119663,
      "learning_rate": 1.9779014100587955e-06,
      "loss": 0.5012,
      "step": 10289
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.7027430526457934,
      "learning_rate": 1.977004425688126e-06,
      "loss": 0.4775,
      "step": 10290
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.5428384770542256,
      "learning_rate": 1.976107594633938e-06,
      "loss": 0.3943,
      "step": 10291
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.5885337725642372,
      "learning_rate": 1.9752109169417113e-06,
      "loss": 0.432,
      "step": 10292
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.2415019414527237,
      "learning_rate": 1.9743143926569287e-06,
      "loss": 0.5012,
      "step": 10293
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.1030107277192664,
      "learning_rate": 1.9734180218250538e-06,
      "loss": 0.4846,
      "step": 10294
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.9193348672427055,
      "learning_rate": 1.972521804491552e-06,
      "loss": 0.4693,
      "step": 10295
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.0880415272540054,
      "learning_rate": 1.97162574070187e-06,
      "loss": 0.4769,
      "step": 10296
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.581364814073945,
      "learning_rate": 1.970729830501461e-06,
      "loss": 0.4783,
      "step": 10297
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.8232292343085474,
      "learning_rate": 1.9698340739357575e-06,
      "loss": 0.5061,
      "step": 10298
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.256615340955819,
      "learning_rate": 1.9689384710501924e-06,
      "loss": 0.4821,
      "step": 10299
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.7993321235563995,
      "learning_rate": 1.9680430218901843e-06,
      "loss": 0.507,
      "step": 10300
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.365849964196769,
      "learning_rate": 1.9671477265011495e-06,
      "loss": 0.4968,
      "step": 10301
    },
    {
      "epoch": 0.72,
      "grad_norm": 18.596442785626223,
      "learning_rate": 1.9662525849284964e-06,
      "loss": 0.4864,
      "step": 10302
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.8909221891280346,
      "learning_rate": 1.96535759721762e-06,
      "loss": 0.4984,
      "step": 10303
    },
    {
      "epoch": 0.72,
      "grad_norm": 3.620164884214329,
      "learning_rate": 1.9644627634139117e-06,
      "loss": 0.4897,
      "step": 10304
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.5687700105512596,
      "learning_rate": 1.963568083562757e-06,
      "loss": 0.4633,
      "step": 10305
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.837584976451731,
      "learning_rate": 1.9626735577095302e-06,
      "loss": 0.5086,
      "step": 10306
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.8156949742032393,
      "learning_rate": 1.961779185899597e-06,
      "loss": 0.4845,
      "step": 10307
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.141788041484579,
      "learning_rate": 1.960884968178319e-06,
      "loss": 0.4792,
      "step": 10308
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.3025208186518515,
      "learning_rate": 1.9599909045910472e-06,
      "loss": 0.4841,
      "step": 10309
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.8163959643149001,
      "learning_rate": 1.9590969951831266e-06,
      "loss": 0.4982,
      "step": 10310
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.154777196750534,
      "learning_rate": 1.958203239999891e-06,
      "loss": 0.4411,
      "step": 10311
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.4223729130509675,
      "learning_rate": 1.9573096390866707e-06,
      "loss": 0.495,
      "step": 10312
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.7573898763060667,
      "learning_rate": 1.9564161924887875e-06,
      "loss": 0.4801,
      "step": 10313
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.5400802448277213,
      "learning_rate": 1.9555229002515504e-06,
      "loss": 0.5274,
      "step": 10314
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.129611389299678,
      "learning_rate": 1.954629762420268e-06,
      "loss": 0.5184,
      "step": 10315
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.6153294783210914,
      "learning_rate": 1.953736779040232e-06,
      "loss": 0.4861,
      "step": 10316
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.7801482083658384,
      "learning_rate": 1.9528439501567385e-06,
      "loss": 0.4676,
      "step": 10317
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.5763188012651193,
      "learning_rate": 1.9519512758150643e-06,
      "loss": 0.418,
      "step": 10318
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.7338178545673593,
      "learning_rate": 1.951058756060486e-06,
      "loss": 0.4374,
      "step": 10319
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.8861178299364498,
      "learning_rate": 1.950166390938265e-06,
      "loss": 0.4598,
      "step": 10320
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.5258012083346814,
      "learning_rate": 1.9492741804936623e-06,
      "loss": 0.42,
      "step": 10321
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.5958849107077024,
      "learning_rate": 1.948382124771927e-06,
      "loss": 0.4148,
      "step": 10322
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.7569167586977157,
      "learning_rate": 1.947490223818303e-06,
      "loss": 0.4849,
      "step": 10323
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.246458787342327,
      "learning_rate": 1.9465984776780215e-06,
      "loss": 0.4833,
      "step": 10324
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.8805150576049798,
      "learning_rate": 1.9457068863963107e-06,
      "loss": 0.4508,
      "step": 10325
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.5899552702833424,
      "learning_rate": 1.9448154500183907e-06,
      "loss": 0.3925,
      "step": 10326
    },
    {
      "epoch": 0.72,
      "grad_norm": 3.45242097485654,
      "learning_rate": 1.943924168589469e-06,
      "loss": 0.481,
      "step": 10327
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.771654282678321,
      "learning_rate": 1.94303304215475e-06,
      "loss": 0.4931,
      "step": 10328
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.057976564912253,
      "learning_rate": 1.9421420707594285e-06,
      "loss": 0.5225,
      "step": 10329
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.9593071188401556,
      "learning_rate": 1.941251254448694e-06,
      "loss": 0.5046,
      "step": 10330
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.3212403694665693,
      "learning_rate": 1.9403605932677223e-06,
      "loss": 0.4763,
      "step": 10331
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.8604149796725253,
      "learning_rate": 1.9394700872616856e-06,
      "loss": 0.498,
      "step": 10332
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.345548223445843,
      "learning_rate": 1.93857973647575e-06,
      "loss": 0.5081,
      "step": 10333
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.9916430693141747,
      "learning_rate": 1.9376895409550685e-06,
      "loss": 0.483,
      "step": 10334
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.824342751910974,
      "learning_rate": 1.936799500744791e-06,
      "loss": 0.4978,
      "step": 10335
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.5841180787591858,
      "learning_rate": 1.9359096158900527e-06,
      "loss": 0.4232,
      "step": 10336
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.239006692000012,
      "learning_rate": 1.9350198864359925e-06,
      "loss": 0.519,
      "step": 10337
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.849726211300385,
      "learning_rate": 1.93413031242773e-06,
      "loss": 0.4303,
      "step": 10338
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.8848584926604706,
      "learning_rate": 1.933240893910384e-06,
      "loss": 0.467,
      "step": 10339
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.9955858862317788,
      "learning_rate": 1.9323516309290583e-06,
      "loss": 0.5015,
      "step": 10340
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.9138030898133724,
      "learning_rate": 1.9314625235288604e-06,
      "loss": 0.4622,
      "step": 10341
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.1472990646670422,
      "learning_rate": 1.930573571754877e-06,
      "loss": 0.4954,
      "step": 10342
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.5366957272420065,
      "learning_rate": 1.9296847756521974e-06,
      "loss": 0.4807,
      "step": 10343
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.7962347060738098,
      "learning_rate": 1.9287961352658948e-06,
      "loss": 0.4799,
      "step": 10344
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.6565933303937386,
      "learning_rate": 1.927907650641039e-06,
      "loss": 0.5158,
      "step": 10345
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.6914877700923787,
      "learning_rate": 1.9270193218226935e-06,
      "loss": 0.4539,
      "step": 10346
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.800847831989828,
      "learning_rate": 1.9261311488559077e-06,
      "loss": 0.5287,
      "step": 10347
    },
    {
      "epoch": 0.72,
      "grad_norm": 3.6405663816263374,
      "learning_rate": 1.9252431317857286e-06,
      "loss": 0.4657,
      "step": 10348
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.98186193726711,
      "learning_rate": 1.9243552706571933e-06,
      "loss": 0.5157,
      "step": 10349
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.0223200199031752,
      "learning_rate": 1.9234675655153334e-06,
      "loss": 0.5407,
      "step": 10350
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.012908552247925,
      "learning_rate": 1.922580016405165e-06,
      "loss": 0.4847,
      "step": 10351
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.1689142830497103,
      "learning_rate": 1.9216926233717087e-06,
      "loss": 0.447,
      "step": 10352
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.9757631953117913,
      "learning_rate": 1.9208053864599653e-06,
      "loss": 0.4706,
      "step": 10353
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.441083178539535,
      "learning_rate": 1.9199183057149355e-06,
      "loss": 0.4969,
      "step": 10354
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.591351691947942,
      "learning_rate": 1.919031381181606e-06,
      "loss": 0.4808,
      "step": 10355
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.8882324736133314,
      "learning_rate": 1.9181446129049598e-06,
      "loss": 0.4754,
      "step": 10356
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.7844825234612367,
      "learning_rate": 1.9172580009299735e-06,
      "loss": 0.5155,
      "step": 10357
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.8469923735069436,
      "learning_rate": 1.916371545301609e-06,
      "loss": 0.4653,
      "step": 10358
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.8373040721395735,
      "learning_rate": 1.915485246064827e-06,
      "loss": 0.4914,
      "step": 10359
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.4412299981815435,
      "learning_rate": 1.9145991032645768e-06,
      "loss": 0.487,
      "step": 10360
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.5915918275305074,
      "learning_rate": 1.9137131169458035e-06,
      "loss": 0.4881,
      "step": 10361
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.8043557138510113,
      "learning_rate": 1.9128272871534363e-06,
      "loss": 0.5242,
      "step": 10362
    },
    {
      "epoch": 0.72,
      "grad_norm": 4.769215385208654,
      "learning_rate": 1.911941613932405e-06,
      "loss": 0.4771,
      "step": 10363
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.3035392859592845,
      "learning_rate": 1.911056097327627e-06,
      "loss": 0.4842,
      "step": 10364
    },
    {
      "epoch": 0.72,
      "grad_norm": 9.604712903192024,
      "learning_rate": 1.9101707373840155e-06,
      "loss": 0.4494,
      "step": 10365
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.6261724377803852,
      "learning_rate": 1.909285534146469e-06,
      "loss": 0.4902,
      "step": 10366
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.678975446696841,
      "learning_rate": 1.908400487659883e-06,
      "loss": 0.466,
      "step": 10367
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.9998506594820487,
      "learning_rate": 1.9075155979691477e-06,
      "loss": 0.4682,
      "step": 10368
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.784761187219538,
      "learning_rate": 1.9066308651191372e-06,
      "loss": 0.4879,
      "step": 10369
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.8266815217468908,
      "learning_rate": 1.9057462891547264e-06,
      "loss": 0.498,
      "step": 10370
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.2195493555939434,
      "learning_rate": 1.9048618701207722e-06,
      "loss": 0.5103,
      "step": 10371
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.457748629768526,
      "learning_rate": 1.9039776080621364e-06,
      "loss": 0.5059,
      "step": 10372
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.2276744274352316,
      "learning_rate": 1.9030935030236613e-06,
      "loss": 0.491,
      "step": 10373
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.7707464560027826,
      "learning_rate": 1.9022095550501884e-06,
      "loss": 0.5123,
      "step": 10374
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.8146071193986288,
      "learning_rate": 1.9013257641865446e-06,
      "loss": 0.4445,
      "step": 10375
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.2114284188835613,
      "learning_rate": 1.9004421304775595e-06,
      "loss": 0.5308,
      "step": 10376
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.2398855985096415,
      "learning_rate": 1.8995586539680422e-06,
      "loss": 0.4432,
      "step": 10377
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.6443144912559862,
      "learning_rate": 1.8986753347028036e-06,
      "loss": 0.4419,
      "step": 10378
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.2899076070511617,
      "learning_rate": 1.8977921727266395e-06,
      "loss": 0.5017,
      "step": 10379
    },
    {
      "epoch": 0.72,
      "grad_norm": 3.240080360591733,
      "learning_rate": 1.8969091680843427e-06,
      "loss": 0.5238,
      "step": 10380
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.7242930236175573,
      "learning_rate": 1.896026320820698e-06,
      "loss": 0.521,
      "step": 10381
    },
    {
      "epoch": 0.72,
      "grad_norm": 4.353085650404778,
      "learning_rate": 1.8951436309804766e-06,
      "loss": 0.4809,
      "step": 10382
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.9509837299422883,
      "learning_rate": 1.8942610986084487e-06,
      "loss": 0.4849,
      "step": 10383
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.7174910078175067,
      "learning_rate": 1.8933787237493717e-06,
      "loss": 0.4941,
      "step": 10384
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.8264109347962063,
      "learning_rate": 1.892496506448e-06,
      "loss": 0.4791,
      "step": 10385
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.6768025073497381,
      "learning_rate": 1.8916144467490727e-06,
      "loss": 0.4354,
      "step": 10386
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.064813181023902,
      "learning_rate": 1.8907325446973263e-06,
      "loss": 0.5186,
      "step": 10387
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.2453657494735824,
      "learning_rate": 1.8898508003374905e-06,
      "loss": 0.5094,
      "step": 10388
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.870964681426288,
      "learning_rate": 1.8889692137142807e-06,
      "loss": 0.4925,
      "step": 10389
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.8889963219504247,
      "learning_rate": 1.8880877848724093e-06,
      "loss": 0.4905,
      "step": 10390
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.5531319169353303,
      "learning_rate": 1.8872065138565808e-06,
      "loss": 0.4134,
      "step": 10391
    },
    {
      "epoch": 0.72,
      "grad_norm": 3.111786018538834,
      "learning_rate": 1.8863254007114912e-06,
      "loss": 0.4752,
      "step": 10392
    },
    {
      "epoch": 0.72,
      "grad_norm": 9.377496573985821,
      "learning_rate": 1.8854444454818238e-06,
      "loss": 0.4681,
      "step": 10393
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.167509611622715,
      "learning_rate": 1.8845636482122626e-06,
      "loss": 0.4945,
      "step": 10394
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.112030169698912,
      "learning_rate": 1.8836830089474723e-06,
      "loss": 0.474,
      "step": 10395
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.453459954678285,
      "learning_rate": 1.8828025277321238e-06,
      "loss": 0.4528,
      "step": 10396
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.249437958171578,
      "learning_rate": 1.8819222046108664e-06,
      "loss": 0.487,
      "step": 10397
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.920115701172961,
      "learning_rate": 1.8810420396283513e-06,
      "loss": 0.5178,
      "step": 10398
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.6719235602373297,
      "learning_rate": 1.8801620328292136e-06,
      "loss": 0.5142,
      "step": 10399
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.8773935126235572,
      "learning_rate": 1.879282184258086e-06,
      "loss": 0.5174,
      "step": 10400
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.7896916056651626,
      "learning_rate": 1.878402493959594e-06,
      "loss": 0.5166,
      "step": 10401
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.8878118573410214,
      "learning_rate": 1.877522961978349e-06,
      "loss": 0.4888,
      "step": 10402
    },
    {
      "epoch": 0.72,
      "grad_norm": 4.505252442717196,
      "learning_rate": 1.8766435883589595e-06,
      "loss": 0.489,
      "step": 10403
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.9274743404539298,
      "learning_rate": 1.875764373146024e-06,
      "loss": 0.5195,
      "step": 10404
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.257636328459611,
      "learning_rate": 1.8748853163841357e-06,
      "loss": 0.4532,
      "step": 10405
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.2658960629596696,
      "learning_rate": 1.8740064181178745e-06,
      "loss": 0.4804,
      "step": 10406
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.9108031253878002,
      "learning_rate": 1.8731276783918162e-06,
      "loss": 0.4598,
      "step": 10407
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.2316805655799836,
      "learning_rate": 1.8722490972505275e-06,
      "loss": 0.5225,
      "step": 10408
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.5344119516208454,
      "learning_rate": 1.8713706747385697e-06,
      "loss": 0.4256,
      "step": 10409
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.8546090017488057,
      "learning_rate": 1.8704924109004895e-06,
      "loss": 0.4833,
      "step": 10410
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.7122556224136904,
      "learning_rate": 1.8696143057808314e-06,
      "loss": 0.4795,
      "step": 10411
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.9641081476750177,
      "learning_rate": 1.868736359424132e-06,
      "loss": 0.4965,
      "step": 10412
    },
    {
      "epoch": 0.72,
      "grad_norm": 3.502083557953602,
      "learning_rate": 1.8678585718749138e-06,
      "loss": 0.482,
      "step": 10413
    },
    {
      "epoch": 0.72,
      "grad_norm": 3.4541937922686508,
      "learning_rate": 1.8669809431776991e-06,
      "loss": 0.5018,
      "step": 10414
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.8730935808827858,
      "learning_rate": 1.8661034733769938e-06,
      "loss": 0.4743,
      "step": 10415
    },
    {
      "epoch": 0.72,
      "grad_norm": 4.266477763861141,
      "learning_rate": 1.8652261625173067e-06,
      "loss": 0.496,
      "step": 10416
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.353341436010036,
      "learning_rate": 1.8643490106431267e-06,
      "loss": 0.4495,
      "step": 10417
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.9322373848461012,
      "learning_rate": 1.8634720177989419e-06,
      "loss": 0.4726,
      "step": 10418
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.1878982042377024,
      "learning_rate": 1.8625951840292312e-06,
      "loss": 0.495,
      "step": 10419
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.125979564456617,
      "learning_rate": 1.8617185093784656e-06,
      "loss": 0.4738,
      "step": 10420
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.074594113773821,
      "learning_rate": 1.8608419938911043e-06,
      "loss": 0.4988,
      "step": 10421
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.9153954886758082,
      "learning_rate": 1.8599656376116026e-06,
      "loss": 0.4624,
      "step": 10422
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.9129386065607739,
      "learning_rate": 1.8590894405844084e-06,
      "loss": 0.521,
      "step": 10423
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.6924372613594936,
      "learning_rate": 1.8582134028539561e-06,
      "loss": 0.4606,
      "step": 10424
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.4493218777671224,
      "learning_rate": 1.857337524464679e-06,
      "loss": 0.5106,
      "step": 10425
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.3496917817603884,
      "learning_rate": 1.8564618054609934e-06,
      "loss": 0.454,
      "step": 10426
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.270111085272135,
      "learning_rate": 1.8555862458873202e-06,
      "loss": 0.4994,
      "step": 10427
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.5473634545166473,
      "learning_rate": 1.8547108457880596e-06,
      "loss": 0.5236,
      "step": 10428
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.866780228617053,
      "learning_rate": 1.8538356052076118e-06,
      "loss": 0.5196,
      "step": 10429
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.8150190244613833,
      "learning_rate": 1.852960524190362e-06,
      "loss": 0.5048,
      "step": 10430
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.591410040311463,
      "learning_rate": 1.8520856027806983e-06,
      "loss": 0.5213,
      "step": 10431
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6031234273091134,
      "learning_rate": 1.8512108410229878e-06,
      "loss": 0.4186,
      "step": 10432
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.106864037683174,
      "learning_rate": 1.8503362389615993e-06,
      "loss": 0.4782,
      "step": 10433
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.8387689748429028,
      "learning_rate": 1.8494617966408867e-06,
      "loss": 0.5089,
      "step": 10434
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.6221265951487314,
      "learning_rate": 1.8485875141052006e-06,
      "loss": 0.4996,
      "step": 10435
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.061596318997014,
      "learning_rate": 1.8477133913988838e-06,
      "loss": 0.4596,
      "step": 10436
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.8029107627607637,
      "learning_rate": 1.8468394285662643e-06,
      "loss": 0.5249,
      "step": 10437
    },
    {
      "epoch": 0.73,
      "grad_norm": 4.229907612507517,
      "learning_rate": 1.8459656256516696e-06,
      "loss": 0.5429,
      "step": 10438
    },
    {
      "epoch": 0.73,
      "grad_norm": 3.549957487488899,
      "learning_rate": 1.845091982699415e-06,
      "loss": 0.485,
      "step": 10439
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.9474073368625247,
      "learning_rate": 1.8442184997538116e-06,
      "loss": 0.5056,
      "step": 10440
    },
    {
      "epoch": 0.73,
      "grad_norm": 5.284912451840555,
      "learning_rate": 1.8433451768591554e-06,
      "loss": 0.4525,
      "step": 10441
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.459668056248024,
      "learning_rate": 1.8424720140597407e-06,
      "loss": 0.4862,
      "step": 10442
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.118886917925343,
      "learning_rate": 1.8415990113998516e-06,
      "loss": 0.504,
      "step": 10443
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.947410601357167,
      "learning_rate": 1.8407261689237649e-06,
      "loss": 0.4801,
      "step": 10444
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.6420641585508895,
      "learning_rate": 1.8398534866757455e-06,
      "loss": 0.5077,
      "step": 10445
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.8204865231538068,
      "learning_rate": 1.838980964700055e-06,
      "loss": 0.4727,
      "step": 10446
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.333498775619499,
      "learning_rate": 1.8381086030409462e-06,
      "loss": 0.5205,
      "step": 10447
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.5789801086414988,
      "learning_rate": 1.8372364017426586e-06,
      "loss": 0.4317,
      "step": 10448
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.127685250415984,
      "learning_rate": 1.8363643608494313e-06,
      "loss": 0.5151,
      "step": 10449
    },
    {
      "epoch": 0.73,
      "grad_norm": 3.9618463152809,
      "learning_rate": 1.8354924804054858e-06,
      "loss": 0.4794,
      "step": 10450
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.470115302027617,
      "learning_rate": 1.8346207604550487e-06,
      "loss": 0.4704,
      "step": 10451
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.9994420760420677,
      "learning_rate": 1.8337492010423252e-06,
      "loss": 0.4759,
      "step": 10452
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.982292741161186,
      "learning_rate": 1.8328778022115213e-06,
      "loss": 0.4669,
      "step": 10453
    },
    {
      "epoch": 0.73,
      "grad_norm": 3.72399036207793,
      "learning_rate": 1.832006564006828e-06,
      "loss": 0.4909,
      "step": 10454
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.9153236990132998,
      "learning_rate": 1.8311354864724334e-06,
      "loss": 0.4907,
      "step": 10455
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.9206143378405616,
      "learning_rate": 1.830264569652518e-06,
      "loss": 0.4772,
      "step": 10456
    },
    {
      "epoch": 0.73,
      "grad_norm": 3.1936203648520864,
      "learning_rate": 1.8293938135912475e-06,
      "loss": 0.5211,
      "step": 10457
    },
    {
      "epoch": 0.73,
      "grad_norm": 3.323742269426877,
      "learning_rate": 1.8285232183327862e-06,
      "loss": 0.4705,
      "step": 10458
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.4878326744107295,
      "learning_rate": 1.8276527839212877e-06,
      "loss": 0.4714,
      "step": 10459
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.9179577357073025,
      "learning_rate": 1.8267825104008991e-06,
      "loss": 0.4527,
      "step": 10460
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.8039367742689651,
      "learning_rate": 1.8259123978157551e-06,
      "loss": 0.4877,
      "step": 10461
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.9736611332080511,
      "learning_rate": 1.8250424462099853e-06,
      "loss": 0.4416,
      "step": 10462
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.2242324719207334,
      "learning_rate": 1.8241726556277122e-06,
      "loss": 0.4984,
      "step": 10463
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.009561442222983,
      "learning_rate": 1.8233030261130503e-06,
      "loss": 0.4279,
      "step": 10464
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.9995255142324466,
      "learning_rate": 1.8224335577100999e-06,
      "loss": 0.47,
      "step": 10465
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.341788062030889,
      "learning_rate": 1.8215642504629604e-06,
      "loss": 0.5091,
      "step": 10466
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.6900576842481803,
      "learning_rate": 1.8206951044157212e-06,
      "loss": 0.4818,
      "step": 10467
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.04913543662132,
      "learning_rate": 1.8198261196124596e-06,
      "loss": 0.4723,
      "step": 10468
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.8557316083386837,
      "learning_rate": 1.8189572960972512e-06,
      "loss": 0.4688,
      "step": 10469
    },
    {
      "epoch": 0.73,
      "grad_norm": 4.422758946087424,
      "learning_rate": 1.818088633914154e-06,
      "loss": 0.5312,
      "step": 10470
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.5779374812018975,
      "learning_rate": 1.8172201331072314e-06,
      "loss": 0.3877,
      "step": 10471
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.2505291999908623,
      "learning_rate": 1.8163517937205254e-06,
      "loss": 0.4897,
      "step": 10472
    },
    {
      "epoch": 0.73,
      "grad_norm": 3.4674170972579437,
      "learning_rate": 1.8154836157980793e-06,
      "loss": 0.4465,
      "step": 10473
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.2914340509838254,
      "learning_rate": 1.8146155993839182e-06,
      "loss": 0.5422,
      "step": 10474
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.141429651992676,
      "learning_rate": 1.8137477445220724e-06,
      "loss": 0.4525,
      "step": 10475
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.9355191440054291,
      "learning_rate": 1.8128800512565514e-06,
      "loss": 0.47,
      "step": 10476
    },
    {
      "epoch": 0.73,
      "grad_norm": 3.201010618503068,
      "learning_rate": 1.8120125196313658e-06,
      "loss": 0.4925,
      "step": 10477
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.7932445459446937,
      "learning_rate": 1.8111451496905096e-06,
      "loss": 0.4829,
      "step": 10478
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.336568695560104,
      "learning_rate": 1.8102779414779754e-06,
      "loss": 0.4711,
      "step": 10479
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.9885033033555037,
      "learning_rate": 1.8094108950377466e-06,
      "loss": 0.4736,
      "step": 10480
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.0527362490471073,
      "learning_rate": 1.8085440104137914e-06,
      "loss": 0.4878,
      "step": 10481
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.068901546918302,
      "learning_rate": 1.8076772876500831e-06,
      "loss": 0.4784,
      "step": 10482
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.040054813838691,
      "learning_rate": 1.8068107267905733e-06,
      "loss": 0.523,
      "step": 10483
    },
    {
      "epoch": 0.73,
      "grad_norm": 3.212312301901851,
      "learning_rate": 1.805944327879215e-06,
      "loss": 0.4803,
      "step": 10484
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.5436998882771105,
      "learning_rate": 1.8050780909599435e-06,
      "loss": 0.4055,
      "step": 10485
    },
    {
      "epoch": 0.73,
      "grad_norm": 26.61901417747376,
      "learning_rate": 1.804212016076699e-06,
      "loss": 0.472,
      "step": 10486
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.1034532119777762,
      "learning_rate": 1.8033461032734e-06,
      "loss": 0.4915,
      "step": 10487
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.0926225441405872,
      "learning_rate": 1.8024803525939672e-06,
      "loss": 0.4712,
      "step": 10488
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.8473008216301416,
      "learning_rate": 1.8016147640823039e-06,
      "loss": 0.4759,
      "step": 10489
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.0743262018615503,
      "learning_rate": 1.8007493377823132e-06,
      "loss": 0.4635,
      "step": 10490
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.8807376682072423,
      "learning_rate": 1.799884073737887e-06,
      "loss": 0.4848,
      "step": 10491
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.5611114054978514,
      "learning_rate": 1.7990189719929064e-06,
      "loss": 0.4084,
      "step": 10492
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.803204399287555,
      "learning_rate": 1.7981540325912477e-06,
      "loss": 0.445,
      "step": 10493
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.873618327541045,
      "learning_rate": 1.7972892555767774e-06,
      "loss": 0.4617,
      "step": 10494
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.5245490815419943,
      "learning_rate": 1.7964246409933567e-06,
      "loss": 0.4238,
      "step": 10495
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.664413255932434,
      "learning_rate": 1.7955601888848322e-06,
      "loss": 0.4494,
      "step": 10496
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.2806881742534726,
      "learning_rate": 1.794695899295048e-06,
      "loss": 0.4629,
      "step": 10497
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.477489505846562,
      "learning_rate": 1.7938317722678377e-06,
      "loss": 0.5115,
      "step": 10498
    },
    {
      "epoch": 0.73,
      "grad_norm": 3.146125790726212,
      "learning_rate": 1.7929678078470285e-06,
      "loss": 0.4945,
      "step": 10499
    },
    {
      "epoch": 0.73,
      "grad_norm": 3.3155208444615445,
      "learning_rate": 1.7921040060764355e-06,
      "loss": 0.4625,
      "step": 10500
    },
    {
      "epoch": 0.73,
      "grad_norm": 3.4729518395234944,
      "learning_rate": 1.791240366999869e-06,
      "loss": 0.4961,
      "step": 10501
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.8843924570901176,
      "learning_rate": 1.7903768906611313e-06,
      "loss": 0.4988,
      "step": 10502
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6060079588334499,
      "learning_rate": 1.7895135771040123e-06,
      "loss": 0.4108,
      "step": 10503
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.9064049966479013,
      "learning_rate": 1.7886504263722992e-06,
      "loss": 0.4885,
      "step": 10504
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.8928447986962111,
      "learning_rate": 1.7877874385097637e-06,
      "loss": 0.5004,
      "step": 10505
    },
    {
      "epoch": 0.73,
      "grad_norm": 61.4338059859985,
      "learning_rate": 1.7869246135601804e-06,
      "loss": 0.4842,
      "step": 10506
    },
    {
      "epoch": 0.73,
      "grad_norm": 4.354401333603066,
      "learning_rate": 1.7860619515673034e-06,
      "loss": 0.5287,
      "step": 10507
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.9637096662396258,
      "learning_rate": 1.7851994525748885e-06,
      "loss": 0.489,
      "step": 10508
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.5745604683490124,
      "learning_rate": 1.7843371166266743e-06,
      "loss": 0.4368,
      "step": 10509
    },
    {
      "epoch": 0.73,
      "grad_norm": 3.3358058181287964,
      "learning_rate": 1.7834749437663977e-06,
      "loss": 0.4883,
      "step": 10510
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.2825915577499694,
      "learning_rate": 1.7826129340377857e-06,
      "loss": 0.4696,
      "step": 10511
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.8409583034766763,
      "learning_rate": 1.7817510874845585e-06,
      "loss": 0.4817,
      "step": 10512
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.1874354592457643,
      "learning_rate": 1.7808894041504221e-06,
      "loss": 0.4922,
      "step": 10513
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.5897713559098374,
      "learning_rate": 1.7800278840790803e-06,
      "loss": 0.4687,
      "step": 10514
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.136107250224801,
      "learning_rate": 1.7791665273142277e-06,
      "loss": 0.5049,
      "step": 10515
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.990392050277152,
      "learning_rate": 1.778305333899547e-06,
      "loss": 0.5149,
      "step": 10516
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.5419948113130437,
      "learning_rate": 1.7774443038787164e-06,
      "loss": 0.5142,
      "step": 10517
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.2506579883312967,
      "learning_rate": 1.7765834372954045e-06,
      "loss": 0.5145,
      "step": 10518
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.324978904063798,
      "learning_rate": 1.7757227341932737e-06,
      "loss": 0.4752,
      "step": 10519
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.8111808319665275,
      "learning_rate": 1.7748621946159721e-06,
      "loss": 0.4717,
      "step": 10520
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.378739846181043,
      "learning_rate": 1.7740018186071455e-06,
      "loss": 0.4951,
      "step": 10521
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.015855487063138,
      "learning_rate": 1.773141606210431e-06,
      "loss": 0.4963,
      "step": 10522
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.9217266746453978,
      "learning_rate": 1.7722815574694524e-06,
      "loss": 0.4826,
      "step": 10523
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.884231732808922,
      "learning_rate": 1.771421672427832e-06,
      "loss": 0.4474,
      "step": 10524
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.966897885254117,
      "learning_rate": 1.770561951129175e-06,
      "loss": 0.4653,
      "step": 10525
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.6861229479300306,
      "learning_rate": 1.769702393617091e-06,
      "loss": 0.5111,
      "step": 10526
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.125456056469384,
      "learning_rate": 1.7688429999351681e-06,
      "loss": 0.4874,
      "step": 10527
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.916488846848178,
      "learning_rate": 1.767983770126996e-06,
      "loss": 0.4752,
      "step": 10528
    },
    {
      "epoch": 0.73,
      "grad_norm": 3.165591571289416,
      "learning_rate": 1.7671247042361467e-06,
      "loss": 0.4988,
      "step": 10529
    },
    {
      "epoch": 0.73,
      "grad_norm": 5.137372852953447,
      "learning_rate": 1.7662658023061962e-06,
      "loss": 0.479,
      "step": 10530
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.9693173705844496,
      "learning_rate": 1.7654070643806997e-06,
      "loss": 0.4696,
      "step": 10531
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.3261451206093073,
      "learning_rate": 1.7645484905032129e-06,
      "loss": 0.4711,
      "step": 10532
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.0372149883758253,
      "learning_rate": 1.7636900807172774e-06,
      "loss": 0.5343,
      "step": 10533
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.5968828208385455,
      "learning_rate": 1.7628318350664297e-06,
      "loss": 0.4856,
      "step": 10534
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.087303509027457,
      "learning_rate": 1.7619737535941993e-06,
      "loss": 0.4979,
      "step": 10535
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.751752724710085,
      "learning_rate": 1.7611158363441016e-06,
      "loss": 0.4563,
      "step": 10536
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.1926761432180784,
      "learning_rate": 1.76025808335965e-06,
      "loss": 0.4747,
      "step": 10537
    },
    {
      "epoch": 0.73,
      "grad_norm": 3.616966875223809,
      "learning_rate": 1.7594004946843458e-06,
      "loss": 0.4868,
      "step": 10538
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.8916242937887098,
      "learning_rate": 1.7585430703616851e-06,
      "loss": 0.4509,
      "step": 10539
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.4265501967950276,
      "learning_rate": 1.7576858104351508e-06,
      "loss": 0.499,
      "step": 10540
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.0931956234558777,
      "learning_rate": 1.756828714948221e-06,
      "loss": 0.4886,
      "step": 10541
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.8116071569380363,
      "learning_rate": 1.7559717839443664e-06,
      "loss": 0.4594,
      "step": 10542
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.9759287102006413,
      "learning_rate": 1.7551150174670473e-06,
      "loss": 0.4399,
      "step": 10543
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.9316721904583563,
      "learning_rate": 1.7542584155597148e-06,
      "loss": 0.4576,
      "step": 10544
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.0584471749070725,
      "learning_rate": 1.7534019782658135e-06,
      "loss": 0.4968,
      "step": 10545
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.3194946098814277,
      "learning_rate": 1.752545705628781e-06,
      "loss": 0.4981,
      "step": 10546
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.637889738542134,
      "learning_rate": 1.7516895976920411e-06,
      "loss": 0.5086,
      "step": 10547
    },
    {
      "epoch": 0.73,
      "grad_norm": 3.189941520283183,
      "learning_rate": 1.7508336544990152e-06,
      "loss": 0.4487,
      "step": 10548
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.9408237101844694,
      "learning_rate": 1.749977876093113e-06,
      "loss": 0.5127,
      "step": 10549
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.8355481750961522,
      "learning_rate": 1.749122262517739e-06,
      "loss": 0.5039,
      "step": 10550
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6038313843482954,
      "learning_rate": 1.748266813816284e-06,
      "loss": 0.4111,
      "step": 10551
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.8517837922408489,
      "learning_rate": 1.7474115300321342e-06,
      "loss": 0.4666,
      "step": 10552
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.7287212777974565,
      "learning_rate": 1.746556411208668e-06,
      "loss": 0.489,
      "step": 10553
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.8378183291624084,
      "learning_rate": 1.7457014573892556e-06,
      "loss": 0.5112,
      "step": 10554
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.1129916872813608,
      "learning_rate": 1.7448466686172544e-06,
      "loss": 0.5012,
      "step": 10555
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.6485634681081538,
      "learning_rate": 1.743992044936017e-06,
      "loss": 0.4939,
      "step": 10556
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.9614099250856505,
      "learning_rate": 1.74313758638889e-06,
      "loss": 0.4833,
      "step": 10557
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.0171166100700226,
      "learning_rate": 1.7422832930192047e-06,
      "loss": 0.4455,
      "step": 10558
    },
    {
      "epoch": 0.73,
      "grad_norm": 7.105775639439076,
      "learning_rate": 1.741429164870292e-06,
      "loss": 0.5078,
      "step": 10559
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.290530996521371,
      "learning_rate": 1.7405752019854644e-06,
      "loss": 0.4925,
      "step": 10560
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.9718619028493112,
      "learning_rate": 1.73972140440804e-06,
      "loss": 0.5373,
      "step": 10561
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.2763954907900112,
      "learning_rate": 1.7388677721813158e-06,
      "loss": 0.469,
      "step": 10562
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.329506126081735,
      "learning_rate": 1.7380143053485871e-06,
      "loss": 0.495,
      "step": 10563
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.350332322960203,
      "learning_rate": 1.737161003953135e-06,
      "loss": 0.497,
      "step": 10564
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.7423027971368878,
      "learning_rate": 1.7363078680382429e-06,
      "loss": 0.4844,
      "step": 10565
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.476999603107412,
      "learning_rate": 1.7354548976471742e-06,
      "loss": 0.5013,
      "step": 10566
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.2751735146197682,
      "learning_rate": 1.734602092823191e-06,
      "loss": 0.5655,
      "step": 10567
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.6172464945192693,
      "learning_rate": 1.7337494536095422e-06,
      "loss": 0.4808,
      "step": 10568
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.8860985342263417,
      "learning_rate": 1.7328969800494727e-06,
      "loss": 0.5198,
      "step": 10569
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.4140409957471882,
      "learning_rate": 1.7320446721862189e-06,
      "loss": 0.472,
      "step": 10570
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.7220752087760183,
      "learning_rate": 1.7311925300630034e-06,
      "loss": 0.5066,
      "step": 10571
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.0084240110238682,
      "learning_rate": 1.7303405537230456e-06,
      "loss": 0.4537,
      "step": 10572
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.8507781448661216,
      "learning_rate": 1.7294887432095554e-06,
      "loss": 0.5017,
      "step": 10573
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.7977823164962428,
      "learning_rate": 1.7286370985657352e-06,
      "loss": 0.498,
      "step": 10574
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.9012220025619784,
      "learning_rate": 1.7277856198347747e-06,
      "loss": 0.4777,
      "step": 10575
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.8328628473770263,
      "learning_rate": 1.7269343070598594e-06,
      "loss": 0.4612,
      "step": 10576
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.71979645404151,
      "learning_rate": 1.726083160284167e-06,
      "loss": 0.4833,
      "step": 10577
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.20885684164193,
      "learning_rate": 1.7252321795508615e-06,
      "loss": 0.4745,
      "step": 10578
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.429740879140246,
      "learning_rate": 1.7243813649031033e-06,
      "loss": 0.4527,
      "step": 10579
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.816621906704786,
      "learning_rate": 1.7235307163840432e-06,
      "loss": 0.4706,
      "step": 10580
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.438635645838761,
      "learning_rate": 1.7226802340368249e-06,
      "loss": 0.4767,
      "step": 10581
    },
    {
      "epoch": 0.74,
      "grad_norm": 3.2884968722504535,
      "learning_rate": 1.7218299179045789e-06,
      "loss": 0.4383,
      "step": 10582
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.1731290500376206,
      "learning_rate": 1.7209797680304335e-06,
      "loss": 0.4962,
      "step": 10583
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.431935305443655,
      "learning_rate": 1.7201297844575004e-06,
      "loss": 0.4449,
      "step": 10584
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.102141773468866,
      "learning_rate": 1.7192799672288957e-06,
      "loss": 0.5125,
      "step": 10585
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.8432371462628925,
      "learning_rate": 1.718430316387713e-06,
      "loss": 0.4515,
      "step": 10586
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.015295022910458,
      "learning_rate": 1.7175808319770482e-06,
      "loss": 0.5111,
      "step": 10587
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.5474892782952305,
      "learning_rate": 1.7167315140399804e-06,
      "loss": 0.5108,
      "step": 10588
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.4299429656431006,
      "learning_rate": 1.7158823626195863e-06,
      "loss": 0.4884,
      "step": 10589
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.9285411230898009,
      "learning_rate": 1.715033377758934e-06,
      "loss": 0.473,
      "step": 10590
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.6033868717634723,
      "learning_rate": 1.714184559501077e-06,
      "loss": 0.48,
      "step": 10591
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.543202045171192,
      "learning_rate": 1.7133359078890666e-06,
      "loss": 0.4402,
      "step": 10592
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.417400343661923,
      "learning_rate": 1.712487422965944e-06,
      "loss": 0.4838,
      "step": 10593
    },
    {
      "epoch": 0.74,
      "grad_norm": 3.4636845800142915,
      "learning_rate": 1.7116391047747434e-06,
      "loss": 0.4902,
      "step": 10594
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.5467351687545485,
      "learning_rate": 1.7107909533584844e-06,
      "loss": 0.5353,
      "step": 10595
    },
    {
      "epoch": 0.74,
      "grad_norm": 4.690941946366423,
      "learning_rate": 1.7099429687601853e-06,
      "loss": 0.4607,
      "step": 10596
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.1753929124307776,
      "learning_rate": 1.7090951510228527e-06,
      "loss": 0.4984,
      "step": 10597
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.312735593621663,
      "learning_rate": 1.7082475001894865e-06,
      "loss": 0.4507,
      "step": 10598
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.9102651789176426,
      "learning_rate": 1.7074000163030735e-06,
      "loss": 0.5374,
      "step": 10599
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.861135672842593,
      "learning_rate": 1.7065526994065973e-06,
      "loss": 0.4869,
      "step": 10600
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.0481725202500987,
      "learning_rate": 1.705705549543033e-06,
      "loss": 0.5095,
      "step": 10601
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.7817771401020144,
      "learning_rate": 1.7048585667553414e-06,
      "loss": 0.4327,
      "step": 10602
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.8784720602854166,
      "learning_rate": 1.7040117510864817e-06,
      "loss": 0.4628,
      "step": 10603
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.0417437701958874,
      "learning_rate": 1.7031651025793977e-06,
      "loss": 0.4818,
      "step": 10604
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.9830073084854147,
      "learning_rate": 1.7023186212770343e-06,
      "loss": 0.4941,
      "step": 10605
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.7166913804661548,
      "learning_rate": 1.7014723072223177e-06,
      "loss": 0.4683,
      "step": 10606
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.6920709666549509,
      "learning_rate": 1.7006261604581725e-06,
      "loss": 0.4212,
      "step": 10607
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.154654724731739,
      "learning_rate": 1.699780181027511e-06,
      "loss": 0.4647,
      "step": 10608
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.5971818775156631,
      "learning_rate": 1.6989343689732418e-06,
      "loss": 0.4187,
      "step": 10609
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.3318528290742218,
      "learning_rate": 1.6980887243382572e-06,
      "loss": 0.4878,
      "step": 10610
    },
    {
      "epoch": 0.74,
      "grad_norm": 4.086483557993418,
      "learning_rate": 1.6972432471654477e-06,
      "loss": 0.5094,
      "step": 10611
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.7587573750556997,
      "learning_rate": 1.6963979374976948e-06,
      "loss": 0.476,
      "step": 10612
    },
    {
      "epoch": 0.74,
      "grad_norm": 3.600803291680933,
      "learning_rate": 1.6955527953778666e-06,
      "loss": 0.5354,
      "step": 10613
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.3816746820227492,
      "learning_rate": 1.6947078208488293e-06,
      "loss": 0.4813,
      "step": 10614
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.722722967434155,
      "learning_rate": 1.6938630139534317e-06,
      "loss": 0.4792,
      "step": 10615
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.2036901842894143,
      "learning_rate": 1.693018374734527e-06,
      "loss": 0.5186,
      "step": 10616
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.832820612365868,
      "learning_rate": 1.6921739032349472e-06,
      "loss": 0.4571,
      "step": 10617
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.8584152819398154,
      "learning_rate": 1.6913295994975242e-06,
      "loss": 0.5178,
      "step": 10618
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.171206009623395,
      "learning_rate": 1.6904854635650742e-06,
      "loss": 0.4802,
      "step": 10619
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.8361471063351753,
      "learning_rate": 1.6896414954804152e-06,
      "loss": 0.448,
      "step": 10620
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.6430599712140543,
      "learning_rate": 1.6887976952863455e-06,
      "loss": 0.5241,
      "step": 10621
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.8060565767795904,
      "learning_rate": 1.687954063025663e-06,
      "loss": 0.5084,
      "step": 10622
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.9895877997116016,
      "learning_rate": 1.6871105987411507e-06,
      "loss": 0.4845,
      "step": 10623
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.942171597717001,
      "learning_rate": 1.6862673024755887e-06,
      "loss": 0.4677,
      "step": 10624
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.058734526275546,
      "learning_rate": 1.685424174271747e-06,
      "loss": 0.4737,
      "step": 10625
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.048506629411583,
      "learning_rate": 1.6845812141723839e-06,
      "loss": 0.4878,
      "step": 10626
    },
    {
      "epoch": 0.74,
      "grad_norm": 4.055099169251329,
      "learning_rate": 1.6837384222202518e-06,
      "loss": 0.5155,
      "step": 10627
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.1536557548017226,
      "learning_rate": 1.6828957984580962e-06,
      "loss": 0.4697,
      "step": 10628
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.1925185372938674,
      "learning_rate": 1.6820533429286523e-06,
      "loss": 0.5404,
      "step": 10629
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.2381857434121244,
      "learning_rate": 1.6812110556746447e-06,
      "loss": 0.5102,
      "step": 10630
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.716623140749939,
      "learning_rate": 1.680368936738792e-06,
      "loss": 0.4728,
      "step": 10631
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.7744482745636432,
      "learning_rate": 1.6795269861638041e-06,
      "loss": 0.4881,
      "step": 10632
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.252617155824712,
      "learning_rate": 1.678685203992384e-06,
      "loss": 0.5028,
      "step": 10633
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.1111111282123347,
      "learning_rate": 1.6778435902672207e-06,
      "loss": 0.4526,
      "step": 10634
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.7110223316894613,
      "learning_rate": 1.6770021450309998e-06,
      "loss": 0.4281,
      "step": 10635
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.007920269825644,
      "learning_rate": 1.676160868326398e-06,
      "loss": 0.4771,
      "step": 10636
    },
    {
      "epoch": 0.74,
      "grad_norm": 3.477137267546713,
      "learning_rate": 1.6753197601960786e-06,
      "loss": 0.4718,
      "step": 10637
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.675492398942147,
      "learning_rate": 1.674478820682704e-06,
      "loss": 0.4969,
      "step": 10638
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.0982130705965725,
      "learning_rate": 1.6736380498289185e-06,
      "loss": 0.4906,
      "step": 10639
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.9727686087205392,
      "learning_rate": 1.6727974476773695e-06,
      "loss": 0.4747,
      "step": 10640
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.360777298253321,
      "learning_rate": 1.6719570142706848e-06,
      "loss": 0.5088,
      "step": 10641
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.9126967485538702,
      "learning_rate": 1.6711167496514925e-06,
      "loss": 0.4969,
      "step": 10642
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.9296409993560897,
      "learning_rate": 1.6702766538624039e-06,
      "loss": 0.5179,
      "step": 10643
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.4190112887466833,
      "learning_rate": 1.669436726946028e-06,
      "loss": 0.5497,
      "step": 10644
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.1766984986998628,
      "learning_rate": 1.668596968944965e-06,
      "loss": 0.5089,
      "step": 10645
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.5561907053611246,
      "learning_rate": 1.6677573799018004e-06,
      "loss": 0.4225,
      "step": 10646
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.8283610578951197,
      "learning_rate": 1.6669179598591183e-06,
      "loss": 0.4985,
      "step": 10647
    },
    {
      "epoch": 0.74,
      "grad_norm": 3.292996235332904,
      "learning_rate": 1.666078708859491e-06,
      "loss": 0.5376,
      "step": 10648
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.084134739320404,
      "learning_rate": 1.6652396269454835e-06,
      "loss": 0.5094,
      "step": 10649
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.1543448739976867,
      "learning_rate": 1.6644007141596485e-06,
      "loss": 0.5014,
      "step": 10650
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.7025630983367694,
      "learning_rate": 1.663561970544535e-06,
      "loss": 0.4871,
      "step": 10651
    },
    {
      "epoch": 0.74,
      "grad_norm": 4.393469391688463,
      "learning_rate": 1.662723396142681e-06,
      "loss": 0.4689,
      "step": 10652
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.2329213824262224,
      "learning_rate": 1.6618849909966172e-06,
      "loss": 0.4641,
      "step": 10653
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.92933386673511,
      "learning_rate": 1.661046755148863e-06,
      "loss": 0.5095,
      "step": 10654
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.8752539106606523,
      "learning_rate": 1.660208688641931e-06,
      "loss": 0.5095,
      "step": 10655
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.5971065266182062,
      "learning_rate": 1.6593707915183276e-06,
      "loss": 0.4307,
      "step": 10656
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.5763140249481297,
      "learning_rate": 1.6585330638205454e-06,
      "loss": 0.4123,
      "step": 10657
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.8018768555978593,
      "learning_rate": 1.6576955055910743e-06,
      "loss": 0.4694,
      "step": 10658
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.163493449630093,
      "learning_rate": 1.6568581168723868e-06,
      "loss": 0.4774,
      "step": 10659
    },
    {
      "epoch": 0.74,
      "grad_norm": 4.651437408782754,
      "learning_rate": 1.6560208977069597e-06,
      "loss": 0.5007,
      "step": 10660
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.952650534447713,
      "learning_rate": 1.6551838481372489e-06,
      "loss": 0.5002,
      "step": 10661
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.7818857480469148,
      "learning_rate": 1.6543469682057105e-06,
      "loss": 0.5148,
      "step": 10662
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.7993297075010968,
      "learning_rate": 1.653510257954783e-06,
      "loss": 0.4863,
      "step": 10663
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.006166690191375,
      "learning_rate": 1.6526737174269085e-06,
      "loss": 0.451,
      "step": 10664
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.746459402178977,
      "learning_rate": 1.6518373466645083e-06,
      "loss": 0.4801,
      "step": 10665
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.8669060943328388,
      "learning_rate": 1.651001145710004e-06,
      "loss": 0.4703,
      "step": 10666
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.6099044572581244,
      "learning_rate": 1.6501651146058011e-06,
      "loss": 0.4223,
      "step": 10667
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.7938248854058787,
      "learning_rate": 1.6493292533943033e-06,
      "loss": 0.4464,
      "step": 10668
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.537032300306397,
      "learning_rate": 1.6484935621179033e-06,
      "loss": 0.5022,
      "step": 10669
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.8231210996054195,
      "learning_rate": 1.6476580408189813e-06,
      "loss": 0.506,
      "step": 10670
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.6083611134083906,
      "learning_rate": 1.6468226895399148e-06,
      "loss": 0.4129,
      "step": 10671
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.997722900565204,
      "learning_rate": 1.6459875083230692e-06,
      "loss": 0.5439,
      "step": 10672
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.8813451425432666,
      "learning_rate": 1.6451524972108041e-06,
      "loss": 0.4859,
      "step": 10673
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.32990214673863,
      "learning_rate": 1.6443176562454633e-06,
      "loss": 0.4979,
      "step": 10674
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.227624530400772,
      "learning_rate": 1.6434829854693946e-06,
      "loss": 0.4709,
      "step": 10675
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.8218279787328535,
      "learning_rate": 1.642648484924924e-06,
      "loss": 0.471,
      "step": 10676
    },
    {
      "epoch": 0.74,
      "grad_norm": 4.790344755363051,
      "learning_rate": 1.6418141546543787e-06,
      "loss": 0.478,
      "step": 10677
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.0135581634662953,
      "learning_rate": 1.6409799947000692e-06,
      "loss": 0.4828,
      "step": 10678
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.944854554054754,
      "learning_rate": 1.6401460051043033e-06,
      "loss": 0.4545,
      "step": 10679
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.9798867751087046,
      "learning_rate": 1.6393121859093796e-06,
      "loss": 0.4617,
      "step": 10680
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.8821667126107187,
      "learning_rate": 1.6384785371575846e-06,
      "loss": 0.5224,
      "step": 10681
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.9591260585629486,
      "learning_rate": 1.6376450588911985e-06,
      "loss": 0.4313,
      "step": 10682
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.8737990090154601,
      "learning_rate": 1.6368117511524934e-06,
      "loss": 0.4789,
      "step": 10683
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.3480387128095983,
      "learning_rate": 1.6359786139837325e-06,
      "loss": 0.4797,
      "step": 10684
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.1038394914463376,
      "learning_rate": 1.6351456474271682e-06,
      "loss": 0.5371,
      "step": 10685
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.0363003409545812,
      "learning_rate": 1.6343128515250462e-06,
      "loss": 0.4704,
      "step": 10686
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.7255795414666615,
      "learning_rate": 1.6334802263196037e-06,
      "loss": 0.4921,
      "step": 10687
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.730069222264177,
      "learning_rate": 1.6326477718530704e-06,
      "loss": 0.4741,
      "step": 10688
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.2595392510232473,
      "learning_rate": 1.6318154881676618e-06,
      "loss": 0.4772,
      "step": 10689
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.325874166855226,
      "learning_rate": 1.630983375305591e-06,
      "loss": 0.465,
      "step": 10690
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.0805903923319713,
      "learning_rate": 1.6301514333090618e-06,
      "loss": 0.468,
      "step": 10691
    },
    {
      "epoch": 0.74,
      "grad_norm": 3.192717964149126,
      "learning_rate": 1.6293196622202635e-06,
      "loss": 0.4606,
      "step": 10692
    },
    {
      "epoch": 0.74,
      "grad_norm": 3.8135778137775307,
      "learning_rate": 1.6284880620813847e-06,
      "loss": 0.4945,
      "step": 10693
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.9110022171456085,
      "learning_rate": 1.6276566329345962e-06,
      "loss": 0.4976,
      "step": 10694
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.8416242091381763,
      "learning_rate": 1.626825374822072e-06,
      "loss": 0.5178,
      "step": 10695
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.256202649549621,
      "learning_rate": 1.6259942877859664e-06,
      "loss": 0.5084,
      "step": 10696
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.0688682156632145,
      "learning_rate": 1.6251633718684317e-06,
      "loss": 0.4851,
      "step": 10697
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.662941772301656,
      "learning_rate": 1.6243326271116067e-06,
      "loss": 0.4998,
      "step": 10698
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.928272356770876,
      "learning_rate": 1.6235020535576256e-06,
      "loss": 0.4967,
      "step": 10699
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.8079085152741183,
      "learning_rate": 1.622671651248613e-06,
      "loss": 0.513,
      "step": 10700
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.2446209201229936,
      "learning_rate": 1.6218414202266842e-06,
      "loss": 0.5115,
      "step": 10701
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.188294276775236,
      "learning_rate": 1.6210113605339439e-06,
      "loss": 0.4778,
      "step": 10702
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.1356978246672758,
      "learning_rate": 1.6201814722124914e-06,
      "loss": 0.4797,
      "step": 10703
    },
    {
      "epoch": 0.74,
      "grad_norm": 3.206132107333783,
      "learning_rate": 1.619351755304417e-06,
      "loss": 0.4699,
      "step": 10704
    },
    {
      "epoch": 0.74,
      "grad_norm": 3.5231055675754765,
      "learning_rate": 1.6185222098517988e-06,
      "loss": 0.4743,
      "step": 10705
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.452518343378932,
      "learning_rate": 1.6176928358967099e-06,
      "loss": 0.4914,
      "step": 10706
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.8966844425422955,
      "learning_rate": 1.6168636334812126e-06,
      "loss": 0.4468,
      "step": 10707
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.6268271811462559,
      "learning_rate": 1.6160346026473644e-06,
      "loss": 0.4239,
      "step": 10708
    },
    {
      "epoch": 0.74,
      "grad_norm": 3.271431108618543,
      "learning_rate": 1.6152057434372077e-06,
      "loss": 0.4595,
      "step": 10709
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.9564819606964403,
      "learning_rate": 1.6143770558927795e-06,
      "loss": 0.4873,
      "step": 10710
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.1032762836426184,
      "learning_rate": 1.613548540056112e-06,
      "loss": 0.4663,
      "step": 10711
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.012615845721323,
      "learning_rate": 1.6127201959692195e-06,
      "loss": 0.5065,
      "step": 10712
    },
    {
      "epoch": 0.74,
      "grad_norm": 4.286771104325919,
      "learning_rate": 1.6118920236741175e-06,
      "loss": 0.4873,
      "step": 10713
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.9881723536619413,
      "learning_rate": 1.6110640232128032e-06,
      "loss": 0.4896,
      "step": 10714
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.137950071156203,
      "learning_rate": 1.610236194627276e-06,
      "loss": 0.4942,
      "step": 10715
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.2309950687185975,
      "learning_rate": 1.6094085379595165e-06,
      "loss": 0.5211,
      "step": 10716
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.5316854068092296,
      "learning_rate": 1.6085810532515033e-06,
      "loss": 0.4309,
      "step": 10717
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.237664695947418,
      "learning_rate": 1.6077537405451993e-06,
      "loss": 0.4988,
      "step": 10718
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.9535930642537416,
      "learning_rate": 1.6069265998825694e-06,
      "loss": 0.4486,
      "step": 10719
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.691695301454469,
      "learning_rate": 1.6060996313055589e-06,
      "loss": 0.4645,
      "step": 10720
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.317202094157363,
      "learning_rate": 1.6052728348561115e-06,
      "loss": 0.5041,
      "step": 10721
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.8668433038451093,
      "learning_rate": 1.604446210576157e-06,
      "loss": 0.4561,
      "step": 10722
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.9537775141050062,
      "learning_rate": 1.6036197585076208e-06,
      "loss": 0.4975,
      "step": 10723
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.9201378303502323,
      "learning_rate": 1.6027934786924187e-06,
      "loss": 0.5063,
      "step": 10724
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.2105278210388395,
      "learning_rate": 1.6019673711724548e-06,
      "loss": 0.459,
      "step": 10725
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.456014533308705,
      "learning_rate": 1.6011414359896272e-06,
      "loss": 0.4734,
      "step": 10726
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.0543427840840507,
      "learning_rate": 1.6003156731858254e-06,
      "loss": 0.43,
      "step": 10727
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.0814835581004196,
      "learning_rate": 1.5994900828029302e-06,
      "loss": 0.5037,
      "step": 10728
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.1715802434513045,
      "learning_rate": 1.5986646648828107e-06,
      "loss": 0.5151,
      "step": 10729
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.826844807364315,
      "learning_rate": 1.5978394194673302e-06,
      "loss": 0.4368,
      "step": 10730
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.863424239204669,
      "learning_rate": 1.5970143465983422e-06,
      "loss": 0.4896,
      "step": 10731
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.8355262240320847,
      "learning_rate": 1.5961894463176942e-06,
      "loss": 0.4987,
      "step": 10732
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.7766663308891384,
      "learning_rate": 1.5953647186672188e-06,
      "loss": 0.4792,
      "step": 10733
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.6522346381140078,
      "learning_rate": 1.5945401636887454e-06,
      "loss": 0.5276,
      "step": 10734
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.1179555786314435,
      "learning_rate": 1.5937157814240934e-06,
      "loss": 0.4782,
      "step": 10735
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.149737523985006,
      "learning_rate": 1.5928915719150705e-06,
      "loss": 0.4709,
      "step": 10736
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.6745679138703435,
      "learning_rate": 1.5920675352034792e-06,
      "loss": 0.4929,
      "step": 10737
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.137952842515018,
      "learning_rate": 1.5912436713311124e-06,
      "loss": 0.4532,
      "step": 10738
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.7986254287492227,
      "learning_rate": 1.5904199803397546e-06,
      "loss": 0.512,
      "step": 10739
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.177041308001783,
      "learning_rate": 1.5895964622711785e-06,
      "loss": 0.486,
      "step": 10740
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.8223961195837033,
      "learning_rate": 1.5887731171671504e-06,
      "loss": 0.4828,
      "step": 10741
    },
    {
      "epoch": 0.75,
      "grad_norm": 3.1234856482265085,
      "learning_rate": 1.587949945069429e-06,
      "loss": 0.4876,
      "step": 10742
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.616468212037366,
      "learning_rate": 1.5871269460197642e-06,
      "loss": 0.4116,
      "step": 10743
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.8572389381768244,
      "learning_rate": 1.5863041200598927e-06,
      "loss": 0.5009,
      "step": 10744
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.269318122387378,
      "learning_rate": 1.5854814672315465e-06,
      "loss": 0.4857,
      "step": 10745
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.2621638621883933,
      "learning_rate": 1.58465898757645e-06,
      "loss": 0.4742,
      "step": 10746
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.3714561484208723,
      "learning_rate": 1.5838366811363138e-06,
      "loss": 0.5115,
      "step": 10747
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.6768912105813585,
      "learning_rate": 1.5830145479528448e-06,
      "loss": 0.4984,
      "step": 10748
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6020863749606503,
      "learning_rate": 1.5821925880677348e-06,
      "loss": 0.4396,
      "step": 10749
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.9210635141244015,
      "learning_rate": 1.5813708015226774e-06,
      "loss": 0.4888,
      "step": 10750
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.8098578365034248,
      "learning_rate": 1.580549188359346e-06,
      "loss": 0.4926,
      "step": 10751
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.708945483013259,
      "learning_rate": 1.5797277486194136e-06,
      "loss": 0.5133,
      "step": 10752
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.205048305309944,
      "learning_rate": 1.578906482344535e-06,
      "loss": 0.5124,
      "step": 10753
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.8319421366890114,
      "learning_rate": 1.5780853895763704e-06,
      "loss": 0.5117,
      "step": 10754
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6499791923405026,
      "learning_rate": 1.5772644703565564e-06,
      "loss": 0.4313,
      "step": 10755
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.443938655359856,
      "learning_rate": 1.5764437247267317e-06,
      "loss": 0.4745,
      "step": 10756
    },
    {
      "epoch": 0.75,
      "grad_norm": 4.922441917366897,
      "learning_rate": 1.5756231527285181e-06,
      "loss": 0.4993,
      "step": 10757
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.8244337923479448,
      "learning_rate": 1.5748027544035343e-06,
      "loss": 0.4469,
      "step": 10758
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.9084882169494604,
      "learning_rate": 1.5739825297933892e-06,
      "loss": 0.5145,
      "step": 10759
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.2466090356740622,
      "learning_rate": 1.5731624789396794e-06,
      "loss": 0.5184,
      "step": 10760
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.1800168948550254,
      "learning_rate": 1.5723426018839966e-06,
      "loss": 0.5677,
      "step": 10761
    },
    {
      "epoch": 0.75,
      "grad_norm": 3.644744970748179,
      "learning_rate": 1.571522898667922e-06,
      "loss": 0.465,
      "step": 10762
    },
    {
      "epoch": 0.75,
      "grad_norm": 15.497955318626287,
      "learning_rate": 1.5707033693330304e-06,
      "loss": 0.4787,
      "step": 10763
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.037895429353743,
      "learning_rate": 1.569884013920882e-06,
      "loss": 0.4586,
      "step": 10764
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.522497409323903,
      "learning_rate": 1.5690648324730334e-06,
      "loss": 0.5066,
      "step": 10765
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.818740414001534,
      "learning_rate": 1.568245825031033e-06,
      "loss": 0.4764,
      "step": 10766
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.5722185190843763,
      "learning_rate": 1.5674269916364144e-06,
      "loss": 0.4433,
      "step": 10767
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.1597175464526432,
      "learning_rate": 1.566608332330708e-06,
      "loss": 0.4869,
      "step": 10768
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.1278965639173477,
      "learning_rate": 1.5657898471554333e-06,
      "loss": 0.4364,
      "step": 10769
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.5514264354690224,
      "learning_rate": 1.5649715361521033e-06,
      "loss": 0.5201,
      "step": 10770
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.5242951079941268,
      "learning_rate": 1.564153399362216e-06,
      "loss": 0.4237,
      "step": 10771
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.1808158794379655,
      "learning_rate": 1.563335436827269e-06,
      "loss": 0.4772,
      "step": 10772
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.303707954824006,
      "learning_rate": 1.5625176485887412e-06,
      "loss": 0.4847,
      "step": 10773
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.3002382790952605,
      "learning_rate": 1.5617000346881145e-06,
      "loss": 0.4519,
      "step": 10774
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.1777547461903857,
      "learning_rate": 1.5608825951668505e-06,
      "loss": 0.5042,
      "step": 10775
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.000260509205872,
      "learning_rate": 1.5600653300664115e-06,
      "loss": 0.4986,
      "step": 10776
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.778506751092852,
      "learning_rate": 1.559248239428242e-06,
      "loss": 0.4566,
      "step": 10777
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.1091756165216826,
      "learning_rate": 1.5584313232937843e-06,
      "loss": 0.5322,
      "step": 10778
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.865284199374902,
      "learning_rate": 1.5576145817044714e-06,
      "loss": 0.4675,
      "step": 10779
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.7778947621494947,
      "learning_rate": 1.5567980147017226e-06,
      "loss": 0.482,
      "step": 10780
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.8707593078339444,
      "learning_rate": 1.555981622326953e-06,
      "loss": 0.5253,
      "step": 10781
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.9179398249343274,
      "learning_rate": 1.555165404621567e-06,
      "loss": 0.4689,
      "step": 10782
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.128462196502344,
      "learning_rate": 1.5543493616269629e-06,
      "loss": 0.5034,
      "step": 10783
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.996561601445488,
      "learning_rate": 1.5535334933845242e-06,
      "loss": 0.4777,
      "step": 10784
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.6137826433905704,
      "learning_rate": 1.5527177999356301e-06,
      "loss": 0.5288,
      "step": 10785
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.909447574129769,
      "learning_rate": 1.551902281321651e-06,
      "loss": 0.4576,
      "step": 10786
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.5927026877760668,
      "learning_rate": 1.5510869375839477e-06,
      "loss": 0.4156,
      "step": 10787
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.812396405286334,
      "learning_rate": 1.5502717687638696e-06,
      "loss": 0.4841,
      "step": 10788
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.790133913197806,
      "learning_rate": 1.5494567749027606e-06,
      "loss": 0.4985,
      "step": 10789
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.8807253310806975,
      "learning_rate": 1.5486419560419563e-06,
      "loss": 0.473,
      "step": 10790
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.6675687644795514,
      "learning_rate": 1.5478273122227783e-06,
      "loss": 0.4858,
      "step": 10791
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.123493245709532,
      "learning_rate": 1.5470128434865455e-06,
      "loss": 0.4743,
      "step": 10792
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.4937718375300717,
      "learning_rate": 1.5461985498745614e-06,
      "loss": 0.398,
      "step": 10793
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.0796234152977067,
      "learning_rate": 1.545384431428129e-06,
      "loss": 0.4735,
      "step": 10794
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.153484322339416,
      "learning_rate": 1.5445704881885348e-06,
      "loss": 0.5374,
      "step": 10795
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.0566065239952462,
      "learning_rate": 1.5437567201970616e-06,
      "loss": 0.4538,
      "step": 10796
    },
    {
      "epoch": 0.75,
      "grad_norm": 3.4715521480748133,
      "learning_rate": 1.5429431274949757e-06,
      "loss": 0.4595,
      "step": 10797
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.208336199814371,
      "learning_rate": 1.5421297101235478e-06,
      "loss": 0.4787,
      "step": 10798
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.8212939332427491,
      "learning_rate": 1.5413164681240255e-06,
      "loss": 0.493,
      "step": 10799
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.0927575671875958,
      "learning_rate": 1.5405034015376557e-06,
      "loss": 0.4623,
      "step": 10800
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.109479062389955,
      "learning_rate": 1.539690510405677e-06,
      "loss": 0.4968,
      "step": 10801
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.1771379455328423,
      "learning_rate": 1.538877794769313e-06,
      "loss": 0.5216,
      "step": 10802
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.6403288383000585,
      "learning_rate": 1.5380652546697844e-06,
      "loss": 0.5355,
      "step": 10803
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.736754630510567,
      "learning_rate": 1.5372528901482963e-06,
      "loss": 0.5174,
      "step": 10804
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.7587258343724175,
      "learning_rate": 1.5364407012460558e-06,
      "loss": 0.4808,
      "step": 10805
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.125512633025823,
      "learning_rate": 1.5356286880042492e-06,
      "loss": 0.5261,
      "step": 10806
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.7773313504214308,
      "learning_rate": 1.5348168504640631e-06,
      "loss": 0.489,
      "step": 10807
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.4652553689597845,
      "learning_rate": 1.5340051886666658e-06,
      "loss": 0.4848,
      "step": 10808
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.9131036333911233,
      "learning_rate": 1.5331937026532284e-06,
      "loss": 0.475,
      "step": 10809
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.333187478534762,
      "learning_rate": 1.532382392464903e-06,
      "loss": 0.4903,
      "step": 10810
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.0672977528872516,
      "learning_rate": 1.5315712581428388e-06,
      "loss": 0.4912,
      "step": 10811
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.9487182906029583,
      "learning_rate": 1.5307602997281706e-06,
      "loss": 0.4936,
      "step": 10812
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.0572321897630923,
      "learning_rate": 1.5299495172620304e-06,
      "loss": 0.4411,
      "step": 10813
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.8264695519078498,
      "learning_rate": 1.5291389107855392e-06,
      "loss": 0.4662,
      "step": 10814
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.9486551059853943,
      "learning_rate": 1.5283284803398047e-06,
      "loss": 0.4605,
      "step": 10815
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.9978245376106154,
      "learning_rate": 1.5275182259659315e-06,
      "loss": 0.4801,
      "step": 10816
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6163796022955222,
      "learning_rate": 1.5267081477050132e-06,
      "loss": 0.451,
      "step": 10817
    },
    {
      "epoch": 0.75,
      "grad_norm": 3.695530813756601,
      "learning_rate": 1.5258982455981359e-06,
      "loss": 0.4873,
      "step": 10818
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.968242782831873,
      "learning_rate": 1.5250885196863713e-06,
      "loss": 0.5077,
      "step": 10819
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.5788555343227609,
      "learning_rate": 1.524278970010788e-06,
      "loss": 0.4053,
      "step": 10820
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.1969576180110693,
      "learning_rate": 1.5234695966124441e-06,
      "loss": 0.5044,
      "step": 10821
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.789114454914607,
      "learning_rate": 1.5226603995323897e-06,
      "loss": 0.4475,
      "step": 10822
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.076388625968161,
      "learning_rate": 1.5218513788116617e-06,
      "loss": 0.491,
      "step": 10823
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.39349545926625,
      "learning_rate": 1.521042534491292e-06,
      "loss": 0.5005,
      "step": 10824
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.9442638163937238,
      "learning_rate": 1.5202338666123045e-06,
      "loss": 0.4722,
      "step": 10825
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.006852731007165,
      "learning_rate": 1.519425375215709e-06,
      "loss": 0.5014,
      "step": 10826
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.0751036819221924,
      "learning_rate": 1.5186170603425132e-06,
      "loss": 0.4955,
      "step": 10827
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.118725862169556,
      "learning_rate": 1.517808922033706e-06,
      "loss": 0.5131,
      "step": 10828
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.8385080159304157,
      "learning_rate": 1.5170009603302816e-06,
      "loss": 0.501,
      "step": 10829
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.2118826142190597,
      "learning_rate": 1.5161931752732116e-06,
      "loss": 0.4892,
      "step": 10830
    },
    {
      "epoch": 0.75,
      "grad_norm": 6.487018159562684,
      "learning_rate": 1.5153855669034672e-06,
      "loss": 0.474,
      "step": 10831
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.5256321488154584,
      "learning_rate": 1.5145781352620054e-06,
      "loss": 0.4072,
      "step": 10832
    },
    {
      "epoch": 0.75,
      "grad_norm": 3.0172661276198376,
      "learning_rate": 1.513770880389777e-06,
      "loss": 0.4769,
      "step": 10833
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.0943085637927368,
      "learning_rate": 1.5129638023277255e-06,
      "loss": 0.4763,
      "step": 10834
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.3553075364162988,
      "learning_rate": 1.5121569011167797e-06,
      "loss": 0.454,
      "step": 10835
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.0186401895369737,
      "learning_rate": 1.511350176797865e-06,
      "loss": 0.5127,
      "step": 10836
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.1865159078564496,
      "learning_rate": 1.5105436294118958e-06,
      "loss": 0.4581,
      "step": 10837
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.7590807937744712,
      "learning_rate": 1.5097372589997788e-06,
      "loss": 0.4713,
      "step": 10838
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.0421646033123775,
      "learning_rate": 1.5089310656024075e-06,
      "loss": 0.5176,
      "step": 10839
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.4223703711089244,
      "learning_rate": 1.5081250492606714e-06,
      "loss": 0.5168,
      "step": 10840
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.228875343046295,
      "learning_rate": 1.5073192100154482e-06,
      "loss": 0.5277,
      "step": 10841
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.1388459410505445,
      "learning_rate": 1.5065135479076098e-06,
      "loss": 0.4753,
      "step": 10842
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.2718717947821205,
      "learning_rate": 1.5057080629780129e-06,
      "loss": 0.4992,
      "step": 10843
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.7168203897767653,
      "learning_rate": 1.5049027552675111e-06,
      "loss": 0.5001,
      "step": 10844
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.009577639421026,
      "learning_rate": 1.5040976248169487e-06,
      "loss": 0.4871,
      "step": 10845
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.6929879903950367,
      "learning_rate": 1.5032926716671558e-06,
      "loss": 0.5382,
      "step": 10846
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.5167002183320724,
      "learning_rate": 1.50248789585896e-06,
      "loss": 0.4809,
      "step": 10847
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.155877118572465,
      "learning_rate": 1.5016832974331725e-06,
      "loss": 0.4725,
      "step": 10848
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.7261176177634565,
      "learning_rate": 1.5008788764306065e-06,
      "loss": 0.524,
      "step": 10849
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.5780115028793589,
      "learning_rate": 1.500074632892054e-06,
      "loss": 0.4923,
      "step": 10850
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.707925708114342,
      "learning_rate": 1.499270566858308e-06,
      "loss": 0.4546,
      "step": 10851
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.3851973521840995,
      "learning_rate": 1.4984666783701417e-06,
      "loss": 0.4871,
      "step": 10852
    },
    {
      "epoch": 0.75,
      "grad_norm": 7.2427371232958935,
      "learning_rate": 1.4976629674683335e-06,
      "loss": 0.483,
      "step": 10853
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.574716899640875,
      "learning_rate": 1.4968594341936398e-06,
      "loss": 0.4232,
      "step": 10854
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.9736161333011544,
      "learning_rate": 1.496056078586816e-06,
      "loss": 0.4206,
      "step": 10855
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.0832451519530566,
      "learning_rate": 1.4952529006886034e-06,
      "loss": 0.5059,
      "step": 10856
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.082848916775039,
      "learning_rate": 1.4944499005397372e-06,
      "loss": 0.5074,
      "step": 10857
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.389598234030032,
      "learning_rate": 1.4936470781809447e-06,
      "loss": 0.4967,
      "step": 10858
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.8890120355995745,
      "learning_rate": 1.4928444336529396e-06,
      "loss": 0.5046,
      "step": 10859
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.2664814801764632,
      "learning_rate": 1.492041966996431e-06,
      "loss": 0.4958,
      "step": 10860
    },
    {
      "epoch": 0.76,
      "grad_norm": 3.1671750315242897,
      "learning_rate": 1.4912396782521172e-06,
      "loss": 0.4727,
      "step": 10861
    },
    {
      "epoch": 0.76,
      "grad_norm": 3.5914501797124068,
      "learning_rate": 1.4904375674606885e-06,
      "loss": 0.5582,
      "step": 10862
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.9827685728351123,
      "learning_rate": 1.4896356346628221e-06,
      "loss": 0.4523,
      "step": 10863
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.6695845981872095,
      "learning_rate": 1.4888338798991952e-06,
      "loss": 0.4822,
      "step": 10864
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.2428425695541456,
      "learning_rate": 1.488032303210465e-06,
      "loss": 0.4392,
      "step": 10865
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.6272190762464924,
      "learning_rate": 1.4872309046372885e-06,
      "loss": 0.5049,
      "step": 10866
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.7818597628996407,
      "learning_rate": 1.4864296842203063e-06,
      "loss": 0.5072,
      "step": 10867
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.2651911136047795,
      "learning_rate": 1.4856286420001558e-06,
      "loss": 0.477,
      "step": 10868
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.5423003061628315,
      "learning_rate": 1.4848277780174647e-06,
      "loss": 0.4139,
      "step": 10869
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.343421594510199,
      "learning_rate": 1.4840270923128469e-06,
      "loss": 0.5116,
      "step": 10870
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.9620149288789699,
      "learning_rate": 1.4832265849269123e-06,
      "loss": 0.5305,
      "step": 10871
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.7547561815187558,
      "learning_rate": 1.4824262559002595e-06,
      "loss": 0.4847,
      "step": 10872
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.0905588848701906,
      "learning_rate": 1.4816261052734816e-06,
      "loss": 0.5031,
      "step": 10873
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.9206320264462164,
      "learning_rate": 1.480826133087155e-06,
      "loss": 0.4944,
      "step": 10874
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.2516221998166595,
      "learning_rate": 1.4800263393818532e-06,
      "loss": 0.5138,
      "step": 10875
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.1703741588237047,
      "learning_rate": 1.4792267241981406e-06,
      "loss": 0.5131,
      "step": 10876
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.9779324114197894,
      "learning_rate": 1.478427287576571e-06,
      "loss": 0.5151,
      "step": 10877
    },
    {
      "epoch": 0.76,
      "grad_norm": 3.138614249770374,
      "learning_rate": 1.4776280295576873e-06,
      "loss": 0.5051,
      "step": 10878
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.7655645896784506,
      "learning_rate": 1.4768289501820265e-06,
      "loss": 0.4753,
      "step": 10879
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.0954371065900737,
      "learning_rate": 1.4760300494901163e-06,
      "loss": 0.5034,
      "step": 10880
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.9735885879943844,
      "learning_rate": 1.4752313275224716e-06,
      "loss": 0.5264,
      "step": 10881
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.1621219370935747,
      "learning_rate": 1.4744327843196043e-06,
      "loss": 0.4958,
      "step": 10882
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.065276842532981,
      "learning_rate": 1.4736344199220093e-06,
      "loss": 0.531,
      "step": 10883
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.1299973521688313,
      "learning_rate": 1.4728362343701825e-06,
      "loss": 0.5026,
      "step": 10884
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.82386175250991,
      "learning_rate": 1.4720382277046013e-06,
      "loss": 0.4739,
      "step": 10885
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.227857450126965,
      "learning_rate": 1.4712403999657415e-06,
      "loss": 0.4796,
      "step": 10886
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.8675487846981502,
      "learning_rate": 1.4704427511940607e-06,
      "loss": 0.4856,
      "step": 10887
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.8655509870727072,
      "learning_rate": 1.4696452814300195e-06,
      "loss": 0.4332,
      "step": 10888
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.0777548186232164,
      "learning_rate": 1.4688479907140586e-06,
      "loss": 0.4572,
      "step": 10889
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.8474493921368857,
      "learning_rate": 1.4680508790866165e-06,
      "loss": 0.4416,
      "step": 10890
    },
    {
      "epoch": 0.76,
      "grad_norm": 3.7922923770546726,
      "learning_rate": 1.467253946588118e-06,
      "loss": 0.4441,
      "step": 10891
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.284182445604743,
      "learning_rate": 1.4664571932589817e-06,
      "loss": 0.466,
      "step": 10892
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.875027310180542,
      "learning_rate": 1.4656606191396177e-06,
      "loss": 0.4788,
      "step": 10893
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.1772636262976133,
      "learning_rate": 1.4648642242704237e-06,
      "loss": 0.4391,
      "step": 10894
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.2383895355313466,
      "learning_rate": 1.4640680086917907e-06,
      "loss": 0.469,
      "step": 10895
    },
    {
      "epoch": 0.76,
      "grad_norm": 3.7965393349989984,
      "learning_rate": 1.4632719724441002e-06,
      "loss": 0.4913,
      "step": 10896
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.9828826071558667,
      "learning_rate": 1.462476115567727e-06,
      "loss": 0.5014,
      "step": 10897
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.512446488129245,
      "learning_rate": 1.4616804381030302e-06,
      "loss": 0.539,
      "step": 10898
    },
    {
      "epoch": 0.76,
      "grad_norm": 3.267873739513814,
      "learning_rate": 1.4608849400903662e-06,
      "loss": 0.4962,
      "step": 10899
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.251440437113339,
      "learning_rate": 1.4600896215700817e-06,
      "loss": 0.4715,
      "step": 10900
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.2107838702649603,
      "learning_rate": 1.4592944825825084e-06,
      "loss": 0.4747,
      "step": 10901
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.5251524634049614,
      "learning_rate": 1.4584995231679778e-06,
      "loss": 0.4573,
      "step": 10902
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.0762081481910877,
      "learning_rate": 1.4577047433668023e-06,
      "loss": 0.4956,
      "step": 10903
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.9703363966944334,
      "learning_rate": 1.4569101432192966e-06,
      "loss": 0.4391,
      "step": 10904
    },
    {
      "epoch": 0.76,
      "grad_norm": 4.052659832133626,
      "learning_rate": 1.4561157227657557e-06,
      "loss": 0.4735,
      "step": 10905
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.6361185225684869,
      "learning_rate": 1.4553214820464734e-06,
      "loss": 0.4961,
      "step": 10906
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.295031035120827,
      "learning_rate": 1.4545274211017264e-06,
      "loss": 0.5207,
      "step": 10907
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.4132940880644775,
      "learning_rate": 1.4537335399717922e-06,
      "loss": 0.4606,
      "step": 10908
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.3530457914005267,
      "learning_rate": 1.4529398386969302e-06,
      "loss": 0.5651,
      "step": 10909
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.082962515586352,
      "learning_rate": 1.4521463173173966e-06,
      "loss": 0.5036,
      "step": 10910
    },
    {
      "epoch": 0.76,
      "grad_norm": 3.788486957805261,
      "learning_rate": 1.451352975873434e-06,
      "loss": 0.4298,
      "step": 10911
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.5292777377447311,
      "learning_rate": 1.450559814405279e-06,
      "loss": 0.4143,
      "step": 10912
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.091241414655221,
      "learning_rate": 1.44976683295316e-06,
      "loss": 0.5133,
      "step": 10913
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.8225875590218403,
      "learning_rate": 1.4489740315572909e-06,
      "loss": 0.4735,
      "step": 10914
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.827304997197674,
      "learning_rate": 1.4481814102578822e-06,
      "loss": 0.5047,
      "step": 10915
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.6693445919156136,
      "learning_rate": 1.4473889690951332e-06,
      "loss": 0.5571,
      "step": 10916
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.9265967805572548,
      "learning_rate": 1.4465967081092346e-06,
      "loss": 0.4636,
      "step": 10917
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.7745398397334653,
      "learning_rate": 1.4458046273403647e-06,
      "loss": 0.5145,
      "step": 10918
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.369026794086251,
      "learning_rate": 1.4450127268286967e-06,
      "loss": 0.4881,
      "step": 10919
    },
    {
      "epoch": 0.76,
      "grad_norm": 3.493425053900645,
      "learning_rate": 1.4442210066143935e-06,
      "loss": 0.4915,
      "step": 10920
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.0722595407537194,
      "learning_rate": 1.4434294667376098e-06,
      "loss": 0.5061,
      "step": 10921
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.341907233312132,
      "learning_rate": 1.4426381072384866e-06,
      "loss": 0.4812,
      "step": 10922
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.8482163739216495,
      "learning_rate": 1.4418469281571611e-06,
      "loss": 0.5013,
      "step": 10923
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.0187752671264283,
      "learning_rate": 1.4410559295337612e-06,
      "loss": 0.5092,
      "step": 10924
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.7160262299716957,
      "learning_rate": 1.4402651114083992e-06,
      "loss": 0.4796,
      "step": 10925
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.6669151476117663,
      "learning_rate": 1.439474473821188e-06,
      "loss": 0.5052,
      "step": 10926
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.7456754320786096,
      "learning_rate": 1.4386840168122196e-06,
      "loss": 0.4887,
      "step": 10927
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.0057266483644502,
      "learning_rate": 1.437893740421591e-06,
      "loss": 0.4554,
      "step": 10928
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.3611319871481347,
      "learning_rate": 1.4371036446893767e-06,
      "loss": 0.5221,
      "step": 10929
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.094078486715665,
      "learning_rate": 1.4363137296556501e-06,
      "loss": 0.5093,
      "step": 10930
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.020941339803709,
      "learning_rate": 1.4355239953604726e-06,
      "loss": 0.5306,
      "step": 10931
    },
    {
      "epoch": 0.76,
      "grad_norm": 18.079973390426392,
      "learning_rate": 1.434734441843899e-06,
      "loss": 0.478,
      "step": 10932
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.8562046342317646,
      "learning_rate": 1.4339450691459695e-06,
      "loss": 0.5254,
      "step": 10933
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.561650830116972,
      "learning_rate": 1.43315587730672e-06,
      "loss": 0.405,
      "step": 10934
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.0901344181478354,
      "learning_rate": 1.4323668663661771e-06,
      "loss": 0.4517,
      "step": 10935
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.3253767724834007,
      "learning_rate": 1.4315780363643545e-06,
      "loss": 0.4703,
      "step": 10936
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.955734853602858,
      "learning_rate": 1.4307893873412616e-06,
      "loss": 0.5073,
      "step": 10937
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.9146621552415413,
      "learning_rate": 1.4300009193368914e-06,
      "loss": 0.5121,
      "step": 10938
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.849778247730221,
      "learning_rate": 1.4292126323912391e-06,
      "loss": 0.4678,
      "step": 10939
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.5025037989163113,
      "learning_rate": 1.4284245265442786e-06,
      "loss": 0.5043,
      "step": 10940
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.6864167410612458,
      "learning_rate": 1.4276366018359845e-06,
      "loss": 0.4826,
      "step": 10941
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.6035072856751316,
      "learning_rate": 1.4268488583063117e-06,
      "loss": 0.4495,
      "step": 10942
    },
    {
      "epoch": 0.76,
      "grad_norm": 3.260853571188612,
      "learning_rate": 1.4260612959952185e-06,
      "loss": 0.4937,
      "step": 10943
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.2723203742073976,
      "learning_rate": 1.4252739149426437e-06,
      "loss": 0.5048,
      "step": 10944
    },
    {
      "epoch": 0.76,
      "grad_norm": 9.071335925821197,
      "learning_rate": 1.4244867151885227e-06,
      "loss": 0.5152,
      "step": 10945
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.7156366661642033,
      "learning_rate": 1.4236996967727778e-06,
      "loss": 0.5051,
      "step": 10946
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.3168566660712364,
      "learning_rate": 1.4229128597353243e-06,
      "loss": 0.4873,
      "step": 10947
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.993176122928347,
      "learning_rate": 1.4221262041160699e-06,
      "loss": 0.4793,
      "step": 10948
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.1030611439592337,
      "learning_rate": 1.4213397299549092e-06,
      "loss": 0.4543,
      "step": 10949
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.6914349786667178,
      "learning_rate": 1.4205534372917296e-06,
      "loss": 0.5066,
      "step": 10950
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.7329574943877928,
      "learning_rate": 1.4197673261664102e-06,
      "loss": 0.4746,
      "step": 10951
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.6523053476495617,
      "learning_rate": 1.4189813966188215e-06,
      "loss": 0.4778,
      "step": 10952
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.2494793421265804,
      "learning_rate": 1.4181956486888198e-06,
      "loss": 0.4786,
      "step": 10953
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.8774143556275498,
      "learning_rate": 1.4174100824162573e-06,
      "loss": 0.4766,
      "step": 10954
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.019101077514545,
      "learning_rate": 1.4166246978409758e-06,
      "loss": 0.5462,
      "step": 10955
    },
    {
      "epoch": 0.76,
      "grad_norm": 3.609269115435455,
      "learning_rate": 1.4158394950028086e-06,
      "loss": 0.4752,
      "step": 10956
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.8091797310145565,
      "learning_rate": 1.4150544739415755e-06,
      "loss": 0.5148,
      "step": 10957
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.5677392606018588,
      "learning_rate": 1.414269634697092e-06,
      "loss": 0.4927,
      "step": 10958
    },
    {
      "epoch": 0.76,
      "grad_norm": 5.928930511304303,
      "learning_rate": 1.4134849773091642e-06,
      "loss": 0.4493,
      "step": 10959
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.6735929641484313,
      "learning_rate": 1.4127005018175838e-06,
      "loss": 0.4598,
      "step": 10960
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.9330164818425586,
      "learning_rate": 1.4119162082621407e-06,
      "loss": 0.4811,
      "step": 10961
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.8892590874583675,
      "learning_rate": 1.411132096682606e-06,
      "loss": 0.4402,
      "step": 10962
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.0385614464812667,
      "learning_rate": 1.410348167118754e-06,
      "loss": 0.4531,
      "step": 10963
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.6168246375829926,
      "learning_rate": 1.4095644196103391e-06,
      "loss": 0.4317,
      "step": 10964
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.8653406573191114,
      "learning_rate": 1.4087808541971126e-06,
      "loss": 0.4579,
      "step": 10965
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.095331003711653,
      "learning_rate": 1.4079974709188116e-06,
      "loss": 0.4555,
      "step": 10966
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.8945001612920211,
      "learning_rate": 1.407214269815168e-06,
      "loss": 0.4469,
      "step": 10967
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.080295708159368,
      "learning_rate": 1.4064312509259053e-06,
      "loss": 0.478,
      "step": 10968
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.9233355954992095,
      "learning_rate": 1.4056484142907322e-06,
      "loss": 0.4949,
      "step": 10969
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.8959881623696082,
      "learning_rate": 1.4048657599493538e-06,
      "loss": 0.481,
      "step": 10970
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.7721069979985558,
      "learning_rate": 1.4040832879414628e-06,
      "loss": 0.5012,
      "step": 10971
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.8445329464967974,
      "learning_rate": 1.4033009983067454e-06,
      "loss": 0.457,
      "step": 10972
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.9290554184871362,
      "learning_rate": 1.4025188910848741e-06,
      "loss": 0.4797,
      "step": 10973
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.6977401850497156,
      "learning_rate": 1.401736966315516e-06,
      "loss": 0.5034,
      "step": 10974
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.964796691187252,
      "learning_rate": 1.4009552240383285e-06,
      "loss": 0.5005,
      "step": 10975
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.9990506326311228,
      "learning_rate": 1.4001736642929598e-06,
      "loss": 0.485,
      "step": 10976
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.5632816146814763,
      "learning_rate": 1.3993922871190445e-06,
      "loss": 0.4164,
      "step": 10977
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.5684526770563803,
      "learning_rate": 1.3986110925562146e-06,
      "loss": 0.4247,
      "step": 10978
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.551337704981047,
      "learning_rate": 1.3978300806440902e-06,
      "loss": 0.4997,
      "step": 10979
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.5890394952520194,
      "learning_rate": 1.397049251422279e-06,
      "loss": 0.4086,
      "step": 10980
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.6998669898034207,
      "learning_rate": 1.3962686049303847e-06,
      "loss": 0.4836,
      "step": 10981
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.233055181508355,
      "learning_rate": 1.3954881412079945e-06,
      "loss": 0.4862,
      "step": 10982
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.9352580840582603,
      "learning_rate": 1.394707860294698e-06,
      "loss": 0.5182,
      "step": 10983
    },
    {
      "epoch": 0.76,
      "grad_norm": 8.067017047088147,
      "learning_rate": 1.3939277622300635e-06,
      "loss": 0.4833,
      "step": 10984
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.7410986430484714,
      "learning_rate": 1.3931478470536575e-06,
      "loss": 0.4746,
      "step": 10985
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.38751956043348,
      "learning_rate": 1.3923681148050304e-06,
      "loss": 0.4533,
      "step": 10986
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.8472729017768466,
      "learning_rate": 1.391588565523735e-06,
      "loss": 0.4743,
      "step": 10987
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.1473366213306244,
      "learning_rate": 1.3908091992493012e-06,
      "loss": 0.5482,
      "step": 10988
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.6711447534291195,
      "learning_rate": 1.39003001602126e-06,
      "loss": 0.5017,
      "step": 10989
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.348577280817791,
      "learning_rate": 1.3892510158791256e-06,
      "loss": 0.4995,
      "step": 10990
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.7224835979288682,
      "learning_rate": 1.3884721988624077e-06,
      "loss": 0.4651,
      "step": 10991
    },
    {
      "epoch": 0.76,
      "grad_norm": 5.13287474166856,
      "learning_rate": 1.387693565010607e-06,
      "loss": 0.4873,
      "step": 10992
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.554150867833981,
      "learning_rate": 1.3869151143632098e-06,
      "loss": 0.4316,
      "step": 10993
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.8779259079542898,
      "learning_rate": 1.3861368469597008e-06,
      "loss": 0.4386,
      "step": 10994
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.003265330814498,
      "learning_rate": 1.3853587628395482e-06,
      "loss": 0.4782,
      "step": 10995
    },
    {
      "epoch": 0.76,
      "grad_norm": 3.4080333638851465,
      "learning_rate": 1.3845808620422158e-06,
      "loss": 0.4818,
      "step": 10996
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.5359295691586432,
      "learning_rate": 1.3838031446071521e-06,
      "loss": 0.4129,
      "step": 10997
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.8053674249624492,
      "learning_rate": 1.3830256105738067e-06,
      "loss": 0.509,
      "step": 10998
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.793589860819909,
      "learning_rate": 1.3822482599816084e-06,
      "loss": 0.4734,
      "step": 10999
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.2913122379169457,
      "learning_rate": 1.3814710928699854e-06,
      "loss": 0.497,
      "step": 11000
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.22603250317888,
      "learning_rate": 1.3806941092783504e-06,
      "loss": 0.4688,
      "step": 11001
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.7781545315688607,
      "learning_rate": 1.3799173092461104e-06,
      "loss": 0.4859,
      "step": 11002
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.623978703159344,
      "learning_rate": 1.3791406928126638e-06,
      "loss": 0.4629,
      "step": 11003
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.5852242636596411,
      "learning_rate": 1.3783642600173946e-06,
      "loss": 0.4492,
      "step": 11004
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.8615941499153374,
      "learning_rate": 1.3775880108996835e-06,
      "loss": 0.5003,
      "step": 11005
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.0189068949330746,
      "learning_rate": 1.3768119454988987e-06,
      "loss": 0.5045,
      "step": 11006
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.791033036969869,
      "learning_rate": 1.3760360638544012e-06,
      "loss": 0.5011,
      "step": 11007
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.5605690784740407,
      "learning_rate": 1.3752603660055381e-06,
      "loss": 0.4808,
      "step": 11008
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.240594759012357,
      "learning_rate": 1.374484851991652e-06,
      "loss": 0.4772,
      "step": 11009
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.671773978336398,
      "learning_rate": 1.373709521852074e-06,
      "loss": 0.4452,
      "step": 11010
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.117257430583968,
      "learning_rate": 1.3729343756261288e-06,
      "loss": 0.5397,
      "step": 11011
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.796911296240241,
      "learning_rate": 1.3721594133531253e-06,
      "loss": 0.507,
      "step": 11012
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.403036478578691,
      "learning_rate": 1.3713846350723686e-06,
      "loss": 0.5086,
      "step": 11013
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.8518482136179077,
      "learning_rate": 1.3706100408231554e-06,
      "loss": 0.4855,
      "step": 11014
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.5718831873654664,
      "learning_rate": 1.3698356306447668e-06,
      "loss": 0.474,
      "step": 11015
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.281488122823738,
      "learning_rate": 1.369061404576481e-06,
      "loss": 0.5096,
      "step": 11016
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.675387475268429,
      "learning_rate": 1.3682873626575606e-06,
      "loss": 0.534,
      "step": 11017
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.817462672142679,
      "learning_rate": 1.367513504927268e-06,
      "loss": 0.5122,
      "step": 11018
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.891538393842508,
      "learning_rate": 1.3667398314248465e-06,
      "loss": 0.5008,
      "step": 11019
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.867277620660625,
      "learning_rate": 1.365966342189537e-06,
      "loss": 0.4842,
      "step": 11020
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.6258045560879701,
      "learning_rate": 1.3651930372605659e-06,
      "loss": 0.4684,
      "step": 11021
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.563176846678278,
      "learning_rate": 1.3644199166771531e-06,
      "loss": 0.4794,
      "step": 11022
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.172212195289796,
      "learning_rate": 1.3636469804785102e-06,
      "loss": 0.4902,
      "step": 11023
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.10080644134946,
      "learning_rate": 1.3628742287038382e-06,
      "loss": 0.4822,
      "step": 11024
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.746507210873763,
      "learning_rate": 1.362101661392326e-06,
      "loss": 0.4918,
      "step": 11025
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.033019722877971,
      "learning_rate": 1.3613292785831577e-06,
      "loss": 0.4586,
      "step": 11026
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.5763991503409461,
      "learning_rate": 1.3605570803155072e-06,
      "loss": 0.4095,
      "step": 11027
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.367160110356219,
      "learning_rate": 1.3597850666285346e-06,
      "loss": 0.4845,
      "step": 11028
    },
    {
      "epoch": 0.77,
      "grad_norm": 7.304971586177121,
      "learning_rate": 1.3590132375613957e-06,
      "loss": 0.4826,
      "step": 11029
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.0349635663365815,
      "learning_rate": 1.358241593153235e-06,
      "loss": 0.4611,
      "step": 11030
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.8557762664809305,
      "learning_rate": 1.3574701334431896e-06,
      "loss": 0.4724,
      "step": 11031
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.5382120219138248,
      "learning_rate": 1.3566988584703817e-06,
      "loss": 0.4146,
      "step": 11032
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.712086810808161,
      "learning_rate": 1.3559277682739302e-06,
      "loss": 0.5132,
      "step": 11033
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.198150022419395,
      "learning_rate": 1.3551568628929434e-06,
      "loss": 0.4365,
      "step": 11034
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.7611875149608294,
      "learning_rate": 1.354386142366516e-06,
      "loss": 0.4721,
      "step": 11035
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.6883000668718362,
      "learning_rate": 1.3536156067337397e-06,
      "loss": 0.481,
      "step": 11036
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.0732431561077997,
      "learning_rate": 1.352845256033689e-06,
      "loss": 0.4995,
      "step": 11037
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.8870882417055688,
      "learning_rate": 1.3520750903054397e-06,
      "loss": 0.4863,
      "step": 11038
    },
    {
      "epoch": 0.77,
      "grad_norm": 3.0258991097463888,
      "learning_rate": 1.351305109588047e-06,
      "loss": 0.4654,
      "step": 11039
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.4242074399930744,
      "learning_rate": 1.3505353139205657e-06,
      "loss": 0.4503,
      "step": 11040
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.9506586374643744,
      "learning_rate": 1.3497657033420319e-06,
      "loss": 0.5026,
      "step": 11041
    },
    {
      "epoch": 0.77,
      "grad_norm": 4.2622263133537786,
      "learning_rate": 1.3489962778914845e-06,
      "loss": 0.489,
      "step": 11042
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.7869719990718176,
      "learning_rate": 1.348227037607941e-06,
      "loss": 0.3997,
      "step": 11043
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.5614234975296922,
      "learning_rate": 1.3474579825304184e-06,
      "loss": 0.4095,
      "step": 11044
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.13215207641607,
      "learning_rate": 1.3466891126979175e-06,
      "loss": 0.5212,
      "step": 11045
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.106245900410253,
      "learning_rate": 1.3459204281494343e-06,
      "loss": 0.5155,
      "step": 11046
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.0382821857814535,
      "learning_rate": 1.3451519289239556e-06,
      "loss": 0.4778,
      "step": 11047
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.1776832223822873,
      "learning_rate": 1.344383615060454e-06,
      "loss": 0.4944,
      "step": 11048
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.5280181052313443,
      "learning_rate": 1.3436154865978973e-06,
      "loss": 0.3957,
      "step": 11049
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.8321518797842447,
      "learning_rate": 1.3428475435752426e-06,
      "loss": 0.4837,
      "step": 11050
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.6698053486990023,
      "learning_rate": 1.3420797860314393e-06,
      "loss": 0.4953,
      "step": 11051
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.1728911048293567,
      "learning_rate": 1.3413122140054219e-06,
      "loss": 0.4844,
      "step": 11052
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.515831295280185,
      "learning_rate": 1.3405448275361217e-06,
      "loss": 0.4813,
      "step": 11053
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.1635858367771488,
      "learning_rate": 1.3397776266624562e-06,
      "loss": 0.4595,
      "step": 11054
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.7080675316457077,
      "learning_rate": 1.3390106114233387e-06,
      "loss": 0.4933,
      "step": 11055
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.2869801672409604,
      "learning_rate": 1.338243781857666e-06,
      "loss": 0.5001,
      "step": 11056
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.2636024819443517,
      "learning_rate": 1.3374771380043306e-06,
      "loss": 0.4556,
      "step": 11057
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.6808818148840126,
      "learning_rate": 1.3367106799022156e-06,
      "loss": 0.4835,
      "step": 11058
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.162176348135237,
      "learning_rate": 1.3359444075901906e-06,
      "loss": 0.4979,
      "step": 11059
    },
    {
      "epoch": 0.77,
      "grad_norm": 3.346891964528714,
      "learning_rate": 1.3351783211071196e-06,
      "loss": 0.4921,
      "step": 11060
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.7658068547188575,
      "learning_rate": 1.3344124204918562e-06,
      "loss": 0.4849,
      "step": 11061
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.266625097378718,
      "learning_rate": 1.3336467057832458e-06,
      "loss": 0.4234,
      "step": 11062
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.7574236767174263,
      "learning_rate": 1.33288117702012e-06,
      "loss": 0.4707,
      "step": 11063
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.5947578793434597,
      "learning_rate": 1.3321158342413055e-06,
      "loss": 0.4185,
      "step": 11064
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.463994466973618,
      "learning_rate": 1.3313506774856177e-06,
      "loss": 0.4761,
      "step": 11065
    },
    {
      "epoch": 0.77,
      "grad_norm": 4.6459577976201185,
      "learning_rate": 1.3305857067918649e-06,
      "loss": 0.4579,
      "step": 11066
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.042941625294482,
      "learning_rate": 1.32982092219884e-06,
      "loss": 0.4646,
      "step": 11067
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.8183935009480545,
      "learning_rate": 1.329056323745333e-06,
      "loss": 0.486,
      "step": 11068
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.2468183470499357,
      "learning_rate": 1.3282919114701226e-06,
      "loss": 0.4614,
      "step": 11069
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.8205132811804097,
      "learning_rate": 1.327527685411974e-06,
      "loss": 0.4534,
      "step": 11070
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.99529092577058,
      "learning_rate": 1.3267636456096506e-06,
      "loss": 0.4373,
      "step": 11071
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.018481346254863,
      "learning_rate": 1.3259997921018963e-06,
      "loss": 0.4747,
      "step": 11072
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.8885615191392255,
      "learning_rate": 1.3252361249274577e-06,
      "loss": 0.4924,
      "step": 11073
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.6317125898981204,
      "learning_rate": 1.3244726441250605e-06,
      "loss": 0.4857,
      "step": 11074
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.550172446357549,
      "learning_rate": 1.3237093497334296e-06,
      "loss": 0.4713,
      "step": 11075
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.108283333129112,
      "learning_rate": 1.322946241791272e-06,
      "loss": 0.5373,
      "step": 11076
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.9644992200089038,
      "learning_rate": 1.3221833203372964e-06,
      "loss": 0.4657,
      "step": 11077
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.0185542728207837,
      "learning_rate": 1.3214205854101907e-06,
      "loss": 0.4776,
      "step": 11078
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.086403280510847,
      "learning_rate": 1.3206580370486422e-06,
      "loss": 0.4357,
      "step": 11079
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.8468433521989531,
      "learning_rate": 1.3198956752913206e-06,
      "loss": 0.4708,
      "step": 11080
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.9431338404508443,
      "learning_rate": 1.3191335001768924e-06,
      "loss": 0.5327,
      "step": 11081
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.5725258256783123,
      "learning_rate": 1.3183715117440143e-06,
      "loss": 0.4738,
      "step": 11082
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.0692985811098112,
      "learning_rate": 1.317609710031329e-06,
      "loss": 0.4818,
      "step": 11083
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.93481173552922,
      "learning_rate": 1.3168480950774742e-06,
      "loss": 0.5087,
      "step": 11084
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.9520621926451749,
      "learning_rate": 1.3160866669210758e-06,
      "loss": 0.5189,
      "step": 11085
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.138594170392535,
      "learning_rate": 1.315325425600753e-06,
      "loss": 0.4828,
      "step": 11086
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.7196903023509282,
      "learning_rate": 1.3145643711551103e-06,
      "loss": 0.4513,
      "step": 11087
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.8303469316522047,
      "learning_rate": 1.313803503622748e-06,
      "loss": 0.4896,
      "step": 11088
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.7238806916859184,
      "learning_rate": 1.3130428230422555e-06,
      "loss": 0.512,
      "step": 11089
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.3693717806830565,
      "learning_rate": 1.3122823294522092e-06,
      "loss": 0.4593,
      "step": 11090
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.811083595978584,
      "learning_rate": 1.3115220228911806e-06,
      "loss": 0.4792,
      "step": 11091
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.879666988515405,
      "learning_rate": 1.3107619033977298e-06,
      "loss": 0.4392,
      "step": 11092
    },
    {
      "epoch": 0.77,
      "grad_norm": 6.550854132060729,
      "learning_rate": 1.3100019710104094e-06,
      "loss": 0.4758,
      "step": 11093
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.2504476438564325,
      "learning_rate": 1.3092422257677573e-06,
      "loss": 0.4905,
      "step": 11094
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.6073407122244554,
      "learning_rate": 1.3084826677083084e-06,
      "loss": 0.408,
      "step": 11095
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.732664872602843,
      "learning_rate": 1.3077232968705805e-06,
      "loss": 0.486,
      "step": 11096
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.693395449750285,
      "learning_rate": 1.3069641132930928e-06,
      "loss": 0.5131,
      "step": 11097
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.136729183420662,
      "learning_rate": 1.3062051170143431e-06,
      "loss": 0.5094,
      "step": 11098
    },
    {
      "epoch": 0.77,
      "grad_norm": 3.1295586986812776,
      "learning_rate": 1.305446308072829e-06,
      "loss": 0.4557,
      "step": 11099
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.872589688718987,
      "learning_rate": 1.3046876865070324e-06,
      "loss": 0.4822,
      "step": 11100
    },
    {
      "epoch": 0.77,
      "grad_norm": 4.7137104870958915,
      "learning_rate": 1.3039292523554287e-06,
      "loss": 0.4637,
      "step": 11101
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.000640713605287,
      "learning_rate": 1.3031710056564844e-06,
      "loss": 0.505,
      "step": 11102
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.5300521185924993,
      "learning_rate": 1.3024129464486534e-06,
      "loss": 0.4703,
      "step": 11103
    },
    {
      "epoch": 0.77,
      "grad_norm": 3.2497014369142776,
      "learning_rate": 1.3016550747703827e-06,
      "loss": 0.5095,
      "step": 11104
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.2739241478858285,
      "learning_rate": 1.3008973906601097e-06,
      "loss": 0.5048,
      "step": 11105
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.3295792031215123,
      "learning_rate": 1.300139894156262e-06,
      "loss": 0.4772,
      "step": 11106
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.6046025932446252,
      "learning_rate": 1.2993825852972559e-06,
      "loss": 0.4184,
      "step": 11107
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.6117809287948561,
      "learning_rate": 1.2986254641215e-06,
      "loss": 0.4471,
      "step": 11108
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.9035368308768363,
      "learning_rate": 1.2978685306673932e-06,
      "loss": 0.4984,
      "step": 11109
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.8803178004890921,
      "learning_rate": 1.2971117849733266e-06,
      "loss": 0.4682,
      "step": 11110
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.822434728755208,
      "learning_rate": 1.2963552270776768e-06,
      "loss": 0.4667,
      "step": 11111
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.131413498690664,
      "learning_rate": 1.2955988570188155e-06,
      "loss": 0.4762,
      "step": 11112
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.002882270502782,
      "learning_rate": 1.294842674835104e-06,
      "loss": 0.4882,
      "step": 11113
    },
    {
      "epoch": 0.77,
      "grad_norm": 3.776026103607355,
      "learning_rate": 1.2940866805648916e-06,
      "loss": 0.4908,
      "step": 11114
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.101156874052386,
      "learning_rate": 1.2933308742465217e-06,
      "loss": 0.458,
      "step": 11115
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.130490691601579,
      "learning_rate": 1.292575255918323e-06,
      "loss": 0.4933,
      "step": 11116
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.4563190252020215,
      "learning_rate": 1.2918198256186232e-06,
      "loss": 0.4861,
      "step": 11117
    },
    {
      "epoch": 0.77,
      "grad_norm": 5.394947076820709,
      "learning_rate": 1.291064583385731e-06,
      "loss": 0.4947,
      "step": 11118
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.0126893718752656,
      "learning_rate": 1.2903095292579509e-06,
      "loss": 0.4829,
      "step": 11119
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.040082545685949,
      "learning_rate": 1.2895546632735777e-06,
      "loss": 0.5,
      "step": 11120
    },
    {
      "epoch": 0.77,
      "grad_norm": 3.2927741029860598,
      "learning_rate": 1.2887999854708966e-06,
      "loss": 0.4676,
      "step": 11121
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.898257405923385,
      "learning_rate": 1.2880454958881794e-06,
      "loss": 0.5055,
      "step": 11122
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.9369881904577095,
      "learning_rate": 1.2872911945636934e-06,
      "loss": 0.5236,
      "step": 11123
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.3141596504403714,
      "learning_rate": 1.2865370815356948e-06,
      "loss": 0.477,
      "step": 11124
    },
    {
      "epoch": 0.77,
      "grad_norm": 3.3981963050243675,
      "learning_rate": 1.2857831568424278e-06,
      "loss": 0.4936,
      "step": 11125
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.278746812950608,
      "learning_rate": 1.2850294205221314e-06,
      "loss": 0.4913,
      "step": 11126
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.814992715534035,
      "learning_rate": 1.2842758726130283e-06,
      "loss": 0.4774,
      "step": 11127
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.3012137980386824,
      "learning_rate": 1.2835225131533419e-06,
      "loss": 0.4965,
      "step": 11128
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.820757580632189,
      "learning_rate": 1.2827693421812758e-06,
      "loss": 0.4762,
      "step": 11129
    },
    {
      "epoch": 0.77,
      "grad_norm": 3.6801365923034326,
      "learning_rate": 1.282016359735031e-06,
      "loss": 0.4731,
      "step": 11130
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.864345131774634,
      "learning_rate": 1.2812635658527928e-06,
      "loss": 0.4788,
      "step": 11131
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.2640317207655114,
      "learning_rate": 1.280510960572745e-06,
      "loss": 0.494,
      "step": 11132
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.1580715172903058,
      "learning_rate": 1.2797585439330539e-06,
      "loss": 0.4576,
      "step": 11133
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.7137523808769888,
      "learning_rate": 1.2790063159718823e-06,
      "loss": 0.512,
      "step": 11134
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.7976787891473545,
      "learning_rate": 1.2782542767273775e-06,
      "loss": 0.467,
      "step": 11135
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.5984287569989863,
      "learning_rate": 1.2775024262376823e-06,
      "loss": 0.458,
      "step": 11136
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.3200519323390036,
      "learning_rate": 1.27675076454093e-06,
      "loss": 0.4656,
      "step": 11137
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.237122620868824,
      "learning_rate": 1.2759992916752384e-06,
      "loss": 0.4804,
      "step": 11138
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.8121924195797707,
      "learning_rate": 1.2752480076787216e-06,
      "loss": 0.4991,
      "step": 11139
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.9119732663198972,
      "learning_rate": 1.274496912589483e-06,
      "loss": 0.4998,
      "step": 11140
    },
    {
      "epoch": 0.77,
      "grad_norm": 3.605338469713424,
      "learning_rate": 1.2737460064456164e-06,
      "loss": 0.4757,
      "step": 11141
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.7989565248334762,
      "learning_rate": 1.272995289285202e-06,
      "loss": 0.4785,
      "step": 11142
    },
    {
      "epoch": 0.77,
      "grad_norm": 3.267696933536757,
      "learning_rate": 1.2722447611463168e-06,
      "loss": 0.5062,
      "step": 11143
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.0822518278592437,
      "learning_rate": 1.2714944220670233e-06,
      "loss": 0.4731,
      "step": 11144
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.9715264602740816,
      "learning_rate": 1.270744272085379e-06,
      "loss": 0.4576,
      "step": 11145
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.8615836863834312,
      "learning_rate": 1.2699943112394259e-06,
      "loss": 0.5336,
      "step": 11146
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.2958462932672896,
      "learning_rate": 1.2692445395672003e-06,
      "loss": 0.4706,
      "step": 11147
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.595211479841051,
      "learning_rate": 1.2684949571067306e-06,
      "loss": 0.4209,
      "step": 11148
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.7668237512877905,
      "learning_rate": 1.2677455638960295e-06,
      "loss": 0.4757,
      "step": 11149
    },
    {
      "epoch": 0.78,
      "grad_norm": 9.277931392341287,
      "learning_rate": 1.2669963599731072e-06,
      "loss": 0.5232,
      "step": 11150
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.9639539102985097,
      "learning_rate": 1.2662473453759562e-06,
      "loss": 0.4808,
      "step": 11151
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.0207256346654754,
      "learning_rate": 1.2654985201425702e-06,
      "loss": 0.4776,
      "step": 11152
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.254996029478544,
      "learning_rate": 1.2647498843109223e-06,
      "loss": 0.4661,
      "step": 11153
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.3488426996270975,
      "learning_rate": 1.264001437918984e-06,
      "loss": 0.497,
      "step": 11154
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.0158077616908003,
      "learning_rate": 1.2632531810047116e-06,
      "loss": 0.4732,
      "step": 11155
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.8809490963899695,
      "learning_rate": 1.2625051136060557e-06,
      "loss": 0.4775,
      "step": 11156
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.822482364218359,
      "learning_rate": 1.2617572357609565e-06,
      "loss": 0.4488,
      "step": 11157
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.5436061333733893,
      "learning_rate": 1.2610095475073415e-06,
      "loss": 0.4554,
      "step": 11158
    },
    {
      "epoch": 0.78,
      "grad_norm": 6.022731666631293,
      "learning_rate": 1.2602620488831324e-06,
      "loss": 0.4539,
      "step": 11159
    },
    {
      "epoch": 0.78,
      "grad_norm": 4.689653782989339,
      "learning_rate": 1.2595147399262402e-06,
      "loss": 0.5069,
      "step": 11160
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.5912988967914264,
      "learning_rate": 1.2587676206745669e-06,
      "loss": 0.4357,
      "step": 11161
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.5473370434629201,
      "learning_rate": 1.2580206911660014e-06,
      "loss": 0.4135,
      "step": 11162
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.3785711192975825,
      "learning_rate": 1.2572739514384269e-06,
      "loss": 0.4926,
      "step": 11163
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.9950020700738147,
      "learning_rate": 1.2565274015297153e-06,
      "loss": 0.4761,
      "step": 11164
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.940528953997768,
      "learning_rate": 1.2557810414777315e-06,
      "loss": 0.4587,
      "step": 11165
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.857187058511803,
      "learning_rate": 1.2550348713203248e-06,
      "loss": 0.4752,
      "step": 11166
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.495086677110406,
      "learning_rate": 1.25428889109534e-06,
      "loss": 0.5033,
      "step": 11167
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.5061116906760973,
      "learning_rate": 1.2535431008406124e-06,
      "loss": 0.4104,
      "step": 11168
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.765662618735661,
      "learning_rate": 1.252797500593963e-06,
      "loss": 0.552,
      "step": 11169
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.7328800537709403,
      "learning_rate": 1.2520520903932093e-06,
      "loss": 0.4583,
      "step": 11170
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.879573338700902,
      "learning_rate": 1.2513068702761515e-06,
      "loss": 0.5215,
      "step": 11171
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.875491711248528,
      "learning_rate": 1.2505618402805909e-06,
      "loss": 0.5008,
      "step": 11172
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.2697707088752734,
      "learning_rate": 1.2498170004443083e-06,
      "loss": 0.4819,
      "step": 11173
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.921744881900966,
      "learning_rate": 1.249072350805083e-06,
      "loss": 0.4991,
      "step": 11174
    },
    {
      "epoch": 0.78,
      "grad_norm": 9.862768384605358,
      "learning_rate": 1.2483278914006758e-06,
      "loss": 0.4968,
      "step": 11175
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.5663682930744454,
      "learning_rate": 1.2475836222688504e-06,
      "loss": 0.4191,
      "step": 11176
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.527432807876602,
      "learning_rate": 1.2468395434473484e-06,
      "loss": 0.4806,
      "step": 11177
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.0492609729017968,
      "learning_rate": 1.2460956549739102e-06,
      "loss": 0.4864,
      "step": 11178
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.0406245421567983,
      "learning_rate": 1.2453519568862599e-06,
      "loss": 0.4765,
      "step": 11179
    },
    {
      "epoch": 0.78,
      "grad_norm": 4.463601919420993,
      "learning_rate": 1.2446084492221183e-06,
      "loss": 0.4484,
      "step": 11180
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.601514745634702,
      "learning_rate": 1.2438651320191942e-06,
      "loss": 0.5007,
      "step": 11181
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.5641792289758314,
      "learning_rate": 1.2431220053151832e-06,
      "loss": 0.4985,
      "step": 11182
    },
    {
      "epoch": 0.78,
      "grad_norm": 3.832971127808193,
      "learning_rate": 1.242379069147776e-06,
      "loss": 0.4817,
      "step": 11183
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.778754539326624,
      "learning_rate": 1.2416363235546518e-06,
      "loss": 0.5049,
      "step": 11184
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.8863967108166353,
      "learning_rate": 1.2408937685734819e-06,
      "loss": 0.4678,
      "step": 11185
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.198807799058023,
      "learning_rate": 1.2401514042419216e-06,
      "loss": 0.4758,
      "step": 11186
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.5248472928161307,
      "learning_rate": 1.2394092305976274e-06,
      "loss": 0.4647,
      "step": 11187
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.7966125500722667,
      "learning_rate": 1.2386672476782351e-06,
      "loss": 0.4892,
      "step": 11188
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.0009667542481724,
      "learning_rate": 1.2379254555213788e-06,
      "loss": 0.4858,
      "step": 11189
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.046504619542301,
      "learning_rate": 1.2371838541646768e-06,
      "loss": 0.4862,
      "step": 11190
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.263971013479827,
      "learning_rate": 1.2364424436457428e-06,
      "loss": 0.4486,
      "step": 11191
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.0406001488037373,
      "learning_rate": 1.2357012240021793e-06,
      "loss": 0.5299,
      "step": 11192
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.9769421981061854,
      "learning_rate": 1.2349601952715757e-06,
      "loss": 0.4943,
      "step": 11193
    },
    {
      "epoch": 0.78,
      "grad_norm": 3.5972940035436114,
      "learning_rate": 1.2342193574915167e-06,
      "loss": 0.465,
      "step": 11194
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.7064869585171114,
      "learning_rate": 1.2334787106995744e-06,
      "loss": 0.4215,
      "step": 11195
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.0403179514395853,
      "learning_rate": 1.232738254933314e-06,
      "loss": 0.4848,
      "step": 11196
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.9319177687844198,
      "learning_rate": 1.2319979902302853e-06,
      "loss": 0.4992,
      "step": 11197
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.8919135630479902,
      "learning_rate": 1.2312579166280347e-06,
      "loss": 0.4935,
      "step": 11198
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.5572979309309156,
      "learning_rate": 1.230518034164096e-06,
      "loss": 0.5185,
      "step": 11199
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.146276245633045,
      "learning_rate": 1.2297783428759941e-06,
      "loss": 0.5193,
      "step": 11200
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.072434398808413,
      "learning_rate": 1.2290388428012422e-06,
      "loss": 0.5166,
      "step": 11201
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.0924256516969,
      "learning_rate": 1.2282995339773456e-06,
      "loss": 0.5356,
      "step": 11202
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.185177620893444,
      "learning_rate": 1.227560416441802e-06,
      "loss": 0.4776,
      "step": 11203
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.8382169042475671,
      "learning_rate": 1.226821490232094e-06,
      "loss": 0.4413,
      "step": 11204
    },
    {
      "epoch": 0.78,
      "grad_norm": 3.03505203217616,
      "learning_rate": 1.2260827553856996e-06,
      "loss": 0.4571,
      "step": 11205
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.0986705158434216,
      "learning_rate": 1.2253442119400815e-06,
      "loss": 0.474,
      "step": 11206
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.9991761157144543,
      "learning_rate": 1.2246058599327021e-06,
      "loss": 0.5156,
      "step": 11207
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.9287585434500194,
      "learning_rate": 1.2238676994010035e-06,
      "loss": 0.4971,
      "step": 11208
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.066540643190425,
      "learning_rate": 1.2231297303824253e-06,
      "loss": 0.4988,
      "step": 11209
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.1954222955535463,
      "learning_rate": 1.222391952914393e-06,
      "loss": 0.5,
      "step": 11210
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.0278068569788847,
      "learning_rate": 1.2216543670343246e-06,
      "loss": 0.4794,
      "step": 11211
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.637515427873781,
      "learning_rate": 1.2209169727796288e-06,
      "loss": 0.4528,
      "step": 11212
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.615331854812141,
      "learning_rate": 1.220179770187705e-06,
      "loss": 0.4802,
      "step": 11213
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.1472770121582254,
      "learning_rate": 1.219442759295939e-06,
      "loss": 0.5107,
      "step": 11214
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.174008753429319,
      "learning_rate": 1.2187059401417105e-06,
      "loss": 0.5091,
      "step": 11215
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.8657633778247757,
      "learning_rate": 1.217969312762391e-06,
      "loss": 0.4863,
      "step": 11216
    },
    {
      "epoch": 0.78,
      "grad_norm": 5.751144053538873,
      "learning_rate": 1.2172328771953363e-06,
      "loss": 0.4399,
      "step": 11217
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.978038122556736,
      "learning_rate": 1.2164966334778971e-06,
      "loss": 0.4904,
      "step": 11218
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.256460772241327,
      "learning_rate": 1.2157605816474143e-06,
      "loss": 0.4346,
      "step": 11219
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.1769303888261384,
      "learning_rate": 1.2150247217412186e-06,
      "loss": 0.5087,
      "step": 11220
    },
    {
      "epoch": 0.78,
      "grad_norm": 3.2288683706939474,
      "learning_rate": 1.2142890537966279e-06,
      "loss": 0.5034,
      "step": 11221
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.656606097010023,
      "learning_rate": 1.2135535778509545e-06,
      "loss": 0.5173,
      "step": 11222
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.5590174846052534,
      "learning_rate": 1.2128182939415e-06,
      "loss": 0.4281,
      "step": 11223
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.0909521641059756,
      "learning_rate": 1.212083202105554e-06,
      "loss": 0.4486,
      "step": 11224
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.595267210711982,
      "learning_rate": 1.2113483023803996e-06,
      "loss": 0.5044,
      "step": 11225
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.8913020310705755,
      "learning_rate": 1.210613594803305e-06,
      "loss": 0.4835,
      "step": 11226
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.3748732873289993,
      "learning_rate": 1.2098790794115372e-06,
      "loss": 0.502,
      "step": 11227
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.7304581238403376,
      "learning_rate": 1.2091447562423447e-06,
      "loss": 0.4798,
      "step": 11228
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.1814720154665026,
      "learning_rate": 1.2084106253329725e-06,
      "loss": 0.5078,
      "step": 11229
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.373934015076642,
      "learning_rate": 1.2076766867206497e-06,
      "loss": 0.4939,
      "step": 11230
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.15213261930346,
      "learning_rate": 1.206942940442604e-06,
      "loss": 0.4661,
      "step": 11231
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.375119159608736,
      "learning_rate": 1.2062093865360458e-06,
      "loss": 0.5146,
      "step": 11232
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.2350109639314284,
      "learning_rate": 1.2054760250381797e-06,
      "loss": 0.4769,
      "step": 11233
    },
    {
      "epoch": 0.78,
      "grad_norm": 6.770214056474624,
      "learning_rate": 1.2047428559861973e-06,
      "loss": 0.4731,
      "step": 11234
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.101529560124341,
      "learning_rate": 1.2040098794172844e-06,
      "loss": 0.5091,
      "step": 11235
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.5285702956024476,
      "learning_rate": 1.2032770953686156e-06,
      "loss": 0.4823,
      "step": 11236
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.2822415896988395,
      "learning_rate": 1.2025445038773537e-06,
      "loss": 0.4729,
      "step": 11237
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.017255589735029,
      "learning_rate": 1.2018121049806542e-06,
      "loss": 0.4561,
      "step": 11238
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.0121367423767356,
      "learning_rate": 1.2010798987156613e-06,
      "loss": 0.4878,
      "step": 11239
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.3136101287901485,
      "learning_rate": 1.2003478851195127e-06,
      "loss": 0.5096,
      "step": 11240
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.3726014293861315,
      "learning_rate": 1.1996160642293303e-06,
      "loss": 0.499,
      "step": 11241
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.4756562836871963,
      "learning_rate": 1.198884436082231e-06,
      "loss": 0.4813,
      "step": 11242
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.684072197588434,
      "learning_rate": 1.1981530007153208e-06,
      "loss": 0.5091,
      "step": 11243
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.78333104528989,
      "learning_rate": 1.1974217581656971e-06,
      "loss": 0.5278,
      "step": 11244
    },
    {
      "epoch": 0.78,
      "grad_norm": 24.333369372207287,
      "learning_rate": 1.1966907084704432e-06,
      "loss": 0.5027,
      "step": 11245
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.8994789361109203,
      "learning_rate": 1.1959598516666372e-06,
      "loss": 0.4783,
      "step": 11246
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.343906085450935,
      "learning_rate": 1.195229187791347e-06,
      "loss": 0.5034,
      "step": 11247
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.9918411715984952,
      "learning_rate": 1.1944987168816264e-06,
      "loss": 0.5267,
      "step": 11248
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.048572167928567,
      "learning_rate": 1.1937684389745247e-06,
      "loss": 0.4961,
      "step": 11249
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.6014273223132776,
      "learning_rate": 1.1930383541070784e-06,
      "loss": 0.4336,
      "step": 11250
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.9116811384346444,
      "learning_rate": 1.1923084623163172e-06,
      "loss": 0.4873,
      "step": 11251
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.792736768271821,
      "learning_rate": 1.191578763639255e-06,
      "loss": 0.4608,
      "step": 11252
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.176461535371773,
      "learning_rate": 1.1908492581129021e-06,
      "loss": 0.4868,
      "step": 11253
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.9560187781283114,
      "learning_rate": 1.1901199457742562e-06,
      "loss": 0.5476,
      "step": 11254
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.8063302187415686,
      "learning_rate": 1.1893908266603077e-06,
      "loss": 0.4668,
      "step": 11255
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.8864850086917118,
      "learning_rate": 1.1886619008080307e-06,
      "loss": 0.5154,
      "step": 11256
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.1590876731041453,
      "learning_rate": 1.1879331682543972e-06,
      "loss": 0.4725,
      "step": 11257
    },
    {
      "epoch": 0.78,
      "grad_norm": 8.266322722202617,
      "learning_rate": 1.1872046290363665e-06,
      "loss": 0.4847,
      "step": 11258
    },
    {
      "epoch": 0.78,
      "grad_norm": 10.076150934837836,
      "learning_rate": 1.1864762831908855e-06,
      "loss": 0.42,
      "step": 11259
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.740599418017658,
      "learning_rate": 1.1857481307548957e-06,
      "loss": 0.5102,
      "step": 11260
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.5537239962156637,
      "learning_rate": 1.1850201717653225e-06,
      "loss": 0.5091,
      "step": 11261
    },
    {
      "epoch": 0.78,
      "grad_norm": 4.139774702447737,
      "learning_rate": 1.1842924062590922e-06,
      "loss": 0.4966,
      "step": 11262
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.5508894999190064,
      "learning_rate": 1.1835648342731087e-06,
      "loss": 0.5123,
      "step": 11263
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.07394356209067,
      "learning_rate": 1.1828374558442769e-06,
      "loss": 0.4486,
      "step": 11264
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.2308718481613123,
      "learning_rate": 1.1821102710094812e-06,
      "loss": 0.4889,
      "step": 11265
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.8294963387410954,
      "learning_rate": 1.1813832798056084e-06,
      "loss": 0.4869,
      "step": 11266
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.8853538099001945,
      "learning_rate": 1.1806564822695255e-06,
      "loss": 0.4274,
      "step": 11267
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.01905864805961,
      "learning_rate": 1.1799298784380946e-06,
      "loss": 0.4835,
      "step": 11268
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.6662281737094604,
      "learning_rate": 1.1792034683481652e-06,
      "loss": 0.4546,
      "step": 11269
    },
    {
      "epoch": 0.78,
      "grad_norm": 5.5090088938440935,
      "learning_rate": 1.1784772520365794e-06,
      "loss": 0.4952,
      "step": 11270
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.9113234257328737,
      "learning_rate": 1.1777512295401694e-06,
      "loss": 0.4938,
      "step": 11271
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.2324016983689465,
      "learning_rate": 1.1770254008957549e-06,
      "loss": 0.4986,
      "step": 11272
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.9810233134682491,
      "learning_rate": 1.1762997661401482e-06,
      "loss": 0.5336,
      "step": 11273
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.7481703980630865,
      "learning_rate": 1.1755743253101514e-06,
      "loss": 0.4873,
      "step": 11274
    },
    {
      "epoch": 0.78,
      "grad_norm": 3.7213755339438643,
      "learning_rate": 1.174849078442558e-06,
      "loss": 0.4508,
      "step": 11275
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.02943388550709,
      "learning_rate": 1.174124025574147e-06,
      "loss": 0.4426,
      "step": 11276
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.116310752582798,
      "learning_rate": 1.1733991667416928e-06,
      "loss": 0.4554,
      "step": 11277
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.0455638995930374,
      "learning_rate": 1.1726745019819585e-06,
      "loss": 0.4947,
      "step": 11278
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.126541486261209,
      "learning_rate": 1.1719500313316946e-06,
      "loss": 0.5049,
      "step": 11279
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.3082070414245304,
      "learning_rate": 1.1712257548276445e-06,
      "loss": 0.468,
      "step": 11280
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.1916204764139957,
      "learning_rate": 1.1705016725065416e-06,
      "loss": 0.4954,
      "step": 11281
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.730954054389683,
      "learning_rate": 1.1697777844051105e-06,
      "loss": 0.5039,
      "step": 11282
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.102127425641333,
      "learning_rate": 1.1690540905600616e-06,
      "loss": 0.4618,
      "step": 11283
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.205839899208528,
      "learning_rate": 1.168330591008101e-06,
      "loss": 0.4763,
      "step": 11284
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.5813587856999736,
      "learning_rate": 1.1676072857859184e-06,
      "loss": 0.4114,
      "step": 11285
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.2800840389282615,
      "learning_rate": 1.1668841749302022e-06,
      "loss": 0.5409,
      "step": 11286
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.493451441926252,
      "learning_rate": 1.1661612584776228e-06,
      "loss": 0.5056,
      "step": 11287
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.7398606087218078,
      "learning_rate": 1.165438536464847e-06,
      "loss": 0.4704,
      "step": 11288
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.3517669578757308,
      "learning_rate": 1.1647160089285252e-06,
      "loss": 0.5222,
      "step": 11289
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.9578794244965922,
      "learning_rate": 1.163993675905304e-06,
      "loss": 0.4936,
      "step": 11290
    },
    {
      "epoch": 0.79,
      "grad_norm": 3.0797057327292436,
      "learning_rate": 1.1632715374318188e-06,
      "loss": 0.4872,
      "step": 11291
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.1460655156388824,
      "learning_rate": 1.1625495935446918e-06,
      "loss": 0.4982,
      "step": 11292
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.1417005178283106,
      "learning_rate": 1.161827844280538e-06,
      "loss": 0.4724,
      "step": 11293
    },
    {
      "epoch": 0.79,
      "grad_norm": 4.164515285875398,
      "learning_rate": 1.1611062896759628e-06,
      "loss": 0.4233,
      "step": 11294
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.4680640230164115,
      "learning_rate": 1.1603849297675628e-06,
      "loss": 0.5327,
      "step": 11295
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.5327658205288459,
      "learning_rate": 1.1596637645919201e-06,
      "loss": 0.4109,
      "step": 11296
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.6481835323865455,
      "learning_rate": 1.1589427941856108e-06,
      "loss": 0.497,
      "step": 11297
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.9836435730657271,
      "learning_rate": 1.1582220185852e-06,
      "loss": 0.5395,
      "step": 11298
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.2402512584126923,
      "learning_rate": 1.1575014378272454e-06,
      "loss": 0.4868,
      "step": 11299
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.5501358437638157,
      "learning_rate": 1.1567810519482892e-06,
      "loss": 0.4344,
      "step": 11300
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.6289382406409036,
      "learning_rate": 1.1560608609848684e-06,
      "loss": 0.4727,
      "step": 11301
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.8485978367657714,
      "learning_rate": 1.1553408649735098e-06,
      "loss": 0.4646,
      "step": 11302
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.099211156124894,
      "learning_rate": 1.1546210639507271e-06,
      "loss": 0.464,
      "step": 11303
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.0557596733119268,
      "learning_rate": 1.153901457953029e-06,
      "loss": 0.5218,
      "step": 11304
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.9210127743744658,
      "learning_rate": 1.153182047016907e-06,
      "loss": 0.5094,
      "step": 11305
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.8380933660395,
      "learning_rate": 1.1524628311788526e-06,
      "loss": 0.4554,
      "step": 11306
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.299224368269994,
      "learning_rate": 1.1517438104753386e-06,
      "loss": 0.4666,
      "step": 11307
    },
    {
      "epoch": 0.79,
      "grad_norm": 3.673326196294886,
      "learning_rate": 1.1510249849428346e-06,
      "loss": 0.473,
      "step": 11308
    },
    {
      "epoch": 0.79,
      "grad_norm": 7.216279320070867,
      "learning_rate": 1.150306354617791e-06,
      "loss": 0.4617,
      "step": 11309
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.4089434046766773,
      "learning_rate": 1.1495879195366622e-06,
      "loss": 0.4404,
      "step": 11310
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.048687994828239,
      "learning_rate": 1.1488696797358789e-06,
      "loss": 0.4887,
      "step": 11311
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.788782356830211,
      "learning_rate": 1.1481516352518702e-06,
      "loss": 0.4866,
      "step": 11312
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.249765647670781,
      "learning_rate": 1.1474337861210543e-06,
      "loss": 0.5225,
      "step": 11313
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.1577070418554087,
      "learning_rate": 1.1467161323798354e-06,
      "loss": 0.4778,
      "step": 11314
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.0862595180115044,
      "learning_rate": 1.1459986740646133e-06,
      "loss": 0.4535,
      "step": 11315
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.2439543917308886,
      "learning_rate": 1.1452814112117706e-06,
      "loss": 0.4585,
      "step": 11316
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.3058902757758166,
      "learning_rate": 1.144564343857691e-06,
      "loss": 0.4774,
      "step": 11317
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.3197702126002016,
      "learning_rate": 1.143847472038736e-06,
      "loss": 0.4766,
      "step": 11318
    },
    {
      "epoch": 0.79,
      "grad_norm": 3.813015530376194,
      "learning_rate": 1.143130795791268e-06,
      "loss": 0.4678,
      "step": 11319
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.477908790688111,
      "learning_rate": 1.1424143151516282e-06,
      "loss": 0.4902,
      "step": 11320
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.7261669196499512,
      "learning_rate": 1.141698030156161e-06,
      "loss": 0.5034,
      "step": 11321
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.3830008081793164,
      "learning_rate": 1.1409819408411898e-06,
      "loss": 0.4483,
      "step": 11322
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.5408816562245786,
      "learning_rate": 1.1402660472430344e-06,
      "loss": 0.4504,
      "step": 11323
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.9408009936587147,
      "learning_rate": 1.1395503493980003e-06,
      "loss": 0.4494,
      "step": 11324
    },
    {
      "epoch": 0.79,
      "grad_norm": 4.438290713332655,
      "learning_rate": 1.1388348473423871e-06,
      "loss": 0.4886,
      "step": 11325
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.6580400983612815,
      "learning_rate": 1.1381195411124834e-06,
      "loss": 0.4655,
      "step": 11326
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.0624098664993347,
      "learning_rate": 1.1374044307445647e-06,
      "loss": 0.4821,
      "step": 11327
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.5523391117813242,
      "learning_rate": 1.1366895162749002e-06,
      "loss": 0.4163,
      "step": 11328
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.7686217106544757,
      "learning_rate": 1.135974797739749e-06,
      "loss": 0.4823,
      "step": 11329
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.1584088458803663,
      "learning_rate": 1.1352602751753595e-06,
      "loss": 0.4861,
      "step": 11330
    },
    {
      "epoch": 0.79,
      "grad_norm": 3.955193249860361,
      "learning_rate": 1.1345459486179678e-06,
      "loss": 0.4736,
      "step": 11331
    },
    {
      "epoch": 0.79,
      "grad_norm": 3.7129336857562913,
      "learning_rate": 1.1338318181038037e-06,
      "loss": 0.454,
      "step": 11332
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.5946713294621597,
      "learning_rate": 1.1331178836690853e-06,
      "loss": 0.4868,
      "step": 11333
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.358298929348717,
      "learning_rate": 1.1324041453500222e-06,
      "loss": 0.493,
      "step": 11334
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.6969039540699127,
      "learning_rate": 1.1316906031828107e-06,
      "loss": 0.4899,
      "step": 11335
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.7757689585612684,
      "learning_rate": 1.1309772572036399e-06,
      "loss": 0.4922,
      "step": 11336
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.2665562413857567,
      "learning_rate": 1.1302641074486909e-06,
      "loss": 0.5061,
      "step": 11337
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.9759560678717396,
      "learning_rate": 1.129551153954128e-06,
      "loss": 0.4872,
      "step": 11338
    },
    {
      "epoch": 0.79,
      "grad_norm": 6.955168923248397,
      "learning_rate": 1.1288383967561146e-06,
      "loss": 0.5067,
      "step": 11339
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.269117865412951,
      "learning_rate": 1.1281258358907937e-06,
      "loss": 0.4626,
      "step": 11340
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.4315889769311396,
      "learning_rate": 1.1274134713943102e-06,
      "loss": 0.4709,
      "step": 11341
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.6679102931682934,
      "learning_rate": 1.1267013033027886e-06,
      "loss": 0.4438,
      "step": 11342
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.809902976410208,
      "learning_rate": 1.1259893316523507e-06,
      "loss": 0.5285,
      "step": 11343
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.615496627917842,
      "learning_rate": 1.1252775564791023e-06,
      "loss": 0.5141,
      "step": 11344
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.373252918414234,
      "learning_rate": 1.1245659778191447e-06,
      "loss": 0.4728,
      "step": 11345
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.6296410059212185,
      "learning_rate": 1.1238545957085667e-06,
      "loss": 0.4632,
      "step": 11346
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.709115520208946,
      "learning_rate": 1.1231434101834453e-06,
      "loss": 0.4908,
      "step": 11347
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.0053973954892967,
      "learning_rate": 1.122432421279851e-06,
      "loss": 0.4941,
      "step": 11348
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.2214272241620416,
      "learning_rate": 1.1217216290338428e-06,
      "loss": 0.511,
      "step": 11349
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.4543130783596316,
      "learning_rate": 1.1210110334814711e-06,
      "loss": 0.4772,
      "step": 11350
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.5565467158848831,
      "learning_rate": 1.120300634658772e-06,
      "loss": 0.4259,
      "step": 11351
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.024050873640476,
      "learning_rate": 1.119590432601776e-06,
      "loss": 0.4981,
      "step": 11352
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.400161403756363,
      "learning_rate": 1.1188804273465026e-06,
      "loss": 0.485,
      "step": 11353
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.7527995564773802,
      "learning_rate": 1.118170618928962e-06,
      "loss": 0.4833,
      "step": 11354
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.7265766229029214,
      "learning_rate": 1.117461007385151e-06,
      "loss": 0.4823,
      "step": 11355
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.638577079237779,
      "learning_rate": 1.1167515927510597e-06,
      "loss": 0.4972,
      "step": 11356
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.8293897372551229,
      "learning_rate": 1.1160423750626693e-06,
      "loss": 0.5056,
      "step": 11357
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.5793129964400547,
      "learning_rate": 1.1153333543559453e-06,
      "loss": 0.4484,
      "step": 11358
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.171002619033804,
      "learning_rate": 1.1146245306668501e-06,
      "loss": 0.4871,
      "step": 11359
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.4511468915946275,
      "learning_rate": 1.1139159040313291e-06,
      "loss": 0.5045,
      "step": 11360
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.793798385186544,
      "learning_rate": 1.1132074744853272e-06,
      "loss": 0.4259,
      "step": 11361
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.0936202332800185,
      "learning_rate": 1.1124992420647685e-06,
      "loss": 0.5078,
      "step": 11362
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.118620518352598,
      "learning_rate": 1.1117912068055764e-06,
      "loss": 0.4607,
      "step": 11363
    },
    {
      "epoch": 0.79,
      "grad_norm": 5.263573855524361,
      "learning_rate": 1.1110833687436545e-06,
      "loss": 0.4834,
      "step": 11364
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.6086738235176428,
      "learning_rate": 1.1103757279149086e-06,
      "loss": 0.4269,
      "step": 11365
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.090982734355503,
      "learning_rate": 1.1096682843552237e-06,
      "loss": 0.5212,
      "step": 11366
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.375635246636964,
      "learning_rate": 1.1089610381004812e-06,
      "loss": 0.4909,
      "step": 11367
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.1767570981469286,
      "learning_rate": 1.1082539891865485e-06,
      "loss": 0.5108,
      "step": 11368
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.900790861062502,
      "learning_rate": 1.1075471376492852e-06,
      "loss": 0.4265,
      "step": 11369
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.6548332421325016,
      "learning_rate": 1.1068404835245422e-06,
      "loss": 0.4466,
      "step": 11370
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.1205326538271483,
      "learning_rate": 1.1061340268481564e-06,
      "loss": 0.5102,
      "step": 11371
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.5706585677746968,
      "learning_rate": 1.1054277676559576e-06,
      "loss": 0.423,
      "step": 11372
    },
    {
      "epoch": 0.79,
      "grad_norm": 3.115953257313695,
      "learning_rate": 1.1047217059837661e-06,
      "loss": 0.4374,
      "step": 11373
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.0060415475041435,
      "learning_rate": 1.1040158418673913e-06,
      "loss": 0.4901,
      "step": 11374
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.730574338023705,
      "learning_rate": 1.1033101753426285e-06,
      "loss": 0.4924,
      "step": 11375
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.2151587221035527,
      "learning_rate": 1.1026047064452727e-06,
      "loss": 0.5018,
      "step": 11376
    },
    {
      "epoch": 0.79,
      "grad_norm": 3.706054822049644,
      "learning_rate": 1.1018994352110983e-06,
      "loss": 0.5233,
      "step": 11377
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.2694620476956797,
      "learning_rate": 1.1011943616758774e-06,
      "loss": 0.5113,
      "step": 11378
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.9871163113908563,
      "learning_rate": 1.1004894858753668e-06,
      "loss": 0.4995,
      "step": 11379
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.2069210721649397,
      "learning_rate": 1.0997848078453155e-06,
      "loss": 0.4924,
      "step": 11380
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.6716835629746494,
      "learning_rate": 1.0990803276214652e-06,
      "loss": 0.5225,
      "step": 11381
    },
    {
      "epoch": 0.79,
      "grad_norm": 3.2794476783979047,
      "learning_rate": 1.0983760452395415e-06,
      "loss": 0.4899,
      "step": 11382
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.324206988571971,
      "learning_rate": 1.0976719607352649e-06,
      "loss": 0.4955,
      "step": 11383
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.6639860335453074,
      "learning_rate": 1.096968074144344e-06,
      "loss": 0.437,
      "step": 11384
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.8689275193458583,
      "learning_rate": 1.096264385502479e-06,
      "loss": 0.4592,
      "step": 11385
    },
    {
      "epoch": 0.79,
      "grad_norm": 3.441744891224487,
      "learning_rate": 1.0955608948453562e-06,
      "loss": 0.4819,
      "step": 11386
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.3013862406193146,
      "learning_rate": 1.0948576022086554e-06,
      "loss": 0.4795,
      "step": 11387
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.5848749556873409,
      "learning_rate": 1.0941545076280458e-06,
      "loss": 0.4046,
      "step": 11388
    },
    {
      "epoch": 0.79,
      "grad_norm": 8.712781489557292,
      "learning_rate": 1.0934516111391873e-06,
      "loss": 0.4914,
      "step": 11389
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.110381739061661,
      "learning_rate": 1.0927489127777252e-06,
      "loss": 0.4745,
      "step": 11390
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.3259157196667917,
      "learning_rate": 1.0920464125793001e-06,
      "loss": 0.5068,
      "step": 11391
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.0371952600353356,
      "learning_rate": 1.091344110579542e-06,
      "loss": 0.5027,
      "step": 11392
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.168257138744356,
      "learning_rate": 1.0906420068140655e-06,
      "loss": 0.4652,
      "step": 11393
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.1062987591495794,
      "learning_rate": 1.089940101318483e-06,
      "loss": 0.4856,
      "step": 11394
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.903121126579102,
      "learning_rate": 1.0892383941283884e-06,
      "loss": 0.423,
      "step": 11395
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.9040081572108902,
      "learning_rate": 1.0885368852793753e-06,
      "loss": 0.4821,
      "step": 11396
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.7423421538594133,
      "learning_rate": 1.087835574807018e-06,
      "loss": 0.4543,
      "step": 11397
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.8920651074956127,
      "learning_rate": 1.0871344627468872e-06,
      "loss": 0.4955,
      "step": 11398
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.109366623459001,
      "learning_rate": 1.0864335491345384e-06,
      "loss": 0.5344,
      "step": 11399
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.017062516739796,
      "learning_rate": 1.0857328340055207e-06,
      "loss": 0.5072,
      "step": 11400
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.942887763755433,
      "learning_rate": 1.085032317395373e-06,
      "loss": 0.5036,
      "step": 11401
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.9480055156296823,
      "learning_rate": 1.0843319993396234e-06,
      "loss": 0.4483,
      "step": 11402
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.544741781372592,
      "learning_rate": 1.0836318798737882e-06,
      "loss": 0.5225,
      "step": 11403
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.2207089736532994,
      "learning_rate": 1.0829319590333759e-06,
      "loss": 0.5038,
      "step": 11404
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.961641418268562,
      "learning_rate": 1.082232236853885e-06,
      "loss": 0.5025,
      "step": 11405
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.6994065650046726,
      "learning_rate": 1.0815327133708015e-06,
      "loss": 0.4914,
      "step": 11406
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.7914530112736426,
      "learning_rate": 1.0808333886196038e-06,
      "loss": 0.5011,
      "step": 11407
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.9594651033304418,
      "learning_rate": 1.0801342626357597e-06,
      "loss": 0.5128,
      "step": 11408
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.5526550899409566,
      "learning_rate": 1.079435335454727e-06,
      "loss": 0.4873,
      "step": 11409
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.7925639840637062,
      "learning_rate": 1.0787366071119516e-06,
      "loss": 0.5301,
      "step": 11410
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.3836227649839055,
      "learning_rate": 1.0780380776428712e-06,
      "loss": 0.5187,
      "step": 11411
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.1450241051620633,
      "learning_rate": 1.0773397470829145e-06,
      "loss": 0.4665,
      "step": 11412
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.6839515822888433,
      "learning_rate": 1.0766416154674958e-06,
      "loss": 0.5291,
      "step": 11413
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.7303390075470557,
      "learning_rate": 1.0759436828320246e-06,
      "loss": 0.4385,
      "step": 11414
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.2560644623227235,
      "learning_rate": 1.0752459492118944e-06,
      "loss": 0.5039,
      "step": 11415
    },
    {
      "epoch": 0.79,
      "grad_norm": 3.2645850096760802,
      "learning_rate": 1.0745484146424966e-06,
      "loss": 0.4759,
      "step": 11416
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.9609728183445736,
      "learning_rate": 1.0738510791592044e-06,
      "loss": 0.4765,
      "step": 11417
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.8800188530629467,
      "learning_rate": 1.073153942797387e-06,
      "loss": 0.4911,
      "step": 11418
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.161139935752261,
      "learning_rate": 1.072457005592396e-06,
      "loss": 0.5089,
      "step": 11419
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.107559891774394,
      "learning_rate": 1.0717602675795846e-06,
      "loss": 0.5118,
      "step": 11420
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.040701032100638,
      "learning_rate": 1.0710637287942837e-06,
      "loss": 0.4767,
      "step": 11421
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.1983580570540964,
      "learning_rate": 1.070367389271823e-06,
      "loss": 0.4549,
      "step": 11422
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.0589659277815944,
      "learning_rate": 1.069671249047516e-06,
      "loss": 0.4808,
      "step": 11423
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.4469216614145206,
      "learning_rate": 1.068975308156669e-06,
      "loss": 0.4991,
      "step": 11424
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.629847675391184,
      "learning_rate": 1.0682795666345801e-06,
      "loss": 0.4848,
      "step": 11425
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.2584508671097896,
      "learning_rate": 1.067584024516532e-06,
      "loss": 0.4607,
      "step": 11426
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.530270093360861,
      "learning_rate": 1.0668886818378022e-06,
      "loss": 0.4005,
      "step": 11427
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.0543597531721196,
      "learning_rate": 1.0661935386336553e-06,
      "loss": 0.4882,
      "step": 11428
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.3086689235087463,
      "learning_rate": 1.0654985949393487e-06,
      "loss": 0.503,
      "step": 11429
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.6299707655037365,
      "learning_rate": 1.0648038507901243e-06,
      "loss": 0.468,
      "step": 11430
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.9846643079454078,
      "learning_rate": 1.0641093062212198e-06,
      "loss": 0.4791,
      "step": 11431
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.817505907981926,
      "learning_rate": 1.063414961267859e-06,
      "loss": 0.4699,
      "step": 11432
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.5134863424034729,
      "learning_rate": 1.062720815965259e-06,
      "loss": 0.3979,
      "step": 11433
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.5374673925502003,
      "learning_rate": 1.062026870348622e-06,
      "loss": 0.4299,
      "step": 11434
    },
    {
      "epoch": 0.8,
      "grad_norm": 3.092484870129337,
      "learning_rate": 1.0613331244531433e-06,
      "loss": 0.4728,
      "step": 11435
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.5041696863384657,
      "learning_rate": 1.060639578314009e-06,
      "loss": 0.5071,
      "step": 11436
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.665212163653659,
      "learning_rate": 1.0599462319663906e-06,
      "loss": 0.5162,
      "step": 11437
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.6118868698411366,
      "learning_rate": 1.0592530854454558e-06,
      "loss": 0.4965,
      "step": 11438
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.9814507862716633,
      "learning_rate": 1.0585601387863542e-06,
      "loss": 0.5314,
      "step": 11439
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.2237102261163058,
      "learning_rate": 1.057867392024235e-06,
      "loss": 0.4568,
      "step": 11440
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.8738937088094028,
      "learning_rate": 1.0571748451942282e-06,
      "loss": 0.4875,
      "step": 11441
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.056625829332707,
      "learning_rate": 1.0564824983314592e-06,
      "loss": 0.4825,
      "step": 11442
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.042854952062603,
      "learning_rate": 1.0557903514710411e-06,
      "loss": 0.4498,
      "step": 11443
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.2484450480142772,
      "learning_rate": 1.0550984046480789e-06,
      "loss": 0.5239,
      "step": 11444
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.4671800133547364,
      "learning_rate": 1.054406657897663e-06,
      "loss": 0.5167,
      "step": 11445
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.5530518218637467,
      "learning_rate": 1.0537151112548782e-06,
      "loss": 0.4316,
      "step": 11446
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.0084739126666546,
      "learning_rate": 1.0530237647547986e-06,
      "loss": 0.4569,
      "step": 11447
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.8963992819418407,
      "learning_rate": 1.0523326184324845e-06,
      "loss": 0.4792,
      "step": 11448
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.3692417955469147,
      "learning_rate": 1.051641672322991e-06,
      "loss": 0.5185,
      "step": 11449
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.5463083373582533,
      "learning_rate": 1.050950926461357e-06,
      "loss": 0.4244,
      "step": 11450
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.070926789066972,
      "learning_rate": 1.05026038088262e-06,
      "loss": 0.5,
      "step": 11451
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.0281633033459747,
      "learning_rate": 1.0495700356217985e-06,
      "loss": 0.4626,
      "step": 11452
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.5511711082575985,
      "learning_rate": 1.048879890713907e-06,
      "loss": 0.4716,
      "step": 11453
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.1847215327111473,
      "learning_rate": 1.0481899461939427e-06,
      "loss": 0.4882,
      "step": 11454
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.1087398503754082,
      "learning_rate": 1.0475002020969038e-06,
      "loss": 0.4823,
      "step": 11455
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.206738635008854,
      "learning_rate": 1.0468106584577675e-06,
      "loss": 0.4797,
      "step": 11456
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.267586652151592,
      "learning_rate": 1.046121315311508e-06,
      "loss": 0.4561,
      "step": 11457
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.000653923728783,
      "learning_rate": 1.0454321726930832e-06,
      "loss": 0.4458,
      "step": 11458
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.962622700062574,
      "learning_rate": 1.0447432306374461e-06,
      "loss": 0.4831,
      "step": 11459
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.3128717610345078,
      "learning_rate": 1.044054489179539e-06,
      "loss": 0.5089,
      "step": 11460
    },
    {
      "epoch": 0.8,
      "grad_norm": 3.048181232092817,
      "learning_rate": 1.0433659483542897e-06,
      "loss": 0.4731,
      "step": 11461
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.1458161757430854,
      "learning_rate": 1.04267760819662e-06,
      "loss": 0.4749,
      "step": 11462
    },
    {
      "epoch": 0.8,
      "grad_norm": 3.6517994866738324,
      "learning_rate": 1.0419894687414406e-06,
      "loss": 0.4756,
      "step": 11463
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.9165565725943523,
      "learning_rate": 1.0413015300236523e-06,
      "loss": 0.478,
      "step": 11464
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.8637506862154618,
      "learning_rate": 1.0406137920781433e-06,
      "loss": 0.4434,
      "step": 11465
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.6769876528919827,
      "learning_rate": 1.0399262549397948e-06,
      "loss": 0.5167,
      "step": 11466
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.979229925218737,
      "learning_rate": 1.039238918643477e-06,
      "loss": 0.523,
      "step": 11467
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.044665818598217,
      "learning_rate": 1.0385517832240472e-06,
      "loss": 0.4805,
      "step": 11468
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.9222965592422507,
      "learning_rate": 1.0378648487163557e-06,
      "loss": 0.4806,
      "step": 11469
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.9442293210739934,
      "learning_rate": 1.0371781151552418e-06,
      "loss": 0.4928,
      "step": 11470
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.8198556901222236,
      "learning_rate": 1.0364915825755357e-06,
      "loss": 0.4885,
      "step": 11471
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.1823732497853854,
      "learning_rate": 1.0358052510120537e-06,
      "loss": 0.497,
      "step": 11472
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6076382584406333,
      "learning_rate": 1.0351191204996065e-06,
      "loss": 0.4195,
      "step": 11473
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.0057441720528413,
      "learning_rate": 1.0344331910729888e-06,
      "loss": 0.5071,
      "step": 11474
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.187629611222302,
      "learning_rate": 1.0337474627669936e-06,
      "loss": 0.467,
      "step": 11475
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.563104119588051,
      "learning_rate": 1.0330619356163945e-06,
      "loss": 0.4969,
      "step": 11476
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.5427273245366775,
      "learning_rate": 1.0323766096559635e-06,
      "loss": 0.3904,
      "step": 11477
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.2621207571749067,
      "learning_rate": 1.0316914849204534e-06,
      "loss": 0.5005,
      "step": 11478
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.7510183250642193,
      "learning_rate": 1.031006561444614e-06,
      "loss": 0.4749,
      "step": 11479
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.14191155197324,
      "learning_rate": 1.0303218392631835e-06,
      "loss": 0.5066,
      "step": 11480
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.795502827563149,
      "learning_rate": 1.0296373184108865e-06,
      "loss": 0.502,
      "step": 11481
    },
    {
      "epoch": 0.8,
      "grad_norm": 8.794259905879258,
      "learning_rate": 1.02895299892244e-06,
      "loss": 0.4379,
      "step": 11482
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.6573809474666636,
      "learning_rate": 1.0282688808325514e-06,
      "loss": 0.4539,
      "step": 11483
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.6506559554110667,
      "learning_rate": 1.0275849641759177e-06,
      "loss": 0.4971,
      "step": 11484
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.6623494578575675,
      "learning_rate": 1.0269012489872226e-06,
      "loss": 0.4576,
      "step": 11485
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.9661227462538025,
      "learning_rate": 1.0262177353011432e-06,
      "loss": 0.4163,
      "step": 11486
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.0228070168506114,
      "learning_rate": 1.025534423152345e-06,
      "loss": 0.5028,
      "step": 11487
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.6756846649265533,
      "learning_rate": 1.0248513125754845e-06,
      "loss": 0.4757,
      "step": 11488
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.5518870111638848,
      "learning_rate": 1.0241684036052047e-06,
      "loss": 0.4289,
      "step": 11489
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.5874822108208478,
      "learning_rate": 1.0234856962761408e-06,
      "loss": 0.411,
      "step": 11490
    },
    {
      "epoch": 0.8,
      "grad_norm": 4.191845190416775,
      "learning_rate": 1.0228031906229202e-06,
      "loss": 0.4691,
      "step": 11491
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.8391476815078984,
      "learning_rate": 1.0221208866801536e-06,
      "loss": 0.4626,
      "step": 11492
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.479791479499144,
      "learning_rate": 1.0214387844824485e-06,
      "loss": 0.5106,
      "step": 11493
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.589517509830946,
      "learning_rate": 1.020756884064395e-06,
      "loss": 0.4806,
      "step": 11494
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.092562414838621,
      "learning_rate": 1.0200751854605816e-06,
      "loss": 0.4822,
      "step": 11495
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.5875931944412383,
      "learning_rate": 1.0193936887055783e-06,
      "loss": 0.4564,
      "step": 11496
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.8472954880125843,
      "learning_rate": 1.018712393833951e-06,
      "loss": 0.459,
      "step": 11497
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.378007537426961,
      "learning_rate": 1.0180313008802484e-06,
      "loss": 0.5146,
      "step": 11498
    },
    {
      "epoch": 0.8,
      "grad_norm": 4.105834517478929,
      "learning_rate": 1.0173504098790188e-06,
      "loss": 0.5287,
      "step": 11499
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.0748186256491836,
      "learning_rate": 1.0166697208647914e-06,
      "loss": 0.4789,
      "step": 11500
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.7874395811802175,
      "learning_rate": 1.0159892338720906e-06,
      "loss": 0.5272,
      "step": 11501
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.088828704031328,
      "learning_rate": 1.0153089489354256e-06,
      "loss": 0.4904,
      "step": 11502
    },
    {
      "epoch": 0.8,
      "grad_norm": 3.2101565214641057,
      "learning_rate": 1.0146288660893e-06,
      "loss": 0.4789,
      "step": 11503
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.200957040201979,
      "learning_rate": 1.0139489853682066e-06,
      "loss": 0.4831,
      "step": 11504
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.2475365699034215,
      "learning_rate": 1.0132693068066228e-06,
      "loss": 0.5412,
      "step": 11505
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.0542536715487105,
      "learning_rate": 1.0125898304390246e-06,
      "loss": 0.474,
      "step": 11506
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.8921817961683747,
      "learning_rate": 1.01191055629987e-06,
      "loss": 0.4793,
      "step": 11507
    },
    {
      "epoch": 0.8,
      "grad_norm": 3.950190671778149,
      "learning_rate": 1.0112314844236105e-06,
      "loss": 0.4934,
      "step": 11508
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.9750446639562609,
      "learning_rate": 1.0105526148446837e-06,
      "loss": 0.5091,
      "step": 11509
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.6147500486367288,
      "learning_rate": 1.0098739475975245e-06,
      "loss": 0.4798,
      "step": 11510
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.8426511482750514,
      "learning_rate": 1.009195482716549e-06,
      "loss": 0.4851,
      "step": 11511
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.8533322313470586,
      "learning_rate": 1.0085172202361686e-06,
      "loss": 0.4494,
      "step": 11512
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.5420670033749546,
      "learning_rate": 1.0078391601907811e-06,
      "loss": 0.4266,
      "step": 11513
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.9769348221284528,
      "learning_rate": 1.0071613026147758e-06,
      "loss": 0.4893,
      "step": 11514
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.5714690558110025,
      "learning_rate": 1.0064836475425332e-06,
      "loss": 0.4947,
      "step": 11515
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.1104786800682898,
      "learning_rate": 1.0058061950084192e-06,
      "loss": 0.4883,
      "step": 11516
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.9369515798410617,
      "learning_rate": 1.0051289450467933e-06,
      "loss": 0.4902,
      "step": 11517
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.9133273727754982,
      "learning_rate": 1.0044518976920032e-06,
      "loss": 0.5271,
      "step": 11518
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.087710390549616,
      "learning_rate": 1.003775052978388e-06,
      "loss": 0.4699,
      "step": 11519
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.1071877734939637,
      "learning_rate": 1.003098410940272e-06,
      "loss": 0.4609,
      "step": 11520
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.8603041100445257,
      "learning_rate": 1.0024219716119742e-06,
      "loss": 0.4763,
      "step": 11521
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.218783120942187,
      "learning_rate": 1.001745735027801e-06,
      "loss": 0.5248,
      "step": 11522
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.5425159463743383,
      "learning_rate": 1.0010697012220505e-06,
      "loss": 0.4942,
      "step": 11523
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.0351875668749573,
      "learning_rate": 1.0003938702290061e-06,
      "loss": 0.5032,
      "step": 11524
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.8567022639182305,
      "learning_rate": 9.997182420829455e-07,
      "loss": 0.4723,
      "step": 11525
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.8785036760368596,
      "learning_rate": 9.99042816818135e-07,
      "loss": 0.4667,
      "step": 11526
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.773734328636444,
      "learning_rate": 9.983675944688277e-07,
      "loss": 0.5097,
      "step": 11527
    },
    {
      "epoch": 0.8,
      "grad_norm": 3.2706944143594754,
      "learning_rate": 9.976925750692713e-07,
      "loss": 0.4793,
      "step": 11528
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.1872677899969344,
      "learning_rate": 9.970177586536962e-07,
      "loss": 0.5028,
      "step": 11529
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.237997678664952,
      "learning_rate": 9.963431452563331e-07,
      "loss": 0.4691,
      "step": 11530
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.5913446092502601,
      "learning_rate": 9.956687349113913e-07,
      "loss": 0.4113,
      "step": 11531
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.2158285360543166,
      "learning_rate": 9.949945276530782e-07,
      "loss": 0.4705,
      "step": 11532
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.6402739897181973,
      "learning_rate": 9.943205235155834e-07,
      "loss": 0.4464,
      "step": 11533
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.8202630353777822,
      "learning_rate": 9.93646722533093e-07,
      "loss": 0.5309,
      "step": 11534
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.8051100790365857,
      "learning_rate": 9.929731247397806e-07,
      "loss": 0.5092,
      "step": 11535
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.12233935169144,
      "learning_rate": 9.922997301698063e-07,
      "loss": 0.5019,
      "step": 11536
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.4204707476978946,
      "learning_rate": 9.916265388573236e-07,
      "loss": 0.4855,
      "step": 11537
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.9594303651797704,
      "learning_rate": 9.909535508364753e-07,
      "loss": 0.4684,
      "step": 11538
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.9584764916555963,
      "learning_rate": 9.902807661413937e-07,
      "loss": 0.4981,
      "step": 11539
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.866300320616499,
      "learning_rate": 9.896081848061978e-07,
      "loss": 0.4763,
      "step": 11540
    },
    {
      "epoch": 0.8,
      "grad_norm": 3.735431007703424,
      "learning_rate": 9.889358068650007e-07,
      "loss": 0.485,
      "step": 11541
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.132481797631027,
      "learning_rate": 9.882636323519019e-07,
      "loss": 0.4669,
      "step": 11542
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.8168453266839464,
      "learning_rate": 9.875916613009944e-07,
      "loss": 0.4731,
      "step": 11543
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.7326244609799335,
      "learning_rate": 9.869198937463553e-07,
      "loss": 0.4961,
      "step": 11544
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.0063940737295285,
      "learning_rate": 9.862483297220554e-07,
      "loss": 0.4755,
      "step": 11545
    },
    {
      "epoch": 0.8,
      "grad_norm": 3.633444586670913,
      "learning_rate": 9.855769692621564e-07,
      "loss": 0.5043,
      "step": 11546
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.101685836111847,
      "learning_rate": 9.849058124007044e-07,
      "loss": 0.5123,
      "step": 11547
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.9800477404515033,
      "learning_rate": 9.842348591717403e-07,
      "loss": 0.4478,
      "step": 11548
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.2735147151266166,
      "learning_rate": 9.835641096092902e-07,
      "loss": 0.5109,
      "step": 11549
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.0780428146880587,
      "learning_rate": 9.828935637473763e-07,
      "loss": 0.449,
      "step": 11550
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.1084866779003164,
      "learning_rate": 9.822232216200033e-07,
      "loss": 0.5204,
      "step": 11551
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.655072414388543,
      "learning_rate": 9.815530832611708e-07,
      "loss": 0.4467,
      "step": 11552
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.9550935048629852,
      "learning_rate": 9.808831487048626e-07,
      "loss": 0.474,
      "step": 11553
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.508638315640723,
      "learning_rate": 9.802134179850608e-07,
      "loss": 0.4646,
      "step": 11554
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.48143039362953,
      "learning_rate": 9.795438911357275e-07,
      "loss": 0.5188,
      "step": 11555
    },
    {
      "epoch": 0.8,
      "grad_norm": 3.343228004217565,
      "learning_rate": 9.788745681908225e-07,
      "loss": 0.4902,
      "step": 11556
    },
    {
      "epoch": 0.8,
      "grad_norm": 4.39379375912305,
      "learning_rate": 9.782054491842879e-07,
      "loss": 0.4985,
      "step": 11557
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.2027954119450452,
      "learning_rate": 9.775365341500613e-07,
      "loss": 0.5197,
      "step": 11558
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.9348308626481536,
      "learning_rate": 9.76867823122069e-07,
      "loss": 0.4987,
      "step": 11559
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.3839671537471507,
      "learning_rate": 9.76199316134223e-07,
      "loss": 0.5229,
      "step": 11560
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.509767727199589,
      "learning_rate": 9.7553101322043e-07,
      "loss": 0.4412,
      "step": 11561
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.83915592482706,
      "learning_rate": 9.748629144145827e-07,
      "loss": 0.4809,
      "step": 11562
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.1113361394023324,
      "learning_rate": 9.741950197505673e-07,
      "loss": 0.4751,
      "step": 11563
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.9118061587358317,
      "learning_rate": 9.735273292622543e-07,
      "loss": 0.4569,
      "step": 11564
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.049379964685239,
      "learning_rate": 9.728598429835084e-07,
      "loss": 0.4755,
      "step": 11565
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.0259396813482287,
      "learning_rate": 9.72192560948182e-07,
      "loss": 0.5027,
      "step": 11566
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.186641777525711,
      "learning_rate": 9.715254831901184e-07,
      "loss": 0.4907,
      "step": 11567
    },
    {
      "epoch": 0.8,
      "grad_norm": 3.653785135021109,
      "learning_rate": 9.708586097431477e-07,
      "loss": 0.478,
      "step": 11568
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.6524702554355917,
      "learning_rate": 9.701919406410926e-07,
      "loss": 0.461,
      "step": 11569
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.8250190511780937,
      "learning_rate": 9.695254759177653e-07,
      "loss": 0.4922,
      "step": 11570
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.5805595504097034,
      "learning_rate": 9.688592156069649e-07,
      "loss": 0.4099,
      "step": 11571
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.319465779504187,
      "learning_rate": 9.681931597424821e-07,
      "loss": 0.487,
      "step": 11572
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.6928746730568762,
      "learning_rate": 9.675273083580982e-07,
      "loss": 0.4748,
      "step": 11573
    },
    {
      "epoch": 0.8,
      "grad_norm": 9.185442077213917,
      "learning_rate": 9.668616614875843e-07,
      "loss": 0.4739,
      "step": 11574
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.156506177387179,
      "learning_rate": 9.661962191646968e-07,
      "loss": 0.4912,
      "step": 11575
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.8842260099387147,
      "learning_rate": 9.655309814231857e-07,
      "loss": 0.4904,
      "step": 11576
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.800420317322488,
      "learning_rate": 9.648659482967898e-07,
      "loss": 0.5018,
      "step": 11577
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.363050320504001,
      "learning_rate": 9.642011198192396e-07,
      "loss": 0.5176,
      "step": 11578
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.9761390088257682,
      "learning_rate": 9.6353649602425e-07,
      "loss": 0.4928,
      "step": 11579
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.815011259997566,
      "learning_rate": 9.628720769455292e-07,
      "loss": 0.4912,
      "step": 11580
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.207760690984442,
      "learning_rate": 9.622078626167764e-07,
      "loss": 0.4636,
      "step": 11581
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.119207690818399,
      "learning_rate": 9.615438530716753e-07,
      "loss": 0.5252,
      "step": 11582
    },
    {
      "epoch": 0.81,
      "grad_norm": 17.513598289816482,
      "learning_rate": 9.608800483439051e-07,
      "loss": 0.5113,
      "step": 11583
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.6714547724073369,
      "learning_rate": 9.602164484671284e-07,
      "loss": 0.4289,
      "step": 11584
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.230407042646802,
      "learning_rate": 9.595530534750052e-07,
      "loss": 0.4919,
      "step": 11585
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.006617668797524,
      "learning_rate": 9.588898634011773e-07,
      "loss": 0.5108,
      "step": 11586
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.802306364146151,
      "learning_rate": 9.582268782792825e-07,
      "loss": 0.4846,
      "step": 11587
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.9271247697485054,
      "learning_rate": 9.575640981429418e-07,
      "loss": 0.4635,
      "step": 11588
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.5903075376583069,
      "learning_rate": 9.569015230257712e-07,
      "loss": 0.396,
      "step": 11589
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.0033730197639144,
      "learning_rate": 9.562391529613735e-07,
      "loss": 0.4834,
      "step": 11590
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.2828335643174853,
      "learning_rate": 9.555769879833443e-07,
      "loss": 0.5201,
      "step": 11591
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.5121793837856649,
      "learning_rate": 9.549150281252633e-07,
      "loss": 0.4071,
      "step": 11592
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.05870321634258,
      "learning_rate": 9.542532734207045e-07,
      "loss": 0.4819,
      "step": 11593
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.8945703253469666,
      "learning_rate": 9.535917239032305e-07,
      "loss": 0.4744,
      "step": 11594
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.5460657819379935,
      "learning_rate": 9.529303796063915e-07,
      "loss": 0.4345,
      "step": 11595
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.2930982767841335,
      "learning_rate": 9.52269240563729e-07,
      "loss": 0.4783,
      "step": 11596
    },
    {
      "epoch": 0.81,
      "grad_norm": 3.0021999242489645,
      "learning_rate": 9.51608306808775e-07,
      "loss": 0.456,
      "step": 11597
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.7878079349911749,
      "learning_rate": 9.5094757837505e-07,
      "loss": 0.4816,
      "step": 11598
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.2421662233301443,
      "learning_rate": 9.502870552960619e-07,
      "loss": 0.467,
      "step": 11599
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.9035442539597163,
      "learning_rate": 9.496267376053114e-07,
      "loss": 0.4574,
      "step": 11600
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.2709780982097505,
      "learning_rate": 9.489666253362889e-07,
      "loss": 0.4774,
      "step": 11601
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.0038784342869174,
      "learning_rate": 9.483067185224709e-07,
      "loss": 0.4839,
      "step": 11602
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.0311325597218546,
      "learning_rate": 9.476470171973284e-07,
      "loss": 0.5166,
      "step": 11603
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.7648508583988796,
      "learning_rate": 9.469875213943153e-07,
      "loss": 0.483,
      "step": 11604
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.24815205938029,
      "learning_rate": 9.463282311468835e-07,
      "loss": 0.4553,
      "step": 11605
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.013773467842425,
      "learning_rate": 9.456691464884671e-07,
      "loss": 0.4703,
      "step": 11606
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.8733907274975292,
      "learning_rate": 9.450102674524952e-07,
      "loss": 0.5183,
      "step": 11607
    },
    {
      "epoch": 0.81,
      "grad_norm": 3.0285486827462034,
      "learning_rate": 9.443515940723797e-07,
      "loss": 0.4577,
      "step": 11608
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.4416071506275006,
      "learning_rate": 9.436931263815319e-07,
      "loss": 0.4757,
      "step": 11609
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.0126713083255865,
      "learning_rate": 9.43034864413343e-07,
      "loss": 0.457,
      "step": 11610
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.8345405695012909,
      "learning_rate": 9.423768082012008e-07,
      "loss": 0.4612,
      "step": 11611
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.1086773522557927,
      "learning_rate": 9.417189577784769e-07,
      "loss": 0.5421,
      "step": 11612
    },
    {
      "epoch": 0.81,
      "grad_norm": 4.025270573325493,
      "learning_rate": 9.410613131785368e-07,
      "loss": 0.4924,
      "step": 11613
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.078777331866564,
      "learning_rate": 9.404038744347349e-07,
      "loss": 0.469,
      "step": 11614
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.9353099749956366,
      "learning_rate": 9.397466415804124e-07,
      "loss": 0.5357,
      "step": 11615
    },
    {
      "epoch": 0.81,
      "grad_norm": 4.209833004040669,
      "learning_rate": 9.390896146489031e-07,
      "loss": 0.4394,
      "step": 11616
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.6640905579089744,
      "learning_rate": 9.384327936735293e-07,
      "loss": 0.4602,
      "step": 11617
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.24973309238551,
      "learning_rate": 9.377761786876038e-07,
      "loss": 0.4788,
      "step": 11618
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.9797782327541578,
      "learning_rate": 9.371197697244255e-07,
      "loss": 0.5058,
      "step": 11619
    },
    {
      "epoch": 0.81,
      "grad_norm": 8.635654436313668,
      "learning_rate": 9.364635668172872e-07,
      "loss": 0.4959,
      "step": 11620
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.1118749326496093,
      "learning_rate": 9.358075699994684e-07,
      "loss": 0.485,
      "step": 11621
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.5586589123823095,
      "learning_rate": 9.351517793042408e-07,
      "loss": 0.4144,
      "step": 11622
    },
    {
      "epoch": 0.81,
      "grad_norm": 5.1630040937447506,
      "learning_rate": 9.344961947648624e-07,
      "loss": 0.5148,
      "step": 11623
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.0548919034340263,
      "learning_rate": 9.338408164145818e-07,
      "loss": 0.4907,
      "step": 11624
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.5436203359272841,
      "learning_rate": 9.331856442866405e-07,
      "loss": 0.4188,
      "step": 11625
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.0317174391686206,
      "learning_rate": 9.325306784142629e-07,
      "loss": 0.4743,
      "step": 11626
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.5618233500270301,
      "learning_rate": 9.318759188306703e-07,
      "loss": 0.4376,
      "step": 11627
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.6090129419322503,
      "learning_rate": 9.31221365569065e-07,
      "loss": 0.5114,
      "step": 11628
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.836325389807471,
      "learning_rate": 9.305670186626503e-07,
      "loss": 0.5203,
      "step": 11629
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.8884160096618445,
      "learning_rate": 9.299128781446076e-07,
      "loss": 0.4736,
      "step": 11630
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.599045350598924,
      "learning_rate": 9.292589440481148e-07,
      "loss": 0.5203,
      "step": 11631
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.221477436385583,
      "learning_rate": 9.286052164063369e-07,
      "loss": 0.5304,
      "step": 11632
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.5265179097761865,
      "learning_rate": 9.279516952524304e-07,
      "loss": 0.4749,
      "step": 11633
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.5977660425819975,
      "learning_rate": 9.272983806195363e-07,
      "loss": 0.4944,
      "step": 11634
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.1816619573357605,
      "learning_rate": 9.266452725407915e-07,
      "loss": 0.4389,
      "step": 11635
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.205211244774153,
      "learning_rate": 9.259923710493191e-07,
      "loss": 0.4708,
      "step": 11636
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.9954100426250958,
      "learning_rate": 9.253396761782308e-07,
      "loss": 0.4997,
      "step": 11637
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.6049351447148901,
      "learning_rate": 9.246871879606306e-07,
      "loss": 0.4251,
      "step": 11638
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.137771623187411,
      "learning_rate": 9.240349064296084e-07,
      "loss": 0.5101,
      "step": 11639
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.9072178781637932,
      "learning_rate": 9.233828316182491e-07,
      "loss": 0.5209,
      "step": 11640
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.7276438242504193,
      "learning_rate": 9.22730963559621e-07,
      "loss": 0.4327,
      "step": 11641
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.0906008228347828,
      "learning_rate": 9.220793022867868e-07,
      "loss": 0.4277,
      "step": 11642
    },
    {
      "epoch": 0.81,
      "grad_norm": 3.043523441806853,
      "learning_rate": 9.214278478327937e-07,
      "loss": 0.5089,
      "step": 11643
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.7873709009808159,
      "learning_rate": 9.20776600230685e-07,
      "loss": 0.4847,
      "step": 11644
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.076980089733795,
      "learning_rate": 9.201255595134872e-07,
      "loss": 0.4467,
      "step": 11645
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.9140368550556268,
      "learning_rate": 9.194747257142211e-07,
      "loss": 0.5016,
      "step": 11646
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.033512577007262,
      "learning_rate": 9.188240988658925e-07,
      "loss": 0.447,
      "step": 11647
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.0860100424562384,
      "learning_rate": 9.181736790015e-07,
      "loss": 0.4763,
      "step": 11648
    },
    {
      "epoch": 0.81,
      "grad_norm": 3.6533981127603328,
      "learning_rate": 9.175234661540327e-07,
      "loss": 0.488,
      "step": 11649
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.4308209129810825,
      "learning_rate": 9.168734603564639e-07,
      "loss": 0.4776,
      "step": 11650
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.0693863501347005,
      "learning_rate": 9.162236616417614e-07,
      "loss": 0.4569,
      "step": 11651
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.522570658092641,
      "learning_rate": 9.155740700428811e-07,
      "loss": 0.5206,
      "step": 11652
    },
    {
      "epoch": 0.81,
      "grad_norm": 3.8972028706774835,
      "learning_rate": 9.14924685592769e-07,
      "loss": 0.468,
      "step": 11653
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.4551153043116076,
      "learning_rate": 9.142755083243577e-07,
      "loss": 0.4683,
      "step": 11654
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.1578052934706577,
      "learning_rate": 9.136265382705722e-07,
      "loss": 0.4941,
      "step": 11655
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.9499486763765053,
      "learning_rate": 9.129777754643276e-07,
      "loss": 0.464,
      "step": 11656
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.095374089761724,
      "learning_rate": 9.123292199385247e-07,
      "loss": 0.4921,
      "step": 11657
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.87366702239214,
      "learning_rate": 9.116808717260572e-07,
      "loss": 0.4885,
      "step": 11658
    },
    {
      "epoch": 0.81,
      "grad_norm": 3.108932225106919,
      "learning_rate": 9.110327308598071e-07,
      "loss": 0.4577,
      "step": 11659
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.9006125781083194,
      "learning_rate": 9.103847973726476e-07,
      "loss": 0.4585,
      "step": 11660
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.5703380358793392,
      "learning_rate": 9.097370712974368e-07,
      "loss": 0.4131,
      "step": 11661
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.356932345281679,
      "learning_rate": 9.090895526670279e-07,
      "loss": 0.48,
      "step": 11662
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.3999331034900444,
      "learning_rate": 9.084422415142569e-07,
      "loss": 0.4717,
      "step": 11663
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.3049811062613976,
      "learning_rate": 9.077951378719591e-07,
      "loss": 0.4422,
      "step": 11664
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.1096672019897613,
      "learning_rate": 9.071482417729494e-07,
      "loss": 0.4788,
      "step": 11665
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.2147572273319214,
      "learning_rate": 9.065015532500388e-07,
      "loss": 0.5076,
      "step": 11666
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.1281231798519977,
      "learning_rate": 9.05855072336022e-07,
      "loss": 0.5444,
      "step": 11667
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.10184369617053,
      "learning_rate": 9.052087990636887e-07,
      "loss": 0.4775,
      "step": 11668
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.0634872388538623,
      "learning_rate": 9.045627334658164e-07,
      "loss": 0.4609,
      "step": 11669
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.868901415380547,
      "learning_rate": 9.039168755751693e-07,
      "loss": 0.4764,
      "step": 11670
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.9601981119637115,
      "learning_rate": 9.032712254245041e-07,
      "loss": 0.4611,
      "step": 11671
    },
    {
      "epoch": 0.81,
      "grad_norm": 4.701484806147663,
      "learning_rate": 9.026257830465663e-07,
      "loss": 0.4742,
      "step": 11672
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.88378732427016,
      "learning_rate": 9.019805484740918e-07,
      "loss": 0.4712,
      "step": 11673
    },
    {
      "epoch": 0.81,
      "grad_norm": 4.174912135462484,
      "learning_rate": 9.013355217398023e-07,
      "loss": 0.4551,
      "step": 11674
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.2490115448326558,
      "learning_rate": 9.006907028764128e-07,
      "loss": 0.5041,
      "step": 11675
    },
    {
      "epoch": 0.81,
      "grad_norm": 5.222730048374085,
      "learning_rate": 9.00046091916626e-07,
      "loss": 0.497,
      "step": 11676
    },
    {
      "epoch": 0.81,
      "grad_norm": 4.530043269917611,
      "learning_rate": 8.994016888931362e-07,
      "loss": 0.488,
      "step": 11677
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.6764529412309424,
      "learning_rate": 8.987574938386229e-07,
      "loss": 0.504,
      "step": 11678
    },
    {
      "epoch": 0.81,
      "grad_norm": 9.023232163775297,
      "learning_rate": 8.981135067857588e-07,
      "loss": 0.5082,
      "step": 11679
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.216855538324987,
      "learning_rate": 8.974697277672057e-07,
      "loss": 0.4857,
      "step": 11680
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.187222680098756,
      "learning_rate": 8.968261568156122e-07,
      "loss": 0.5066,
      "step": 11681
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.8518318486252738,
      "learning_rate": 8.961827939636198e-07,
      "loss": 0.4505,
      "step": 11682
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.7383175430743913,
      "learning_rate": 8.955396392438543e-07,
      "loss": 0.4667,
      "step": 11683
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.6839124831162278,
      "learning_rate": 8.948966926889396e-07,
      "loss": 0.5103,
      "step": 11684
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.257595665038397,
      "learning_rate": 8.942539543314799e-07,
      "loss": 0.4695,
      "step": 11685
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.280041839387563,
      "learning_rate": 8.936114242040756e-07,
      "loss": 0.4488,
      "step": 11686
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.215730619996181,
      "learning_rate": 8.9296910233931e-07,
      "loss": 0.4888,
      "step": 11687
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.2089956751874786,
      "learning_rate": 8.923269887697638e-07,
      "loss": 0.4648,
      "step": 11688
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.3949190240673826,
      "learning_rate": 8.91685083528e-07,
      "loss": 0.4905,
      "step": 11689
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.181743467724734,
      "learning_rate": 8.910433866465757e-07,
      "loss": 0.4589,
      "step": 11690
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.324079467682137,
      "learning_rate": 8.904018981580342e-07,
      "loss": 0.5414,
      "step": 11691
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.903164874544658,
      "learning_rate": 8.897606180949097e-07,
      "loss": 0.4903,
      "step": 11692
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.592019470192246,
      "learning_rate": 8.891195464897285e-07,
      "loss": 0.4498,
      "step": 11693
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.0972050107043065,
      "learning_rate": 8.884786833750003e-07,
      "loss": 0.4827,
      "step": 11694
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.9339859200850138,
      "learning_rate": 8.878380287832284e-07,
      "loss": 0.4766,
      "step": 11695
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.3988794726090217,
      "learning_rate": 8.871975827469054e-07,
      "loss": 0.4999,
      "step": 11696
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.8462730167200654,
      "learning_rate": 8.865573452985143e-07,
      "loss": 0.45,
      "step": 11697
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.123534495053879,
      "learning_rate": 8.85917316470521e-07,
      "loss": 0.4686,
      "step": 11698
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.7700124313684358,
      "learning_rate": 8.852774962953914e-07,
      "loss": 0.4962,
      "step": 11699
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.5637414959616148,
      "learning_rate": 8.846378848055715e-07,
      "loss": 0.4244,
      "step": 11700
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.396847254761972,
      "learning_rate": 8.839984820335018e-07,
      "loss": 0.4943,
      "step": 11701
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.8025569350644213,
      "learning_rate": 8.833592880116093e-07,
      "loss": 0.4792,
      "step": 11702
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.7920087131703852,
      "learning_rate": 8.827203027723125e-07,
      "loss": 0.4311,
      "step": 11703
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.72160105594345,
      "learning_rate": 8.820815263480203e-07,
      "loss": 0.4595,
      "step": 11704
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.2731030306501916,
      "learning_rate": 8.814429587711265e-07,
      "loss": 0.4833,
      "step": 11705
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.3601514491539906,
      "learning_rate": 8.808046000740189e-07,
      "loss": 0.4461,
      "step": 11706
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.0920623694596823,
      "learning_rate": 8.801664502890722e-07,
      "loss": 0.5037,
      "step": 11707
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.252668161818456,
      "learning_rate": 8.795285094486533e-07,
      "loss": 0.4733,
      "step": 11708
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.8537755302096848,
      "learning_rate": 8.788907775851135e-07,
      "loss": 0.4853,
      "step": 11709
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.9789918740485357,
      "learning_rate": 8.782532547307982e-07,
      "loss": 0.4737,
      "step": 11710
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.6675207529103253,
      "learning_rate": 8.776159409180396e-07,
      "loss": 0.49,
      "step": 11711
    },
    {
      "epoch": 0.81,
      "grad_norm": 3.556693906305307,
      "learning_rate": 8.76978836179162e-07,
      "loss": 0.5163,
      "step": 11712
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.315503280898535,
      "learning_rate": 8.763419405464751e-07,
      "loss": 0.4819,
      "step": 11713
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.0454146123307,
      "learning_rate": 8.757052540522809e-07,
      "loss": 0.4757,
      "step": 11714
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.4590979496412,
      "learning_rate": 8.750687767288718e-07,
      "loss": 0.4705,
      "step": 11715
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.159776195330514,
      "learning_rate": 8.744325086085248e-07,
      "loss": 0.4812,
      "step": 11716
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.671299854797633,
      "learning_rate": 8.737964497235119e-07,
      "loss": 0.491,
      "step": 11717
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.9135670072144946,
      "learning_rate": 8.731606001060883e-07,
      "loss": 0.4868,
      "step": 11718
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.0186871407452087,
      "learning_rate": 8.725249597885078e-07,
      "loss": 0.4861,
      "step": 11719
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.1713162371490977,
      "learning_rate": 8.718895288030032e-07,
      "loss": 0.4794,
      "step": 11720
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.8954020889896186,
      "learning_rate": 8.712543071818047e-07,
      "loss": 0.5186,
      "step": 11721
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.0291536692837537,
      "learning_rate": 8.706192949571262e-07,
      "loss": 0.5021,
      "step": 11722
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.1455208100473215,
      "learning_rate": 8.699844921611744e-07,
      "loss": 0.4745,
      "step": 11723
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.6251300759472187,
      "learning_rate": 8.693498988261462e-07,
      "loss": 0.4834,
      "step": 11724
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.8502793185317785,
      "learning_rate": 8.687155149842224e-07,
      "loss": 0.4255,
      "step": 11725
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.000517703016088,
      "learning_rate": 8.680813406675798e-07,
      "loss": 0.4969,
      "step": 11726
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.8126390672982737,
      "learning_rate": 8.674473759083801e-07,
      "loss": 0.4935,
      "step": 11727
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.8100890873520705,
      "learning_rate": 8.668136207387779e-07,
      "loss": 0.4433,
      "step": 11728
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.8192758767211812,
      "learning_rate": 8.661800751909128e-07,
      "loss": 0.5052,
      "step": 11729
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.707561484122576,
      "learning_rate": 8.655467392969175e-07,
      "loss": 0.4364,
      "step": 11730
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.5923890939747626,
      "learning_rate": 8.649136130889119e-07,
      "loss": 0.4141,
      "step": 11731
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.2939757739705136,
      "learning_rate": 8.64280696599008e-07,
      "loss": 0.4843,
      "step": 11732
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.7188021411580667,
      "learning_rate": 8.636479898593031e-07,
      "loss": 0.4938,
      "step": 11733
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.9137173794901852,
      "learning_rate": 8.630154929018869e-07,
      "loss": 0.4954,
      "step": 11734
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.258262068174284,
      "learning_rate": 8.623832057588389e-07,
      "loss": 0.5058,
      "step": 11735
    },
    {
      "epoch": 0.82,
      "grad_norm": 5.6554853903497735,
      "learning_rate": 8.617511284622238e-07,
      "loss": 0.4924,
      "step": 11736
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.7524533148204293,
      "learning_rate": 8.611192610441011e-07,
      "loss": 0.4734,
      "step": 11737
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.273761322813978,
      "learning_rate": 8.604876035365134e-07,
      "loss": 0.4493,
      "step": 11738
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.3361280119898495,
      "learning_rate": 8.598561559715013e-07,
      "loss": 0.4614,
      "step": 11739
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6358051129801772,
      "learning_rate": 8.592249183810863e-07,
      "loss": 0.414,
      "step": 11740
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.8685863458153975,
      "learning_rate": 8.585938907972852e-07,
      "loss": 0.4652,
      "step": 11741
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.194106579367335,
      "learning_rate": 8.579630732520977e-07,
      "loss": 0.49,
      "step": 11742
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.0011529116904847,
      "learning_rate": 8.573324657775217e-07,
      "loss": 0.4737,
      "step": 11743
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.095813221737829,
      "learning_rate": 8.567020684055355e-07,
      "loss": 0.4739,
      "step": 11744
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.8104706368877161,
      "learning_rate": 8.56071881168114e-07,
      "loss": 0.5108,
      "step": 11745
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.7982515361965214,
      "learning_rate": 8.554419040972156e-07,
      "loss": 0.4705,
      "step": 11746
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.5636950505958941,
      "learning_rate": 8.54812137224792e-07,
      "loss": 0.4104,
      "step": 11747
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.341794210034744,
      "learning_rate": 8.541825805827836e-07,
      "loss": 0.4534,
      "step": 11748
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.664436327580605,
      "learning_rate": 8.535532342031172e-07,
      "loss": 0.4866,
      "step": 11749
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.0686051310652447,
      "learning_rate": 8.529240981177128e-07,
      "loss": 0.4734,
      "step": 11750
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.0612262629087685,
      "learning_rate": 8.522951723584777e-07,
      "loss": 0.4849,
      "step": 11751
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.43409236831781,
      "learning_rate": 8.516664569573107e-07,
      "loss": 0.5229,
      "step": 11752
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.2962607348302306,
      "learning_rate": 8.510379519460948e-07,
      "loss": 0.5214,
      "step": 11753
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.8079671706614944,
      "learning_rate": 8.504096573567084e-07,
      "loss": 0.4731,
      "step": 11754
    },
    {
      "epoch": 0.82,
      "grad_norm": 3.0326388213858473,
      "learning_rate": 8.497815732210152e-07,
      "loss": 0.511,
      "step": 11755
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.0609719070529606,
      "learning_rate": 8.491536995708715e-07,
      "loss": 0.5253,
      "step": 11756
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.3884229906325056,
      "learning_rate": 8.485260364381187e-07,
      "loss": 0.5015,
      "step": 11757
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.2546325603897253,
      "learning_rate": 8.478985838545906e-07,
      "loss": 0.4698,
      "step": 11758
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.197109380200041,
      "learning_rate": 8.472713418521105e-07,
      "loss": 0.4988,
      "step": 11759
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.207898329336354,
      "learning_rate": 8.466443104624883e-07,
      "loss": 0.4999,
      "step": 11760
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.3671068754188775,
      "learning_rate": 8.460174897175261e-07,
      "loss": 0.4673,
      "step": 11761
    },
    {
      "epoch": 0.82,
      "grad_norm": 3.771544435493363,
      "learning_rate": 8.45390879649014e-07,
      "loss": 0.5264,
      "step": 11762
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.9848543042117397,
      "learning_rate": 8.447644802887328e-07,
      "loss": 0.4372,
      "step": 11763
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.6219744571536615,
      "learning_rate": 8.441382916684493e-07,
      "loss": 0.4217,
      "step": 11764
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.5824931685660777,
      "learning_rate": 8.435123138199225e-07,
      "loss": 0.428,
      "step": 11765
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.083829761566968,
      "learning_rate": 8.428865467749004e-07,
      "loss": 0.4626,
      "step": 11766
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.5936438139367461,
      "learning_rate": 8.422609905651208e-07,
      "loss": 0.4051,
      "step": 11767
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.011962187936982,
      "learning_rate": 8.416356452223073e-07,
      "loss": 0.5049,
      "step": 11768
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.4380104279107018,
      "learning_rate": 8.410105107781769e-07,
      "loss": 0.4622,
      "step": 11769
    },
    {
      "epoch": 0.82,
      "grad_norm": 3.094513809246439,
      "learning_rate": 8.403855872644357e-07,
      "loss": 0.5227,
      "step": 11770
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.7296500576298448,
      "learning_rate": 8.397608747127755e-07,
      "loss": 0.4883,
      "step": 11771
    },
    {
      "epoch": 0.82,
      "grad_norm": 3.392147585199025,
      "learning_rate": 8.391363731548813e-07,
      "loss": 0.4891,
      "step": 11772
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.4605636754907865,
      "learning_rate": 8.38512082622423e-07,
      "loss": 0.525,
      "step": 11773
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.2637048876882346,
      "learning_rate": 8.378880031470666e-07,
      "loss": 0.5164,
      "step": 11774
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.656200090323824,
      "learning_rate": 8.372641347604604e-07,
      "loss": 0.5052,
      "step": 11775
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.0438055688960906,
      "learning_rate": 8.366404774942472e-07,
      "loss": 0.4418,
      "step": 11776
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.6033668953891644,
      "learning_rate": 8.360170313800548e-07,
      "loss": 0.4673,
      "step": 11777
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.2513625701067714,
      "learning_rate": 8.353937964495029e-07,
      "loss": 0.493,
      "step": 11778
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.1201624044103915,
      "learning_rate": 8.347707727342002e-07,
      "loss": 0.4837,
      "step": 11779
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.24178684189859,
      "learning_rate": 8.341479602657454e-07,
      "loss": 0.4308,
      "step": 11780
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.0153892042193755,
      "learning_rate": 8.335253590757241e-07,
      "loss": 0.4467,
      "step": 11781
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.830985773980475,
      "learning_rate": 8.329029691957124e-07,
      "loss": 0.4737,
      "step": 11782
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.9950716328172182,
      "learning_rate": 8.322807906572783e-07,
      "loss": 0.4862,
      "step": 11783
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.1553952982413294,
      "learning_rate": 8.316588234919737e-07,
      "loss": 0.4669,
      "step": 11784
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.6284798548240729,
      "learning_rate": 8.31037067731344e-07,
      "loss": 0.474,
      "step": 11785
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.100630987944442,
      "learning_rate": 8.304155234069223e-07,
      "loss": 0.4504,
      "step": 11786
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.508585921677034,
      "learning_rate": 8.297941905502327e-07,
      "loss": 0.4986,
      "step": 11787
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.733764493533343,
      "learning_rate": 8.291730691927852e-07,
      "loss": 0.5132,
      "step": 11788
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.121981507053675,
      "learning_rate": 8.285521593660822e-07,
      "loss": 0.5038,
      "step": 11789
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.9594239907723787,
      "learning_rate": 8.279314611016149e-07,
      "loss": 0.429,
      "step": 11790
    },
    {
      "epoch": 0.82,
      "grad_norm": 3.407217402787331,
      "learning_rate": 8.273109744308611e-07,
      "loss": 0.472,
      "step": 11791
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.0546065904893758,
      "learning_rate": 8.266906993852919e-07,
      "loss": 0.4391,
      "step": 11792
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.8819018383791635,
      "learning_rate": 8.260706359963622e-07,
      "loss": 0.4644,
      "step": 11793
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.175655403258035,
      "learning_rate": 8.254507842955251e-07,
      "loss": 0.531,
      "step": 11794
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.9837968241800368,
      "learning_rate": 8.248311443142126e-07,
      "loss": 0.4766,
      "step": 11795
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.1421869665558755,
      "learning_rate": 8.242117160838542e-07,
      "loss": 0.4906,
      "step": 11796
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.8996943347094823,
      "learning_rate": 8.235924996358608e-07,
      "loss": 0.4962,
      "step": 11797
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.2381138304462493,
      "learning_rate": 8.229734950016427e-07,
      "loss": 0.4744,
      "step": 11798
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.104545762496072,
      "learning_rate": 8.2235470221259e-07,
      "loss": 0.5388,
      "step": 11799
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.7833460790728495,
      "learning_rate": 8.217361213000874e-07,
      "loss": 0.5042,
      "step": 11800
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.6388918168036946,
      "learning_rate": 8.211177522955061e-07,
      "loss": 0.4612,
      "step": 11801
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.9701537735542571,
      "learning_rate": 8.204995952302087e-07,
      "loss": 0.4391,
      "step": 11802
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.3599576934692217,
      "learning_rate": 8.198816501355467e-07,
      "loss": 0.5968,
      "step": 11803
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.7327939096809035,
      "learning_rate": 8.192639170428585e-07,
      "loss": 0.4346,
      "step": 11804
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.7564816728162116,
      "learning_rate": 8.186463959834739e-07,
      "loss": 0.4738,
      "step": 11805
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.0182523683204403,
      "learning_rate": 8.180290869887125e-07,
      "loss": 0.4906,
      "step": 11806
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.156848897817214,
      "learning_rate": 8.17411990089883e-07,
      "loss": 0.4988,
      "step": 11807
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.501479511758888,
      "learning_rate": 8.167951053182805e-07,
      "loss": 0.4668,
      "step": 11808
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.5561488387080293,
      "learning_rate": 8.161784327051919e-07,
      "loss": 0.4309,
      "step": 11809
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.5494799797594737,
      "learning_rate": 8.155619722818931e-07,
      "loss": 0.4138,
      "step": 11810
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.099265365390003,
      "learning_rate": 8.149457240796499e-07,
      "loss": 0.4321,
      "step": 11811
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.177677907953542,
      "learning_rate": 8.143296881297147e-07,
      "loss": 0.4505,
      "step": 11812
    },
    {
      "epoch": 0.82,
      "grad_norm": 3.15836964994201,
      "learning_rate": 8.137138644633319e-07,
      "loss": 0.4925,
      "step": 11813
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.3238409142812237,
      "learning_rate": 8.130982531117342e-07,
      "loss": 0.4628,
      "step": 11814
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.4301859284505665,
      "learning_rate": 8.124828541061424e-07,
      "loss": 0.4627,
      "step": 11815
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.7611207320435927,
      "learning_rate": 8.118676674777698e-07,
      "loss": 0.4551,
      "step": 11816
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.109203855059429,
      "learning_rate": 8.112526932578118e-07,
      "loss": 0.4481,
      "step": 11817
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.9099416063984669,
      "learning_rate": 8.106379314774638e-07,
      "loss": 0.4844,
      "step": 11818
    },
    {
      "epoch": 0.82,
      "grad_norm": 3.074095168243847,
      "learning_rate": 8.100233821679004e-07,
      "loss": 0.4685,
      "step": 11819
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.1981666351754443,
      "learning_rate": 8.094090453602926e-07,
      "loss": 0.5136,
      "step": 11820
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.6758429266044015,
      "learning_rate": 8.087949210857932e-07,
      "loss": 0.4159,
      "step": 11821
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.673780347061889,
      "learning_rate": 8.081810093755537e-07,
      "loss": 0.4998,
      "step": 11822
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.7737544589762564,
      "learning_rate": 8.075673102607063e-07,
      "loss": 0.4935,
      "step": 11823
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.8146530014182034,
      "learning_rate": 8.069538237723762e-07,
      "loss": 0.4899,
      "step": 11824
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.103723849323278,
      "learning_rate": 8.063405499416799e-07,
      "loss": 0.5148,
      "step": 11825
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.2320226450592804,
      "learning_rate": 8.057274887997174e-07,
      "loss": 0.4609,
      "step": 11826
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.1916898241308806,
      "learning_rate": 8.051146403775839e-07,
      "loss": 0.4749,
      "step": 11827
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.9308391919229155,
      "learning_rate": 8.045020047063567e-07,
      "loss": 0.4356,
      "step": 11828
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.1152362786972105,
      "learning_rate": 8.038895818171127e-07,
      "loss": 0.5022,
      "step": 11829
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.210795749901292,
      "learning_rate": 8.032773717409076e-07,
      "loss": 0.4595,
      "step": 11830
    },
    {
      "epoch": 0.82,
      "grad_norm": 3.2731412897850913,
      "learning_rate": 8.026653745087937e-07,
      "loss": 0.4678,
      "step": 11831
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.5916593273910888,
      "learning_rate": 8.02053590151805e-07,
      "loss": 0.4427,
      "step": 11832
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.9057380767604204,
      "learning_rate": 8.014420187009747e-07,
      "loss": 0.5062,
      "step": 11833
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.7409473508471387,
      "learning_rate": 8.008306601873161e-07,
      "loss": 0.4573,
      "step": 11834
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.6495346601715086,
      "learning_rate": 8.002195146418373e-07,
      "loss": 0.5449,
      "step": 11835
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.5401910535891739,
      "learning_rate": 7.996085820955313e-07,
      "loss": 0.4192,
      "step": 11836
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.079770140097872,
      "learning_rate": 7.989978625793843e-07,
      "loss": 0.4834,
      "step": 11837
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.462970670077635,
      "learning_rate": 7.983873561243704e-07,
      "loss": 0.4763,
      "step": 11838
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.9036041336067444,
      "learning_rate": 7.977770627614512e-07,
      "loss": 0.4274,
      "step": 11839
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.3223698392562473,
      "learning_rate": 7.971669825215789e-07,
      "loss": 0.4657,
      "step": 11840
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.8256862953103756,
      "learning_rate": 7.965571154356954e-07,
      "loss": 0.4422,
      "step": 11841
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.32830584117891,
      "learning_rate": 7.959474615347318e-07,
      "loss": 0.5085,
      "step": 11842
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.044006177009429,
      "learning_rate": 7.953380208496064e-07,
      "loss": 0.4755,
      "step": 11843
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.1264032117498415,
      "learning_rate": 7.94728793411228e-07,
      "loss": 0.492,
      "step": 11844
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.795823128374124,
      "learning_rate": 7.941197792504968e-07,
      "loss": 0.5111,
      "step": 11845
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.8483673025544325,
      "learning_rate": 7.935109783982969e-07,
      "loss": 0.4912,
      "step": 11846
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.050060658522426,
      "learning_rate": 7.929023908855066e-07,
      "loss": 0.4684,
      "step": 11847
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.6387531360041834,
      "learning_rate": 7.92294016742991e-07,
      "loss": 0.4723,
      "step": 11848
    },
    {
      "epoch": 0.82,
      "grad_norm": 4.09358403114972,
      "learning_rate": 7.916858560016061e-07,
      "loss": 0.5084,
      "step": 11849
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.47061655333068,
      "learning_rate": 7.910779086921938e-07,
      "loss": 0.4925,
      "step": 11850
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.1821014430439805,
      "learning_rate": 7.90470174845589e-07,
      "loss": 0.4447,
      "step": 11851
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.271063320232249,
      "learning_rate": 7.898626544926102e-07,
      "loss": 0.4893,
      "step": 11852
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.6482300176714633,
      "learning_rate": 7.892553476640746e-07,
      "loss": 0.4901,
      "step": 11853
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.5708924421880978,
      "learning_rate": 7.886482543907792e-07,
      "loss": 0.3945,
      "step": 11854
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.3357350652254945,
      "learning_rate": 7.880413747035154e-07,
      "loss": 0.4947,
      "step": 11855
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.0124724033177266,
      "learning_rate": 7.874347086330597e-07,
      "loss": 0.4915,
      "step": 11856
    },
    {
      "epoch": 0.82,
      "grad_norm": 4.754587580729607,
      "learning_rate": 7.868282562101819e-07,
      "loss": 0.495,
      "step": 11857
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.132103300160829,
      "learning_rate": 7.862220174656409e-07,
      "loss": 0.4675,
      "step": 11858
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.9262442058504619,
      "learning_rate": 7.856159924301798e-07,
      "loss": 0.4842,
      "step": 11859
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.9700527919998474,
      "learning_rate": 7.850101811345362e-07,
      "loss": 0.4934,
      "step": 11860
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.139945078414461,
      "learning_rate": 7.844045836094343e-07,
      "loss": 0.4379,
      "step": 11861
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.9964912945599098,
      "learning_rate": 7.837991998855899e-07,
      "loss": 0.5504,
      "step": 11862
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.2741137288149575,
      "learning_rate": 7.83194029993703e-07,
      "loss": 0.4893,
      "step": 11863
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.2080025113757094,
      "learning_rate": 7.825890739644676e-07,
      "loss": 0.4511,
      "step": 11864
    },
    {
      "epoch": 0.82,
      "grad_norm": 3.326025257397546,
      "learning_rate": 7.819843318285641e-07,
      "loss": 0.4764,
      "step": 11865
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.253796113693487,
      "learning_rate": 7.813798036166659e-07,
      "loss": 0.5066,
      "step": 11866
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.363692398911388,
      "learning_rate": 7.807754893594288e-07,
      "loss": 0.4991,
      "step": 11867
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.2114754759778883,
      "learning_rate": 7.801713890875034e-07,
      "loss": 0.4528,
      "step": 11868
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.410005638866592,
      "learning_rate": 7.795675028315292e-07,
      "loss": 0.4977,
      "step": 11869
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.128887006454387,
      "learning_rate": 7.789638306221303e-07,
      "loss": 0.4636,
      "step": 11870
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.4989277649672483,
      "learning_rate": 7.783603724899258e-07,
      "loss": 0.5014,
      "step": 11871
    },
    {
      "epoch": 0.83,
      "grad_norm": 3.5241486380700127,
      "learning_rate": 7.777571284655178e-07,
      "loss": 0.5119,
      "step": 11872
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.038735944031431,
      "learning_rate": 7.771540985795051e-07,
      "loss": 0.5493,
      "step": 11873
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.4473510204410087,
      "learning_rate": 7.765512828624683e-07,
      "loss": 0.4884,
      "step": 11874
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.2855773871003944,
      "learning_rate": 7.759486813449818e-07,
      "loss": 0.5044,
      "step": 11875
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.2654344512506635,
      "learning_rate": 7.75346294057605e-07,
      "loss": 0.476,
      "step": 11876
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.9402214220974134,
      "learning_rate": 7.747441210308937e-07,
      "loss": 0.4636,
      "step": 11877
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.7252812147324126,
      "learning_rate": 7.741421622953838e-07,
      "loss": 0.5125,
      "step": 11878
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.905525850180147,
      "learning_rate": 7.735404178816075e-07,
      "loss": 0.4863,
      "step": 11879
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.031308958506441,
      "learning_rate": 7.729388878200811e-07,
      "loss": 0.5211,
      "step": 11880
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.1879790431573287,
      "learning_rate": 7.723375721413134e-07,
      "loss": 0.5198,
      "step": 11881
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.9172687174590075,
      "learning_rate": 7.717364708758024e-07,
      "loss": 0.5011,
      "step": 11882
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.995659635128208,
      "learning_rate": 7.711355840540308e-07,
      "loss": 0.4834,
      "step": 11883
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.423640095707279,
      "learning_rate": 7.705349117064759e-07,
      "loss": 0.4614,
      "step": 11884
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.8643408377144632,
      "learning_rate": 7.699344538636016e-07,
      "loss": 0.4712,
      "step": 11885
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.251594251495589,
      "learning_rate": 7.693342105558621e-07,
      "loss": 0.4346,
      "step": 11886
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.566894954820152,
      "learning_rate": 7.687341818136962e-07,
      "loss": 0.4536,
      "step": 11887
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.300393249446129,
      "learning_rate": 7.681343676675407e-07,
      "loss": 0.523,
      "step": 11888
    },
    {
      "epoch": 0.83,
      "grad_norm": 9.30501746140648,
      "learning_rate": 7.675347681478118e-07,
      "loss": 0.5214,
      "step": 11889
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.8654489625643838,
      "learning_rate": 7.669353832849219e-07,
      "loss": 0.4822,
      "step": 11890
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.4489637764937457,
      "learning_rate": 7.663362131092677e-07,
      "loss": 0.5117,
      "step": 11891
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.008095055802057,
      "learning_rate": 7.657372576512384e-07,
      "loss": 0.4661,
      "step": 11892
    },
    {
      "epoch": 0.83,
      "grad_norm": 3.3836025633243083,
      "learning_rate": 7.651385169412117e-07,
      "loss": 0.5,
      "step": 11893
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.7885208656205145,
      "learning_rate": 7.645399910095519e-07,
      "loss": 0.4922,
      "step": 11894
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.8979336937996967,
      "learning_rate": 7.639416798866156e-07,
      "loss": 0.4632,
      "step": 11895
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.6051761772997386,
      "learning_rate": 7.633435836027469e-07,
      "loss": 0.4838,
      "step": 11896
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.0964670259749423,
      "learning_rate": 7.627457021882806e-07,
      "loss": 0.5019,
      "step": 11897
    },
    {
      "epoch": 0.83,
      "grad_norm": 3.1082107331548987,
      "learning_rate": 7.621480356735367e-07,
      "loss": 0.4869,
      "step": 11898
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.052261022682771,
      "learning_rate": 7.615505840888282e-07,
      "loss": 0.5041,
      "step": 11899
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.8021019787431702,
      "learning_rate": 7.60953347464456e-07,
      "loss": 0.4932,
      "step": 11900
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.8103987609744385,
      "learning_rate": 7.603563258307112e-07,
      "loss": 0.4944,
      "step": 11901
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.2216471304301137,
      "learning_rate": 7.597595192178702e-07,
      "loss": 0.5206,
      "step": 11902
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.361297717152627,
      "learning_rate": 7.591629276562024e-07,
      "loss": 0.4757,
      "step": 11903
    },
    {
      "epoch": 0.83,
      "grad_norm": 4.760588031239285,
      "learning_rate": 7.585665511759666e-07,
      "loss": 0.5082,
      "step": 11904
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.945905336126262,
      "learning_rate": 7.579703898074059e-07,
      "loss": 0.4549,
      "step": 11905
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.1396893834289847,
      "learning_rate": 7.573744435807584e-07,
      "loss": 0.5019,
      "step": 11906
    },
    {
      "epoch": 0.83,
      "grad_norm": 3.4916752871197048,
      "learning_rate": 7.567787125262449e-07,
      "loss": 0.4721,
      "step": 11907
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.0130153890588462,
      "learning_rate": 7.56183196674084e-07,
      "loss": 0.4648,
      "step": 11908
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.577875367998288,
      "learning_rate": 7.555878960544743e-07,
      "loss": 0.4833,
      "step": 11909
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.2389003866688206,
      "learning_rate": 7.549928106976101e-07,
      "loss": 0.4708,
      "step": 11910
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.0997857482826485,
      "learning_rate": 7.543979406336699e-07,
      "loss": 0.4759,
      "step": 11911
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.6621293017399854,
      "learning_rate": 7.538032858928252e-07,
      "loss": 0.4612,
      "step": 11912
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.8371078256223297,
      "learning_rate": 7.532088465052351e-07,
      "loss": 0.4164,
      "step": 11913
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.3093153267431137,
      "learning_rate": 7.526146225010455e-07,
      "loss": 0.507,
      "step": 11914
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.4151677246151517,
      "learning_rate": 7.520206139103959e-07,
      "loss": 0.4795,
      "step": 11915
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.453221229351646,
      "learning_rate": 7.514268207634107e-07,
      "loss": 0.4976,
      "step": 11916
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.9591239170539831,
      "learning_rate": 7.508332430902077e-07,
      "loss": 0.4743,
      "step": 11917
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.342362665935826,
      "learning_rate": 7.502398809208877e-07,
      "loss": 0.5094,
      "step": 11918
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.8808578858763954,
      "learning_rate": 7.496467342855468e-07,
      "loss": 0.4625,
      "step": 11919
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.7678131634883762,
      "learning_rate": 7.490538032142658e-07,
      "loss": 0.4528,
      "step": 11920
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.310506390000274,
      "learning_rate": 7.48461087737119e-07,
      "loss": 0.4462,
      "step": 11921
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.201128838954843,
      "learning_rate": 7.478685878841629e-07,
      "loss": 0.4741,
      "step": 11922
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.0603797184175843,
      "learning_rate": 7.472763036854502e-07,
      "loss": 0.4866,
      "step": 11923
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.1035683913268186,
      "learning_rate": 7.466842351710191e-07,
      "loss": 0.5005,
      "step": 11924
    },
    {
      "epoch": 0.83,
      "grad_norm": 3.2159393146353965,
      "learning_rate": 7.460923823708965e-07,
      "loss": 0.4871,
      "step": 11925
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.4000626281232993,
      "learning_rate": 7.455007453151003e-07,
      "loss": 0.5021,
      "step": 11926
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.0460407302382815,
      "learning_rate": 7.449093240336341e-07,
      "loss": 0.4586,
      "step": 11927
    },
    {
      "epoch": 0.83,
      "grad_norm": 3.040187080899777,
      "learning_rate": 7.443181185564963e-07,
      "loss": 0.4949,
      "step": 11928
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.6888067759506484,
      "learning_rate": 7.437271289136683e-07,
      "loss": 0.4615,
      "step": 11929
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.5391105041923683,
      "learning_rate": 7.431363551351256e-07,
      "loss": 0.496,
      "step": 11930
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.48172737078084,
      "learning_rate": 7.42545797250826e-07,
      "loss": 0.4601,
      "step": 11931
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.9167705720089876,
      "learning_rate": 7.41955455290726e-07,
      "loss": 0.4993,
      "step": 11932
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.370767834688221,
      "learning_rate": 7.413653292847617e-07,
      "loss": 0.4918,
      "step": 11933
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.033664032605762,
      "learning_rate": 7.407754192628658e-07,
      "loss": 0.4769,
      "step": 11934
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.844960598720331,
      "learning_rate": 7.401857252549532e-07,
      "loss": 0.4646,
      "step": 11935
    },
    {
      "epoch": 0.83,
      "grad_norm": 3.0998017865120566,
      "learning_rate": 7.39596247290933e-07,
      "loss": 0.5145,
      "step": 11936
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.5225387436049997,
      "learning_rate": 7.390069854007026e-07,
      "loss": 0.5064,
      "step": 11937
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.476522920399906,
      "learning_rate": 7.38417939614145e-07,
      "loss": 0.5055,
      "step": 11938
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.398181609985512,
      "learning_rate": 7.378291099611357e-07,
      "loss": 0.4642,
      "step": 11939
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.5708358598794888,
      "learning_rate": 7.372404964715385e-07,
      "loss": 0.436,
      "step": 11940
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.982505639859961,
      "learning_rate": 7.366520991752075e-07,
      "loss": 0.4855,
      "step": 11941
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.620436455755694,
      "learning_rate": 7.360639181019813e-07,
      "loss": 0.4096,
      "step": 11942
    },
    {
      "epoch": 0.83,
      "grad_norm": 3.068855159509244,
      "learning_rate": 7.354759532816918e-07,
      "loss": 0.4633,
      "step": 11943
    },
    {
      "epoch": 0.83,
      "grad_norm": 4.878416516121828,
      "learning_rate": 7.348882047441591e-07,
      "loss": 0.5029,
      "step": 11944
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.4222525295836443,
      "learning_rate": 7.343006725191926e-07,
      "loss": 0.4984,
      "step": 11945
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.2606951612190045,
      "learning_rate": 7.337133566365878e-07,
      "loss": 0.4959,
      "step": 11946
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.0767048144050992,
      "learning_rate": 7.331262571261327e-07,
      "loss": 0.5233,
      "step": 11947
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.827023170801003,
      "learning_rate": 7.325393740176046e-07,
      "loss": 0.4961,
      "step": 11948
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.0490551546728906,
      "learning_rate": 7.319527073407651e-07,
      "loss": 0.513,
      "step": 11949
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.0607936917991605,
      "learning_rate": 7.31366257125371e-07,
      "loss": 0.4885,
      "step": 11950
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.260704739312968,
      "learning_rate": 7.307800234011614e-07,
      "loss": 0.4909,
      "step": 11951
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.2345245867054637,
      "learning_rate": 7.301940061978724e-07,
      "loss": 0.5003,
      "step": 11952
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.8916305691092614,
      "learning_rate": 7.296082055452225e-07,
      "loss": 0.5209,
      "step": 11953
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.5640002200121271,
      "learning_rate": 7.290226214729218e-07,
      "loss": 0.4151,
      "step": 11954
    },
    {
      "epoch": 0.83,
      "grad_norm": 3.564787257172038,
      "learning_rate": 7.284372540106699e-07,
      "loss": 0.4814,
      "step": 11955
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.5870352762878848,
      "learning_rate": 7.278521031881553e-07,
      "loss": 0.4798,
      "step": 11956
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.35089976479608,
      "learning_rate": 7.27267169035053e-07,
      "loss": 0.5072,
      "step": 11957
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.941126044437245,
      "learning_rate": 7.2668245158103e-07,
      "loss": 0.4998,
      "step": 11958
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.010557242125463,
      "learning_rate": 7.260979508557419e-07,
      "loss": 0.4946,
      "step": 11959
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.5754040871793911,
      "learning_rate": 7.255136668888313e-07,
      "loss": 0.4389,
      "step": 11960
    },
    {
      "epoch": 0.83,
      "grad_norm": 11.83777108386463,
      "learning_rate": 7.249295997099332e-07,
      "loss": 0.4498,
      "step": 11961
    },
    {
      "epoch": 0.83,
      "grad_norm": 11.19589157073845,
      "learning_rate": 7.243457493486661e-07,
      "loss": 0.5167,
      "step": 11962
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.134694205438641,
      "learning_rate": 7.237621158346447e-07,
      "loss": 0.5084,
      "step": 11963
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.5587176086670773,
      "learning_rate": 7.23178699197467e-07,
      "loss": 0.4286,
      "step": 11964
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.677122353461063,
      "learning_rate": 7.225954994667234e-07,
      "loss": 0.5328,
      "step": 11965
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.7739312447875402,
      "learning_rate": 7.220125166719894e-07,
      "loss": 0.4718,
      "step": 11966
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.224685916641896,
      "learning_rate": 7.214297508428336e-07,
      "loss": 0.4548,
      "step": 11967
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.5408353664838312,
      "learning_rate": 7.208472020088125e-07,
      "loss": 0.4143,
      "step": 11968
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.9087141737865188,
      "learning_rate": 7.202648701994713e-07,
      "loss": 0.4458,
      "step": 11969
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.5586000546490191,
      "learning_rate": 7.196827554443419e-07,
      "loss": 0.41,
      "step": 11970
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.703218115183435,
      "learning_rate": 7.191008577729485e-07,
      "loss": 0.5075,
      "step": 11971
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.224786592599107,
      "learning_rate": 7.185191772148043e-07,
      "loss": 0.5192,
      "step": 11972
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.0171042329495474,
      "learning_rate": 7.179377137994076e-07,
      "loss": 0.4751,
      "step": 11973
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.9610210116488604,
      "learning_rate": 7.1735646755625e-07,
      "loss": 0.5172,
      "step": 11974
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.9620343889752256,
      "learning_rate": 7.167754385148101e-07,
      "loss": 0.472,
      "step": 11975
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.8869991022651107,
      "learning_rate": 7.161946267045566e-07,
      "loss": 0.4776,
      "step": 11976
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.0821114867950543,
      "learning_rate": 7.156140321549448e-07,
      "loss": 0.5038,
      "step": 11977
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.5472321204783035,
      "learning_rate": 7.150336548954218e-07,
      "loss": 0.4003,
      "step": 11978
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.5163934923520324,
      "learning_rate": 7.144534949554227e-07,
      "loss": 0.4914,
      "step": 11979
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.9909023055658452,
      "learning_rate": 7.138735523643697e-07,
      "loss": 0.4721,
      "step": 11980
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.20664807761764,
      "learning_rate": 7.132938271516776e-07,
      "loss": 0.5128,
      "step": 11981
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.137110916471991,
      "learning_rate": 7.127143193467445e-07,
      "loss": 0.4823,
      "step": 11982
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.380446536709534,
      "learning_rate": 7.121350289789663e-07,
      "loss": 0.5117,
      "step": 11983
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.2429439361295818,
      "learning_rate": 7.115559560777191e-07,
      "loss": 0.5294,
      "step": 11984
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.143729462263868,
      "learning_rate": 7.109771006723742e-07,
      "loss": 0.5443,
      "step": 11985
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.5641808998841182,
      "learning_rate": 7.10398462792285e-07,
      "loss": 0.4185,
      "step": 11986
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.105020574963663,
      "learning_rate": 7.098200424668034e-07,
      "loss": 0.5134,
      "step": 11987
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.8624303674140215,
      "learning_rate": 7.092418397252609e-07,
      "loss": 0.4852,
      "step": 11988
    },
    {
      "epoch": 0.83,
      "grad_norm": 3.1869782728431373,
      "learning_rate": 7.086638545969848e-07,
      "loss": 0.4952,
      "step": 11989
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.1820997229864454,
      "learning_rate": 7.080860871112866e-07,
      "loss": 0.4963,
      "step": 11990
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.5796258279234939,
      "learning_rate": 7.0750853729747e-07,
      "loss": 0.4231,
      "step": 11991
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.9026411133861654,
      "learning_rate": 7.069312051848265e-07,
      "loss": 0.4714,
      "step": 11992
    },
    {
      "epoch": 0.83,
      "grad_norm": 3.2097963829412297,
      "learning_rate": 7.06354090802635e-07,
      "loss": 0.4628,
      "step": 11993
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.5498810943182724,
      "learning_rate": 7.057771941801661e-07,
      "loss": 0.475,
      "step": 11994
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.1234944693323006,
      "learning_rate": 7.052005153466779e-07,
      "loss": 0.498,
      "step": 11995
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.007293778346299,
      "learning_rate": 7.046240543314187e-07,
      "loss": 0.4813,
      "step": 11996
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.8866040769903378,
      "learning_rate": 7.040478111636229e-07,
      "loss": 0.4655,
      "step": 11997
    },
    {
      "epoch": 0.83,
      "grad_norm": 3.307242092717069,
      "learning_rate": 7.034717858725165e-07,
      "loss": 0.454,
      "step": 11998
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.3213420330121246,
      "learning_rate": 7.028959784873135e-07,
      "loss": 0.4828,
      "step": 11999
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.7314597140156804,
      "learning_rate": 7.023203890372182e-07,
      "loss": 0.4589,
      "step": 12000
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.0629121001730724,
      "learning_rate": 7.017450175514207e-07,
      "loss": 0.4967,
      "step": 12001
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.4734000886914447,
      "learning_rate": 7.011698640591025e-07,
      "loss": 0.5189,
      "step": 12002
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.449878532331609,
      "learning_rate": 7.005949285894348e-07,
      "loss": 0.4811,
      "step": 12003
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.407395389304542,
      "learning_rate": 7.000202111715743e-07,
      "loss": 0.4442,
      "step": 12004
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.9824737988000547,
      "learning_rate": 6.994457118346715e-07,
      "loss": 0.496,
      "step": 12005
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.589013078088459,
      "learning_rate": 6.988714306078592e-07,
      "loss": 0.4941,
      "step": 12006
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.3740618799612028,
      "learning_rate": 6.982973675202676e-07,
      "loss": 0.484,
      "step": 12007
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.5689634993761788,
      "learning_rate": 6.977235226010077e-07,
      "loss": 0.4248,
      "step": 12008
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.986564550255082,
      "learning_rate": 6.971498958791861e-07,
      "loss": 0.5055,
      "step": 12009
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.285617811233509,
      "learning_rate": 6.965764873838915e-07,
      "loss": 0.4331,
      "step": 12010
    },
    {
      "epoch": 0.84,
      "grad_norm": 3.019359606889107,
      "learning_rate": 6.960032971442094e-07,
      "loss": 0.4768,
      "step": 12011
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.9322709536424205,
      "learning_rate": 6.95430325189207e-07,
      "loss": 0.4633,
      "step": 12012
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.893041900961039,
      "learning_rate": 6.948575715479461e-07,
      "loss": 0.4897,
      "step": 12013
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.0289745489786273,
      "learning_rate": 6.94285036249473e-07,
      "loss": 0.5387,
      "step": 12014
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.2503022384670603,
      "learning_rate": 6.937127193228249e-07,
      "loss": 0.4703,
      "step": 12015
    },
    {
      "epoch": 0.84,
      "grad_norm": 3.6289095503954725,
      "learning_rate": 6.931406207970293e-07,
      "loss": 0.4675,
      "step": 12016
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.9657652112124295,
      "learning_rate": 6.925687407010983e-07,
      "loss": 0.427,
      "step": 12017
    },
    {
      "epoch": 0.84,
      "grad_norm": 7.028630304997008,
      "learning_rate": 6.919970790640401e-07,
      "loss": 0.5633,
      "step": 12018
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.9972383517859482,
      "learning_rate": 6.914256359148435e-07,
      "loss": 0.473,
      "step": 12019
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.2221603101277743,
      "learning_rate": 6.908544112824939e-07,
      "loss": 0.4913,
      "step": 12020
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.5673762515469273,
      "learning_rate": 6.902834051959573e-07,
      "loss": 0.431,
      "step": 12021
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.9010066151041487,
      "learning_rate": 6.897126176841978e-07,
      "loss": 0.5175,
      "step": 12022
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.9752685676445754,
      "learning_rate": 6.891420487761613e-07,
      "loss": 0.485,
      "step": 12023
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.9393431430544013,
      "learning_rate": 6.885716985007867e-07,
      "loss": 0.5235,
      "step": 12024
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.004908080074594,
      "learning_rate": 6.880015668869983e-07,
      "loss": 0.4832,
      "step": 12025
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.625672588052724,
      "learning_rate": 6.874316539637127e-07,
      "loss": 0.5106,
      "step": 12026
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.7919756876509492,
      "learning_rate": 6.868619597598347e-07,
      "loss": 0.5107,
      "step": 12027
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.2790813950582933,
      "learning_rate": 6.862924843042557e-07,
      "loss": 0.4313,
      "step": 12028
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.0119984936713204,
      "learning_rate": 6.857232276258585e-07,
      "loss": 0.499,
      "step": 12029
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.5565132867981945,
      "learning_rate": 6.851541897535136e-07,
      "loss": 0.4171,
      "step": 12030
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.9632075918372514,
      "learning_rate": 6.845853707160821e-07,
      "loss": 0.4648,
      "step": 12031
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.1156506402131563,
      "learning_rate": 6.840167705424106e-07,
      "loss": 0.5078,
      "step": 12032
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.3004286769388393,
      "learning_rate": 6.83448389261337e-07,
      "loss": 0.4635,
      "step": 12033
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.9230621688758167,
      "learning_rate": 6.828802269016899e-07,
      "loss": 0.5027,
      "step": 12034
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.430374579456977,
      "learning_rate": 6.823122834922819e-07,
      "loss": 0.4829,
      "step": 12035
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.9016658642241142,
      "learning_rate": 6.817445590619187e-07,
      "loss": 0.4657,
      "step": 12036
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.6269983762251499,
      "learning_rate": 6.81177053639393e-07,
      "loss": 0.4617,
      "step": 12037
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.206530203971389,
      "learning_rate": 6.806097672534878e-07,
      "loss": 0.482,
      "step": 12038
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.527557453707265,
      "learning_rate": 6.800426999329723e-07,
      "loss": 0.5236,
      "step": 12039
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.5417200806480222,
      "learning_rate": 6.79475851706608e-07,
      "loss": 0.4754,
      "step": 12040
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.8112408426536972,
      "learning_rate": 6.789092226031408e-07,
      "loss": 0.5117,
      "step": 12041
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.0399536722207876,
      "learning_rate": 6.783428126513125e-07,
      "loss": 0.5039,
      "step": 12042
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.6860907122249604,
      "learning_rate": 6.777766218798459e-07,
      "loss": 0.4288,
      "step": 12043
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.9630658360138473,
      "learning_rate": 6.772106503174597e-07,
      "loss": 0.462,
      "step": 12044
    },
    {
      "epoch": 0.84,
      "grad_norm": 3.0462151039690872,
      "learning_rate": 6.766448979928541e-07,
      "loss": 0.4943,
      "step": 12045
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.903040822856045,
      "learning_rate": 6.760793649347253e-07,
      "loss": 0.477,
      "step": 12046
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.6750151689473405,
      "learning_rate": 6.755140511717545e-07,
      "loss": 0.5046,
      "step": 12047
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.138042143791599,
      "learning_rate": 6.749489567326117e-07,
      "loss": 0.4742,
      "step": 12048
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.553850832884588,
      "learning_rate": 6.743840816459574e-07,
      "loss": 0.4994,
      "step": 12049
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.171427255299802,
      "learning_rate": 6.738194259404401e-07,
      "loss": 0.4999,
      "step": 12050
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.5328969070624379,
      "learning_rate": 6.732549896446989e-07,
      "loss": 0.3989,
      "step": 12051
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.04304783732706,
      "learning_rate": 6.726907727873572e-07,
      "loss": 0.4607,
      "step": 12052
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.4607389323166506,
      "learning_rate": 6.721267753970312e-07,
      "loss": 0.5344,
      "step": 12053
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.758065364000503,
      "learning_rate": 6.715629975023258e-07,
      "loss": 0.509,
      "step": 12054
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.9284616209686238,
      "learning_rate": 6.709994391318347e-07,
      "loss": 0.4971,
      "step": 12055
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.2235765812457853,
      "learning_rate": 6.70436100314138e-07,
      "loss": 0.4765,
      "step": 12056
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.9808481931926873,
      "learning_rate": 6.698729810778065e-07,
      "loss": 0.5041,
      "step": 12057
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.6705361482410378,
      "learning_rate": 6.69310081451402e-07,
      "loss": 0.4085,
      "step": 12058
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.962337638508073,
      "learning_rate": 6.687474014634698e-07,
      "loss": 0.4936,
      "step": 12059
    },
    {
      "epoch": 0.84,
      "grad_norm": 6.201733304315728,
      "learning_rate": 6.681849411425501e-07,
      "loss": 0.5144,
      "step": 12060
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.8032004905740058,
      "learning_rate": 6.676227005171653e-07,
      "loss": 0.4706,
      "step": 12061
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.0225421171804947,
      "learning_rate": 6.670606796158352e-07,
      "loss": 0.4577,
      "step": 12062
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.461547246698673,
      "learning_rate": 6.664988784670595e-07,
      "loss": 0.5721,
      "step": 12063
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.162714937841729,
      "learning_rate": 6.659372970993344e-07,
      "loss": 0.493,
      "step": 12064
    },
    {
      "epoch": 0.84,
      "grad_norm": 4.3145663682783235,
      "learning_rate": 6.653759355411377e-07,
      "loss": 0.4901,
      "step": 12065
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.535651456255286,
      "learning_rate": 6.648147938209431e-07,
      "loss": 0.4998,
      "step": 12066
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.019472309062813,
      "learning_rate": 6.642538719672087e-07,
      "loss": 0.462,
      "step": 12067
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.0364959340471276,
      "learning_rate": 6.636931700083827e-07,
      "loss": 0.5454,
      "step": 12068
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.5917052931205564,
      "learning_rate": 6.631326879729017e-07,
      "loss": 0.5009,
      "step": 12069
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.9298247102468036,
      "learning_rate": 6.625724258891908e-07,
      "loss": 0.4952,
      "step": 12070
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.065611571628139,
      "learning_rate": 6.620123837856673e-07,
      "loss": 0.48,
      "step": 12071
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.361695633311375,
      "learning_rate": 6.614525616907319e-07,
      "loss": 0.4705,
      "step": 12072
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.9156820424854588,
      "learning_rate": 6.608929596327785e-07,
      "loss": 0.4917,
      "step": 12073
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.3271536728243634,
      "learning_rate": 6.603335776401871e-07,
      "loss": 0.4638,
      "step": 12074
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.9399846845000315,
      "learning_rate": 6.5977441574133e-07,
      "loss": 0.4682,
      "step": 12075
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.546892941029822,
      "learning_rate": 6.592154739645634e-07,
      "loss": 0.432,
      "step": 12076
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.0653964232996613,
      "learning_rate": 6.586567523382364e-07,
      "loss": 0.4498,
      "step": 12077
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.7650185820379578,
      "learning_rate": 6.580982508906852e-07,
      "loss": 0.5218,
      "step": 12078
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.913589865674627,
      "learning_rate": 6.575399696502361e-07,
      "loss": 0.4787,
      "step": 12079
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.7972861290008424,
      "learning_rate": 6.569819086452018e-07,
      "loss": 0.5053,
      "step": 12080
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.0930546015265463,
      "learning_rate": 6.564240679038858e-07,
      "loss": 0.4057,
      "step": 12081
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.4433827199104914,
      "learning_rate": 6.558664474545817e-07,
      "loss": 0.4756,
      "step": 12082
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.9868825190070936,
      "learning_rate": 6.553090473255675e-07,
      "loss": 0.4874,
      "step": 12083
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.572914075084785,
      "learning_rate": 6.547518675451136e-07,
      "loss": 0.5059,
      "step": 12084
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.8107444306090277,
      "learning_rate": 6.541949081414789e-07,
      "loss": 0.4754,
      "step": 12085
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.1554010127235435,
      "learning_rate": 6.536381691429111e-07,
      "loss": 0.4926,
      "step": 12086
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.7408008203956546,
      "learning_rate": 6.530816505776444e-07,
      "loss": 0.4481,
      "step": 12087
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.5580689620096955,
      "learning_rate": 6.52525352473905e-07,
      "loss": 0.5265,
      "step": 12088
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.416295188680615,
      "learning_rate": 6.51969274859906e-07,
      "loss": 0.4596,
      "step": 12089
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.31301167097098,
      "learning_rate": 6.514134177638509e-07,
      "loss": 0.5043,
      "step": 12090
    },
    {
      "epoch": 0.84,
      "grad_norm": 5.9005715777342385,
      "learning_rate": 6.508577812139288e-07,
      "loss": 0.459,
      "step": 12091
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.0217317607691716,
      "learning_rate": 6.503023652383211e-07,
      "loss": 0.4501,
      "step": 12092
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.9771426017472589,
      "learning_rate": 6.49747169865198e-07,
      "loss": 0.4943,
      "step": 12093
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.9922215839805932,
      "learning_rate": 6.491921951227142e-07,
      "loss": 0.4608,
      "step": 12094
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.0920867334190056,
      "learning_rate": 6.486374410390195e-07,
      "loss": 0.5285,
      "step": 12095
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.751327228085394,
      "learning_rate": 6.480829076422451e-07,
      "loss": 0.4566,
      "step": 12096
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.2940740072533794,
      "learning_rate": 6.475285949605198e-07,
      "loss": 0.4901,
      "step": 12097
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.056037760362927,
      "learning_rate": 6.469745030219531e-07,
      "loss": 0.4751,
      "step": 12098
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.454720295400563,
      "learning_rate": 6.46420631854649e-07,
      "loss": 0.4793,
      "step": 12099
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.05540438684598,
      "learning_rate": 6.458669814866958e-07,
      "loss": 0.4968,
      "step": 12100
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.089514010298916,
      "learning_rate": 6.453135519461745e-07,
      "loss": 0.5272,
      "step": 12101
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.4826337843491633,
      "learning_rate": 6.447603432611533e-07,
      "loss": 0.4851,
      "step": 12102
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.7182882693386987,
      "learning_rate": 6.442073554596879e-07,
      "loss": 0.4971,
      "step": 12103
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.3220619314697695,
      "learning_rate": 6.436545885698243e-07,
      "loss": 0.4432,
      "step": 12104
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.8797195574182362,
      "learning_rate": 6.431020426195977e-07,
      "loss": 0.4687,
      "step": 12105
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.7249753715852858,
      "learning_rate": 6.425497176370321e-07,
      "loss": 0.397,
      "step": 12106
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.8026229654833401,
      "learning_rate": 6.419976136501377e-07,
      "loss": 0.4974,
      "step": 12107
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.964401187399447,
      "learning_rate": 6.414457306869165e-07,
      "loss": 0.4892,
      "step": 12108
    },
    {
      "epoch": 0.84,
      "grad_norm": 4.721247498957968,
      "learning_rate": 6.408940687753585e-07,
      "loss": 0.4891,
      "step": 12109
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.799016050554979,
      "learning_rate": 6.403426279434427e-07,
      "loss": 0.4744,
      "step": 12110
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.6165415469494973,
      "learning_rate": 6.397914082191343e-07,
      "loss": 0.4829,
      "step": 12111
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.1374285961236024,
      "learning_rate": 6.392404096303906e-07,
      "loss": 0.5288,
      "step": 12112
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.9788075685602344,
      "learning_rate": 6.386896322051572e-07,
      "loss": 0.4464,
      "step": 12113
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.7774120559139306,
      "learning_rate": 6.381390759713662e-07,
      "loss": 0.5225,
      "step": 12114
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.36429199903965,
      "learning_rate": 6.37588740956942e-07,
      "loss": 0.4522,
      "step": 12115
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.376309953455077,
      "learning_rate": 6.370386271897922e-07,
      "loss": 0.4704,
      "step": 12116
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.3382418959666516,
      "learning_rate": 6.364887346978211e-07,
      "loss": 0.4864,
      "step": 12117
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.5760820717439801,
      "learning_rate": 6.359390635089146e-07,
      "loss": 0.4183,
      "step": 12118
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.8481370798777532,
      "learning_rate": 6.353896136509524e-07,
      "loss": 0.4879,
      "step": 12119
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.07921666645315,
      "learning_rate": 6.348403851517976e-07,
      "loss": 0.4798,
      "step": 12120
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.8831651895903436,
      "learning_rate": 6.34291378039309e-07,
      "loss": 0.4721,
      "step": 12121
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.6746398717386592,
      "learning_rate": 6.337425923413276e-07,
      "loss": 0.462,
      "step": 12122
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.136336915881553,
      "learning_rate": 6.331940280856886e-07,
      "loss": 0.4859,
      "step": 12123
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.9530375496599688,
      "learning_rate": 6.326456853002105e-07,
      "loss": 0.4841,
      "step": 12124
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.7977058334357805,
      "learning_rate": 6.320975640127048e-07,
      "loss": 0.4921,
      "step": 12125
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.5692822826370545,
      "learning_rate": 6.315496642509716e-07,
      "loss": 0.4175,
      "step": 12126
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.8588557170387165,
      "learning_rate": 6.310019860427963e-07,
      "loss": 0.5256,
      "step": 12127
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.822532781741807,
      "learning_rate": 6.304545294159564e-07,
      "loss": 0.4228,
      "step": 12128
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.224300695076216,
      "learning_rate": 6.299072943982176e-07,
      "loss": 0.4528,
      "step": 12129
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.5670579582805259,
      "learning_rate": 6.293602810173344e-07,
      "loss": 0.4272,
      "step": 12130
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.8147023006985779,
      "learning_rate": 6.288134893010472e-07,
      "loss": 0.4641,
      "step": 12131
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.2088099042579366,
      "learning_rate": 6.282669192770896e-07,
      "loss": 0.4396,
      "step": 12132
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.8905753626141415,
      "learning_rate": 6.277205709731809e-07,
      "loss": 0.4848,
      "step": 12133
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.577620136488257,
      "learning_rate": 6.271744444170313e-07,
      "loss": 0.435,
      "step": 12134
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.5849598038644626,
      "learning_rate": 6.266285396363369e-07,
      "loss": 0.5268,
      "step": 12135
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.9444611610126286,
      "learning_rate": 6.260828566587845e-07,
      "loss": 0.4583,
      "step": 12136
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.6529482639447366,
      "learning_rate": 6.255373955120514e-07,
      "loss": 0.4926,
      "step": 12137
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.617048390544818,
      "learning_rate": 6.249921562237987e-07,
      "loss": 0.4868,
      "step": 12138
    },
    {
      "epoch": 0.84,
      "grad_norm": 4.160662990335112,
      "learning_rate": 6.244471388216816e-07,
      "loss": 0.4608,
      "step": 12139
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.055412748429422,
      "learning_rate": 6.239023433333386e-07,
      "loss": 0.4651,
      "step": 12140
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.805907577238605,
      "learning_rate": 6.233577697864035e-07,
      "loss": 0.5435,
      "step": 12141
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.1029144716714083,
      "learning_rate": 6.228134182084927e-07,
      "loss": 0.4356,
      "step": 12142
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.7532371073444097,
      "learning_rate": 6.222692886272152e-07,
      "loss": 0.5035,
      "step": 12143
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.4522603031886407,
      "learning_rate": 6.217253810701668e-07,
      "loss": 0.4848,
      "step": 12144
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.3369274796089154,
      "learning_rate": 6.211816955649341e-07,
      "loss": 0.452,
      "step": 12145
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.0144525265689017,
      "learning_rate": 6.206382321390892e-07,
      "loss": 0.4614,
      "step": 12146
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.18886726655161,
      "learning_rate": 6.200949908201959e-07,
      "loss": 0.4999,
      "step": 12147
    },
    {
      "epoch": 0.84,
      "grad_norm": 7.145654215486206,
      "learning_rate": 6.195519716358061e-07,
      "loss": 0.436,
      "step": 12148
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.042953792683201,
      "learning_rate": 6.19009174613458e-07,
      "loss": 0.4554,
      "step": 12149
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.8064501624494684,
      "learning_rate": 6.184665997806832e-07,
      "loss": 0.4703,
      "step": 12150
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.9589520720761706,
      "learning_rate": 6.179242471649955e-07,
      "loss": 0.4488,
      "step": 12151
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.8536530002123806,
      "learning_rate": 6.173821167939054e-07,
      "loss": 0.4605,
      "step": 12152
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.8529110513847533,
      "learning_rate": 6.168402086949054e-07,
      "loss": 0.5049,
      "step": 12153
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.9708361004047608,
      "learning_rate": 6.16298522895481e-07,
      "loss": 0.4714,
      "step": 12154
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.9411240397028546,
      "learning_rate": 6.157570594231033e-07,
      "loss": 0.4848,
      "step": 12155
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.4198344115577526,
      "learning_rate": 6.152158183052337e-07,
      "loss": 0.532,
      "step": 12156
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.128257224048138,
      "learning_rate": 6.146747995693225e-07,
      "loss": 0.5244,
      "step": 12157
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.0118061138462355,
      "learning_rate": 6.141340032428095e-07,
      "loss": 0.4705,
      "step": 12158
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.0028011906157626,
      "learning_rate": 6.135934293531203e-07,
      "loss": 0.4498,
      "step": 12159
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.06940458442489,
      "learning_rate": 6.130530779276717e-07,
      "loss": 0.5134,
      "step": 12160
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.7327692222568405,
      "learning_rate": 6.125129489938697e-07,
      "loss": 0.5065,
      "step": 12161
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.6374708886109586,
      "learning_rate": 6.119730425791059e-07,
      "loss": 0.5066,
      "step": 12162
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.9173952103566294,
      "learning_rate": 6.114333587107635e-07,
      "loss": 0.5307,
      "step": 12163
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.8478725155451505,
      "learning_rate": 6.108938974162137e-07,
      "loss": 0.4713,
      "step": 12164
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.447969151090322,
      "learning_rate": 6.103546587228176e-07,
      "loss": 0.5091,
      "step": 12165
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.138053064352397,
      "learning_rate": 6.098156426579205e-07,
      "loss": 0.4447,
      "step": 12166
    },
    {
      "epoch": 0.85,
      "grad_norm": 3.0434385752781905,
      "learning_rate": 6.092768492488616e-07,
      "loss": 0.4774,
      "step": 12167
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.767057195826373,
      "learning_rate": 6.087382785229668e-07,
      "loss": 0.5033,
      "step": 12168
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.9875164444542606,
      "learning_rate": 6.081999305075498e-07,
      "loss": 0.4405,
      "step": 12169
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.8794679246015311,
      "learning_rate": 6.076618052299149e-07,
      "loss": 0.5013,
      "step": 12170
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.637390369278673,
      "learning_rate": 6.071239027173514e-07,
      "loss": 0.4899,
      "step": 12171
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.373164072636895,
      "learning_rate": 6.065862229971436e-07,
      "loss": 0.4751,
      "step": 12172
    },
    {
      "epoch": 0.85,
      "grad_norm": 3.123497415997043,
      "learning_rate": 6.060487660965586e-07,
      "loss": 0.4457,
      "step": 12173
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.519534883532676,
      "learning_rate": 6.055115320428561e-07,
      "loss": 0.4676,
      "step": 12174
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.7936832161989775,
      "learning_rate": 6.049745208632801e-07,
      "loss": 0.4662,
      "step": 12175
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.897500201456215,
      "learning_rate": 6.044377325850692e-07,
      "loss": 0.4749,
      "step": 12176
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.9492633907733283,
      "learning_rate": 6.039011672354456e-07,
      "loss": 0.4793,
      "step": 12177
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.1229997524340316,
      "learning_rate": 6.033648248416235e-07,
      "loss": 0.474,
      "step": 12178
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.409405828223149,
      "learning_rate": 6.02828705430803e-07,
      "loss": 0.4981,
      "step": 12179
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.1241902183730375,
      "learning_rate": 6.022928090301744e-07,
      "loss": 0.5128,
      "step": 12180
    },
    {
      "epoch": 0.85,
      "grad_norm": 3.126972879488434,
      "learning_rate": 6.017571356669183e-07,
      "loss": 0.4732,
      "step": 12181
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.957090097710896,
      "learning_rate": 6.012216853682001e-07,
      "loss": 0.5116,
      "step": 12182
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.6780212582321044,
      "learning_rate": 6.006864581611777e-07,
      "loss": 0.5008,
      "step": 12183
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.888167240838479,
      "learning_rate": 6.001514540729953e-07,
      "loss": 0.4722,
      "step": 12184
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.7924169240681438,
      "learning_rate": 5.996166731307879e-07,
      "loss": 0.4623,
      "step": 12185
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.3675779242417234,
      "learning_rate": 5.990821153616755e-07,
      "loss": 0.4605,
      "step": 12186
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.975790800000941,
      "learning_rate": 5.985477807927703e-07,
      "loss": 0.5498,
      "step": 12187
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.1079538546018113,
      "learning_rate": 5.980136694511724e-07,
      "loss": 0.4946,
      "step": 12188
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.076041803585423,
      "learning_rate": 5.974797813639704e-07,
      "loss": 0.4444,
      "step": 12189
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.7016324208669853,
      "learning_rate": 5.969461165582402e-07,
      "loss": 0.4818,
      "step": 12190
    },
    {
      "epoch": 0.85,
      "grad_norm": 4.2698103216920025,
      "learning_rate": 5.964126750610483e-07,
      "loss": 0.4899,
      "step": 12191
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.619067020271719,
      "learning_rate": 5.958794568994503e-07,
      "loss": 0.4781,
      "step": 12192
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.7115776306023316,
      "learning_rate": 5.953464621004862e-07,
      "loss": 0.4959,
      "step": 12193
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.849627496307458,
      "learning_rate": 5.948136906911911e-07,
      "loss": 0.5246,
      "step": 12194
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.1461759638094784,
      "learning_rate": 5.942811426985817e-07,
      "loss": 0.5452,
      "step": 12195
    },
    {
      "epoch": 0.85,
      "grad_norm": 3.217671480122306,
      "learning_rate": 5.937488181496714e-07,
      "loss": 0.4702,
      "step": 12196
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.9224705315938746,
      "learning_rate": 5.932167170714548e-07,
      "loss": 0.4938,
      "step": 12197
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.1609085012428473,
      "learning_rate": 5.926848394909202e-07,
      "loss": 0.5001,
      "step": 12198
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.5686929235230117,
      "learning_rate": 5.921531854350399e-07,
      "loss": 0.4141,
      "step": 12199
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.886568596618855,
      "learning_rate": 5.916217549307818e-07,
      "loss": 0.4778,
      "step": 12200
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.1019695616398884,
      "learning_rate": 5.910905480050949e-07,
      "loss": 0.5133,
      "step": 12201
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.9125180296439381,
      "learning_rate": 5.905595646849227e-07,
      "loss": 0.4672,
      "step": 12202
    },
    {
      "epoch": 0.85,
      "grad_norm": 3.119507006035204,
      "learning_rate": 5.900288049971931e-07,
      "loss": 0.4851,
      "step": 12203
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.8317677779975605,
      "learning_rate": 5.894982689688244e-07,
      "loss": 0.4722,
      "step": 12204
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.6194559970521505,
      "learning_rate": 5.889679566267259e-07,
      "loss": 0.4907,
      "step": 12205
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.786259384455875,
      "learning_rate": 5.884378679977909e-07,
      "loss": 0.4785,
      "step": 12206
    },
    {
      "epoch": 0.85,
      "grad_norm": 3.4960624832112708,
      "learning_rate": 5.879080031089047e-07,
      "loss": 0.4925,
      "step": 12207
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.415595831379317,
      "learning_rate": 5.873783619869405e-07,
      "loss": 0.4859,
      "step": 12208
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.8856771765227347,
      "learning_rate": 5.868489446587605e-07,
      "loss": 0.5103,
      "step": 12209
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.168752617740829,
      "learning_rate": 5.863197511512125e-07,
      "loss": 0.4616,
      "step": 12210
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.172034083661871,
      "learning_rate": 5.85790781491139e-07,
      "loss": 0.4375,
      "step": 12211
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.882403325432805,
      "learning_rate": 5.852620357053651e-07,
      "loss": 0.4463,
      "step": 12212
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.191566427775765,
      "learning_rate": 5.847335138207089e-07,
      "loss": 0.4896,
      "step": 12213
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.081292770382422,
      "learning_rate": 5.842052158639733e-07,
      "loss": 0.5309,
      "step": 12214
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.8252029615513012,
      "learning_rate": 5.83677141861953e-07,
      "loss": 0.5052,
      "step": 12215
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.9787065790521767,
      "learning_rate": 5.831492918414305e-07,
      "loss": 0.4782,
      "step": 12216
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.156924913518675,
      "learning_rate": 5.826216658291756e-07,
      "loss": 0.4391,
      "step": 12217
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.0800089434318467,
      "learning_rate": 5.820942638519483e-07,
      "loss": 0.5303,
      "step": 12218
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.068676813385061,
      "learning_rate": 5.815670859364964e-07,
      "loss": 0.4817,
      "step": 12219
    },
    {
      "epoch": 0.85,
      "grad_norm": 3.6153142241534106,
      "learning_rate": 5.810401321095582e-07,
      "loss": 0.5035,
      "step": 12220
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.2604081762443995,
      "learning_rate": 5.80513402397857e-07,
      "loss": 0.4858,
      "step": 12221
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.6559070646808642,
      "learning_rate": 5.799868968281075e-07,
      "loss": 0.4555,
      "step": 12222
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.8867567784675048,
      "learning_rate": 5.794606154270139e-07,
      "loss": 0.5429,
      "step": 12223
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.6349500031121855,
      "learning_rate": 5.789345582212647e-07,
      "loss": 0.4024,
      "step": 12224
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.912410285507676,
      "learning_rate": 5.784087252375414e-07,
      "loss": 0.4746,
      "step": 12225
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.8222912393892086,
      "learning_rate": 5.778831165025123e-07,
      "loss": 0.4751,
      "step": 12226
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.020577706899561,
      "learning_rate": 5.773577320428353e-07,
      "loss": 0.4888,
      "step": 12227
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.5827229512796565,
      "learning_rate": 5.768325718851547e-07,
      "loss": 0.4256,
      "step": 12228
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.630128334746928,
      "learning_rate": 5.763076360561071e-07,
      "loss": 0.421,
      "step": 12229
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.6261532957887617,
      "learning_rate": 5.757829245823116e-07,
      "loss": 0.4563,
      "step": 12230
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.9778365332233987,
      "learning_rate": 5.752584374903847e-07,
      "loss": 0.4901,
      "step": 12231
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.99283662819256,
      "learning_rate": 5.747341748069229e-07,
      "loss": 0.5013,
      "step": 12232
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.216272353761666,
      "learning_rate": 5.742101365585178e-07,
      "loss": 0.4892,
      "step": 12233
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.006123158003475,
      "learning_rate": 5.736863227717449e-07,
      "loss": 0.4838,
      "step": 12234
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.1196068324465425,
      "learning_rate": 5.73162733473171e-07,
      "loss": 0.4619,
      "step": 12235
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.046664583731267,
      "learning_rate": 5.726393686893516e-07,
      "loss": 0.482,
      "step": 12236
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.926462273250697,
      "learning_rate": 5.72116228446829e-07,
      "loss": 0.4804,
      "step": 12237
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.1675058151077176,
      "learning_rate": 5.715933127721352e-07,
      "loss": 0.495,
      "step": 12238
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.5334823967603566,
      "learning_rate": 5.71070621691791e-07,
      "loss": 0.4177,
      "step": 12239
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.093119588079017,
      "learning_rate": 5.705481552323072e-07,
      "loss": 0.4455,
      "step": 12240
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.639871232873981,
      "learning_rate": 5.700259134201786e-07,
      "loss": 0.5452,
      "step": 12241
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.8113438380154117,
      "learning_rate": 5.695038962818933e-07,
      "loss": 0.4701,
      "step": 12242
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.7434345250321375,
      "learning_rate": 5.689821038439264e-07,
      "loss": 0.5205,
      "step": 12243
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.883246152000548,
      "learning_rate": 5.684605361327416e-07,
      "loss": 0.4665,
      "step": 12244
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.8453211808810748,
      "learning_rate": 5.679391931747907e-07,
      "loss": 0.5245,
      "step": 12245
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.380467582010352,
      "learning_rate": 5.674180749965136e-07,
      "loss": 0.5084,
      "step": 12246
    },
    {
      "epoch": 0.85,
      "grad_norm": 3.5379682091408253,
      "learning_rate": 5.668971816243423e-07,
      "loss": 0.4301,
      "step": 12247
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.8494640039971206,
      "learning_rate": 5.663765130846921e-07,
      "loss": 0.4678,
      "step": 12248
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.272412963496621,
      "learning_rate": 5.658560694039717e-07,
      "loss": 0.487,
      "step": 12249
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.3891957261190933,
      "learning_rate": 5.653358506085732e-07,
      "loss": 0.444,
      "step": 12250
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.5705515236086421,
      "learning_rate": 5.648158567248845e-07,
      "loss": 0.3961,
      "step": 12251
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.844213401031796,
      "learning_rate": 5.642960877792752e-07,
      "loss": 0.47,
      "step": 12252
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.813061466187491,
      "learning_rate": 5.637765437981079e-07,
      "loss": 0.4448,
      "step": 12253
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.6019076713883856,
      "learning_rate": 5.632572248077295e-07,
      "loss": 0.4179,
      "step": 12254
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.9424466524791097,
      "learning_rate": 5.62738130834482e-07,
      "loss": 0.4965,
      "step": 12255
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.8484773193720998,
      "learning_rate": 5.622192619046896e-07,
      "loss": 0.4819,
      "step": 12256
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.7898886919392907,
      "learning_rate": 5.617006180446688e-07,
      "loss": 0.5176,
      "step": 12257
    },
    {
      "epoch": 0.85,
      "grad_norm": 16.68188481835806,
      "learning_rate": 5.61182199280722e-07,
      "loss": 0.4778,
      "step": 12258
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.9288347135619863,
      "learning_rate": 5.606640056391426e-07,
      "loss": 0.4541,
      "step": 12259
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.8923225264078298,
      "learning_rate": 5.601460371462131e-07,
      "loss": 0.4295,
      "step": 12260
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.8427255641494988,
      "learning_rate": 5.596282938282005e-07,
      "loss": 0.4624,
      "step": 12261
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.985759780463252,
      "learning_rate": 5.591107757113645e-07,
      "loss": 0.4635,
      "step": 12262
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.649607898067778,
      "learning_rate": 5.585934828219519e-07,
      "loss": 0.4732,
      "step": 12263
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.2518899893858597,
      "learning_rate": 5.580764151861989e-07,
      "loss": 0.4689,
      "step": 12264
    },
    {
      "epoch": 0.85,
      "grad_norm": 3.826862632527272,
      "learning_rate": 5.575595728303279e-07,
      "loss": 0.4603,
      "step": 12265
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.229964054550322,
      "learning_rate": 5.570429557805518e-07,
      "loss": 0.4973,
      "step": 12266
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.2454001689729397,
      "learning_rate": 5.565265640630724e-07,
      "loss": 0.5415,
      "step": 12267
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.3858914491825534,
      "learning_rate": 5.560103977040798e-07,
      "loss": 0.4889,
      "step": 12268
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.1061369239335384,
      "learning_rate": 5.55494456729751e-07,
      "loss": 0.4537,
      "step": 12269
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.0558996298332888,
      "learning_rate": 5.549787411662532e-07,
      "loss": 0.4801,
      "step": 12270
    },
    {
      "epoch": 0.85,
      "grad_norm": 6.65710037195479,
      "learning_rate": 5.544632510397429e-07,
      "loss": 0.4324,
      "step": 12271
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.9210789211526587,
      "learning_rate": 5.539479863763625e-07,
      "loss": 0.4725,
      "step": 12272
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.227143808852558,
      "learning_rate": 5.534329472022454e-07,
      "loss": 0.5046,
      "step": 12273
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.8243150417925744,
      "learning_rate": 5.529181335435124e-07,
      "loss": 0.481,
      "step": 12274
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.8465398699112885,
      "learning_rate": 5.524035454262738e-07,
      "loss": 0.4964,
      "step": 12275
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.504562512712974,
      "learning_rate": 5.518891828766271e-07,
      "loss": 0.4775,
      "step": 12276
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.5408995871131768,
      "learning_rate": 5.513750459206591e-07,
      "loss": 0.5078,
      "step": 12277
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.9404184996743785,
      "learning_rate": 5.508611345844456e-07,
      "loss": 0.4838,
      "step": 12278
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.8003918479310963,
      "learning_rate": 5.503474488940513e-07,
      "loss": 0.4604,
      "step": 12279
    },
    {
      "epoch": 0.85,
      "grad_norm": 4.223861367908373,
      "learning_rate": 5.49833988875526e-07,
      "loss": 0.5427,
      "step": 12280
    },
    {
      "epoch": 0.85,
      "grad_norm": 4.923297388050726,
      "learning_rate": 5.493207545549134e-07,
      "loss": 0.472,
      "step": 12281
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.019124089869876,
      "learning_rate": 5.488077459582425e-07,
      "loss": 0.4584,
      "step": 12282
    },
    {
      "epoch": 0.85,
      "grad_norm": 4.066522635354581,
      "learning_rate": 5.482949631115303e-07,
      "loss": 0.5502,
      "step": 12283
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.9970354671557748,
      "learning_rate": 5.477824060407849e-07,
      "loss": 0.5283,
      "step": 12284
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.6879278583798816,
      "learning_rate": 5.472700747719989e-07,
      "loss": 0.489,
      "step": 12285
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.0509022767371317,
      "learning_rate": 5.467579693311603e-07,
      "loss": 0.47,
      "step": 12286
    },
    {
      "epoch": 0.85,
      "grad_norm": 3.5938790574409794,
      "learning_rate": 5.462460897442378e-07,
      "loss": 0.5053,
      "step": 12287
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.1030559557104427,
      "learning_rate": 5.457344360371947e-07,
      "loss": 0.4908,
      "step": 12288
    },
    {
      "epoch": 0.85,
      "grad_norm": 3.056315966902947,
      "learning_rate": 5.452230082359778e-07,
      "loss": 0.4866,
      "step": 12289
    },
    {
      "epoch": 0.85,
      "grad_norm": 3.2698956180431837,
      "learning_rate": 5.447118063665268e-07,
      "loss": 0.5192,
      "step": 12290
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.60517074530896,
      "learning_rate": 5.442008304547691e-07,
      "loss": 0.4936,
      "step": 12291
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.5577465550160507,
      "learning_rate": 5.436900805266171e-07,
      "loss": 0.5195,
      "step": 12292
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.687671246212302,
      "learning_rate": 5.431795566079762e-07,
      "loss": 0.4671,
      "step": 12293
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.1991356049678386,
      "learning_rate": 5.426692587247379e-07,
      "loss": 0.5132,
      "step": 12294
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.975893295372619,
      "learning_rate": 5.421591869027843e-07,
      "loss": 0.483,
      "step": 12295
    },
    {
      "epoch": 0.85,
      "grad_norm": 4.288038065316265,
      "learning_rate": 5.416493411679824e-07,
      "loss": 0.4577,
      "step": 12296
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.6200300799538865,
      "learning_rate": 5.411397215461905e-07,
      "loss": 0.4718,
      "step": 12297
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.676738624581573,
      "learning_rate": 5.406303280632552e-07,
      "loss": 0.4731,
      "step": 12298
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.6951571731210942,
      "learning_rate": 5.401211607450129e-07,
      "loss": 0.4952,
      "step": 12299
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.0641443963483668,
      "learning_rate": 5.396122196172837e-07,
      "loss": 0.4855,
      "step": 12300
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.7159997557032811,
      "learning_rate": 5.391035047058812e-07,
      "loss": 0.4504,
      "step": 12301
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.2023280303436055,
      "learning_rate": 5.385950160366066e-07,
      "loss": 0.4757,
      "step": 12302
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.3908191113810617,
      "learning_rate": 5.380867536352469e-07,
      "loss": 0.4704,
      "step": 12303
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.0794559574644147,
      "learning_rate": 5.37578717527581e-07,
      "loss": 0.5049,
      "step": 12304
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.3068867771339474,
      "learning_rate": 5.370709077393721e-07,
      "loss": 0.5066,
      "step": 12305
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.794362171436657,
      "learning_rate": 5.365633242963792e-07,
      "loss": 0.5033,
      "step": 12306
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.0671277223885127,
      "learning_rate": 5.360559672243421e-07,
      "loss": 0.4722,
      "step": 12307
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.002616100019259,
      "learning_rate": 5.355488365489936e-07,
      "loss": 0.4884,
      "step": 12308
    },
    {
      "epoch": 0.86,
      "grad_norm": 4.060387604185685,
      "learning_rate": 5.35041932296051e-07,
      "loss": 0.4406,
      "step": 12309
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.3732595659315723,
      "learning_rate": 5.345352544912275e-07,
      "loss": 0.5236,
      "step": 12310
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.0706364011786307,
      "learning_rate": 5.340288031602165e-07,
      "loss": 0.4831,
      "step": 12311
    },
    {
      "epoch": 0.86,
      "grad_norm": 3.28712285248918,
      "learning_rate": 5.335225783287051e-07,
      "loss": 0.5039,
      "step": 12312
    },
    {
      "epoch": 0.86,
      "grad_norm": 4.6124281713847655,
      "learning_rate": 5.330165800223669e-07,
      "loss": 0.5214,
      "step": 12313
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.7595061062512447,
      "learning_rate": 5.32510808266864e-07,
      "loss": 0.486,
      "step": 12314
    },
    {
      "epoch": 0.86,
      "grad_norm": 3.789509627536415,
      "learning_rate": 5.320052630878492e-07,
      "loss": 0.4529,
      "step": 12315
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.9427750365161587,
      "learning_rate": 5.314999445109597e-07,
      "loss": 0.4653,
      "step": 12316
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.8193117960487681,
      "learning_rate": 5.309948525618252e-07,
      "loss": 0.4992,
      "step": 12317
    },
    {
      "epoch": 0.86,
      "grad_norm": 4.287082545132608,
      "learning_rate": 5.304899872660618e-07,
      "loss": 0.4772,
      "step": 12318
    },
    {
      "epoch": 0.86,
      "grad_norm": 3.2577999569722116,
      "learning_rate": 5.299853486492762e-07,
      "loss": 0.4979,
      "step": 12319
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.5845743446083536,
      "learning_rate": 5.29480936737059e-07,
      "loss": 0.4167,
      "step": 12320
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.968195632583826,
      "learning_rate": 5.289767515549943e-07,
      "loss": 0.4847,
      "step": 12321
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.5629250047787282,
      "learning_rate": 5.284727931286526e-07,
      "loss": 0.3926,
      "step": 12322
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.4323222584940254,
      "learning_rate": 5.279690614835936e-07,
      "loss": 0.4802,
      "step": 12323
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.1476925876061213,
      "learning_rate": 5.274655566453629e-07,
      "loss": 0.4882,
      "step": 12324
    },
    {
      "epoch": 0.86,
      "grad_norm": 3.305075786413503,
      "learning_rate": 5.269622786394985e-07,
      "loss": 0.5414,
      "step": 12325
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.7204890694517627,
      "learning_rate": 5.264592274915248e-07,
      "loss": 0.508,
      "step": 12326
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.295744370428109,
      "learning_rate": 5.259564032269538e-07,
      "loss": 0.4873,
      "step": 12327
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.018019557553673,
      "learning_rate": 5.254538058712883e-07,
      "loss": 0.4657,
      "step": 12328
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.8351209285559615,
      "learning_rate": 5.249514354500163e-07,
      "loss": 0.4961,
      "step": 12329
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.5611921779509003,
      "learning_rate": 5.244492919886202e-07,
      "loss": 0.386,
      "step": 12330
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.5060407466583206,
      "learning_rate": 5.239473755125634e-07,
      "loss": 0.5246,
      "step": 12331
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.951503094199984,
      "learning_rate": 5.234456860473042e-07,
      "loss": 0.432,
      "step": 12332
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.0739975189171487,
      "learning_rate": 5.229442236182836e-07,
      "loss": 0.5056,
      "step": 12333
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.523257187508116,
      "learning_rate": 5.22442988250938e-07,
      "loss": 0.4631,
      "step": 12334
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.3688955303694224,
      "learning_rate": 5.219419799706849e-07,
      "loss": 0.5185,
      "step": 12335
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.3406061858086367,
      "learning_rate": 5.214411988029355e-07,
      "loss": 0.4606,
      "step": 12336
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.9318916635622547,
      "learning_rate": 5.209406447730886e-07,
      "loss": 0.481,
      "step": 12337
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.9903428317780179,
      "learning_rate": 5.204403179065282e-07,
      "loss": 0.4835,
      "step": 12338
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.63992574032161,
      "learning_rate": 5.199402182286323e-07,
      "loss": 0.5316,
      "step": 12339
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.6939339781013945,
      "learning_rate": 5.194403457647601e-07,
      "loss": 0.4842,
      "step": 12340
    },
    {
      "epoch": 0.86,
      "grad_norm": 3.338025646503701,
      "learning_rate": 5.189407005402686e-07,
      "loss": 0.4243,
      "step": 12341
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.001528216818983,
      "learning_rate": 5.184412825804947e-07,
      "loss": 0.4743,
      "step": 12342
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.9338806246442803,
      "learning_rate": 5.179420919107686e-07,
      "loss": 0.524,
      "step": 12343
    },
    {
      "epoch": 0.86,
      "grad_norm": 4.138578170042801,
      "learning_rate": 5.174431285564057e-07,
      "loss": 0.4924,
      "step": 12344
    },
    {
      "epoch": 0.86,
      "grad_norm": 3.0316767775947935,
      "learning_rate": 5.169443925427154e-07,
      "loss": 0.5069,
      "step": 12345
    },
    {
      "epoch": 0.86,
      "grad_norm": 3.70985811544852,
      "learning_rate": 5.164458838949887e-07,
      "loss": 0.4449,
      "step": 12346
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.610786529246349,
      "learning_rate": 5.159476026385107e-07,
      "loss": 0.4891,
      "step": 12347
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.853615891851956,
      "learning_rate": 5.154495487985506e-07,
      "loss": 0.4857,
      "step": 12348
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.8423698893683158,
      "learning_rate": 5.149517224003686e-07,
      "loss": 0.4723,
      "step": 12349
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.9485133671084485,
      "learning_rate": 5.144541234692147e-07,
      "loss": 0.4833,
      "step": 12350
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.620975781441079,
      "learning_rate": 5.139567520303224e-07,
      "loss": 0.5043,
      "step": 12351
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.7939171045870044,
      "learning_rate": 5.134596081089182e-07,
      "loss": 0.4569,
      "step": 12352
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.0561398638718384,
      "learning_rate": 5.129626917302161e-07,
      "loss": 0.5215,
      "step": 12353
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.8380850090637328,
      "learning_rate": 5.124660029194184e-07,
      "loss": 0.4955,
      "step": 12354
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.8300726143656068,
      "learning_rate": 5.119695417017139e-07,
      "loss": 0.4691,
      "step": 12355
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.257274345428352,
      "learning_rate": 5.114733081022827e-07,
      "loss": 0.4665,
      "step": 12356
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.04759577108535,
      "learning_rate": 5.109773021462921e-07,
      "loss": 0.4674,
      "step": 12357
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.9394744422886503,
      "learning_rate": 5.104815238588973e-07,
      "loss": 0.4919,
      "step": 12358
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.6379339850931578,
      "learning_rate": 5.099859732652429e-07,
      "loss": 0.4785,
      "step": 12359
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.674541408657523,
      "learning_rate": 5.094906503904618e-07,
      "loss": 0.5106,
      "step": 12360
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.534832547449148,
      "learning_rate": 5.089955552596759e-07,
      "loss": 0.5024,
      "step": 12361
    },
    {
      "epoch": 0.86,
      "grad_norm": 4.986025952892122,
      "learning_rate": 5.085006878979926e-07,
      "loss": 0.4723,
      "step": 12362
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.81048383712058,
      "learning_rate": 5.080060483305128e-07,
      "loss": 0.4678,
      "step": 12363
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.358779227057349,
      "learning_rate": 5.07511636582319e-07,
      "loss": 0.4887,
      "step": 12364
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.68191926523936,
      "learning_rate": 5.07017452678491e-07,
      "loss": 0.5068,
      "step": 12365
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.242584955995152,
      "learning_rate": 5.065234966440886e-07,
      "loss": 0.4399,
      "step": 12366
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.4394145265986564,
      "learning_rate": 5.06029768504166e-07,
      "loss": 0.4668,
      "step": 12367
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.096666282064866,
      "learning_rate": 5.055362682837611e-07,
      "loss": 0.5051,
      "step": 12368
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.94608555694017,
      "learning_rate": 5.050429960079039e-07,
      "loss": 0.4899,
      "step": 12369
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.0383365541878673,
      "learning_rate": 5.045499517016128e-07,
      "loss": 0.4752,
      "step": 12370
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.9337996376876478,
      "learning_rate": 5.04057135389891e-07,
      "loss": 0.557,
      "step": 12371
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.2651736633722,
      "learning_rate": 5.03564547097734e-07,
      "loss": 0.4762,
      "step": 12372
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.8267193865011835,
      "learning_rate": 5.030721868501237e-07,
      "loss": 0.4747,
      "step": 12373
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.567930198681575,
      "learning_rate": 5.025800546720322e-07,
      "loss": 0.497,
      "step": 12374
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.904901783918152,
      "learning_rate": 5.020881505884168e-07,
      "loss": 0.4812,
      "step": 12375
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.203116212520071,
      "learning_rate": 5.015964746242263e-07,
      "loss": 0.5522,
      "step": 12376
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.7351979045794066,
      "learning_rate": 5.011050268043971e-07,
      "loss": 0.5093,
      "step": 12377
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.422686959822649,
      "learning_rate": 5.006138071538552e-07,
      "loss": 0.4456,
      "step": 12378
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.1196498049240624,
      "learning_rate": 5.001228156975107e-07,
      "loss": 0.4862,
      "step": 12379
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.998037155197931,
      "learning_rate": 4.996320524602665e-07,
      "loss": 0.4868,
      "step": 12380
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.124908611977181,
      "learning_rate": 4.991415174670134e-07,
      "loss": 0.4633,
      "step": 12381
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.940517415142837,
      "learning_rate": 4.986512107426283e-07,
      "loss": 0.4868,
      "step": 12382
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.6076273176318379,
      "learning_rate": 4.981611323119795e-07,
      "loss": 0.4031,
      "step": 12383
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.8509099267933151,
      "learning_rate": 4.976712821999191e-07,
      "loss": 0.4897,
      "step": 12384
    },
    {
      "epoch": 0.86,
      "grad_norm": 3.043244041394018,
      "learning_rate": 4.971816604312946e-07,
      "loss": 0.4647,
      "step": 12385
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.952260159607214,
      "learning_rate": 4.966922670309354e-07,
      "loss": 0.4388,
      "step": 12386
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.6336899110736663,
      "learning_rate": 4.96203102023664e-07,
      "loss": 0.4127,
      "step": 12387
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.5146999890299635,
      "learning_rate": 4.957141654342862e-07,
      "loss": 0.4591,
      "step": 12388
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.2502695306254448,
      "learning_rate": 4.952254572876025e-07,
      "loss": 0.4685,
      "step": 12389
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.50028328201931,
      "learning_rate": 4.947369776083965e-07,
      "loss": 0.4837,
      "step": 12390
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.0903151476233535,
      "learning_rate": 4.942487264214441e-07,
      "loss": 0.4966,
      "step": 12391
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.203280266373182,
      "learning_rate": 4.937607037515057e-07,
      "loss": 0.5131,
      "step": 12392
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.055404642460075,
      "learning_rate": 4.93272909623333e-07,
      "loss": 0.4698,
      "step": 12393
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.9797983833671577,
      "learning_rate": 4.927853440616665e-07,
      "loss": 0.4919,
      "step": 12394
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.129127698429987,
      "learning_rate": 4.922980070912325e-07,
      "loss": 0.4869,
      "step": 12395
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.782001672407508,
      "learning_rate": 4.918108987367471e-07,
      "loss": 0.5289,
      "step": 12396
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.4687683484338754,
      "learning_rate": 4.913240190229157e-07,
      "loss": 0.5309,
      "step": 12397
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.482618603917297,
      "learning_rate": 4.908373679744316e-07,
      "loss": 0.5311,
      "step": 12398
    },
    {
      "epoch": 0.86,
      "grad_norm": 3.6082461904413,
      "learning_rate": 4.903509456159738e-07,
      "loss": 0.4599,
      "step": 12399
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.8479291356604637,
      "learning_rate": 4.898647519722155e-07,
      "loss": 0.4985,
      "step": 12400
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.9084085709182523,
      "learning_rate": 4.893787870678123e-07,
      "loss": 0.4825,
      "step": 12401
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.0964879238894825,
      "learning_rate": 4.888930509274125e-07,
      "loss": 0.4855,
      "step": 12402
    },
    {
      "epoch": 0.86,
      "grad_norm": 3.153924677612759,
      "learning_rate": 4.884075435756491e-07,
      "loss": 0.4496,
      "step": 12403
    },
    {
      "epoch": 0.86,
      "grad_norm": 4.609152927523817,
      "learning_rate": 4.879222650371462e-07,
      "loss": 0.4965,
      "step": 12404
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.5026812332810437,
      "learning_rate": 4.87437215336517e-07,
      "loss": 0.4921,
      "step": 12405
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.8013720332611474,
      "learning_rate": 4.869523944983595e-07,
      "loss": 0.4598,
      "step": 12406
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.8938970064761211,
      "learning_rate": 4.864678025472635e-07,
      "loss": 0.4366,
      "step": 12407
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.5217304508905778,
      "learning_rate": 4.85983439507805e-07,
      "loss": 0.3982,
      "step": 12408
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.1260159581849867,
      "learning_rate": 4.85499305404551e-07,
      "loss": 0.5404,
      "step": 12409
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.815908980525084,
      "learning_rate": 4.850154002620533e-07,
      "loss": 0.4882,
      "step": 12410
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.9200051195993555,
      "learning_rate": 4.845317241048547e-07,
      "loss": 0.481,
      "step": 12411
    },
    {
      "epoch": 0.86,
      "grad_norm": 3.150616235759188,
      "learning_rate": 4.840482769574861e-07,
      "loss": 0.5276,
      "step": 12412
    },
    {
      "epoch": 0.86,
      "grad_norm": 3.443215366868858,
      "learning_rate": 4.835650588444668e-07,
      "loss": 0.4602,
      "step": 12413
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.364612764069679,
      "learning_rate": 4.830820697903021e-07,
      "loss": 0.4859,
      "step": 12414
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.3960871277143183,
      "learning_rate": 4.825993098194892e-07,
      "loss": 0.4891,
      "step": 12415
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.226958424558984,
      "learning_rate": 4.821167789565124e-07,
      "loss": 0.5151,
      "step": 12416
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.2461627238973088,
      "learning_rate": 4.816344772258425e-07,
      "loss": 0.4973,
      "step": 12417
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.596751806803096,
      "learning_rate": 4.811524046519423e-07,
      "loss": 0.4633,
      "step": 12418
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.09749839674652,
      "learning_rate": 4.806705612592577e-07,
      "loss": 0.5298,
      "step": 12419
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.9209681117993687,
      "learning_rate": 4.801889470722304e-07,
      "loss": 0.4706,
      "step": 12420
    },
    {
      "epoch": 0.86,
      "grad_norm": 3.3402686016741874,
      "learning_rate": 4.797075621152836e-07,
      "loss": 0.4541,
      "step": 12421
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.004396094313551,
      "learning_rate": 4.792264064128327e-07,
      "loss": 0.4864,
      "step": 12422
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.8978467216551516,
      "learning_rate": 4.787454799892793e-07,
      "loss": 0.4755,
      "step": 12423
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.7939312081685066,
      "learning_rate": 4.782647828690146e-07,
      "loss": 0.4675,
      "step": 12424
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.30918910032415,
      "learning_rate": 4.7778431507642e-07,
      "loss": 0.5184,
      "step": 12425
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.00872720097764,
      "learning_rate": 4.773040766358599e-07,
      "loss": 0.5075,
      "step": 12426
    },
    {
      "epoch": 0.86,
      "grad_norm": 3.3969149744295524,
      "learning_rate": 4.7682406757169286e-07,
      "loss": 0.5022,
      "step": 12427
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.1432262206449675,
      "learning_rate": 4.763442879082625e-07,
      "loss": 0.4798,
      "step": 12428
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.175177839874269,
      "learning_rate": 4.758647376699033e-07,
      "loss": 0.5111,
      "step": 12429
    },
    {
      "epoch": 0.86,
      "grad_norm": 3.0571768164758923,
      "learning_rate": 4.7538541688093355e-07,
      "loss": 0.4634,
      "step": 12430
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.1676063326286887,
      "learning_rate": 4.749063255656644e-07,
      "loss": 0.5113,
      "step": 12431
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.803734145414193,
      "learning_rate": 4.7442746374839363e-07,
      "loss": 0.4825,
      "step": 12432
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.562559978876529,
      "learning_rate": 4.739488314534091e-07,
      "loss": 0.4571,
      "step": 12433
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.8207608286274841,
      "learning_rate": 4.7347042870498296e-07,
      "loss": 0.467,
      "step": 12434
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.093527044432064,
      "learning_rate": 4.7299225552737915e-07,
      "loss": 0.4721,
      "step": 12435
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.751346967150201,
      "learning_rate": 4.7251431194485054e-07,
      "loss": 0.4433,
      "step": 12436
    },
    {
      "epoch": 0.86,
      "grad_norm": 9.597356248982477,
      "learning_rate": 4.7203659798163434e-07,
      "loss": 0.457,
      "step": 12437
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.1948738162137817,
      "learning_rate": 4.7155911366196073e-07,
      "loss": 0.5024,
      "step": 12438
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.924870466877163,
      "learning_rate": 4.7108185901004356e-07,
      "loss": 0.453,
      "step": 12439
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.4828013995950813,
      "learning_rate": 4.7060483405009126e-07,
      "loss": 0.4944,
      "step": 12440
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.0553614655833927,
      "learning_rate": 4.7012803880629455e-07,
      "loss": 0.4733,
      "step": 12441
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.0631466163696395,
      "learning_rate": 4.696514733028357e-07,
      "loss": 0.496,
      "step": 12442
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.5815367546650143,
      "learning_rate": 4.6917513756388313e-07,
      "loss": 0.3937,
      "step": 12443
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.9898662481253173,
      "learning_rate": 4.6869903161359754e-07,
      "loss": 0.4965,
      "step": 12444
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.1404670541558253,
      "learning_rate": 4.682231554761235e-07,
      "loss": 0.479,
      "step": 12445
    },
    {
      "epoch": 0.87,
      "grad_norm": 3.3255076603902074,
      "learning_rate": 4.677475091755973e-07,
      "loss": 0.5087,
      "step": 12446
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.4267111747188856,
      "learning_rate": 4.672720927361413e-07,
      "loss": 0.5064,
      "step": 12447
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.2297781880783503,
      "learning_rate": 4.6679690618186615e-07,
      "loss": 0.4687,
      "step": 12448
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.3078916460254706,
      "learning_rate": 4.6632194953687424e-07,
      "loss": 0.5049,
      "step": 12449
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.5870067528391605,
      "learning_rate": 4.6584722282525143e-07,
      "loss": 0.4925,
      "step": 12450
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.786607531244085,
      "learning_rate": 4.653727260710755e-07,
      "loss": 0.5121,
      "step": 12451
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.760311348184509,
      "learning_rate": 4.6489845929841125e-07,
      "loss": 0.468,
      "step": 12452
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.9885051197976524,
      "learning_rate": 4.6442442253131214e-07,
      "loss": 0.4991,
      "step": 12453
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.663940200105499,
      "learning_rate": 4.639506157938195e-07,
      "loss": 0.4461,
      "step": 12454
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.09877005944137,
      "learning_rate": 4.634770391099624e-07,
      "loss": 0.5061,
      "step": 12455
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.6916534350625723,
      "learning_rate": 4.6300369250376067e-07,
      "loss": 0.4006,
      "step": 12456
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.6115717839337567,
      "learning_rate": 4.625305759992205e-07,
      "loss": 0.5288,
      "step": 12457
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.3322564600394875,
      "learning_rate": 4.6205768962033604e-07,
      "loss": 0.4853,
      "step": 12458
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.282814471762355,
      "learning_rate": 4.615850333910904e-07,
      "loss": 0.4948,
      "step": 12459
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.3048488900317805,
      "learning_rate": 4.6111260733545714e-07,
      "loss": 0.4742,
      "step": 12460
    },
    {
      "epoch": 0.87,
      "grad_norm": 3.371819180319145,
      "learning_rate": 4.606404114773938e-07,
      "loss": 0.4782,
      "step": 12461
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.9705044821624058,
      "learning_rate": 4.601684458408506e-07,
      "loss": 0.4866,
      "step": 12462
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.185923841007115,
      "learning_rate": 4.5969671044976184e-07,
      "loss": 0.4815,
      "step": 12463
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.8875252512699414,
      "learning_rate": 4.5922520532805495e-07,
      "loss": 0.4832,
      "step": 12464
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.8267705711875724,
      "learning_rate": 4.5875393049964077e-07,
      "loss": 0.4749,
      "step": 12465
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.903940350912034,
      "learning_rate": 4.5828288598842194e-07,
      "loss": 0.4993,
      "step": 12466
    },
    {
      "epoch": 0.87,
      "grad_norm": 3.7075188015282197,
      "learning_rate": 4.578120718182888e-07,
      "loss": 0.5076,
      "step": 12467
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.9968410798969776,
      "learning_rate": 4.573414880131194e-07,
      "loss": 0.4736,
      "step": 12468
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.571068997949039,
      "learning_rate": 4.568711345967791e-07,
      "loss": 0.4674,
      "step": 12469
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.6471972520554076,
      "learning_rate": 4.5640101159312333e-07,
      "loss": 0.4088,
      "step": 12470
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.2045300533192145,
      "learning_rate": 4.559311190259963e-07,
      "loss": 0.4782,
      "step": 12471
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.5590594381793579,
      "learning_rate": 4.554614569192273e-07,
      "loss": 0.3938,
      "step": 12472
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.7117405139652313,
      "learning_rate": 4.549920252966383e-07,
      "loss": 0.4881,
      "step": 12473
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.0471265415603646,
      "learning_rate": 4.545228241820343e-07,
      "loss": 0.4701,
      "step": 12474
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.9243986872524386,
      "learning_rate": 4.540538535992156e-07,
      "loss": 0.5234,
      "step": 12475
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.5758797270823796,
      "learning_rate": 4.535851135719638e-07,
      "loss": 0.3903,
      "step": 12476
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.204776554655169,
      "learning_rate": 4.531166041240531e-07,
      "loss": 0.44,
      "step": 12477
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.168986335357729,
      "learning_rate": 4.526483252792446e-07,
      "loss": 0.513,
      "step": 12478
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.7993174178866336,
      "learning_rate": 4.521802770612871e-07,
      "loss": 0.4579,
      "step": 12479
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.88534662625994,
      "learning_rate": 4.5171245949391983e-07,
      "loss": 0.4965,
      "step": 12480
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.5940733969213705,
      "learning_rate": 4.512448726008689e-07,
      "loss": 0.449,
      "step": 12481
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.089728007187719,
      "learning_rate": 4.50777516405847e-07,
      "loss": 0.4606,
      "step": 12482
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.8292753445783674,
      "learning_rate": 4.5031039093255845e-07,
      "loss": 0.476,
      "step": 12483
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.077151357630977,
      "learning_rate": 4.498434962046949e-07,
      "loss": 0.5077,
      "step": 12484
    },
    {
      "epoch": 0.87,
      "grad_norm": 3.011914772264344,
      "learning_rate": 4.4937683224593407e-07,
      "loss": 0.5082,
      "step": 12485
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.3951437871154764,
      "learning_rate": 4.489103990799448e-07,
      "loss": 0.5193,
      "step": 12486
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.134385083564522,
      "learning_rate": 4.484441967303821e-07,
      "loss": 0.4698,
      "step": 12487
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.537906487843399,
      "learning_rate": 4.4797822522089194e-07,
      "loss": 0.5352,
      "step": 12488
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.847481183794769,
      "learning_rate": 4.47512484575105e-07,
      "loss": 0.4864,
      "step": 12489
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.7754976037662364,
      "learning_rate": 4.4704697481664226e-07,
      "loss": 0.4924,
      "step": 12490
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.9143380169973951,
      "learning_rate": 4.4658169596911493e-07,
      "loss": 0.5153,
      "step": 12491
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.9767269079985683,
      "learning_rate": 4.46116648056118e-07,
      "loss": 0.4688,
      "step": 12492
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.6428401398761907,
      "learning_rate": 4.456518311012392e-07,
      "loss": 0.4735,
      "step": 12493
    },
    {
      "epoch": 0.87,
      "grad_norm": 23.02602619834593,
      "learning_rate": 4.4518724512804924e-07,
      "loss": 0.4517,
      "step": 12494
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.5711818789734086,
      "learning_rate": 4.447228901601147e-07,
      "loss": 0.4219,
      "step": 12495
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.1156097610287197,
      "learning_rate": 4.4425876622098354e-07,
      "loss": 0.5116,
      "step": 12496
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.5600864262907894,
      "learning_rate": 4.437948733341957e-07,
      "loss": 0.5445,
      "step": 12497
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.68760459101022,
      "learning_rate": 4.433312115232763e-07,
      "loss": 0.511,
      "step": 12498
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.6026656859555843,
      "learning_rate": 4.4286778081174374e-07,
      "loss": 0.413,
      "step": 12499
    },
    {
      "epoch": 0.87,
      "grad_norm": 5.392460361448372,
      "learning_rate": 4.4240458122309925e-07,
      "loss": 0.5472,
      "step": 12500
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.5118717205549213,
      "learning_rate": 4.419416127808368e-07,
      "loss": 0.4787,
      "step": 12501
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.601666101398424,
      "learning_rate": 4.414788755084348e-07,
      "loss": 0.489,
      "step": 12502
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.6785273917449457,
      "learning_rate": 4.410163694293629e-07,
      "loss": 0.4589,
      "step": 12503
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.1342912958264684,
      "learning_rate": 4.4055409456707833e-07,
      "loss": 0.4641,
      "step": 12504
    },
    {
      "epoch": 0.87,
      "grad_norm": 3.434160671516088,
      "learning_rate": 4.400920509450246e-07,
      "loss": 0.4756,
      "step": 12505
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.525598949840513,
      "learning_rate": 4.396302385866352e-07,
      "loss": 0.4999,
      "step": 12506
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.7835262651703074,
      "learning_rate": 4.3916865751533313e-07,
      "loss": 0.4891,
      "step": 12507
    },
    {
      "epoch": 0.87,
      "grad_norm": 3.260831833532795,
      "learning_rate": 4.387073077545284e-07,
      "loss": 0.4757,
      "step": 12508
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.056445712048122,
      "learning_rate": 4.382461893276174e-07,
      "loss": 0.4436,
      "step": 12509
    },
    {
      "epoch": 0.87,
      "grad_norm": 3.839559867189791,
      "learning_rate": 4.3778530225798756e-07,
      "loss": 0.4501,
      "step": 12510
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.4040848636968226,
      "learning_rate": 4.373246465690134e-07,
      "loss": 0.5234,
      "step": 12511
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.1407616776175558,
      "learning_rate": 4.3686422228405856e-07,
      "loss": 0.5059,
      "step": 12512
    },
    {
      "epoch": 0.87,
      "grad_norm": 3.2114901558939875,
      "learning_rate": 4.364040294264732e-07,
      "loss": 0.4236,
      "step": 12513
    },
    {
      "epoch": 0.87,
      "grad_norm": 3.5301122936651566,
      "learning_rate": 4.3594406801959755e-07,
      "loss": 0.5004,
      "step": 12514
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.3849110432210985,
      "learning_rate": 4.354843380867596e-07,
      "loss": 0.5043,
      "step": 12515
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.986529614906038,
      "learning_rate": 4.3502483965127407e-07,
      "loss": 0.4659,
      "step": 12516
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.072638448013317,
      "learning_rate": 4.3456557273644675e-07,
      "loss": 0.4867,
      "step": 12517
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.865447815611383,
      "learning_rate": 4.341065373655678e-07,
      "loss": 0.4849,
      "step": 12518
    },
    {
      "epoch": 0.87,
      "grad_norm": 5.929702176647783,
      "learning_rate": 4.33647733561921e-07,
      "loss": 0.4797,
      "step": 12519
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.026564221316688,
      "learning_rate": 4.3318916134877376e-07,
      "loss": 0.5075,
      "step": 12520
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.8519301915521942,
      "learning_rate": 4.327308207493841e-07,
      "loss": 0.4693,
      "step": 12521
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.651187114059773,
      "learning_rate": 4.322727117869951e-07,
      "loss": 0.4683,
      "step": 12522
    },
    {
      "epoch": 0.87,
      "grad_norm": 4.990872606463331,
      "learning_rate": 4.318148344848444e-07,
      "loss": 0.517,
      "step": 12523
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.593296502851684,
      "learning_rate": 4.3135718886615163e-07,
      "loss": 0.3933,
      "step": 12524
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.0282164655081063,
      "learning_rate": 4.3089977495412825e-07,
      "loss": 0.4949,
      "step": 12525
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.8251425531389946,
      "learning_rate": 4.3044259277197134e-07,
      "loss": 0.4889,
      "step": 12526
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.7693004037242943,
      "learning_rate": 4.299856423428683e-07,
      "loss": 0.4836,
      "step": 12527
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.032715250087319,
      "learning_rate": 4.2952892368999523e-07,
      "loss": 0.4629,
      "step": 12528
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.8593962488716862,
      "learning_rate": 4.290724368365129e-07,
      "loss": 0.481,
      "step": 12529
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.8099524731927963,
      "learning_rate": 4.286161818055767e-07,
      "loss": 0.4888,
      "step": 12530
    },
    {
      "epoch": 0.87,
      "grad_norm": 3.1463537452832755,
      "learning_rate": 4.2816015862032265e-07,
      "loss": 0.5046,
      "step": 12531
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.8341243899565158,
      "learning_rate": 4.2770436730388166e-07,
      "loss": 0.4957,
      "step": 12532
    },
    {
      "epoch": 0.87,
      "grad_norm": 7.965787005456218,
      "learning_rate": 4.272488078793663e-07,
      "loss": 0.4684,
      "step": 12533
    },
    {
      "epoch": 0.87,
      "grad_norm": 3.6235271571135184,
      "learning_rate": 4.267934803698859e-07,
      "loss": 0.4614,
      "step": 12534
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.9645369014257223,
      "learning_rate": 4.263383847985292e-07,
      "loss": 0.4963,
      "step": 12535
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.0944060720239124,
      "learning_rate": 4.258835211883794e-07,
      "loss": 0.4631,
      "step": 12536
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.933496285101827,
      "learning_rate": 4.2542888956250475e-07,
      "loss": 0.4933,
      "step": 12537
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.2302858070642295,
      "learning_rate": 4.2497448994396227e-07,
      "loss": 0.4822,
      "step": 12538
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.8057058946197677,
      "learning_rate": 4.245203223557992e-07,
      "loss": 0.4808,
      "step": 12539
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.230484519856337,
      "learning_rate": 4.240663868210476e-07,
      "loss": 0.4858,
      "step": 12540
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.70464398464148,
      "learning_rate": 4.2361268336273075e-07,
      "loss": 0.4476,
      "step": 12541
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.481236872143136,
      "learning_rate": 4.231592120038586e-07,
      "loss": 0.4825,
      "step": 12542
    },
    {
      "epoch": 0.87,
      "grad_norm": 4.797184005935096,
      "learning_rate": 4.2270597276743044e-07,
      "loss": 0.4733,
      "step": 12543
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.287979637353757,
      "learning_rate": 4.222529656764318e-07,
      "loss": 0.488,
      "step": 12544
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.96189767733189,
      "learning_rate": 4.218001907538383e-07,
      "loss": 0.4832,
      "step": 12545
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.2044136097847775,
      "learning_rate": 4.213476480226142e-07,
      "loss": 0.4702,
      "step": 12546
    },
    {
      "epoch": 0.87,
      "grad_norm": 3.193297500860908,
      "learning_rate": 4.208953375057095e-07,
      "loss": 0.5244,
      "step": 12547
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.9287919197765253,
      "learning_rate": 4.2044325922606435e-07,
      "loss": 0.492,
      "step": 12548
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.993546865230648,
      "learning_rate": 4.199914132066069e-07,
      "loss": 0.5181,
      "step": 12549
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.8263167426513205,
      "learning_rate": 4.1953979947025434e-07,
      "loss": 0.4702,
      "step": 12550
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.0712062001367073,
      "learning_rate": 4.190884180399091e-07,
      "loss": 0.452,
      "step": 12551
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.003258822297249,
      "learning_rate": 4.186372689384655e-07,
      "loss": 0.4757,
      "step": 12552
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.9358546280186775,
      "learning_rate": 4.1818635218880186e-07,
      "loss": 0.447,
      "step": 12553
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.0108179138509588,
      "learning_rate": 4.1773566781379007e-07,
      "loss": 0.5064,
      "step": 12554
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.94981887339536,
      "learning_rate": 4.172852158362861e-07,
      "loss": 0.4981,
      "step": 12555
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.0623762924571443,
      "learning_rate": 4.168349962791357e-07,
      "loss": 0.4676,
      "step": 12556
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.5163350683366468,
      "learning_rate": 4.163850091651717e-07,
      "loss": 0.4907,
      "step": 12557
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.9011213899971044,
      "learning_rate": 4.1593525451721684e-07,
      "loss": 0.4497,
      "step": 12558
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.6024033617105644,
      "learning_rate": 4.154857323580813e-07,
      "loss": 0.4891,
      "step": 12559
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.083496691849713,
      "learning_rate": 4.1503644271056244e-07,
      "loss": 0.5321,
      "step": 12560
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.6308060277351974,
      "learning_rate": 4.145873855974475e-07,
      "loss": 0.4991,
      "step": 12561
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.977231053382404,
      "learning_rate": 4.141385610415105e-07,
      "loss": 0.4412,
      "step": 12562
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.8342416342119838,
      "learning_rate": 4.136899690655166e-07,
      "loss": 0.462,
      "step": 12563
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.111626891904837,
      "learning_rate": 4.132416096922137e-07,
      "loss": 0.4192,
      "step": 12564
    },
    {
      "epoch": 0.87,
      "grad_norm": 3.9274259114616434,
      "learning_rate": 4.1279348294434307e-07,
      "loss": 0.4675,
      "step": 12565
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.8885930450101955,
      "learning_rate": 4.123455888446315e-07,
      "loss": 0.507,
      "step": 12566
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.4544867048586108,
      "learning_rate": 4.118979274157964e-07,
      "loss": 0.4722,
      "step": 12567
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.3565600684627457,
      "learning_rate": 4.11450498680539e-07,
      "loss": 0.4849,
      "step": 12568
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.5554607479201913,
      "learning_rate": 4.110033026615529e-07,
      "loss": 0.4271,
      "step": 12569
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.8366748799198804,
      "learning_rate": 4.105563393815193e-07,
      "loss": 0.4794,
      "step": 12570
    },
    {
      "epoch": 0.87,
      "grad_norm": 3.8700132797850078,
      "learning_rate": 4.1010960886310515e-07,
      "loss": 0.5257,
      "step": 12571
    },
    {
      "epoch": 0.87,
      "grad_norm": 3.1399440726513475,
      "learning_rate": 4.0966311112896785e-07,
      "loss": 0.4357,
      "step": 12572
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.816295468426738,
      "learning_rate": 4.0921684620175097e-07,
      "loss": 0.4878,
      "step": 12573
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.898101743337136,
      "learning_rate": 4.0877081410409025e-07,
      "loss": 0.5092,
      "step": 12574
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.5515885455098934,
      "learning_rate": 4.0832501485860487e-07,
      "loss": 0.4089,
      "step": 12575
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.8494742480950692,
      "learning_rate": 4.0787944848790615e-07,
      "loss": 0.4725,
      "step": 12576
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.7129362862697217,
      "learning_rate": 4.0743411501458886e-07,
      "loss": 0.4533,
      "step": 12577
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.0920189876458295,
      "learning_rate": 4.0698901446124204e-07,
      "loss": 0.4728,
      "step": 12578
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.3055313502221546,
      "learning_rate": 4.0654414685043775e-07,
      "loss": 0.4694,
      "step": 12579
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.696926882831716,
      "learning_rate": 4.0609951220473956e-07,
      "loss": 0.4906,
      "step": 12580
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.1755382693653447,
      "learning_rate": 4.05655110546696e-07,
      "loss": 0.4933,
      "step": 12581
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.14788645676106,
      "learning_rate": 4.05210941898847e-07,
      "loss": 0.4672,
      "step": 12582
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.6707845877667489,
      "learning_rate": 4.0476700628372e-07,
      "loss": 0.5119,
      "step": 12583
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.6780997342679798,
      "learning_rate": 4.043233037238281e-07,
      "loss": 0.5146,
      "step": 12584
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.020781907147643,
      "learning_rate": 4.038798342416761e-07,
      "loss": 0.5265,
      "step": 12585
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.1739541464676027,
      "learning_rate": 4.0343659785975433e-07,
      "loss": 0.4842,
      "step": 12586
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.857443837599401,
      "learning_rate": 4.0299359460054313e-07,
      "loss": 0.483,
      "step": 12587
    },
    {
      "epoch": 0.88,
      "grad_norm": 3.942424949492168,
      "learning_rate": 4.025508244865095e-07,
      "loss": 0.435,
      "step": 12588
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.5722562971394605,
      "learning_rate": 4.021082875401089e-07,
      "loss": 0.4662,
      "step": 12589
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.11708064100456,
      "learning_rate": 4.0166598378378607e-07,
      "loss": 0.4953,
      "step": 12590
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.8699566535674512,
      "learning_rate": 4.012239132399742e-07,
      "loss": 0.4569,
      "step": 12591
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.6729457573850628,
      "learning_rate": 4.007820759310921e-07,
      "loss": 0.4095,
      "step": 12592
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.0452985026724515,
      "learning_rate": 4.0034047187954785e-07,
      "loss": 0.4411,
      "step": 12593
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.033590620700027,
      "learning_rate": 3.998991011077408e-07,
      "loss": 0.4737,
      "step": 12594
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.930189645458167,
      "learning_rate": 3.99457963638053e-07,
      "loss": 0.483,
      "step": 12595
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.89775635586686,
      "learning_rate": 3.990170594928583e-07,
      "loss": 0.4728,
      "step": 12596
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.115071835920647,
      "learning_rate": 3.985763886945188e-07,
      "loss": 0.4353,
      "step": 12597
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.9338967233388717,
      "learning_rate": 3.981359512653843e-07,
      "loss": 0.495,
      "step": 12598
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.4152695431508655,
      "learning_rate": 3.976957472277898e-07,
      "loss": 0.4343,
      "step": 12599
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.3515316778717144,
      "learning_rate": 3.9725577660406353e-07,
      "loss": 0.4791,
      "step": 12600
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.7195112011757976,
      "learning_rate": 3.968160394165177e-07,
      "loss": 0.4853,
      "step": 12601
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.116100242268423,
      "learning_rate": 3.963765356874566e-07,
      "loss": 0.4806,
      "step": 12602
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.6194037664512346,
      "learning_rate": 3.9593726543916743e-07,
      "loss": 0.4502,
      "step": 12603
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.190633460410911,
      "learning_rate": 3.9549822869393073e-07,
      "loss": 0.5017,
      "step": 12604
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.8541676056056335,
      "learning_rate": 3.950594254740125e-07,
      "loss": 0.485,
      "step": 12605
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.7872753243714443,
      "learning_rate": 3.946208558016673e-07,
      "loss": 0.4719,
      "step": 12606
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.5897675198929884,
      "learning_rate": 3.941825196991378e-07,
      "loss": 0.5075,
      "step": 12607
    },
    {
      "epoch": 0.88,
      "grad_norm": 3.4432712677532384,
      "learning_rate": 3.93744417188654e-07,
      "loss": 0.463,
      "step": 12608
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.0993081467383257,
      "learning_rate": 3.9330654829243753e-07,
      "loss": 0.4848,
      "step": 12609
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.1091977517635696,
      "learning_rate": 3.928689130326935e-07,
      "loss": 0.4737,
      "step": 12610
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.8446853347532266,
      "learning_rate": 3.924315114316185e-07,
      "loss": 0.4659,
      "step": 12611
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.8705543911344797,
      "learning_rate": 3.9199434351139544e-07,
      "loss": 0.452,
      "step": 12612
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.7944140115864506,
      "learning_rate": 3.9155740929419595e-07,
      "loss": 0.4894,
      "step": 12613
    },
    {
      "epoch": 0.88,
      "grad_norm": 3.0666878448465593,
      "learning_rate": 3.9112070880218123e-07,
      "loss": 0.5061,
      "step": 12614
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.0863349765955057,
      "learning_rate": 3.90684242057498e-07,
      "loss": 0.4859,
      "step": 12615
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.169182900100784,
      "learning_rate": 3.902480090822819e-07,
      "loss": 0.4886,
      "step": 12616
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.167320928386904,
      "learning_rate": 3.8981200989865855e-07,
      "loss": 0.4742,
      "step": 12617
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.1382993037147924,
      "learning_rate": 3.8937624452874136e-07,
      "loss": 0.4645,
      "step": 12618
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.7301082532429704,
      "learning_rate": 3.8894071299462767e-07,
      "loss": 0.4831,
      "step": 12619
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.1416389276973944,
      "learning_rate": 3.885054153184087e-07,
      "loss": 0.518,
      "step": 12620
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.015575931920328,
      "learning_rate": 3.8807035152216067e-07,
      "loss": 0.4552,
      "step": 12621
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.2281265814592146,
      "learning_rate": 3.8763552162794983e-07,
      "loss": 0.5252,
      "step": 12622
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.669455487775823,
      "learning_rate": 3.8720092565782685e-07,
      "loss": 0.4551,
      "step": 12623
    },
    {
      "epoch": 0.88,
      "grad_norm": 3.312420543173888,
      "learning_rate": 3.8676656363383416e-07,
      "loss": 0.5016,
      "step": 12624
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.905821446933257,
      "learning_rate": 3.8633243557800235e-07,
      "loss": 0.4547,
      "step": 12625
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.466595961097217,
      "learning_rate": 3.858985415123473e-07,
      "loss": 0.4731,
      "step": 12626
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.9479854733452688,
      "learning_rate": 3.8546488145887627e-07,
      "loss": 0.5426,
      "step": 12627
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.867942044714366,
      "learning_rate": 3.8503145543958065e-07,
      "loss": 0.5048,
      "step": 12628
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.329101547951914,
      "learning_rate": 3.845982634764456e-07,
      "loss": 0.4578,
      "step": 12629
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.7548068171197109,
      "learning_rate": 3.8416530559143847e-07,
      "loss": 0.4696,
      "step": 12630
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.196012103375711,
      "learning_rate": 3.8373258180651904e-07,
      "loss": 0.4743,
      "step": 12631
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.9059108723304312,
      "learning_rate": 3.8330009214363197e-07,
      "loss": 0.4787,
      "step": 12632
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.927497505593297,
      "learning_rate": 3.828678366247146e-07,
      "loss": 0.5256,
      "step": 12633
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.019715878165006,
      "learning_rate": 3.824358152716873e-07,
      "loss": 0.46,
      "step": 12634
    },
    {
      "epoch": 0.88,
      "grad_norm": 3.3950042140907586,
      "learning_rate": 3.820040281064613e-07,
      "loss": 0.4989,
      "step": 12635
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.9060992269302335,
      "learning_rate": 3.815724751509353e-07,
      "loss": 0.4508,
      "step": 12636
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.1320030093957336,
      "learning_rate": 3.8114115642699624e-07,
      "loss": 0.4349,
      "step": 12637
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.9901864118535086,
      "learning_rate": 3.8071007195652044e-07,
      "loss": 0.5146,
      "step": 12638
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.2450473484177786,
      "learning_rate": 3.802792217613688e-07,
      "loss": 0.4831,
      "step": 12639
    },
    {
      "epoch": 0.88,
      "grad_norm": 10.12637425007655,
      "learning_rate": 3.798486058633943e-07,
      "loss": 0.4817,
      "step": 12640
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.110652464547469,
      "learning_rate": 3.794182242844352e-07,
      "loss": 0.4745,
      "step": 12641
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.9792153239777899,
      "learning_rate": 3.789880770463217e-07,
      "loss": 0.4961,
      "step": 12642
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.0261657277543788,
      "learning_rate": 3.785581641708658e-07,
      "loss": 0.4683,
      "step": 12643
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.2319196891339503,
      "learning_rate": 3.7812848567987335e-07,
      "loss": 0.4651,
      "step": 12644
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.5670524116643249,
      "learning_rate": 3.7769904159513595e-07,
      "loss": 0.4137,
      "step": 12645
    },
    {
      "epoch": 0.88,
      "grad_norm": 13.945635484231865,
      "learning_rate": 3.772698319384349e-07,
      "loss": 0.4603,
      "step": 12646
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.478913624829602,
      "learning_rate": 3.768408567315357e-07,
      "loss": 0.4887,
      "step": 12647
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.5507074308741998,
      "learning_rate": 3.764121159961959e-07,
      "loss": 0.4163,
      "step": 12648
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.6284566105879716,
      "learning_rate": 3.7598360975416084e-07,
      "loss": 0.4289,
      "step": 12649
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.0830162670957297,
      "learning_rate": 3.7555533802716094e-07,
      "loss": 0.4751,
      "step": 12650
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.328885042485205,
      "learning_rate": 3.7512730083691826e-07,
      "loss": 0.5109,
      "step": 12651
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.5207580211063614,
      "learning_rate": 3.7469949820513996e-07,
      "loss": 0.4918,
      "step": 12652
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.0746461499061772,
      "learning_rate": 3.742719301535247e-07,
      "loss": 0.4705,
      "step": 12653
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.416636323629967,
      "learning_rate": 3.738445967037563e-07,
      "loss": 0.4801,
      "step": 12654
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.9473211086198714,
      "learning_rate": 3.734174978775074e-07,
      "loss": 0.5097,
      "step": 12655
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.383243522719419,
      "learning_rate": 3.729906336964395e-07,
      "loss": 0.5052,
      "step": 12656
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.119092110865248,
      "learning_rate": 3.725640041822026e-07,
      "loss": 0.5369,
      "step": 12657
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.1766605711255798,
      "learning_rate": 3.7213760935643216e-07,
      "loss": 0.4966,
      "step": 12658
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.8681510141471052,
      "learning_rate": 3.7171144924075477e-07,
      "loss": 0.4733,
      "step": 12659
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.774345795432506,
      "learning_rate": 3.712855238567842e-07,
      "loss": 0.4903,
      "step": 12660
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.0289832086805033,
      "learning_rate": 3.708598332261204e-07,
      "loss": 0.4841,
      "step": 12661
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.9770437828474414,
      "learning_rate": 3.7043437737035506e-07,
      "loss": 0.5163,
      "step": 12662
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.6507862775602287,
      "learning_rate": 3.7000915631106303e-07,
      "loss": 0.4948,
      "step": 12663
    },
    {
      "epoch": 0.88,
      "grad_norm": 3.116953550705927,
      "learning_rate": 3.695841700698138e-07,
      "loss": 0.4185,
      "step": 12664
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.9212473683256654,
      "learning_rate": 3.691594186681585e-07,
      "loss": 0.4368,
      "step": 12665
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.6198550904983103,
      "learning_rate": 3.6873490212764097e-07,
      "loss": 0.3939,
      "step": 12666
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.3873883322555693,
      "learning_rate": 3.683106204697895e-07,
      "loss": 0.5036,
      "step": 12667
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.8330229024049465,
      "learning_rate": 3.678865737161236e-07,
      "loss": 0.4961,
      "step": 12668
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.3250289694988706,
      "learning_rate": 3.6746276188814824e-07,
      "loss": 0.4998,
      "step": 12669
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.704251266812983,
      "learning_rate": 3.670391850073601e-07,
      "loss": 0.4534,
      "step": 12670
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.84908040776957,
      "learning_rate": 3.666158430952393e-07,
      "loss": 0.5105,
      "step": 12671
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.042945032305893,
      "learning_rate": 3.66192736173257e-07,
      "loss": 0.4769,
      "step": 12672
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.16473556097341,
      "learning_rate": 3.657698642628732e-07,
      "loss": 0.5122,
      "step": 12673
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.656659881731155,
      "learning_rate": 3.653472273855324e-07,
      "loss": 0.437,
      "step": 12674
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.533555760065293,
      "learning_rate": 3.6492482556267085e-07,
      "loss": 0.4734,
      "step": 12675
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.8693844800443915,
      "learning_rate": 3.645026588157102e-07,
      "loss": 0.47,
      "step": 12676
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.9127723321365782,
      "learning_rate": 3.6408072716606346e-07,
      "loss": 0.506,
      "step": 12677
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.095515753465428,
      "learning_rate": 3.636590306351273e-07,
      "loss": 0.5149,
      "step": 12678
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.268590112082202,
      "learning_rate": 3.6323756924428963e-07,
      "loss": 0.4399,
      "step": 12679
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.8416871665220755,
      "learning_rate": 3.628163430149267e-07,
      "loss": 0.4713,
      "step": 12680
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.222818309087998,
      "learning_rate": 3.623953519683998e-07,
      "loss": 0.5319,
      "step": 12681
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.5518215431928853,
      "learning_rate": 3.619745961260623e-07,
      "loss": 0.4016,
      "step": 12682
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.077451191200088,
      "learning_rate": 3.6155407550925057e-07,
      "loss": 0.4787,
      "step": 12683
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.342346288837128,
      "learning_rate": 3.611337901392953e-07,
      "loss": 0.4703,
      "step": 12684
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.0171467580653646,
      "learning_rate": 3.6071374003751045e-07,
      "loss": 0.5234,
      "step": 12685
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.126789066966496,
      "learning_rate": 3.6029392522520023e-07,
      "loss": 0.4989,
      "step": 12686
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.3090614755179915,
      "learning_rate": 3.598743457236542e-07,
      "loss": 0.444,
      "step": 12687
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.142788333949294,
      "learning_rate": 3.5945500155415536e-07,
      "loss": 0.516,
      "step": 12688
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.1785602845982517,
      "learning_rate": 3.590358927379689e-07,
      "loss": 0.5087,
      "step": 12689
    },
    {
      "epoch": 0.88,
      "grad_norm": 3.2448825764528353,
      "learning_rate": 3.5861701929635227e-07,
      "loss": 0.4888,
      "step": 12690
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.0545083214235578,
      "learning_rate": 3.5819838125054797e-07,
      "loss": 0.4712,
      "step": 12691
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.785346721442085,
      "learning_rate": 3.5777997862178835e-07,
      "loss": 0.5513,
      "step": 12692
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.7317829123245936,
      "learning_rate": 3.573618114312949e-07,
      "loss": 0.5098,
      "step": 12693
    },
    {
      "epoch": 0.88,
      "grad_norm": 3.2588549475143003,
      "learning_rate": 3.5694387970027333e-07,
      "loss": 0.4797,
      "step": 12694
    },
    {
      "epoch": 0.88,
      "grad_norm": 4.673201303141959,
      "learning_rate": 3.565261834499212e-07,
      "loss": 0.4587,
      "step": 12695
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.3152214604373245,
      "learning_rate": 3.561087227014226e-07,
      "loss": 0.4604,
      "step": 12696
    },
    {
      "epoch": 0.88,
      "grad_norm": 3.254871132406111,
      "learning_rate": 3.556914974759501e-07,
      "loss": 0.5029,
      "step": 12697
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.0957411099435657,
      "learning_rate": 3.552745077946629e-07,
      "loss": 0.4697,
      "step": 12698
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.6349566097673373,
      "learning_rate": 3.5485775367871013e-07,
      "loss": 0.4467,
      "step": 12699
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.6674363877379217,
      "learning_rate": 3.544412351492277e-07,
      "loss": 0.4954,
      "step": 12700
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.5872907214560817,
      "learning_rate": 3.540249522273415e-07,
      "loss": 0.439,
      "step": 12701
    },
    {
      "epoch": 0.88,
      "grad_norm": 4.363867902479778,
      "learning_rate": 3.5360890493416235e-07,
      "loss": 0.4967,
      "step": 12702
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.6183706122481785,
      "learning_rate": 3.531930932907912e-07,
      "loss": 0.4485,
      "step": 12703
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.7433128274046785,
      "learning_rate": 3.527775173183173e-07,
      "loss": 0.457,
      "step": 12704
    },
    {
      "epoch": 0.88,
      "grad_norm": 3.97066472572465,
      "learning_rate": 3.523621770378166e-07,
      "loss": 0.4404,
      "step": 12705
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.0047110797038323,
      "learning_rate": 3.5194707247035495e-07,
      "loss": 0.5053,
      "step": 12706
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.3440019570811064,
      "learning_rate": 3.5153220363698225e-07,
      "loss": 0.5356,
      "step": 12707
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.8509119859493197,
      "learning_rate": 3.511175705587433e-07,
      "loss": 0.4697,
      "step": 12708
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.762016391164963,
      "learning_rate": 3.50703173256664e-07,
      "loss": 0.5023,
      "step": 12709
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.8596653116911481,
      "learning_rate": 3.5028901175176324e-07,
      "loss": 0.4383,
      "step": 12710
    },
    {
      "epoch": 0.88,
      "grad_norm": 3.2988452687931846,
      "learning_rate": 3.4987508606504294e-07,
      "loss": 0.5041,
      "step": 12711
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.462762968471643,
      "learning_rate": 3.4946139621749973e-07,
      "loss": 0.4744,
      "step": 12712
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.6703804389130352,
      "learning_rate": 3.4904794223011187e-07,
      "loss": 0.4473,
      "step": 12713
    },
    {
      "epoch": 0.88,
      "grad_norm": 3.118258230392939,
      "learning_rate": 3.4863472412385025e-07,
      "loss": 0.528,
      "step": 12714
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.122085896863733,
      "learning_rate": 3.482217419196704e-07,
      "loss": 0.4417,
      "step": 12715
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.7803969870939564,
      "learning_rate": 3.478089956385183e-07,
      "loss": 0.4666,
      "step": 12716
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.60846035152185,
      "learning_rate": 3.473964853013273e-07,
      "loss": 0.4674,
      "step": 12717
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.793255963079507,
      "learning_rate": 3.469842109290178e-07,
      "loss": 0.4491,
      "step": 12718
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.4128960288167276,
      "learning_rate": 3.465721725424992e-07,
      "loss": 0.4981,
      "step": 12719
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.752188402335621,
      "learning_rate": 3.461603701626692e-07,
      "loss": 0.4632,
      "step": 12720
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.8786792266764807,
      "learning_rate": 3.457488038104134e-07,
      "loss": 0.4551,
      "step": 12721
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.9622028646490142,
      "learning_rate": 3.453374735066034e-07,
      "loss": 0.5492,
      "step": 12722
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.4398159361317533,
      "learning_rate": 3.449263792721025e-07,
      "loss": 0.4753,
      "step": 12723
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.6657260256320419,
      "learning_rate": 3.44515521127759e-07,
      "loss": 0.471,
      "step": 12724
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.0729488622138845,
      "learning_rate": 3.4410489909441125e-07,
      "loss": 0.5017,
      "step": 12725
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.2960655527383684,
      "learning_rate": 3.4369451319288315e-07,
      "loss": 0.4831,
      "step": 12726
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.2145200555774998,
      "learning_rate": 3.432843634439886e-07,
      "loss": 0.4711,
      "step": 12727
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.422859885305485,
      "learning_rate": 3.428744498685305e-07,
      "loss": 0.4782,
      "step": 12728
    },
    {
      "epoch": 0.89,
      "grad_norm": 3.02879981800286,
      "learning_rate": 3.4246477248729595e-07,
      "loss": 0.5107,
      "step": 12729
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.359619512349983,
      "learning_rate": 3.4205533132106396e-07,
      "loss": 0.4766,
      "step": 12730
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.221467457443153,
      "learning_rate": 3.416461263906001e-07,
      "loss": 0.4797,
      "step": 12731
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.9176989171260292,
      "learning_rate": 3.4123715771665786e-07,
      "loss": 0.4671,
      "step": 12732
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.6196538568462797,
      "learning_rate": 3.408284253199784e-07,
      "loss": 0.4596,
      "step": 12733
    },
    {
      "epoch": 0.89,
      "grad_norm": 3.3182072314331252,
      "learning_rate": 3.404199292212906e-07,
      "loss": 0.5266,
      "step": 12734
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.076982474335151,
      "learning_rate": 3.400116694413147e-07,
      "loss": 0.4672,
      "step": 12735
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.199104974048952,
      "learning_rate": 3.396036460007529e-07,
      "loss": 0.4828,
      "step": 12736
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.6060516855360025,
      "learning_rate": 3.391958589203004e-07,
      "loss": 0.4917,
      "step": 12737
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.2229799348897314,
      "learning_rate": 3.3878830822063946e-07,
      "loss": 0.5238,
      "step": 12738
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.17093255898656,
      "learning_rate": 3.3838099392243915e-07,
      "loss": 0.4841,
      "step": 12739
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.114788315025676,
      "learning_rate": 3.3797391604635686e-07,
      "loss": 0.4883,
      "step": 12740
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.7704470032811614,
      "learning_rate": 3.375670746130388e-07,
      "loss": 0.5091,
      "step": 12741
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.5563307175208282,
      "learning_rate": 3.3716046964311743e-07,
      "loss": 0.4127,
      "step": 12742
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.9421186967991535,
      "learning_rate": 3.367541011572162e-07,
      "loss": 0.4842,
      "step": 12743
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.36026125740327,
      "learning_rate": 3.363479691759436e-07,
      "loss": 0.4569,
      "step": 12744
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.7108696886838801,
      "learning_rate": 3.3594207371989815e-07,
      "loss": 0.4606,
      "step": 12745
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.0819828998587546,
      "learning_rate": 3.3553641480966404e-07,
      "loss": 0.4905,
      "step": 12746
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.493111910505828,
      "learning_rate": 3.3513099246581636e-07,
      "loss": 0.4956,
      "step": 12747
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.1804766423832147,
      "learning_rate": 3.347258067089171e-07,
      "loss": 0.4661,
      "step": 12748
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.9799723122762445,
      "learning_rate": 3.3432085755951416e-07,
      "loss": 0.4941,
      "step": 12749
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.7890955103202357,
      "learning_rate": 3.339161450381467e-07,
      "loss": 0.4717,
      "step": 12750
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.0741717721441746,
      "learning_rate": 3.335116691653395e-07,
      "loss": 0.4638,
      "step": 12751
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.5644052392623224,
      "learning_rate": 3.331074299616083e-07,
      "loss": 0.4116,
      "step": 12752
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.8371422164837041,
      "learning_rate": 3.327034274474522e-07,
      "loss": 0.4739,
      "step": 12753
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.9467594114344438,
      "learning_rate": 3.3229966164336156e-07,
      "loss": 0.483,
      "step": 12754
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.8766279864426185,
      "learning_rate": 3.31896132569815e-07,
      "loss": 0.4924,
      "step": 12755
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.7313424665679764,
      "learning_rate": 3.314928402472789e-07,
      "loss": 0.4544,
      "step": 12756
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.9769341813804748,
      "learning_rate": 3.310897846962041e-07,
      "loss": 0.4814,
      "step": 12757
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.960627810694632,
      "learning_rate": 3.3068696593703433e-07,
      "loss": 0.4696,
      "step": 12758
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.055905810660816,
      "learning_rate": 3.302843839901998e-07,
      "loss": 0.4648,
      "step": 12759
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.829230866543658,
      "learning_rate": 3.298820388761159e-07,
      "loss": 0.5298,
      "step": 12760
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.004136236014993,
      "learning_rate": 3.294799306151908e-07,
      "loss": 0.5037,
      "step": 12761
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.123423212266729,
      "learning_rate": 3.290780592278148e-07,
      "loss": 0.5302,
      "step": 12762
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.6833217201634738,
      "learning_rate": 3.286764247343732e-07,
      "loss": 0.4902,
      "step": 12763
    },
    {
      "epoch": 0.89,
      "grad_norm": 4.469801110619528,
      "learning_rate": 3.2827502715523375e-07,
      "loss": 0.496,
      "step": 12764
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.9730519694134157,
      "learning_rate": 3.278738665107545e-07,
      "loss": 0.5175,
      "step": 12765
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.9285303048028337,
      "learning_rate": 3.2747294282127916e-07,
      "loss": 0.4642,
      "step": 12766
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.019424194571091,
      "learning_rate": 3.2707225610714433e-07,
      "loss": 0.4557,
      "step": 12767
    },
    {
      "epoch": 0.89,
      "grad_norm": 4.8271359030839,
      "learning_rate": 3.2667180638866926e-07,
      "loss": 0.4895,
      "step": 12768
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.910243547472104,
      "learning_rate": 3.2627159368616543e-07,
      "loss": 0.4509,
      "step": 12769
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.7962556394833449,
      "learning_rate": 3.258716180199278e-07,
      "loss": 0.4696,
      "step": 12770
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.5069463792646265,
      "learning_rate": 3.254718794102435e-07,
      "loss": 0.4972,
      "step": 12771
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.6991607597721015,
      "learning_rate": 3.250723778773868e-07,
      "loss": 0.4403,
      "step": 12772
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.9597058371692324,
      "learning_rate": 3.2467311344161643e-07,
      "loss": 0.4723,
      "step": 12773
    },
    {
      "epoch": 0.89,
      "grad_norm": 5.2045397841323195,
      "learning_rate": 3.2427408612318355e-07,
      "loss": 0.5197,
      "step": 12774
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.0923035969561865,
      "learning_rate": 3.238752959423258e-07,
      "loss": 0.5529,
      "step": 12775
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.7925090796305538,
      "learning_rate": 3.234767429192681e-07,
      "loss": 0.4621,
      "step": 12776
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.004476341111728,
      "learning_rate": 3.2307842707422324e-07,
      "loss": 0.449,
      "step": 12777
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.0898085177939354,
      "learning_rate": 3.2268034842739273e-07,
      "loss": 0.46,
      "step": 12778
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.237384157459694,
      "learning_rate": 3.22282506998966e-07,
      "loss": 0.4993,
      "step": 12779
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.6740355861262777,
      "learning_rate": 3.2188490280912146e-07,
      "loss": 0.4905,
      "step": 12780
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.2216584875378076,
      "learning_rate": 3.214875358780217e-07,
      "loss": 0.4537,
      "step": 12781
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.146255995887903,
      "learning_rate": 3.2109040622582186e-07,
      "loss": 0.4563,
      "step": 12782
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.086617895623947,
      "learning_rate": 3.2069351387266303e-07,
      "loss": 0.4935,
      "step": 12783
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.5973551487479772,
      "learning_rate": 3.202968588386729e-07,
      "loss": 0.4451,
      "step": 12784
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.177401635549389,
      "learning_rate": 3.1990044114396935e-07,
      "loss": 0.4988,
      "step": 12785
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.5058419662383655,
      "learning_rate": 3.195042608086579e-07,
      "loss": 0.5065,
      "step": 12786
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.9322868125346089,
      "learning_rate": 3.1910831785283146e-07,
      "loss": 0.5362,
      "step": 12787
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.0968098397685453,
      "learning_rate": 3.1871261229656945e-07,
      "loss": 0.4781,
      "step": 12788
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.704718393806316,
      "learning_rate": 3.183171441599425e-07,
      "loss": 0.4623,
      "step": 12789
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.5453605560027172,
      "learning_rate": 3.179219134630063e-07,
      "loss": 0.408,
      "step": 12790
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.087532940494244,
      "learning_rate": 3.1752692022580745e-07,
      "loss": 0.5165,
      "step": 12791
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.8597982799788122,
      "learning_rate": 3.1713216446837613e-07,
      "loss": 0.4967,
      "step": 12792
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.8821693559361121,
      "learning_rate": 3.1673764621073465e-07,
      "loss": 0.5011,
      "step": 12793
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.2310196979844634,
      "learning_rate": 3.163433654728926e-07,
      "loss": 0.5077,
      "step": 12794
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.7155862240309123,
      "learning_rate": 3.1594932227484445e-07,
      "loss": 0.482,
      "step": 12795
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.987000669791703,
      "learning_rate": 3.155555166365765e-07,
      "loss": 0.5193,
      "step": 12796
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.3833089280056172,
      "learning_rate": 3.151619485780588e-07,
      "loss": 0.4758,
      "step": 12797
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.642291339198526,
      "learning_rate": 3.1476861811925554e-07,
      "loss": 0.5113,
      "step": 12798
    },
    {
      "epoch": 0.89,
      "grad_norm": 3.8089140699755193,
      "learning_rate": 3.1437552528011227e-07,
      "loss": 0.5261,
      "step": 12799
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.441208916501505,
      "learning_rate": 3.1398267008056703e-07,
      "loss": 0.492,
      "step": 12800
    },
    {
      "epoch": 0.89,
      "grad_norm": 3.2583485416256104,
      "learning_rate": 3.135900525405428e-07,
      "loss": 0.4783,
      "step": 12801
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.4170282526195606,
      "learning_rate": 3.1319767267995236e-07,
      "loss": 0.5022,
      "step": 12802
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.5907835861528872,
      "learning_rate": 3.1280553051869724e-07,
      "loss": 0.4113,
      "step": 12803
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.1349354598989843,
      "learning_rate": 3.124136260766636e-07,
      "loss": 0.5267,
      "step": 12804
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.9166050554981438,
      "learning_rate": 3.120219593737284e-07,
      "loss": 0.4773,
      "step": 12805
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.2799071367446317,
      "learning_rate": 3.116305304297557e-07,
      "loss": 0.4816,
      "step": 12806
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.8324747356568651,
      "learning_rate": 3.112393392645985e-07,
      "loss": 0.4758,
      "step": 12807
    },
    {
      "epoch": 0.89,
      "grad_norm": 3.049099994044643,
      "learning_rate": 3.108483858980943e-07,
      "loss": 0.4951,
      "step": 12808
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.910111533382717,
      "learning_rate": 3.104576703500733e-07,
      "loss": 0.5232,
      "step": 12809
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.5961199311861494,
      "learning_rate": 3.100671926403498e-07,
      "loss": 0.4908,
      "step": 12810
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.5575905872174114,
      "learning_rate": 3.0967695278872946e-07,
      "loss": 0.3949,
      "step": 12811
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.0290342802707553,
      "learning_rate": 3.0928695081500206e-07,
      "loss": 0.5522,
      "step": 12812
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.339829155931952,
      "learning_rate": 3.0889718673894787e-07,
      "loss": 0.4663,
      "step": 12813
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.9547276884686378,
      "learning_rate": 3.0850766058033497e-07,
      "loss": 0.4985,
      "step": 12814
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.929334246969889,
      "learning_rate": 3.081183723589176e-07,
      "loss": 0.5328,
      "step": 12815
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.8214264660663146,
      "learning_rate": 3.0772932209444104e-07,
      "loss": 0.4536,
      "step": 12816
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.222603762182097,
      "learning_rate": 3.0734050980663344e-07,
      "loss": 0.4989,
      "step": 12817
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.5476013948552776,
      "learning_rate": 3.069519355152184e-07,
      "loss": 0.4858,
      "step": 12818
    },
    {
      "epoch": 0.89,
      "grad_norm": 4.867106829078087,
      "learning_rate": 3.065635992399002e-07,
      "loss": 0.4142,
      "step": 12819
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.040605503989804,
      "learning_rate": 3.061755010003753e-07,
      "loss": 0.4104,
      "step": 12820
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.5565682956684213,
      "learning_rate": 3.057876408163246e-07,
      "loss": 0.5179,
      "step": 12821
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.913075051357237,
      "learning_rate": 3.054000187074224e-07,
      "loss": 0.4662,
      "step": 12822
    },
    {
      "epoch": 0.89,
      "grad_norm": 3.1989532228660194,
      "learning_rate": 3.050126346933252e-07,
      "loss": 0.4649,
      "step": 12823
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.9871960135883209,
      "learning_rate": 3.046254887936817e-07,
      "loss": 0.5202,
      "step": 12824
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.1529125829554605,
      "learning_rate": 3.0423858102812453e-07,
      "loss": 0.4744,
      "step": 12825
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.5603657524481043,
      "learning_rate": 3.0385191141627747e-07,
      "loss": 0.4896,
      "step": 12826
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.064337047329553,
      "learning_rate": 3.03465479977752e-07,
      "loss": 0.5056,
      "step": 12827
    },
    {
      "epoch": 0.89,
      "grad_norm": 4.537844454156381,
      "learning_rate": 3.030792867321447e-07,
      "loss": 0.5157,
      "step": 12828
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.578447862832131,
      "learning_rate": 3.026933316990438e-07,
      "loss": 0.4294,
      "step": 12829
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.363397683291529,
      "learning_rate": 3.023076148980225e-07,
      "loss": 0.4608,
      "step": 12830
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.2522471660455814,
      "learning_rate": 3.0192213634864465e-07,
      "loss": 0.5022,
      "step": 12831
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.677919917032904,
      "learning_rate": 3.015368960704584e-07,
      "loss": 0.469,
      "step": 12832
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.058350135125452,
      "learning_rate": 3.0115189408300325e-07,
      "loss": 0.4268,
      "step": 12833
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.854106412149455,
      "learning_rate": 3.007671304058046e-07,
      "loss": 0.5041,
      "step": 12834
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.208207374828056,
      "learning_rate": 3.003826050583775e-07,
      "loss": 0.474,
      "step": 12835
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.415304646073721,
      "learning_rate": 2.9999831806022227e-07,
      "loss": 0.4778,
      "step": 12836
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.7044916418244827,
      "learning_rate": 2.996142694308296e-07,
      "loss": 0.486,
      "step": 12837
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.8884184211350277,
      "learning_rate": 2.9923045918967777e-07,
      "loss": 0.4896,
      "step": 12838
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.3563071670313493,
      "learning_rate": 2.9884688735623113e-07,
      "loss": 0.4838,
      "step": 12839
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.244402912040759,
      "learning_rate": 2.984635539499442e-07,
      "loss": 0.4895,
      "step": 12840
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.8605923193269813,
      "learning_rate": 2.9808045899025637e-07,
      "loss": 0.4641,
      "step": 12841
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.8606375527936656,
      "learning_rate": 2.9769760249659997e-07,
      "loss": 0.4706,
      "step": 12842
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.9757780512697891,
      "learning_rate": 2.973149844883899e-07,
      "loss": 0.5021,
      "step": 12843
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.709911744320432,
      "learning_rate": 2.9693260498503354e-07,
      "loss": 0.4443,
      "step": 12844
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.9141120189684697,
      "learning_rate": 2.965504640059208e-07,
      "loss": 0.4559,
      "step": 12845
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.0889563863251213,
      "learning_rate": 2.961685615704357e-07,
      "loss": 0.5055,
      "step": 12846
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.785896661621969,
      "learning_rate": 2.95786897697945e-07,
      "loss": 0.5064,
      "step": 12847
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.7913944521862364,
      "learning_rate": 2.9540547240780646e-07,
      "loss": 0.4865,
      "step": 12848
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.9034520213658113,
      "learning_rate": 2.9502428571936527e-07,
      "loss": 0.4564,
      "step": 12849
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.8458464346009256,
      "learning_rate": 2.946433376519525e-07,
      "loss": 0.45,
      "step": 12850
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.1704408004940854,
      "learning_rate": 2.9426262822489005e-07,
      "loss": 0.5101,
      "step": 12851
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.0109955522677665,
      "learning_rate": 2.9388215745748347e-07,
      "loss": 0.4775,
      "step": 12852
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.6038060401563925,
      "learning_rate": 2.93501925369033e-07,
      "loss": 0.4433,
      "step": 12853
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.9936161283808016,
      "learning_rate": 2.9312193197882035e-07,
      "loss": 0.4534,
      "step": 12854
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.9681376630185785,
      "learning_rate": 2.927421773061184e-07,
      "loss": 0.4685,
      "step": 12855
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.7476386187905601,
      "learning_rate": 2.9236266137018577e-07,
      "loss": 0.4972,
      "step": 12856
    },
    {
      "epoch": 0.89,
      "grad_norm": 3.7391335850795615,
      "learning_rate": 2.919833841902714e-07,
      "loss": 0.4624,
      "step": 12857
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.5711005798531956,
      "learning_rate": 2.916043457856105e-07,
      "loss": 0.4649,
      "step": 12858
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.785104488530853,
      "learning_rate": 2.912255461754282e-07,
      "loss": 0.4744,
      "step": 12859
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.228303661709935,
      "learning_rate": 2.9084698537893364e-07,
      "loss": 0.4675,
      "step": 12860
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.9075900380254451,
      "learning_rate": 2.90468663415327e-07,
      "loss": 0.4823,
      "step": 12861
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.5370793689786595,
      "learning_rate": 2.900905803037968e-07,
      "loss": 0.4116,
      "step": 12862
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.0243349058385594,
      "learning_rate": 2.8971273606351656e-07,
      "loss": 0.4896,
      "step": 12863
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.4979365148137904,
      "learning_rate": 2.893351307136499e-07,
      "loss": 0.3999,
      "step": 12864
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.620701929836961,
      "learning_rate": 2.8895776427334765e-07,
      "loss": 0.408,
      "step": 12865
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.8381145489675208,
      "learning_rate": 2.885806367617494e-07,
      "loss": 0.4756,
      "step": 12866
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.242779566784677,
      "learning_rate": 2.882037481979805e-07,
      "loss": 0.5309,
      "step": 12867
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.1198993452116084,
      "learning_rate": 2.878270986011561e-07,
      "loss": 0.4955,
      "step": 12868
    },
    {
      "epoch": 0.89,
      "grad_norm": 3.2800952416328957,
      "learning_rate": 2.874506879903799e-07,
      "loss": 0.4963,
      "step": 12869
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.9477283744650005,
      "learning_rate": 2.8707451638473937e-07,
      "loss": 0.4881,
      "step": 12870
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.5560121867383107,
      "learning_rate": 2.866985838033159e-07,
      "loss": 0.4063,
      "step": 12871
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.5536811040886931,
      "learning_rate": 2.863228902651721e-07,
      "loss": 0.4122,
      "step": 12872
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.9136287950392021,
      "learning_rate": 2.8594743578936546e-07,
      "loss": 0.512,
      "step": 12873
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.486018665824421,
      "learning_rate": 2.8557222039493514e-07,
      "loss": 0.4656,
      "step": 12874
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.445267325414001,
      "learning_rate": 2.851972441009132e-07,
      "loss": 0.4697,
      "step": 12875
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.203368911928418,
      "learning_rate": 2.8482250692631387e-07,
      "loss": 0.4797,
      "step": 12876
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.5539490073206648,
      "learning_rate": 2.8444800889014635e-07,
      "loss": 0.4474,
      "step": 12877
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.4675155179075374,
      "learning_rate": 2.8407375001140157e-07,
      "loss": 0.4921,
      "step": 12878
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.6643657570081243,
      "learning_rate": 2.8369973030906216e-07,
      "loss": 0.462,
      "step": 12879
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.818895356952555,
      "learning_rate": 2.8332594980209574e-07,
      "loss": 0.4492,
      "step": 12880
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.319694475051821,
      "learning_rate": 2.8295240850945927e-07,
      "loss": 0.4683,
      "step": 12881
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.884962628982688,
      "learning_rate": 2.8257910645009935e-07,
      "loss": 0.5181,
      "step": 12882
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.9406602738501184,
      "learning_rate": 2.822060436429469e-07,
      "loss": 0.481,
      "step": 12883
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.5638867980776721,
      "learning_rate": 2.8183322010692294e-07,
      "loss": 0.4168,
      "step": 12884
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.7218772204668107,
      "learning_rate": 2.814606358609356e-07,
      "loss": 0.508,
      "step": 12885
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.783766952917469,
      "learning_rate": 2.810882909238827e-07,
      "loss": 0.4614,
      "step": 12886
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.217705327053485,
      "learning_rate": 2.807161853146462e-07,
      "loss": 0.488,
      "step": 12887
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.51232019781319,
      "learning_rate": 2.803443190520988e-07,
      "loss": 0.5128,
      "step": 12888
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.8017689282691567,
      "learning_rate": 2.7997269215510106e-07,
      "loss": 0.4813,
      "step": 12889
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.1783789297902265,
      "learning_rate": 2.7960130464250054e-07,
      "loss": 0.5029,
      "step": 12890
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.193286624608105,
      "learning_rate": 2.792301565331318e-07,
      "loss": 0.4334,
      "step": 12891
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.9058110366775716,
      "learning_rate": 2.7885924784581906e-07,
      "loss": 0.5183,
      "step": 12892
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.441377066259722,
      "learning_rate": 2.7848857859937404e-07,
      "loss": 0.458,
      "step": 12893
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.5724073662637937,
      "learning_rate": 2.7811814881259503e-07,
      "loss": 0.4251,
      "step": 12894
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.1694665033867686,
      "learning_rate": 2.777479585042697e-07,
      "loss": 0.542,
      "step": 12895
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.0596531793986035,
      "learning_rate": 2.7737800769317093e-07,
      "loss": 0.4978,
      "step": 12896
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.5828462361554922,
      "learning_rate": 2.770082963980647e-07,
      "loss": 0.3965,
      "step": 12897
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.264494283847071,
      "learning_rate": 2.7663882463769886e-07,
      "loss": 0.5015,
      "step": 12898
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.90451734122374,
      "learning_rate": 2.762695924308134e-07,
      "loss": 0.4401,
      "step": 12899
    },
    {
      "epoch": 0.9,
      "grad_norm": 9.04759015380325,
      "learning_rate": 2.759005997961328e-07,
      "loss": 0.4907,
      "step": 12900
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.7483624897408314,
      "learning_rate": 2.755318467523738e-07,
      "loss": 0.4995,
      "step": 12901
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.270295198496414,
      "learning_rate": 2.7516333331823573e-07,
      "loss": 0.4945,
      "step": 12902
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.248146561635909,
      "learning_rate": 2.747950595124105e-07,
      "loss": 0.4792,
      "step": 12903
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.9519674768766113,
      "learning_rate": 2.744270253535741e-07,
      "loss": 0.5169,
      "step": 12904
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.2238335699510836,
      "learning_rate": 2.740592308603929e-07,
      "loss": 0.4613,
      "step": 12905
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.288659561723575,
      "learning_rate": 2.736916760515207e-07,
      "loss": 0.4939,
      "step": 12906
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.2795595506428374,
      "learning_rate": 2.733243609455971e-07,
      "loss": 0.4477,
      "step": 12907
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.8542546593551947,
      "learning_rate": 2.729572855612522e-07,
      "loss": 0.5005,
      "step": 12908
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.2927766580830595,
      "learning_rate": 2.725904499171028e-07,
      "loss": 0.5039,
      "step": 12909
    },
    {
      "epoch": 0.9,
      "grad_norm": 3.4036051649434182,
      "learning_rate": 2.72223854031754e-07,
      "loss": 0.4906,
      "step": 12910
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.6830390682129384,
      "learning_rate": 2.7185749792379703e-07,
      "loss": 0.4616,
      "step": 12911
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.4487859877997815,
      "learning_rate": 2.714913816118142e-07,
      "loss": 0.5479,
      "step": 12912
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.2209897047731952,
      "learning_rate": 2.7112550511437186e-07,
      "loss": 0.4908,
      "step": 12913
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.5803863830613633,
      "learning_rate": 2.707598684500279e-07,
      "loss": 0.3998,
      "step": 12914
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.5711642552332207,
      "learning_rate": 2.7039447163732415e-07,
      "loss": 0.4271,
      "step": 12915
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.1082206220015944,
      "learning_rate": 2.7002931469479353e-07,
      "loss": 0.5032,
      "step": 12916
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.4286160300734165,
      "learning_rate": 2.6966439764095577e-07,
      "loss": 0.4262,
      "step": 12917
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.2844179296975815,
      "learning_rate": 2.692997204943182e-07,
      "loss": 0.4911,
      "step": 12918
    },
    {
      "epoch": 0.9,
      "grad_norm": 3.028195147180432,
      "learning_rate": 2.689352832733749e-07,
      "loss": 0.4627,
      "step": 12919
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.9848195807764615,
      "learning_rate": 2.6857108599661065e-07,
      "loss": 0.4878,
      "step": 12920
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.0133329255260084,
      "learning_rate": 2.6820712868249553e-07,
      "loss": 0.5351,
      "step": 12921
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.2217602286365046,
      "learning_rate": 2.678434113494882e-07,
      "loss": 0.4609,
      "step": 12922
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.7186191684439318,
      "learning_rate": 2.67479934016035e-07,
      "loss": 0.4709,
      "step": 12923
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.597928726249388,
      "learning_rate": 2.6711669670057174e-07,
      "loss": 0.4429,
      "step": 12924
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.6838088403363325,
      "learning_rate": 2.6675369942151864e-07,
      "loss": 0.4826,
      "step": 12925
    },
    {
      "epoch": 0.9,
      "grad_norm": 8.175829805271247,
      "learning_rate": 2.6639094219728654e-07,
      "loss": 0.4212,
      "step": 12926
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.333371687647432,
      "learning_rate": 2.66028425046273e-07,
      "loss": 0.4834,
      "step": 12927
    },
    {
      "epoch": 0.9,
      "grad_norm": 5.7625875708525856,
      "learning_rate": 2.656661479868655e-07,
      "loss": 0.4578,
      "step": 12928
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.8402096948642046,
      "learning_rate": 2.653041110374349e-07,
      "loss": 0.5154,
      "step": 12929
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.301354164859757,
      "learning_rate": 2.649423142163449e-07,
      "loss": 0.4887,
      "step": 12930
    },
    {
      "epoch": 0.9,
      "grad_norm": 3.3336052314705604,
      "learning_rate": 2.6458075754194237e-07,
      "loss": 0.5007,
      "step": 12931
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.8135662943153839,
      "learning_rate": 2.6421944103256657e-07,
      "loss": 0.4642,
      "step": 12932
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.0857424448692945,
      "learning_rate": 2.638583647065401e-07,
      "loss": 0.516,
      "step": 12933
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.0646752514561713,
      "learning_rate": 2.634975285821778e-07,
      "loss": 0.4838,
      "step": 12934
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.6767020328359776,
      "learning_rate": 2.631369326777783e-07,
      "loss": 0.4406,
      "step": 12935
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.908047664408069,
      "learning_rate": 2.627765770116303e-07,
      "loss": 0.4679,
      "step": 12936
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.239775971513557,
      "learning_rate": 2.6241646160201084e-07,
      "loss": 0.5276,
      "step": 12937
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.9577539530922734,
      "learning_rate": 2.6205658646718257e-07,
      "loss": 0.4419,
      "step": 12938
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.8864161110599043,
      "learning_rate": 2.61696951625397e-07,
      "loss": 0.5222,
      "step": 12939
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.850043662652165,
      "learning_rate": 2.613375570948951e-07,
      "loss": 0.4429,
      "step": 12940
    },
    {
      "epoch": 0.9,
      "grad_norm": 3.689810060913611,
      "learning_rate": 2.6097840289390333e-07,
      "loss": 0.4896,
      "step": 12941
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.4039599723498846,
      "learning_rate": 2.6061948904063663e-07,
      "loss": 0.4959,
      "step": 12942
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.9222610134475453,
      "learning_rate": 2.602608155532982e-07,
      "loss": 0.4871,
      "step": 12943
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.026576027930332,
      "learning_rate": 2.599023824500785e-07,
      "loss": 0.459,
      "step": 12944
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.8108665199561547,
      "learning_rate": 2.595441897491574e-07,
      "loss": 0.4572,
      "step": 12945
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.5999446169311526,
      "learning_rate": 2.591862374686993e-07,
      "loss": 0.4378,
      "step": 12946
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.9787470470908193,
      "learning_rate": 2.588285256268591e-07,
      "loss": 0.4482,
      "step": 12947
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.1557712967538083,
      "learning_rate": 2.5847105424178007e-07,
      "loss": 0.4516,
      "step": 12948
    },
    {
      "epoch": 0.9,
      "grad_norm": 3.0402350221345276,
      "learning_rate": 2.5811382333158997e-07,
      "loss": 0.4815,
      "step": 12949
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.802098368073037,
      "learning_rate": 2.577568329144081e-07,
      "loss": 0.4706,
      "step": 12950
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.2258070753323262,
      "learning_rate": 2.5740008300833787e-07,
      "loss": 0.4809,
      "step": 12951
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.7412721370350615,
      "learning_rate": 2.570435736314747e-07,
      "loss": 0.4772,
      "step": 12952
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.8772912828676802,
      "learning_rate": 2.566873048018981e-07,
      "loss": 0.4216,
      "step": 12953
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.9005633421977004,
      "learning_rate": 2.56331276537678e-07,
      "loss": 0.4886,
      "step": 12954
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.274286825081427,
      "learning_rate": 2.559754888568683e-07,
      "loss": 0.4945,
      "step": 12955
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.8255218098561228,
      "learning_rate": 2.556199417775174e-07,
      "loss": 0.439,
      "step": 12956
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.508419274631586,
      "learning_rate": 2.5526463531765467e-07,
      "loss": 0.46,
      "step": 12957
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.5639470173381131,
      "learning_rate": 2.549095694953019e-07,
      "loss": 0.4247,
      "step": 12958
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.3016697980801455,
      "learning_rate": 2.545547443284646e-07,
      "loss": 0.4625,
      "step": 12959
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.7738593841758914,
      "learning_rate": 2.542001598351401e-07,
      "loss": 0.4989,
      "step": 12960
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.038066763151901,
      "learning_rate": 2.538458160333118e-07,
      "loss": 0.509,
      "step": 12961
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.8021425214078546,
      "learning_rate": 2.534917129409498e-07,
      "loss": 0.4836,
      "step": 12962
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.855665863175861,
      "learning_rate": 2.5313785057601346e-07,
      "loss": 0.4474,
      "step": 12963
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.2022622457842886,
      "learning_rate": 2.527842289564497e-07,
      "loss": 0.4113,
      "step": 12964
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.8656564956831,
      "learning_rate": 2.5243084810019357e-07,
      "loss": 0.4553,
      "step": 12965
    },
    {
      "epoch": 0.9,
      "grad_norm": 3.457031365652877,
      "learning_rate": 2.5207770802516626e-07,
      "loss": 0.5075,
      "step": 12966
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.968686347406648,
      "learning_rate": 2.517248087492785e-07,
      "loss": 0.4724,
      "step": 12967
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.5543477401859604,
      "learning_rate": 2.5137215029042814e-07,
      "loss": 0.4727,
      "step": 12968
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.8706670690998222,
      "learning_rate": 2.51019732666502e-07,
      "loss": 0.4776,
      "step": 12969
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.9453280557590946,
      "learning_rate": 2.506675558953714e-07,
      "loss": 0.4493,
      "step": 12970
    },
    {
      "epoch": 0.9,
      "grad_norm": 4.326064157793967,
      "learning_rate": 2.503156199948986e-07,
      "loss": 0.5283,
      "step": 12971
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.0424075802456865,
      "learning_rate": 2.4996392498293334e-07,
      "loss": 0.456,
      "step": 12972
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.5188295783332167,
      "learning_rate": 2.4961247087731123e-07,
      "loss": 0.4252,
      "step": 12973
    },
    {
      "epoch": 0.9,
      "grad_norm": 7.308974202329599,
      "learning_rate": 2.4926125769585806e-07,
      "loss": 0.4534,
      "step": 12974
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.8630127642458343,
      "learning_rate": 2.4891028545638463e-07,
      "loss": 0.5312,
      "step": 12975
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.1710387572400283,
      "learning_rate": 2.485595541766933e-07,
      "loss": 0.4549,
      "step": 12976
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.8097022281953339,
      "learning_rate": 2.482090638745699e-07,
      "loss": 0.4264,
      "step": 12977
    },
    {
      "epoch": 0.9,
      "grad_norm": 4.400116495845086,
      "learning_rate": 2.4785881456779073e-07,
      "loss": 0.5087,
      "step": 12978
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.5446285467212237,
      "learning_rate": 2.475088062741199e-07,
      "loss": 0.4028,
      "step": 12979
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.228070910655919,
      "learning_rate": 2.471590390113093e-07,
      "loss": 0.4926,
      "step": 12980
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.885035217714756,
      "learning_rate": 2.4680951279709654e-07,
      "loss": 0.4789,
      "step": 12981
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.0932759935479157,
      "learning_rate": 2.4646022764920843e-07,
      "loss": 0.4735,
      "step": 12982
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.3702564637860215,
      "learning_rate": 2.4611118358536136e-07,
      "loss": 0.4836,
      "step": 12983
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.3167617364765554,
      "learning_rate": 2.4576238062325563e-07,
      "loss": 0.4745,
      "step": 12984
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.342288590300973,
      "learning_rate": 2.454138187805827e-07,
      "loss": 0.5625,
      "step": 12985
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.8332363752402154,
      "learning_rate": 2.450654980750189e-07,
      "loss": 0.4585,
      "step": 12986
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.9750527538740104,
      "learning_rate": 2.447174185242324e-07,
      "loss": 0.4719,
      "step": 12987
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.298061603734985,
      "learning_rate": 2.4436958014587455e-07,
      "loss": 0.5409,
      "step": 12988
    },
    {
      "epoch": 0.9,
      "grad_norm": 3.4913967781918265,
      "learning_rate": 2.440219829575879e-07,
      "loss": 0.4795,
      "step": 12989
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.1366560377209773,
      "learning_rate": 2.4367462697700074e-07,
      "loss": 0.4767,
      "step": 12990
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.5969726172466405,
      "learning_rate": 2.433275122217293e-07,
      "loss": 0.4616,
      "step": 12991
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.722083174129117,
      "learning_rate": 2.4298063870938025e-07,
      "loss": 0.4321,
      "step": 12992
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.5539603739685772,
      "learning_rate": 2.426340064575433e-07,
      "loss": 0.4016,
      "step": 12993
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.1421514842803946,
      "learning_rate": 2.422876154837994e-07,
      "loss": 0.4788,
      "step": 12994
    },
    {
      "epoch": 0.9,
      "grad_norm": 3.142283334252361,
      "learning_rate": 2.4194146580571677e-07,
      "loss": 0.495,
      "step": 12995
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.0694809929455404,
      "learning_rate": 2.415955574408518e-07,
      "loss": 0.4986,
      "step": 12996
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.6463371643660365,
      "learning_rate": 2.4124989040674617e-07,
      "loss": 0.4587,
      "step": 12997
    },
    {
      "epoch": 0.9,
      "grad_norm": 3.2206950397878273,
      "learning_rate": 2.4090446472093133e-07,
      "loss": 0.4932,
      "step": 12998
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.031053200971879,
      "learning_rate": 2.405592804009266e-07,
      "loss": 0.4507,
      "step": 12999
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.9147720319879142,
      "learning_rate": 2.402143374642396e-07,
      "loss": 0.506,
      "step": 13000
    },
    {
      "epoch": 0.9,
      "grad_norm": 3.686291615352502,
      "learning_rate": 2.3986963592836255e-07,
      "loss": 0.5467,
      "step": 13001
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.94522968832639,
      "learning_rate": 2.395251758107786e-07,
      "loss": 0.4746,
      "step": 13002
    },
    {
      "epoch": 0.9,
      "grad_norm": 3.117410707467043,
      "learning_rate": 2.3918095712895826e-07,
      "loss": 0.4868,
      "step": 13003
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.5444770987037013,
      "learning_rate": 2.3883697990035816e-07,
      "loss": 0.4039,
      "step": 13004
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.8530124114900857,
      "learning_rate": 2.384932441424248e-07,
      "loss": 0.4783,
      "step": 13005
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.319599840192406,
      "learning_rate": 2.3814974987258932e-07,
      "loss": 0.4511,
      "step": 13006
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.207488799243402,
      "learning_rate": 2.3780649710827552e-07,
      "loss": 0.4749,
      "step": 13007
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.156913535689224,
      "learning_rate": 2.374634858668895e-07,
      "loss": 0.4672,
      "step": 13008
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.9629820056052938,
      "learning_rate": 2.3712071616582954e-07,
      "loss": 0.4411,
      "step": 13009
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.3978889995638912,
      "learning_rate": 2.3677818802247787e-07,
      "loss": 0.4827,
      "step": 13010
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.9521725612016072,
      "learning_rate": 2.3643590145420892e-07,
      "loss": 0.5002,
      "step": 13011
    },
    {
      "epoch": 0.9,
      "grad_norm": 6.672432329844484,
      "learning_rate": 2.360938564783799e-07,
      "loss": 0.4497,
      "step": 13012
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.886815681064615,
      "learning_rate": 2.3575205311234027e-07,
      "loss": 0.473,
      "step": 13013
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.8027591019407017,
      "learning_rate": 2.3541049137342286e-07,
      "loss": 0.4779,
      "step": 13014
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.8935263457813438,
      "learning_rate": 2.3506917127895268e-07,
      "loss": 0.5299,
      "step": 13015
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.1912097340780288,
      "learning_rate": 2.3472809284623975e-07,
      "loss": 0.4765,
      "step": 13016
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.1569732870308322,
      "learning_rate": 2.3438725609258138e-07,
      "loss": 0.487,
      "step": 13017
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.8717073380693239,
      "learning_rate": 2.3404666103526542e-07,
      "loss": 0.4104,
      "step": 13018
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.100919339443979,
      "learning_rate": 2.3370630769156412e-07,
      "loss": 0.4377,
      "step": 13019
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.047050866241392,
      "learning_rate": 2.333661960787409e-07,
      "loss": 0.494,
      "step": 13020
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.233955455944302,
      "learning_rate": 2.3302632621404308e-07,
      "loss": 0.5101,
      "step": 13021
    },
    {
      "epoch": 0.91,
      "grad_norm": 6.287199010059297,
      "learning_rate": 2.326866981147091e-07,
      "loss": 0.4969,
      "step": 13022
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.0148511222581793,
      "learning_rate": 2.3234731179796356e-07,
      "loss": 0.4943,
      "step": 13023
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.7330505296188763,
      "learning_rate": 2.3200816728101927e-07,
      "loss": 0.5347,
      "step": 13024
    },
    {
      "epoch": 0.91,
      "grad_norm": 3.0361999918488074,
      "learning_rate": 2.3166926458107586e-07,
      "loss": 0.4512,
      "step": 13025
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.8277439630836803,
      "learning_rate": 2.313306037153218e-07,
      "loss": 0.5131,
      "step": 13026
    },
    {
      "epoch": 0.91,
      "grad_norm": 3.086489069005378,
      "learning_rate": 2.3099218470093277e-07,
      "loss": 0.4908,
      "step": 13027
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.144285338730411,
      "learning_rate": 2.3065400755507228e-07,
      "loss": 0.4581,
      "step": 13028
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.7990704007309253,
      "learning_rate": 2.3031607229489161e-07,
      "loss": 0.4465,
      "step": 13029
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.7775640602215104,
      "learning_rate": 2.2997837893752872e-07,
      "loss": 0.4409,
      "step": 13030
    },
    {
      "epoch": 0.91,
      "grad_norm": 3.067098049391583,
      "learning_rate": 2.296409275001127e-07,
      "loss": 0.492,
      "step": 13031
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.204439707774767,
      "learning_rate": 2.2930371799975593e-07,
      "loss": 0.4751,
      "step": 13032
    },
    {
      "epoch": 0.91,
      "grad_norm": 3.0588794238399886,
      "learning_rate": 2.2896675045356143e-07,
      "loss": 0.4929,
      "step": 13033
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.1237372329593422,
      "learning_rate": 2.286300248786183e-07,
      "loss": 0.4738,
      "step": 13034
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.0441619882105124,
      "learning_rate": 2.2829354129200566e-07,
      "loss": 0.4885,
      "step": 13035
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.549176087592543,
      "learning_rate": 2.2795729971078707e-07,
      "loss": 0.4364,
      "step": 13036
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.839771950295833,
      "learning_rate": 2.2762130015201721e-07,
      "loss": 0.5049,
      "step": 13037
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.0465055399334777,
      "learning_rate": 2.2728554263273583e-07,
      "loss": 0.5221,
      "step": 13038
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.3824129254508652,
      "learning_rate": 2.269500271699715e-07,
      "loss": 0.5125,
      "step": 13039
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.163150349164707,
      "learning_rate": 2.266147537807417e-07,
      "loss": 0.4871,
      "step": 13040
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.5539012839047874,
      "learning_rate": 2.262797224820479e-07,
      "loss": 0.4704,
      "step": 13041
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.5948267700378077,
      "learning_rate": 2.2594493329088474e-07,
      "loss": 0.4013,
      "step": 13042
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.1030347360851485,
      "learning_rate": 2.2561038622422925e-07,
      "loss": 0.4836,
      "step": 13043
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.8458101055350358,
      "learning_rate": 2.2527608129905066e-07,
      "loss": 0.4866,
      "step": 13044
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.8918056943241435,
      "learning_rate": 2.2494201853230202e-07,
      "loss": 0.4961,
      "step": 13045
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.5393818643685906,
      "learning_rate": 2.2460819794092647e-07,
      "loss": 0.4154,
      "step": 13046
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.1809476645652888,
      "learning_rate": 2.2427461954185493e-07,
      "loss": 0.4727,
      "step": 13047
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.1363412399736874,
      "learning_rate": 2.2394128335200492e-07,
      "loss": 0.496,
      "step": 13048
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.592506260024834,
      "learning_rate": 2.2360818938828189e-07,
      "loss": 0.4329,
      "step": 13049
    },
    {
      "epoch": 0.91,
      "grad_norm": 4.302009966070339,
      "learning_rate": 2.2327533766757949e-07,
      "loss": 0.5012,
      "step": 13050
    },
    {
      "epoch": 0.91,
      "grad_norm": 4.726497582634082,
      "learning_rate": 2.229427282067792e-07,
      "loss": 0.515,
      "step": 13051
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.9864582756969027,
      "learning_rate": 2.226103610227498e-07,
      "loss": 0.5032,
      "step": 13052
    },
    {
      "epoch": 0.91,
      "grad_norm": 8.397720692124748,
      "learning_rate": 2.2227823613234721e-07,
      "loss": 0.4647,
      "step": 13053
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.2742685286932685,
      "learning_rate": 2.2194635355241578e-07,
      "loss": 0.4942,
      "step": 13054
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.9763859351616915,
      "learning_rate": 2.2161471329978924e-07,
      "loss": 0.4959,
      "step": 13055
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.9806676090065531,
      "learning_rate": 2.2128331539128522e-07,
      "loss": 0.4536,
      "step": 13056
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.9515639484968759,
      "learning_rate": 2.20952159843712e-07,
      "loss": 0.4916,
      "step": 13057
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.0909478642818593,
      "learning_rate": 2.2062124667386497e-07,
      "loss": 0.4899,
      "step": 13058
    },
    {
      "epoch": 0.91,
      "grad_norm": 13.133975713190644,
      "learning_rate": 2.2029057589852632e-07,
      "loss": 0.4872,
      "step": 13059
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.0084039316316855,
      "learning_rate": 2.199601475344676e-07,
      "loss": 0.5064,
      "step": 13060
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.9576212687933214,
      "learning_rate": 2.1962996159844485e-07,
      "loss": 0.5167,
      "step": 13061
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6268871495304635,
      "learning_rate": 2.1930001810720692e-07,
      "loss": 0.4323,
      "step": 13062
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.3161284802768574,
      "learning_rate": 2.189703170774854e-07,
      "loss": 0.4645,
      "step": 13063
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.5278217736734762,
      "learning_rate": 2.1864085852600303e-07,
      "loss": 0.4071,
      "step": 13064
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.145031764173959,
      "learning_rate": 2.18311642469467e-07,
      "loss": 0.5105,
      "step": 13065
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.9136396994352023,
      "learning_rate": 2.179826689245762e-07,
      "loss": 0.503,
      "step": 13066
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.9774776115859618,
      "learning_rate": 2.1765393790801393e-07,
      "loss": 0.461,
      "step": 13067
    },
    {
      "epoch": 0.91,
      "grad_norm": 5.053801271521481,
      "learning_rate": 2.1732544943645295e-07,
      "loss": 0.5337,
      "step": 13068
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.808040013471105,
      "learning_rate": 2.1699720352655217e-07,
      "loss": 0.4903,
      "step": 13069
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.018484487800091,
      "learning_rate": 2.1666920019495996e-07,
      "loss": 0.492,
      "step": 13070
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.527636614904625,
      "learning_rate": 2.1634143945831187e-07,
      "loss": 0.4712,
      "step": 13071
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.9189054599624924,
      "learning_rate": 2.160139213332296e-07,
      "loss": 0.4722,
      "step": 13072
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.2128571561494463,
      "learning_rate": 2.1568664583632492e-07,
      "loss": 0.4979,
      "step": 13073
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.1567463940419813,
      "learning_rate": 2.153596129841956e-07,
      "loss": 0.4429,
      "step": 13074
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.594855771609785,
      "learning_rate": 2.1503282279342842e-07,
      "loss": 0.4745,
      "step": 13075
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.5319410805357364,
      "learning_rate": 2.1470627528059563e-07,
      "loss": 0.4042,
      "step": 13076
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.1447461415069236,
      "learning_rate": 2.1437997046226012e-07,
      "loss": 0.4766,
      "step": 13077
    },
    {
      "epoch": 0.91,
      "grad_norm": 3.216215220258659,
      "learning_rate": 2.140539083549703e-07,
      "loss": 0.4766,
      "step": 13078
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.1711704825944262,
      "learning_rate": 2.1372808897526354e-07,
      "loss": 0.4971,
      "step": 13079
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.1392438426412097,
      "learning_rate": 2.134025123396638e-07,
      "loss": 0.4933,
      "step": 13080
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.5440321424065857,
      "learning_rate": 2.1307717846468345e-07,
      "loss": 0.4805,
      "step": 13081
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.1843644530197057,
      "learning_rate": 2.1275208736682262e-07,
      "loss": 0.462,
      "step": 13082
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.639280033454532,
      "learning_rate": 2.1242723906256812e-07,
      "loss": 0.4927,
      "step": 13083
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.4017268243049195,
      "learning_rate": 2.1210263356839621e-07,
      "loss": 0.4812,
      "step": 13084
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.571374161578757,
      "learning_rate": 2.117782709007682e-07,
      "loss": 0.4578,
      "step": 13085
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.4140110174164793,
      "learning_rate": 2.1145415107613699e-07,
      "loss": 0.4767,
      "step": 13086
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.3037684517563504,
      "learning_rate": 2.111302741109389e-07,
      "loss": 0.4927,
      "step": 13087
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.0140164785609174,
      "learning_rate": 2.1080664002160133e-07,
      "loss": 0.4722,
      "step": 13088
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.3154121311711573,
      "learning_rate": 2.104832488245362e-07,
      "loss": 0.4628,
      "step": 13089
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.430824635681778,
      "learning_rate": 2.10160100536147e-07,
      "loss": 0.5329,
      "step": 13090
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.709477918624373,
      "learning_rate": 2.0983719517282119e-07,
      "loss": 0.4811,
      "step": 13091
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.630977302365051,
      "learning_rate": 2.095145327509368e-07,
      "loss": 0.4547,
      "step": 13092
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.280442043998942,
      "learning_rate": 2.0919211328685684e-07,
      "loss": 0.5083,
      "step": 13093
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.5635347906852693,
      "learning_rate": 2.088699367969338e-07,
      "loss": 0.4041,
      "step": 13094
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.6691982884889245,
      "learning_rate": 2.0854800329750847e-07,
      "loss": 0.4823,
      "step": 13095
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.7821378111713662,
      "learning_rate": 2.0822631280490613e-07,
      "loss": 0.4714,
      "step": 13096
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.8345402738024144,
      "learning_rate": 2.0790486533544373e-07,
      "loss": 0.437,
      "step": 13097
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.712908144432128,
      "learning_rate": 2.0758366090542327e-07,
      "loss": 0.5295,
      "step": 13098
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.5818430461958051,
      "learning_rate": 2.072626995311361e-07,
      "loss": 0.4349,
      "step": 13099
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.9478089769536202,
      "learning_rate": 2.0694198122885868e-07,
      "loss": 0.4815,
      "step": 13100
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.2246986251527447,
      "learning_rate": 2.0662150601485798e-07,
      "loss": 0.4928,
      "step": 13101
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.9417726819225232,
      "learning_rate": 2.0630127390538656e-07,
      "loss": 0.4861,
      "step": 13102
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.694830897566899,
      "learning_rate": 2.0598128491668756e-07,
      "loss": 0.5169,
      "step": 13103
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.3186196469748546,
      "learning_rate": 2.056615390649874e-07,
      "loss": 0.4721,
      "step": 13104
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.240346099874642,
      "learning_rate": 2.0534203636650373e-07,
      "loss": 0.4024,
      "step": 13105
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.214093343129265,
      "learning_rate": 2.0502277683744075e-07,
      "loss": 0.5065,
      "step": 13106
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.2949778197649118,
      "learning_rate": 2.0470376049398944e-07,
      "loss": 0.4427,
      "step": 13107
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.369861270473334,
      "learning_rate": 2.0438498735233015e-07,
      "loss": 0.4834,
      "step": 13108
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.2707807663610655,
      "learning_rate": 2.0406645742862997e-07,
      "loss": 0.513,
      "step": 13109
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.3541669560043443,
      "learning_rate": 2.037481707390432e-07,
      "loss": 0.4731,
      "step": 13110
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.3044277913873383,
      "learning_rate": 2.0343012729971244e-07,
      "loss": 0.5417,
      "step": 13111
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.7334654195092438,
      "learning_rate": 2.0311232712676766e-07,
      "loss": 0.4625,
      "step": 13112
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.5634564718974673,
      "learning_rate": 2.027947702363281e-07,
      "loss": 0.4836,
      "step": 13113
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.9202945620334135,
      "learning_rate": 2.0247745664449703e-07,
      "loss": 0.5173,
      "step": 13114
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.983256572942329,
      "learning_rate": 2.0216038636736822e-07,
      "loss": 0.4627,
      "step": 13115
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.8733382963386156,
      "learning_rate": 2.0184355942102273e-07,
      "loss": 0.4651,
      "step": 13116
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6239820354001596,
      "learning_rate": 2.0152697582152991e-07,
      "loss": 0.3867,
      "step": 13117
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.6693396383306993,
      "learning_rate": 2.012106355849447e-07,
      "loss": 0.5128,
      "step": 13118
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.108257487197885,
      "learning_rate": 2.0089453872731145e-07,
      "loss": 0.4849,
      "step": 13119
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.749947908599338,
      "learning_rate": 2.0057868526465963e-07,
      "loss": 0.4781,
      "step": 13120
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.7967528910096418,
      "learning_rate": 2.0026307521301135e-07,
      "loss": 0.4677,
      "step": 13121
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.0466676219425,
      "learning_rate": 1.999477085883711e-07,
      "loss": 0.5147,
      "step": 13122
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.9096741234357215,
      "learning_rate": 1.9963258540673493e-07,
      "loss": 0.4884,
      "step": 13123
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.5609389167372523,
      "learning_rate": 1.9931770568408337e-07,
      "loss": 0.4162,
      "step": 13124
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.6382134467359741,
      "learning_rate": 1.990030694363865e-07,
      "loss": 0.4716,
      "step": 13125
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.3032880583660296,
      "learning_rate": 1.98688676679602e-07,
      "loss": 0.5018,
      "step": 13126
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.259192195683303,
      "learning_rate": 1.9837452742967444e-07,
      "loss": 0.5765,
      "step": 13127
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.206798414110405,
      "learning_rate": 1.9806062170253658e-07,
      "loss": 0.4474,
      "step": 13128
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.1111292660360457,
      "learning_rate": 1.9774695951410904e-07,
      "loss": 0.4509,
      "step": 13129
    },
    {
      "epoch": 0.91,
      "grad_norm": 5.925350025271843,
      "learning_rate": 1.9743354088029966e-07,
      "loss": 0.4445,
      "step": 13130
    },
    {
      "epoch": 0.91,
      "grad_norm": 3.195108767351505,
      "learning_rate": 1.9712036581700344e-07,
      "loss": 0.499,
      "step": 13131
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.062680331096833,
      "learning_rate": 1.9680743434010385e-07,
      "loss": 0.5498,
      "step": 13132
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.8153938458276644,
      "learning_rate": 1.9649474646547207e-07,
      "loss": 0.4421,
      "step": 13133
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.5794709641647935,
      "learning_rate": 1.961823022089665e-07,
      "loss": 0.4654,
      "step": 13134
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.4262082528535807,
      "learning_rate": 1.9587010158643338e-07,
      "loss": 0.4758,
      "step": 13135
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.9689048359230323,
      "learning_rate": 1.955581446137056e-07,
      "loss": 0.4815,
      "step": 13136
    },
    {
      "epoch": 0.91,
      "grad_norm": 3.157459024438797,
      "learning_rate": 1.9524643130660658e-07,
      "loss": 0.4741,
      "step": 13137
    },
    {
      "epoch": 0.91,
      "grad_norm": 4.188142009578212,
      "learning_rate": 1.9493496168094316e-07,
      "loss": 0.5206,
      "step": 13138
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.4408052918297547,
      "learning_rate": 1.946237357525138e-07,
      "loss": 0.4897,
      "step": 13139
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.7448325707856438,
      "learning_rate": 1.943127535371009e-07,
      "loss": 0.4766,
      "step": 13140
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.6985314124889643,
      "learning_rate": 1.94002015050479e-07,
      "loss": 0.481,
      "step": 13141
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.4758860635092352,
      "learning_rate": 1.9369152030840553e-07,
      "loss": 0.4865,
      "step": 13142
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.764695725054955,
      "learning_rate": 1.933812693266296e-07,
      "loss": 0.4928,
      "step": 13143
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.8876199806089116,
      "learning_rate": 1.9307126212088411e-07,
      "loss": 0.4775,
      "step": 13144
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.7555418392409319,
      "learning_rate": 1.9276149870689375e-07,
      "loss": 0.4545,
      "step": 13145
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.3955461314450464,
      "learning_rate": 1.9245197910036706e-07,
      "loss": 0.4734,
      "step": 13146
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.9745353165700352,
      "learning_rate": 1.9214270331700312e-07,
      "loss": 0.4703,
      "step": 13147
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.278775364568696,
      "learning_rate": 1.918336713724861e-07,
      "loss": 0.472,
      "step": 13148
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.003918022903895,
      "learning_rate": 1.9152488328249008e-07,
      "loss": 0.5228,
      "step": 13149
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.3382375841728873,
      "learning_rate": 1.9121633906267532e-07,
      "loss": 0.4664,
      "step": 13150
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.9026208924845214,
      "learning_rate": 1.9090803872869046e-07,
      "loss": 0.452,
      "step": 13151
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.5230688500251164,
      "learning_rate": 1.9059998229617072e-07,
      "loss": 0.507,
      "step": 13152
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.828479898957151,
      "learning_rate": 1.9029216978074084e-07,
      "loss": 0.5312,
      "step": 13153
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.0004536733351337,
      "learning_rate": 1.8998460119801221e-07,
      "loss": 0.5,
      "step": 13154
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.3085915693817696,
      "learning_rate": 1.8967727656358182e-07,
      "loss": 0.482,
      "step": 13155
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.271982868017305,
      "learning_rate": 1.8937019589303774e-07,
      "loss": 0.5018,
      "step": 13156
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.1223515199089364,
      "learning_rate": 1.8906335920195418e-07,
      "loss": 0.4632,
      "step": 13157
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.901037881652382,
      "learning_rate": 1.887567665058926e-07,
      "loss": 0.4638,
      "step": 13158
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.320196040394275,
      "learning_rate": 1.8845041782040162e-07,
      "loss": 0.5093,
      "step": 13159
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.148966534447551,
      "learning_rate": 1.881443131610189e-07,
      "loss": 0.4927,
      "step": 13160
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.8595079740353906,
      "learning_rate": 1.8783845254327027e-07,
      "loss": 0.4652,
      "step": 13161
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.800347338503199,
      "learning_rate": 1.8753283598266558e-07,
      "loss": 0.4807,
      "step": 13162
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.8295036149432624,
      "learning_rate": 1.8722746349470634e-07,
      "loss": 0.479,
      "step": 13163
    },
    {
      "epoch": 0.92,
      "grad_norm": 4.526644883793925,
      "learning_rate": 1.86922335094879e-07,
      "loss": 0.4999,
      "step": 13164
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.4751703453294978,
      "learning_rate": 1.8661745079866011e-07,
      "loss": 0.5135,
      "step": 13165
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.9638409299601574,
      "learning_rate": 1.8631281062151117e-07,
      "loss": 0.433,
      "step": 13166
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.5261579930691651,
      "learning_rate": 1.8600841457888264e-07,
      "loss": 0.3978,
      "step": 13167
    },
    {
      "epoch": 0.92,
      "grad_norm": 3.442742483431661,
      "learning_rate": 1.857042626862132e-07,
      "loss": 0.4727,
      "step": 13168
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.2851631878781085,
      "learning_rate": 1.8540035495892837e-07,
      "loss": 0.4834,
      "step": 13169
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.8498281678763344,
      "learning_rate": 1.850966914124408e-07,
      "loss": 0.5268,
      "step": 13170
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.457488914284248,
      "learning_rate": 1.8479327206215148e-07,
      "loss": 0.4852,
      "step": 13171
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.0139305239686673,
      "learning_rate": 1.8449009692344923e-07,
      "loss": 0.4895,
      "step": 13172
    },
    {
      "epoch": 0.92,
      "grad_norm": 3.0984120319134116,
      "learning_rate": 1.841871660117095e-07,
      "loss": 0.4612,
      "step": 13173
    },
    {
      "epoch": 0.92,
      "grad_norm": 4.1469782290039765,
      "learning_rate": 1.838844793422967e-07,
      "loss": 0.5151,
      "step": 13174
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.9554349062962693,
      "learning_rate": 1.835820369305602e-07,
      "loss": 0.4516,
      "step": 13175
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.511844148158881,
      "learning_rate": 1.8327983879184164e-07,
      "loss": 0.5281,
      "step": 13176
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.6056371554313364,
      "learning_rate": 1.8297788494146597e-07,
      "loss": 0.4868,
      "step": 13177
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.9077392661250856,
      "learning_rate": 1.8267617539474812e-07,
      "loss": 0.4433,
      "step": 13178
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.991549646961861,
      "learning_rate": 1.823747101669887e-07,
      "loss": 0.5206,
      "step": 13179
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.5804604770638178,
      "learning_rate": 1.8207348927347713e-07,
      "loss": 0.5029,
      "step": 13180
    },
    {
      "epoch": 0.92,
      "grad_norm": 3.409864403706355,
      "learning_rate": 1.8177251272949225e-07,
      "loss": 0.4832,
      "step": 13181
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.6353099468336594,
      "learning_rate": 1.814717805502958e-07,
      "loss": 0.4841,
      "step": 13182
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.418240360295461,
      "learning_rate": 1.8117129275114165e-07,
      "loss": 0.4775,
      "step": 13183
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.887429698482345,
      "learning_rate": 1.8087104934726985e-07,
      "loss": 0.465,
      "step": 13184
    },
    {
      "epoch": 0.92,
      "grad_norm": 4.023247260393936,
      "learning_rate": 1.805710503539071e-07,
      "loss": 0.4455,
      "step": 13185
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.0244217939949842,
      "learning_rate": 1.802712957862679e-07,
      "loss": 0.4917,
      "step": 13186
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.6530296290948034,
      "learning_rate": 1.7997178565955507e-07,
      "loss": 0.4738,
      "step": 13187
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.4812836495059516,
      "learning_rate": 1.7967251998895985e-07,
      "loss": 0.4097,
      "step": 13188
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.5914823886809265,
      "learning_rate": 1.7937349878965894e-07,
      "loss": 0.421,
      "step": 13189
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.9447693408627513,
      "learning_rate": 1.7907472207681798e-07,
      "loss": 0.4612,
      "step": 13190
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.633419793163098,
      "learning_rate": 1.7877618986558986e-07,
      "loss": 0.4941,
      "step": 13191
    },
    {
      "epoch": 0.92,
      "grad_norm": 4.166983141838388,
      "learning_rate": 1.7847790217111639e-07,
      "loss": 0.5123,
      "step": 13192
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.128070840043774,
      "learning_rate": 1.781798590085232e-07,
      "loss": 0.4874,
      "step": 13193
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.7082615524710114,
      "learning_rate": 1.7788206039292877e-07,
      "loss": 0.4948,
      "step": 13194
    },
    {
      "epoch": 0.92,
      "grad_norm": 3.562507184151498,
      "learning_rate": 1.775845063394338e-07,
      "loss": 0.4798,
      "step": 13195
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.2264090572065367,
      "learning_rate": 1.7728719686313178e-07,
      "loss": 0.4611,
      "step": 13196
    },
    {
      "epoch": 0.92,
      "grad_norm": 3.228658916297471,
      "learning_rate": 1.7699013197909954e-07,
      "loss": 0.4977,
      "step": 13197
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.4116595853054363,
      "learning_rate": 1.76693311702405e-07,
      "loss": 0.449,
      "step": 13198
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.402169960827136,
      "learning_rate": 1.7639673604809893e-07,
      "loss": 0.4906,
      "step": 13199
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.138979415407591,
      "learning_rate": 1.761004050312265e-07,
      "loss": 0.4996,
      "step": 13200
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.4903487464507843,
      "learning_rate": 1.7580431866681347e-07,
      "loss": 0.4692,
      "step": 13201
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.8818155720279626,
      "learning_rate": 1.755084769698784e-07,
      "loss": 0.4797,
      "step": 13202
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.3093583468078,
      "learning_rate": 1.7521287995542424e-07,
      "loss": 0.4587,
      "step": 13203
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.5359649394635311,
      "learning_rate": 1.7491752763844294e-07,
      "loss": 0.3924,
      "step": 13204
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.064213520270098,
      "learning_rate": 1.7462242003391417e-07,
      "loss": 0.4713,
      "step": 13205
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.98695339955925,
      "learning_rate": 1.7432755715680484e-07,
      "loss": 0.4447,
      "step": 13206
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.061725375022978,
      "learning_rate": 1.7403293902206851e-07,
      "loss": 0.4763,
      "step": 13207
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.5469101040561172,
      "learning_rate": 1.737385656446483e-07,
      "loss": 0.4118,
      "step": 13208
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.8810993143410348,
      "learning_rate": 1.7344443703947388e-07,
      "loss": 0.4597,
      "step": 13209
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.4221362682842527,
      "learning_rate": 1.731505532214617e-07,
      "loss": 0.478,
      "step": 13210
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.073954466234217,
      "learning_rate": 1.7285691420551698e-07,
      "loss": 0.4777,
      "step": 13211
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.8563564942858313,
      "learning_rate": 1.725635200065323e-07,
      "loss": 0.4892,
      "step": 13212
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.1086990833675068,
      "learning_rate": 1.72270370639388e-07,
      "loss": 0.5513,
      "step": 13213
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.4335920647143876,
      "learning_rate": 1.7197746611895106e-07,
      "loss": 0.44,
      "step": 13214
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.4947351016802175,
      "learning_rate": 1.7168480646007624e-07,
      "loss": 0.5016,
      "step": 13215
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.088852658154244,
      "learning_rate": 1.7139239167760724e-07,
      "loss": 0.5059,
      "step": 13216
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.9286617311813323,
      "learning_rate": 1.7110022178637387e-07,
      "loss": 0.4455,
      "step": 13217
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.8186633842511442,
      "learning_rate": 1.7080829680119482e-07,
      "loss": 0.4797,
      "step": 13218
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.2196964637424585,
      "learning_rate": 1.7051661673687324e-07,
      "loss": 0.4468,
      "step": 13219
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.083578122603959,
      "learning_rate": 1.7022518160820512e-07,
      "loss": 0.4904,
      "step": 13220
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.8770550244685096,
      "learning_rate": 1.6993399142996969e-07,
      "loss": 0.4466,
      "step": 13221
    },
    {
      "epoch": 0.92,
      "grad_norm": 4.211814085853046,
      "learning_rate": 1.6964304621693516e-07,
      "loss": 0.4304,
      "step": 13222
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.9894205794021274,
      "learning_rate": 1.6935234598385696e-07,
      "loss": 0.5361,
      "step": 13223
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.1741157457369527,
      "learning_rate": 1.690618907454794e-07,
      "loss": 0.4987,
      "step": 13224
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.3707095191471548,
      "learning_rate": 1.6877168051653292e-07,
      "loss": 0.5042,
      "step": 13225
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.7261108592249728,
      "learning_rate": 1.6848171531173686e-07,
      "loss": 0.529,
      "step": 13226
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.6580330026064047,
      "learning_rate": 1.6819199514579553e-07,
      "loss": 0.4685,
      "step": 13227
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.4101519171303565,
      "learning_rate": 1.6790252003340335e-07,
      "loss": 0.4603,
      "step": 13228
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.7317549466268742,
      "learning_rate": 1.6761328998924297e-07,
      "loss": 0.5041,
      "step": 13229
    },
    {
      "epoch": 0.92,
      "grad_norm": 3.0322518020961042,
      "learning_rate": 1.673243050279816e-07,
      "loss": 0.527,
      "step": 13230
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.966937977326437,
      "learning_rate": 1.670355651642752e-07,
      "loss": 0.468,
      "step": 13231
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.4480397398962284,
      "learning_rate": 1.667470704127694e-07,
      "loss": 0.4409,
      "step": 13232
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.6132841443460727,
      "learning_rate": 1.6645882078809515e-07,
      "loss": 0.4121,
      "step": 13233
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.5743731428451107,
      "learning_rate": 1.661708163048703e-07,
      "loss": 0.459,
      "step": 13234
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.97469789734207,
      "learning_rate": 1.6588305697770313e-07,
      "loss": 0.4349,
      "step": 13235
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.8552956577418305,
      "learning_rate": 1.6559554282118696e-07,
      "loss": 0.4883,
      "step": 13236
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.189227571893186,
      "learning_rate": 1.65308273849904e-07,
      "loss": 0.4613,
      "step": 13237
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.0597008649044666,
      "learning_rate": 1.6502125007842317e-07,
      "loss": 0.5045,
      "step": 13238
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.023333301813236,
      "learning_rate": 1.6473447152130173e-07,
      "loss": 0.4814,
      "step": 13239
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.7183349310922,
      "learning_rate": 1.6444793819308413e-07,
      "loss": 0.497,
      "step": 13240
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.74424326355329,
      "learning_rate": 1.641616501083021e-07,
      "loss": 0.5167,
      "step": 13241
    },
    {
      "epoch": 0.92,
      "grad_norm": 5.082638660986347,
      "learning_rate": 1.6387560728147512e-07,
      "loss": 0.4671,
      "step": 13242
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.109784229550352,
      "learning_rate": 1.6358980972711102e-07,
      "loss": 0.4589,
      "step": 13243
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.8638905479497996,
      "learning_rate": 1.633042574597049e-07,
      "loss": 0.5185,
      "step": 13244
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.233566887965015,
      "learning_rate": 1.630189504937374e-07,
      "loss": 0.466,
      "step": 13245
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.1969427812285915,
      "learning_rate": 1.6273388884367914e-07,
      "loss": 0.5249,
      "step": 13246
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.9233347180535671,
      "learning_rate": 1.6244907252398855e-07,
      "loss": 0.4854,
      "step": 13247
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.702931675472124,
      "learning_rate": 1.6216450154910858e-07,
      "loss": 0.46,
      "step": 13248
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.7500301788179826,
      "learning_rate": 1.618801759334737e-07,
      "loss": 0.4802,
      "step": 13249
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.670845806386466,
      "learning_rate": 1.6159609569150247e-07,
      "loss": 0.5317,
      "step": 13250
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.1607427635005654,
      "learning_rate": 1.6131226083760388e-07,
      "loss": 0.5152,
      "step": 13251
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.957375528115927,
      "learning_rate": 1.610286713861714e-07,
      "loss": 0.4779,
      "step": 13252
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.8655208128429062,
      "learning_rate": 1.6074532735158966e-07,
      "loss": 0.5126,
      "step": 13253
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.7131302631127587,
      "learning_rate": 1.6046222874822714e-07,
      "loss": 0.399,
      "step": 13254
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.253016650257454,
      "learning_rate": 1.6017937559044348e-07,
      "loss": 0.4836,
      "step": 13255
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.4525887529471935,
      "learning_rate": 1.598967678925828e-07,
      "loss": 0.4881,
      "step": 13256
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.677650826771498,
      "learning_rate": 1.5961440566897913e-07,
      "loss": 0.4572,
      "step": 13257
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.7700088908867375,
      "learning_rate": 1.5933228893395102e-07,
      "loss": 0.4712,
      "step": 13258
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.763412019560297,
      "learning_rate": 1.5905041770180818e-07,
      "loss": 0.4921,
      "step": 13259
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.021692344416132,
      "learning_rate": 1.5876879198684637e-07,
      "loss": 0.511,
      "step": 13260
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.17398745142356,
      "learning_rate": 1.5848741180334748e-07,
      "loss": 0.5248,
      "step": 13261
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.7901002604388774,
      "learning_rate": 1.5820627716558235e-07,
      "loss": 0.4095,
      "step": 13262
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.215343542573138,
      "learning_rate": 1.5792538808781012e-07,
      "loss": 0.5089,
      "step": 13263
    },
    {
      "epoch": 0.92,
      "grad_norm": 7.979641121928828,
      "learning_rate": 1.5764474458427714e-07,
      "loss": 0.4969,
      "step": 13264
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.5784132095544372,
      "learning_rate": 1.573643466692143e-07,
      "loss": 0.4224,
      "step": 13265
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.739814940827559,
      "learning_rate": 1.5708419435684463e-07,
      "loss": 0.5032,
      "step": 13266
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.9890483386565998,
      "learning_rate": 1.5680428766137512e-07,
      "loss": 0.4913,
      "step": 13267
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.1473424982515477,
      "learning_rate": 1.565246265970033e-07,
      "loss": 0.4419,
      "step": 13268
    },
    {
      "epoch": 0.92,
      "grad_norm": 3.029358510574734,
      "learning_rate": 1.562452111779117e-07,
      "loss": 0.4824,
      "step": 13269
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.2643185841836857,
      "learning_rate": 1.5596604141827066e-07,
      "loss": 0.5264,
      "step": 13270
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.9043921018351628,
      "learning_rate": 1.556871173322405e-07,
      "loss": 0.5381,
      "step": 13271
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.206261901606993,
      "learning_rate": 1.554084389339655e-07,
      "loss": 0.4855,
      "step": 13272
    },
    {
      "epoch": 0.92,
      "grad_norm": 15.868490431499717,
      "learning_rate": 1.55130006237581e-07,
      "loss": 0.4722,
      "step": 13273
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.013657440218873,
      "learning_rate": 1.5485181925720682e-07,
      "loss": 0.4746,
      "step": 13274
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.5272184427287363,
      "learning_rate": 1.545738780069528e-07,
      "loss": 0.4543,
      "step": 13275
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.892378817024701,
      "learning_rate": 1.5429618250091426e-07,
      "loss": 0.4613,
      "step": 13276
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.8425337660650807,
      "learning_rate": 1.540187327531756e-07,
      "loss": 0.4799,
      "step": 13277
    },
    {
      "epoch": 0.92,
      "grad_norm": 3.179573028284304,
      "learning_rate": 1.5374152877780712e-07,
      "loss": 0.4799,
      "step": 13278
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.9863055802401464,
      "learning_rate": 1.5346457058886988e-07,
      "loss": 0.4872,
      "step": 13279
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.84429502112779,
      "learning_rate": 1.531878582004087e-07,
      "loss": 0.466,
      "step": 13280
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.899724440494826,
      "learning_rate": 1.5291139162645797e-07,
      "loss": 0.4478,
      "step": 13281
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.8704977559819047,
      "learning_rate": 1.5263517088103862e-07,
      "loss": 0.5177,
      "step": 13282
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.8929283112838453,
      "learning_rate": 1.5235919597816007e-07,
      "loss": 0.427,
      "step": 13283
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.5492764885767927,
      "learning_rate": 1.520834669318194e-07,
      "loss": 0.4261,
      "step": 13284
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.1858571079656284,
      "learning_rate": 1.5180798375599937e-07,
      "loss": 0.5111,
      "step": 13285
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.8330277050282675,
      "learning_rate": 1.5153274646467263e-07,
      "loss": 0.5466,
      "step": 13286
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.559580767287368,
      "learning_rate": 1.5125775507179806e-07,
      "loss": 0.4245,
      "step": 13287
    },
    {
      "epoch": 0.92,
      "grad_norm": 3.2957884061255536,
      "learning_rate": 1.509830095913234e-07,
      "loss": 0.4776,
      "step": 13288
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.0761362516306283,
      "learning_rate": 1.507085100371808e-07,
      "loss": 0.4861,
      "step": 13289
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.8854291052453358,
      "learning_rate": 1.50434256423293e-07,
      "loss": 0.5062,
      "step": 13290
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.237600444232576,
      "learning_rate": 1.5016024876356893e-07,
      "loss": 0.4816,
      "step": 13291
    },
    {
      "epoch": 0.92,
      "grad_norm": 3.152542897584661,
      "learning_rate": 1.4988648707190634e-07,
      "loss": 0.4664,
      "step": 13292
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.1987683085270637,
      "learning_rate": 1.4961297136218854e-07,
      "loss": 0.4842,
      "step": 13293
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.7348406124160007,
      "learning_rate": 1.4933970164828727e-07,
      "loss": 0.4776,
      "step": 13294
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.7859899337052982,
      "learning_rate": 1.4906667794406305e-07,
      "loss": 0.5211,
      "step": 13295
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.8499288179212334,
      "learning_rate": 1.4879390026336148e-07,
      "loss": 0.5045,
      "step": 13296
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.1672167223318843,
      "learning_rate": 1.4852136862001766e-07,
      "loss": 0.5017,
      "step": 13297
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.12224606160641,
      "learning_rate": 1.4824908302785323e-07,
      "loss": 0.4628,
      "step": 13298
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.8044282615407543,
      "learning_rate": 1.4797704350067776e-07,
      "loss": 0.4892,
      "step": 13299
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.7911095865927984,
      "learning_rate": 1.4770525005228797e-07,
      "loss": 0.4551,
      "step": 13300
    },
    {
      "epoch": 0.92,
      "grad_norm": 3.3585529039619004,
      "learning_rate": 1.474337026964684e-07,
      "loss": 0.4786,
      "step": 13301
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.264066839137473,
      "learning_rate": 1.471624014469919e-07,
      "loss": 0.4771,
      "step": 13302
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.533674420339102,
      "learning_rate": 1.4689134631761636e-07,
      "loss": 0.4121,
      "step": 13303
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.414333185318614,
      "learning_rate": 1.466205373220897e-07,
      "loss": 0.5113,
      "step": 13304
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.9265747050656516,
      "learning_rate": 1.4634997447414702e-07,
      "loss": 0.5014,
      "step": 13305
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.9170147063948926,
      "learning_rate": 1.4607965778750955e-07,
      "loss": 0.483,
      "step": 13306
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.390219427942074,
      "learning_rate": 1.4580958727588746e-07,
      "loss": 0.4985,
      "step": 13307
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.989449169451972,
      "learning_rate": 1.4553976295297755e-07,
      "loss": 0.4223,
      "step": 13308
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.6975154802541532,
      "learning_rate": 1.4527018483246335e-07,
      "loss": 0.5014,
      "step": 13309
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.3573407645907642,
      "learning_rate": 1.4500085292801891e-07,
      "loss": 0.4778,
      "step": 13310
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.4228420515794706,
      "learning_rate": 1.4473176725330274e-07,
      "loss": 0.4653,
      "step": 13311
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.8868818671814105,
      "learning_rate": 1.444629278219628e-07,
      "loss": 0.4967,
      "step": 13312
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.418259622027275,
      "learning_rate": 1.4419433464763265e-07,
      "loss": 0.5088,
      "step": 13313
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.2578668933876402,
      "learning_rate": 1.439259877439353e-07,
      "loss": 0.4711,
      "step": 13314
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.204152411528703,
      "learning_rate": 1.4365788712448037e-07,
      "loss": 0.4913,
      "step": 13315
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.1863675904132127,
      "learning_rate": 1.4339003280286423e-07,
      "loss": 0.4998,
      "step": 13316
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.9513452811334544,
      "learning_rate": 1.4312242479267213e-07,
      "loss": 0.4409,
      "step": 13317
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.781683170712162,
      "learning_rate": 1.4285506310747655e-07,
      "loss": 0.4843,
      "step": 13318
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.5001184147381825,
      "learning_rate": 1.4258794776083718e-07,
      "loss": 0.505,
      "step": 13319
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.5557448960715373,
      "learning_rate": 1.4232107876630098e-07,
      "loss": 0.4135,
      "step": 13320
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.2779542575407774,
      "learning_rate": 1.4205445613740266e-07,
      "loss": 0.4927,
      "step": 13321
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.009956046319167,
      "learning_rate": 1.4178807988766419e-07,
      "loss": 0.4961,
      "step": 13322
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.098750447911791,
      "learning_rate": 1.4152195003059588e-07,
      "loss": 0.4999,
      "step": 13323
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.9546081335778362,
      "learning_rate": 1.4125606657969472e-07,
      "loss": 0.4862,
      "step": 13324
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.1560818688931715,
      "learning_rate": 1.4099042954844543e-07,
      "loss": 0.494,
      "step": 13325
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.003252470997151,
      "learning_rate": 1.4072503895032064e-07,
      "loss": 0.4302,
      "step": 13326
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.051385088650078,
      "learning_rate": 1.4045989479877898e-07,
      "loss": 0.4962,
      "step": 13327
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.9074144686542918,
      "learning_rate": 1.4019499710726913e-07,
      "loss": 0.4493,
      "step": 13328
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.4296354129022584,
      "learning_rate": 1.3993034588922428e-07,
      "loss": 0.4981,
      "step": 13329
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.835584924714294,
      "learning_rate": 1.3966594115806863e-07,
      "loss": 0.4874,
      "step": 13330
    },
    {
      "epoch": 0.93,
      "grad_norm": 3.4683301664720103,
      "learning_rate": 1.394017829272104e-07,
      "loss": 0.4356,
      "step": 13331
    },
    {
      "epoch": 0.93,
      "grad_norm": 3.008066799312929,
      "learning_rate": 1.3913787121004717e-07,
      "loss": 0.5103,
      "step": 13332
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.7049021396776978,
      "learning_rate": 1.3887420601996325e-07,
      "loss": 0.4585,
      "step": 13333
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.0329210556061446,
      "learning_rate": 1.386107873703324e-07,
      "loss": 0.5043,
      "step": 13334
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.247622833685456,
      "learning_rate": 1.3834761527451279e-07,
      "loss": 0.5161,
      "step": 13335
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.3000484600082345,
      "learning_rate": 1.3808468974585266e-07,
      "loss": 0.463,
      "step": 13336
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.9495897395208732,
      "learning_rate": 1.378220107976863e-07,
      "loss": 0.4685,
      "step": 13337
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.5876537160737191,
      "learning_rate": 1.3755957844333535e-07,
      "loss": 0.3857,
      "step": 13338
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.9067265555951558,
      "learning_rate": 1.3729739269611074e-07,
      "loss": 0.4921,
      "step": 13339
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.9449422553371836,
      "learning_rate": 1.370354535693086e-07,
      "loss": 0.5147,
      "step": 13340
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.1268557569465996,
      "learning_rate": 1.3677376107621431e-07,
      "loss": 0.5126,
      "step": 13341
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.1723721127856392,
      "learning_rate": 1.3651231523009955e-07,
      "loss": 0.4662,
      "step": 13342
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.795674371754469,
      "learning_rate": 1.362511160442248e-07,
      "loss": 0.5068,
      "step": 13343
    },
    {
      "epoch": 0.93,
      "grad_norm": 3.0980821678493125,
      "learning_rate": 1.3599016353183669e-07,
      "loss": 0.4412,
      "step": 13344
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.745309839551028,
      "learning_rate": 1.3572945770616907e-07,
      "loss": 0.4513,
      "step": 13345
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.091675282333002,
      "learning_rate": 1.3546899858044582e-07,
      "loss": 0.4793,
      "step": 13346
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.5106829629683554,
      "learning_rate": 1.3520878616787525e-07,
      "loss": 0.4889,
      "step": 13347
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.3257739829257593,
      "learning_rate": 1.3494882048165513e-07,
      "loss": 0.4774,
      "step": 13348
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.2294932429527217,
      "learning_rate": 1.3468910153496938e-07,
      "loss": 0.4208,
      "step": 13349
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.8439342237214003,
      "learning_rate": 1.3442962934099135e-07,
      "loss": 0.4728,
      "step": 13350
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.9568832080096465,
      "learning_rate": 1.3417040391287938e-07,
      "loss": 0.4595,
      "step": 13351
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.7556333420527248,
      "learning_rate": 1.3391142526378133e-07,
      "loss": 0.4541,
      "step": 13352
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.0047105102251987,
      "learning_rate": 1.3365269340683052e-07,
      "loss": 0.4747,
      "step": 13353
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.055546833680884,
      "learning_rate": 1.3339420835515093e-07,
      "loss": 0.5035,
      "step": 13354
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.969922258718494,
      "learning_rate": 1.3313597012185043e-07,
      "loss": 0.4766,
      "step": 13355
    },
    {
      "epoch": 0.93,
      "grad_norm": 3.224521646979643,
      "learning_rate": 1.3287797872002738e-07,
      "loss": 0.4685,
      "step": 13356
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.8096909856640964,
      "learning_rate": 1.3262023416276414e-07,
      "loss": 0.4621,
      "step": 13357
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.937762332319627,
      "learning_rate": 1.3236273646313525e-07,
      "loss": 0.5126,
      "step": 13358
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.1285470302928773,
      "learning_rate": 1.3210548563419857e-07,
      "loss": 0.4738,
      "step": 13359
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.286803791412056,
      "learning_rate": 1.3184848168900143e-07,
      "loss": 0.4728,
      "step": 13360
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.1145740475955557,
      "learning_rate": 1.3159172464057844e-07,
      "loss": 0.4714,
      "step": 13361
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.2891035107252975,
      "learning_rate": 1.3133521450195086e-07,
      "loss": 0.4647,
      "step": 13362
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.6886839095891033,
      "learning_rate": 1.3107895128612936e-07,
      "loss": 0.4813,
      "step": 13363
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.3084850279521714,
      "learning_rate": 1.3082293500610855e-07,
      "loss": 0.4795,
      "step": 13364
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.8901277637779454,
      "learning_rate": 1.3056716567487472e-07,
      "loss": 0.4399,
      "step": 13365
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.352741647928054,
      "learning_rate": 1.303116433053986e-07,
      "loss": 0.5019,
      "step": 13366
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.838041523982088,
      "learning_rate": 1.300563679106409e-07,
      "loss": 0.4715,
      "step": 13367
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.508171881297129,
      "learning_rate": 1.2980133950354634e-07,
      "loss": 0.5071,
      "step": 13368
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.8213462450990279,
      "learning_rate": 1.2954655809705007e-07,
      "loss": 0.5144,
      "step": 13369
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.8847733018502102,
      "learning_rate": 1.29292023704074e-07,
      "loss": 0.4791,
      "step": 13370
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.69240540316841,
      "learning_rate": 1.2903773633752727e-07,
      "loss": 0.5155,
      "step": 13371
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.2617969969628593,
      "learning_rate": 1.287836960103056e-07,
      "loss": 0.4861,
      "step": 13372
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.8869459466415295,
      "learning_rate": 1.285299027352943e-07,
      "loss": 0.4842,
      "step": 13373
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.105257234923184,
      "learning_rate": 1.2827635652536475e-07,
      "loss": 0.5216,
      "step": 13374
    },
    {
      "epoch": 0.93,
      "grad_norm": 6.050178052561349,
      "learning_rate": 1.2802305739337494e-07,
      "loss": 0.5159,
      "step": 13375
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.9525129691271226,
      "learning_rate": 1.2777000535217243e-07,
      "loss": 0.4969,
      "step": 13376
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.070494595254005,
      "learning_rate": 1.275172004145908e-07,
      "loss": 0.5287,
      "step": 13377
    },
    {
      "epoch": 0.93,
      "grad_norm": 3.0753282142975613,
      "learning_rate": 1.2726464259345206e-07,
      "loss": 0.5388,
      "step": 13378
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.0253392476383487,
      "learning_rate": 1.2701233190156425e-07,
      "loss": 0.4608,
      "step": 13379
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.8506586402947713,
      "learning_rate": 1.2676026835172384e-07,
      "loss": 0.4279,
      "step": 13380
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.116507083244992,
      "learning_rate": 1.2650845195671557e-07,
      "loss": 0.4557,
      "step": 13381
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.0796841391421,
      "learning_rate": 1.2625688272930925e-07,
      "loss": 0.4762,
      "step": 13382
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.060609593282235,
      "learning_rate": 1.2600556068226523e-07,
      "loss": 0.5053,
      "step": 13383
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.4038386868460795,
      "learning_rate": 1.2575448582832828e-07,
      "loss": 0.4841,
      "step": 13384
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.387564337882527,
      "learning_rate": 1.255036581802338e-07,
      "loss": 0.518,
      "step": 13385
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.0781546307726857,
      "learning_rate": 1.2525307775070162e-07,
      "loss": 0.4243,
      "step": 13386
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.8681656715698887,
      "learning_rate": 1.25002744552441e-07,
      "loss": 0.441,
      "step": 13387
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.7830037772599303,
      "learning_rate": 1.2475265859814678e-07,
      "loss": 0.5163,
      "step": 13388
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.2966552297076044,
      "learning_rate": 1.2450281990050438e-07,
      "loss": 0.4863,
      "step": 13389
    },
    {
      "epoch": 0.93,
      "grad_norm": 3.070938092576739,
      "learning_rate": 1.2425322847218368e-07,
      "loss": 0.4769,
      "step": 13390
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.5439419724843887,
      "learning_rate": 1.2400388432584397e-07,
      "loss": 0.4038,
      "step": 13391
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.5500489522012546,
      "learning_rate": 1.2375478747413017e-07,
      "loss": 0.4877,
      "step": 13392
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.5664570755524427,
      "learning_rate": 1.2350593792967547e-07,
      "loss": 0.4028,
      "step": 13393
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.0371641672990437,
      "learning_rate": 1.2325733570510202e-07,
      "loss": 0.5068,
      "step": 13394
    },
    {
      "epoch": 0.93,
      "grad_norm": 4.086765542243983,
      "learning_rate": 1.2300898081301747e-07,
      "loss": 0.4421,
      "step": 13395
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.0655229939671695,
      "learning_rate": 1.2276087326601682e-07,
      "loss": 0.4933,
      "step": 13396
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.230350990215548,
      "learning_rate": 1.225130130766844e-07,
      "loss": 0.4679,
      "step": 13397
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.8317790052069611,
      "learning_rate": 1.222654002575907e-07,
      "loss": 0.4636,
      "step": 13398
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.840596307950557,
      "learning_rate": 1.2201803482129293e-07,
      "loss": 0.479,
      "step": 13399
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.5495225403505097,
      "learning_rate": 1.217709167803377e-07,
      "loss": 0.3942,
      "step": 13400
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.9585435956236767,
      "learning_rate": 1.2152404614725777e-07,
      "loss": 0.547,
      "step": 13401
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.278236710988328,
      "learning_rate": 1.2127742293457312e-07,
      "loss": 0.4333,
      "step": 13402
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.386571176961659,
      "learning_rate": 1.2103104715479207e-07,
      "loss": 0.462,
      "step": 13403
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.6776869184829393,
      "learning_rate": 1.2078491882041022e-07,
      "loss": 0.4823,
      "step": 13404
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.667655573917943,
      "learning_rate": 1.205390379439103e-07,
      "loss": 0.4495,
      "step": 13405
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.4675217367836244,
      "learning_rate": 1.2029340453776183e-07,
      "loss": 0.4789,
      "step": 13406
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.833840131891573,
      "learning_rate": 1.2004801861442373e-07,
      "loss": 0.4333,
      "step": 13407
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.728074236187363,
      "learning_rate": 1.198028801863399e-07,
      "loss": 0.4961,
      "step": 13408
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.873560991227233,
      "learning_rate": 1.1955798926594431e-07,
      "loss": 0.4958,
      "step": 13409
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.3446199199196207,
      "learning_rate": 1.193133458656559e-07,
      "loss": 0.486,
      "step": 13410
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.8517332544196032,
      "learning_rate": 1.190689499978831e-07,
      "loss": 0.4568,
      "step": 13411
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.9619113977890499,
      "learning_rate": 1.1882480167501931e-07,
      "loss": 0.5126,
      "step": 13412
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.8835572188068774,
      "learning_rate": 1.1858090090944907e-07,
      "loss": 0.4556,
      "step": 13413
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.382006576915082,
      "learning_rate": 1.1833724771354082e-07,
      "loss": 0.4478,
      "step": 13414
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.35176026145392,
      "learning_rate": 1.1809384209965247e-07,
      "loss": 0.4748,
      "step": 13415
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.296636924769435,
      "learning_rate": 1.1785068408012857e-07,
      "loss": 0.4682,
      "step": 13416
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.419120593870259,
      "learning_rate": 1.1760777366730092e-07,
      "loss": 0.4945,
      "step": 13417
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.18052054744226,
      "learning_rate": 1.1736511087348967e-07,
      "loss": 0.4723,
      "step": 13418
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.3338797994740204,
      "learning_rate": 1.1712269571100165e-07,
      "loss": 0.4936,
      "step": 13419
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.806135061313799,
      "learning_rate": 1.1688052819213092e-07,
      "loss": 0.4975,
      "step": 13420
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.3805954136393717,
      "learning_rate": 1.166386083291604e-07,
      "loss": 0.4666,
      "step": 13421
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.9258263177655532,
      "learning_rate": 1.1639693613435921e-07,
      "loss": 0.5525,
      "step": 13422
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.706398247141753,
      "learning_rate": 1.1615551161998362e-07,
      "loss": 0.4391,
      "step": 13423
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.2132043984414445,
      "learning_rate": 1.159143347982783e-07,
      "loss": 0.4528,
      "step": 13424
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.9738436455030244,
      "learning_rate": 1.1567340568147455e-07,
      "loss": 0.4952,
      "step": 13425
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.7812290901878374,
      "learning_rate": 1.1543272428179264e-07,
      "loss": 0.4539,
      "step": 13426
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.490334987621149,
      "learning_rate": 1.1519229061143777e-07,
      "loss": 0.4586,
      "step": 13427
    },
    {
      "epoch": 0.93,
      "grad_norm": 3.1130687628951175,
      "learning_rate": 1.1495210468260465e-07,
      "loss": 0.45,
      "step": 13428
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.7539804365509515,
      "learning_rate": 1.1471216650747518e-07,
      "loss": 0.4287,
      "step": 13429
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.4212480550559055,
      "learning_rate": 1.1447247609821687e-07,
      "loss": 0.4757,
      "step": 13430
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.073932174848536,
      "learning_rate": 1.1423303346698667e-07,
      "loss": 0.4669,
      "step": 13431
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.325540796143029,
      "learning_rate": 1.1399383862592928e-07,
      "loss": 0.4992,
      "step": 13432
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.3120559265201086,
      "learning_rate": 1.1375489158717501e-07,
      "loss": 0.4518,
      "step": 13433
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.039456661948262,
      "learning_rate": 1.1351619236284195e-07,
      "loss": 0.4827,
      "step": 13434
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.0080997489608916,
      "learning_rate": 1.1327774096503708e-07,
      "loss": 0.4934,
      "step": 13435
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.5876879883963144,
      "learning_rate": 1.1303953740585405e-07,
      "loss": 0.5168,
      "step": 13436
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.5933495103870747,
      "learning_rate": 1.1280158169737265e-07,
      "loss": 0.4375,
      "step": 13437
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.8298289922715496,
      "learning_rate": 1.1256387385166212e-07,
      "loss": 0.4846,
      "step": 13438
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.0311559672504207,
      "learning_rate": 1.1232641388077726e-07,
      "loss": 0.4515,
      "step": 13439
    },
    {
      "epoch": 0.93,
      "grad_norm": 3.2326853684744146,
      "learning_rate": 1.1208920179676286e-07,
      "loss": 0.4731,
      "step": 13440
    },
    {
      "epoch": 0.93,
      "grad_norm": 3.000264116106232,
      "learning_rate": 1.1185223761164821e-07,
      "loss": 0.5242,
      "step": 13441
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.9167865288547934,
      "learning_rate": 1.1161552133745202e-07,
      "loss": 0.4554,
      "step": 13442
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.4413204995294273,
      "learning_rate": 1.1137905298617912e-07,
      "loss": 0.4505,
      "step": 13443
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.565639387483978,
      "learning_rate": 1.1114283256982327e-07,
      "loss": 0.4117,
      "step": 13444
    },
    {
      "epoch": 0.93,
      "grad_norm": 5.780992350282999,
      "learning_rate": 1.1090686010036434e-07,
      "loss": 0.4801,
      "step": 13445
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.034406046731642,
      "learning_rate": 1.1067113558976994e-07,
      "loss": 0.4941,
      "step": 13446
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.9941381689539124,
      "learning_rate": 1.1043565904999554e-07,
      "loss": 0.5001,
      "step": 13447
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.2195789682676135,
      "learning_rate": 1.1020043049298324e-07,
      "loss": 0.4588,
      "step": 13448
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.9263696868470035,
      "learning_rate": 1.0996544993066405e-07,
      "loss": 0.5572,
      "step": 13449
    },
    {
      "epoch": 0.94,
      "grad_norm": 3.2399469084748476,
      "learning_rate": 1.0973071737495455e-07,
      "loss": 0.456,
      "step": 13450
    },
    {
      "epoch": 0.94,
      "grad_norm": 12.849516907768447,
      "learning_rate": 1.0949623283775968e-07,
      "loss": 0.4716,
      "step": 13451
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.935541311076242,
      "learning_rate": 1.0926199633097156e-07,
      "loss": 0.4978,
      "step": 13452
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.3070821743588796,
      "learning_rate": 1.0902800786647127e-07,
      "loss": 0.4769,
      "step": 13453
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.0815026062075237,
      "learning_rate": 1.0879426745612431e-07,
      "loss": 0.4857,
      "step": 13454
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.5470905125807167,
      "learning_rate": 1.0856077511178564e-07,
      "loss": 0.4122,
      "step": 13455
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.067185793774878,
      "learning_rate": 1.0832753084529802e-07,
      "loss": 0.4408,
      "step": 13456
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.2677892249211613,
      "learning_rate": 1.0809453466849029e-07,
      "loss": 0.5011,
      "step": 13457
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.8525284958931016,
      "learning_rate": 1.0786178659317858e-07,
      "loss": 0.4926,
      "step": 13458
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.9004467530285394,
      "learning_rate": 1.0762928663116789e-07,
      "loss": 0.4608,
      "step": 13459
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.1126666442133697,
      "learning_rate": 1.0739703479425046e-07,
      "loss": 0.4829,
      "step": 13460
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.0062589629831984,
      "learning_rate": 1.0716503109420407e-07,
      "loss": 0.517,
      "step": 13461
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.199300324132208,
      "learning_rate": 1.0693327554279598e-07,
      "loss": 0.5034,
      "step": 13462
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.229204272733213,
      "learning_rate": 1.0670176815177957e-07,
      "loss": 0.4435,
      "step": 13463
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.062362819221592,
      "learning_rate": 1.0647050893289656e-07,
      "loss": 0.5296,
      "step": 13464
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.4099122398814714,
      "learning_rate": 1.0623949789787535e-07,
      "loss": 0.4394,
      "step": 13465
    },
    {
      "epoch": 0.94,
      "grad_norm": 5.302820661300084,
      "learning_rate": 1.0600873505843267e-07,
      "loss": 0.4689,
      "step": 13466
    },
    {
      "epoch": 0.94,
      "grad_norm": 3.777382888889259,
      "learning_rate": 1.0577822042627084e-07,
      "loss": 0.4418,
      "step": 13467
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.6990046218062547,
      "learning_rate": 1.0554795401308215e-07,
      "loss": 0.5018,
      "step": 13468
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.778136891587844,
      "learning_rate": 1.053179358305445e-07,
      "loss": 0.4381,
      "step": 13469
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.069170926202023,
      "learning_rate": 1.0508816589032355e-07,
      "loss": 0.4999,
      "step": 13470
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.2444311163137813,
      "learning_rate": 1.0485864420407221e-07,
      "loss": 0.489,
      "step": 13471
    },
    {
      "epoch": 0.94,
      "grad_norm": 3.294068754717929,
      "learning_rate": 1.0462937078343116e-07,
      "loss": 0.498,
      "step": 13472
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.7665467195253486,
      "learning_rate": 1.0440034564002943e-07,
      "loss": 0.5499,
      "step": 13473
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.744582450543702,
      "learning_rate": 1.0417156878548107e-07,
      "loss": 0.4785,
      "step": 13474
    },
    {
      "epoch": 0.94,
      "grad_norm": 3.718961533346141,
      "learning_rate": 1.0394304023138901e-07,
      "loss": 0.4425,
      "step": 13475
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.003557314814918,
      "learning_rate": 1.0371475998934455e-07,
      "loss": 0.4855,
      "step": 13476
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.650835279480011,
      "learning_rate": 1.0348672807092453e-07,
      "loss": 0.4763,
      "step": 13477
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.0819219547767585,
      "learning_rate": 1.0325894448769413e-07,
      "loss": 0.4677,
      "step": 13478
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.2944720337288933,
      "learning_rate": 1.0303140925120526e-07,
      "loss": 0.4846,
      "step": 13479
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.5974580300949617,
      "learning_rate": 1.0280412237299864e-07,
      "loss": 0.4801,
      "step": 13480
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.5346584666776246,
      "learning_rate": 1.025770838646012e-07,
      "loss": 0.4093,
      "step": 13481
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.1549471029205858,
      "learning_rate": 1.0235029373752758e-07,
      "loss": 0.4403,
      "step": 13482
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.578953235995501,
      "learning_rate": 1.0212375200327973e-07,
      "loss": 0.4818,
      "step": 13483
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.482353103821561,
      "learning_rate": 1.0189745867334733e-07,
      "loss": 0.4705,
      "step": 13484
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.322783101766487,
      "learning_rate": 1.0167141375920675e-07,
      "loss": 0.5107,
      "step": 13485
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.8258327707994932,
      "learning_rate": 1.0144561727232327e-07,
      "loss": 0.4628,
      "step": 13486
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.7724072689337511,
      "learning_rate": 1.0122006922414718e-07,
      "loss": 0.4654,
      "step": 13487
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.9539160431294198,
      "learning_rate": 1.0099476962611876e-07,
      "loss": 0.4858,
      "step": 13488
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.2500076563954114,
      "learning_rate": 1.0076971848966333e-07,
      "loss": 0.5012,
      "step": 13489
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.5243719461001375,
      "learning_rate": 1.0054491582619563e-07,
      "loss": 0.4102,
      "step": 13490
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.8269645931382406,
      "learning_rate": 1.0032036164711712e-07,
      "loss": 0.5274,
      "step": 13491
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.2779678358813005,
      "learning_rate": 1.0009605596381532e-07,
      "loss": 0.4837,
      "step": 13492
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.91211392111082,
      "learning_rate": 9.98719987876673e-08,
      "loss": 0.4824,
      "step": 13493
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.8096017746081277,
      "learning_rate": 9.964819013003557e-08,
      "loss": 0.454,
      "step": 13494
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.8984104400366653,
      "learning_rate": 9.942463000227276e-08,
      "loss": 0.4664,
      "step": 13495
    },
    {
      "epoch": 0.94,
      "grad_norm": 3.322804035541811,
      "learning_rate": 9.920131841571479e-08,
      "loss": 0.4784,
      "step": 13496
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.3320405922577545,
      "learning_rate": 9.897825538168926e-08,
      "loss": 0.4862,
      "step": 13497
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.942799712090451,
      "learning_rate": 9.875544091150769e-08,
      "loss": 0.4679,
      "step": 13498
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.2842133992709255,
      "learning_rate": 9.853287501647157e-08,
      "loss": 0.5235,
      "step": 13499
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.8809895480548897,
      "learning_rate": 9.831055770786856e-08,
      "loss": 0.5069,
      "step": 13500
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.6646755628804004,
      "learning_rate": 9.808848899697354e-08,
      "loss": 0.467,
      "step": 13501
    },
    {
      "epoch": 0.94,
      "grad_norm": 3.5121380285452006,
      "learning_rate": 9.786666889504858e-08,
      "loss": 0.4778,
      "step": 13502
    },
    {
      "epoch": 0.94,
      "grad_norm": 4.446196662164183,
      "learning_rate": 9.764509741334471e-08,
      "loss": 0.488,
      "step": 13503
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.085456359455186,
      "learning_rate": 9.742377456309903e-08,
      "loss": 0.5102,
      "step": 13504
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.334574512687037,
      "learning_rate": 9.720270035553648e-08,
      "loss": 0.4455,
      "step": 13505
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.948113079079011,
      "learning_rate": 9.698187480186805e-08,
      "loss": 0.4791,
      "step": 13506
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.983497729915746,
      "learning_rate": 9.676129791329481e-08,
      "loss": 0.4473,
      "step": 13507
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.5444581198992802,
      "learning_rate": 9.65409697010028e-08,
      "loss": 0.4006,
      "step": 13508
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.809630277328445,
      "learning_rate": 9.632089017616698e-08,
      "loss": 0.4516,
      "step": 13509
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.864303912506203,
      "learning_rate": 9.61010593499484e-08,
      "loss": 0.4955,
      "step": 13510
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.8560254075006304,
      "learning_rate": 9.588147723349594e-08,
      "loss": 0.4873,
      "step": 13511
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.91809734008518,
      "learning_rate": 9.566214383794736e-08,
      "loss": 0.4642,
      "step": 13512
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.9530390121969132,
      "learning_rate": 9.544305917442598e-08,
      "loss": 0.4356,
      "step": 13513
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.3740496243906786,
      "learning_rate": 9.522422325404234e-08,
      "loss": 0.4719,
      "step": 13514
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.85306441881423,
      "learning_rate": 9.500563608789592e-08,
      "loss": 0.4502,
      "step": 13515
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.5339431138388635,
      "learning_rate": 9.478729768707173e-08,
      "loss": 0.4659,
      "step": 13516
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.677319171133368,
      "learning_rate": 9.45692080626448e-08,
      "loss": 0.4481,
      "step": 13517
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.8214253420896216,
      "learning_rate": 9.435136722567407e-08,
      "loss": 0.5305,
      "step": 13518
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.8484135716701549,
      "learning_rate": 9.413377518720956e-08,
      "loss": 0.4236,
      "step": 13519
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.965947883499042,
      "learning_rate": 9.391643195828581e-08,
      "loss": 0.4653,
      "step": 13520
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.6808354146400883,
      "learning_rate": 9.369933754992566e-08,
      "loss": 0.491,
      "step": 13521
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.0713685446362753,
      "learning_rate": 9.348249197313918e-08,
      "loss": 0.4474,
      "step": 13522
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.3360555129604754,
      "learning_rate": 9.326589523892538e-08,
      "loss": 0.4332,
      "step": 13523
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.5550029608473849,
      "learning_rate": 9.304954735826822e-08,
      "loss": 0.4479,
      "step": 13524
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.4255378735198403,
      "learning_rate": 9.283344834214058e-08,
      "loss": 0.4867,
      "step": 13525
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.3291408383192582,
      "learning_rate": 9.261759820150152e-08,
      "loss": 0.5379,
      "step": 13526
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.938081850890567,
      "learning_rate": 9.240199694729946e-08,
      "loss": 0.4681,
      "step": 13527
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.461763206733064,
      "learning_rate": 9.218664459046845e-08,
      "loss": 0.4863,
      "step": 13528
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.0261132233508232,
      "learning_rate": 9.19715411419303e-08,
      "loss": 0.4925,
      "step": 13529
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.9275991102271772,
      "learning_rate": 9.175668661259407e-08,
      "loss": 0.4975,
      "step": 13530
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.9575564809028612,
      "learning_rate": 9.154208101335716e-08,
      "loss": 0.4985,
      "step": 13531
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.051946849332994,
      "learning_rate": 9.132772435510362e-08,
      "loss": 0.4807,
      "step": 13532
    },
    {
      "epoch": 0.94,
      "grad_norm": 3.671059378785694,
      "learning_rate": 9.111361664870478e-08,
      "loss": 0.5356,
      "step": 13533
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.9238442163504597,
      "learning_rate": 9.089975790501915e-08,
      "loss": 0.4939,
      "step": 13534
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.581895455731759,
      "learning_rate": 9.068614813489307e-08,
      "loss": 0.4826,
      "step": 13535
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.858831091176448,
      "learning_rate": 9.047278734916065e-08,
      "loss": 0.4805,
      "step": 13536
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.0649556909167197,
      "learning_rate": 9.025967555864212e-08,
      "loss": 0.4612,
      "step": 13537
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.771685444361964,
      "learning_rate": 9.004681277414661e-08,
      "loss": 0.4444,
      "step": 13538
    },
    {
      "epoch": 0.94,
      "grad_norm": 3.818110160501334,
      "learning_rate": 8.983419900646939e-08,
      "loss": 0.4982,
      "step": 13539
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.5652414037756002,
      "learning_rate": 8.962183426639292e-08,
      "loss": 0.4727,
      "step": 13540
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.899333905834838,
      "learning_rate": 8.940971856468917e-08,
      "loss": 0.5033,
      "step": 13541
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.060175646418778,
      "learning_rate": 8.919785191211395e-08,
      "loss": 0.5007,
      "step": 13542
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.196340250442034,
      "learning_rate": 8.898623431941422e-08,
      "loss": 0.5087,
      "step": 13543
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.750648015081126,
      "learning_rate": 8.877486579732197e-08,
      "loss": 0.4638,
      "step": 13544
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.782786107007217,
      "learning_rate": 8.856374635655696e-08,
      "loss": 0.5046,
      "step": 13545
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.0422758234049994,
      "learning_rate": 8.83528760078256e-08,
      "loss": 0.483,
      "step": 13546
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.5354719705716726,
      "learning_rate": 8.814225476182492e-08,
      "loss": 0.4978,
      "step": 13547
    },
    {
      "epoch": 0.94,
      "grad_norm": 3.0863618200765734,
      "learning_rate": 8.793188262923468e-08,
      "loss": 0.5102,
      "step": 13548
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.7322703695442736,
      "learning_rate": 8.772175962072526e-08,
      "loss": 0.4775,
      "step": 13549
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.832165593496264,
      "learning_rate": 8.751188574695314e-08,
      "loss": 0.4615,
      "step": 13550
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.22004317708183,
      "learning_rate": 8.730226101856255e-08,
      "loss": 0.4806,
      "step": 13551
    },
    {
      "epoch": 0.94,
      "grad_norm": 7.6515350090403045,
      "learning_rate": 8.709288544618555e-08,
      "loss": 0.5168,
      "step": 13552
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.1010794666004595,
      "learning_rate": 8.688375904043922e-08,
      "loss": 0.4595,
      "step": 13553
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.593721507024391,
      "learning_rate": 8.667488181193229e-08,
      "loss": 0.4786,
      "step": 13554
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.6508082887052815,
      "learning_rate": 8.646625377125573e-08,
      "loss": 0.4753,
      "step": 13555
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.039223060190213,
      "learning_rate": 8.625787492899274e-08,
      "loss": 0.4529,
      "step": 13556
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.9413201628582728,
      "learning_rate": 8.604974529571042e-08,
      "loss": 0.4733,
      "step": 13557
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.6943086908248808,
      "learning_rate": 8.584186488196422e-08,
      "loss": 0.4368,
      "step": 13558
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.3854762139083285,
      "learning_rate": 8.563423369829793e-08,
      "loss": 0.4979,
      "step": 13559
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.099782425294714,
      "learning_rate": 8.542685175524146e-08,
      "loss": 0.4368,
      "step": 13560
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.7989843081848218,
      "learning_rate": 8.52197190633125e-08,
      "loss": 0.4521,
      "step": 13561
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.07705710021352,
      "learning_rate": 8.501283563301598e-08,
      "loss": 0.5185,
      "step": 13562
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.9934231308197394,
      "learning_rate": 8.48062014748452e-08,
      "loss": 0.4758,
      "step": 13563
    },
    {
      "epoch": 0.94,
      "grad_norm": 3.3971017764930864,
      "learning_rate": 8.459981659927951e-08,
      "loss": 0.487,
      "step": 13564
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.5666943780048947,
      "learning_rate": 8.439368101678557e-08,
      "loss": 0.3971,
      "step": 13565
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.887491754668453,
      "learning_rate": 8.418779473781835e-08,
      "loss": 0.4799,
      "step": 13566
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.470599094034159,
      "learning_rate": 8.398215777282004e-08,
      "loss": 0.4543,
      "step": 13567
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.0760415934153387,
      "learning_rate": 8.377677013221897e-08,
      "loss": 0.4983,
      "step": 13568
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.0630102748997237,
      "learning_rate": 8.357163182643291e-08,
      "loss": 0.4363,
      "step": 13569
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.565912946150052,
      "learning_rate": 8.336674286586521e-08,
      "loss": 0.4669,
      "step": 13570
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.1608514743624916,
      "learning_rate": 8.316210326090701e-08,
      "loss": 0.4811,
      "step": 13571
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.8224567534013034,
      "learning_rate": 8.295771302193723e-08,
      "loss": 0.5022,
      "step": 13572
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.0864811542977817,
      "learning_rate": 8.27535721593209e-08,
      "loss": 0.5126,
      "step": 13573
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.510078468500025,
      "learning_rate": 8.254968068341363e-08,
      "loss": 0.4884,
      "step": 13574
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.268048131747682,
      "learning_rate": 8.234603860455381e-08,
      "loss": 0.5478,
      "step": 13575
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.799733709337228,
      "learning_rate": 8.214264593307097e-08,
      "loss": 0.4609,
      "step": 13576
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.3503993355388806,
      "learning_rate": 8.193950267927908e-08,
      "loss": 0.4975,
      "step": 13577
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.6385172952955225,
      "learning_rate": 8.173660885348267e-08,
      "loss": 0.4724,
      "step": 13578
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.8058714533150826,
      "learning_rate": 8.153396446597073e-08,
      "loss": 0.5009,
      "step": 13579
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.520130942807631,
      "learning_rate": 8.133156952702115e-08,
      "loss": 0.5023,
      "step": 13580
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.9363227370940321,
      "learning_rate": 8.11294240468985e-08,
      "loss": 0.4785,
      "step": 13581
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.4339522022165636,
      "learning_rate": 8.092752803585513e-08,
      "loss": 0.4915,
      "step": 13582
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.8581272182664144,
      "learning_rate": 8.072588150413063e-08,
      "loss": 0.5191,
      "step": 13583
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.23089980728374,
      "learning_rate": 8.052448446195071e-08,
      "loss": 0.4667,
      "step": 13584
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.8095867115179365,
      "learning_rate": 8.032333691953109e-08,
      "loss": 0.4614,
      "step": 13585
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.8651499655835688,
      "learning_rate": 8.012243888707305e-08,
      "loss": 0.4732,
      "step": 13586
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.9068159041064487,
      "learning_rate": 7.992179037476511e-08,
      "loss": 0.5214,
      "step": 13587
    },
    {
      "epoch": 0.94,
      "grad_norm": 7.151930477071072,
      "learning_rate": 7.972139139278357e-08,
      "loss": 0.5422,
      "step": 13588
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.615660071836288,
      "learning_rate": 7.95212419512914e-08,
      "loss": 0.5007,
      "step": 13589
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.9380831654771615,
      "learning_rate": 7.932134206044051e-08,
      "loss": 0.448,
      "step": 13590
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.845272136054553,
      "learning_rate": 7.912169173036943e-08,
      "loss": 0.5336,
      "step": 13591
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.5373727439164697,
      "learning_rate": 7.89222909712023e-08,
      "loss": 0.4052,
      "step": 13592
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.0991235704821842,
      "learning_rate": 7.872313979305324e-08,
      "loss": 0.4886,
      "step": 13593
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.9039646798045318,
      "learning_rate": 7.852423820602251e-08,
      "loss": 0.502,
      "step": 13594
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.3453941878698292,
      "learning_rate": 7.832558622019759e-08,
      "loss": 0.4793,
      "step": 13595
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.9831117585140428,
      "learning_rate": 7.812718384565321e-08,
      "loss": 0.5004,
      "step": 13596
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.232878932957881,
      "learning_rate": 7.79290310924513e-08,
      "loss": 0.4675,
      "step": 13597
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.7982469560191594,
      "learning_rate": 7.773112797064275e-08,
      "loss": 0.4548,
      "step": 13598
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.6775439530641765,
      "learning_rate": 7.753347449026338e-08,
      "loss": 0.4397,
      "step": 13599
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.2547939676109094,
      "learning_rate": 7.733607066133852e-08,
      "loss": 0.5051,
      "step": 13600
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.284545980765436,
      "learning_rate": 7.713891649387851e-08,
      "loss": 0.4823,
      "step": 13601
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.865619759093288,
      "learning_rate": 7.69420119978842e-08,
      "loss": 0.5153,
      "step": 13602
    },
    {
      "epoch": 0.95,
      "grad_norm": 3.2832054237579165,
      "learning_rate": 7.674535718333986e-08,
      "loss": 0.4664,
      "step": 13603
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.2743150943040056,
      "learning_rate": 7.65489520602214e-08,
      "loss": 0.5045,
      "step": 13604
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.9853715521532165,
      "learning_rate": 7.635279663848805e-08,
      "loss": 0.4909,
      "step": 13605
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.2497861083102277,
      "learning_rate": 7.615689092808909e-08,
      "loss": 0.4982,
      "step": 13606
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.225993841957343,
      "learning_rate": 7.59612349389599e-08,
      "loss": 0.5002,
      "step": 13607
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.6157809811642236,
      "learning_rate": 7.576582868102366e-08,
      "loss": 0.4686,
      "step": 13608
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.171207655401616,
      "learning_rate": 7.557067216419023e-08,
      "loss": 0.475,
      "step": 13609
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.8567220621221057,
      "learning_rate": 7.537576539835833e-08,
      "loss": 0.5121,
      "step": 13610
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.9540396507358677,
      "learning_rate": 7.518110839341231e-08,
      "loss": 0.509,
      "step": 13611
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.9416071400531163,
      "learning_rate": 7.498670115922424e-08,
      "loss": 0.4902,
      "step": 13612
    },
    {
      "epoch": 0.95,
      "grad_norm": 6.433718767984377,
      "learning_rate": 7.479254370565458e-08,
      "loss": 0.5202,
      "step": 13613
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.0586732610211236,
      "learning_rate": 7.459863604254991e-08,
      "loss": 0.473,
      "step": 13614
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.740275626608515,
      "learning_rate": 7.440497817974457e-08,
      "loss": 0.5192,
      "step": 13615
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.184074586394504,
      "learning_rate": 7.42115701270607e-08,
      "loss": 0.502,
      "step": 13616
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.0763972154225034,
      "learning_rate": 7.401841189430659e-08,
      "loss": 0.4697,
      "step": 13617
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.1278839370277063,
      "learning_rate": 7.382550349127937e-08,
      "loss": 0.4507,
      "step": 13618
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.830101414727911,
      "learning_rate": 7.363284492776235e-08,
      "loss": 0.4673,
      "step": 13619
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.9714185429149038,
      "learning_rate": 7.344043621352603e-08,
      "loss": 0.5136,
      "step": 13620
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.225656161992847,
      "learning_rate": 7.324827735832929e-08,
      "loss": 0.48,
      "step": 13621
    },
    {
      "epoch": 0.95,
      "grad_norm": 3.9254438891640686,
      "learning_rate": 7.305636837191876e-08,
      "loss": 0.4781,
      "step": 13622
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.9250068376102012,
      "learning_rate": 7.286470926402556e-08,
      "loss": 0.4699,
      "step": 13623
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.8686357309402484,
      "learning_rate": 7.267330004437134e-08,
      "loss": 0.4821,
      "step": 13624
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.05766152068725,
      "learning_rate": 7.248214072266336e-08,
      "loss": 0.5051,
      "step": 13625
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.181355486782183,
      "learning_rate": 7.229123130859606e-08,
      "loss": 0.4241,
      "step": 13626
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.5429292042252127,
      "learning_rate": 7.210057181185282e-08,
      "loss": 0.4077,
      "step": 13627
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.5078949715592787,
      "learning_rate": 7.1910162242102e-08,
      "loss": 0.4994,
      "step": 13628
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.026761780098418,
      "learning_rate": 7.172000260900203e-08,
      "loss": 0.4625,
      "step": 13629
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.5058093439029943,
      "learning_rate": 7.153009292219626e-08,
      "loss": 0.5009,
      "step": 13630
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.006401117386154,
      "learning_rate": 7.134043319131644e-08,
      "loss": 0.4927,
      "step": 13631
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.67724859569472,
      "learning_rate": 7.115102342598101e-08,
      "loss": 0.4588,
      "step": 13632
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.8159746956452878,
      "learning_rate": 7.096186363579727e-08,
      "loss": 0.4988,
      "step": 13633
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.9955257090476186,
      "learning_rate": 7.07729538303581e-08,
      "loss": 0.4772,
      "step": 13634
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.9011747208606884,
      "learning_rate": 7.058429401924472e-08,
      "loss": 0.511,
      "step": 13635
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.2013809799781114,
      "learning_rate": 7.039588421202448e-08,
      "loss": 0.5066,
      "step": 13636
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.7984620925228996,
      "learning_rate": 7.020772441825363e-08,
      "loss": 0.5278,
      "step": 13637
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.2273985678379717,
      "learning_rate": 7.001981464747565e-08,
      "loss": 0.4746,
      "step": 13638
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.9012530691585718,
      "learning_rate": 6.983215490921957e-08,
      "loss": 0.4727,
      "step": 13639
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.379111166650314,
      "learning_rate": 6.964474521300335e-08,
      "loss": 0.4608,
      "step": 13640
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.6103559000898193,
      "learning_rate": 6.94575855683316e-08,
      "loss": 0.4527,
      "step": 13641
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.6341498142701323,
      "learning_rate": 6.927067598469672e-08,
      "loss": 0.4502,
      "step": 13642
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.781650287169131,
      "learning_rate": 6.908401647157836e-08,
      "loss": 0.4702,
      "step": 13643
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.096925374916768,
      "learning_rate": 6.889760703844229e-08,
      "loss": 0.5277,
      "step": 13644
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.9462063164413754,
      "learning_rate": 6.87114476947437e-08,
      "loss": 0.462,
      "step": 13645
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.3366437467538166,
      "learning_rate": 6.852553844992394e-08,
      "loss": 0.4853,
      "step": 13646
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.2169775635745466,
      "learning_rate": 6.833987931341046e-08,
      "loss": 0.5015,
      "step": 13647
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.5923379887067965,
      "learning_rate": 6.815447029462074e-08,
      "loss": 0.4531,
      "step": 13648
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.843717876271875,
      "learning_rate": 6.796931140295781e-08,
      "loss": 0.4624,
      "step": 13649
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.6974211527999448,
      "learning_rate": 6.778440264781139e-08,
      "loss": 0.4984,
      "step": 13650
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.9086140258897444,
      "learning_rate": 6.759974403856118e-08,
      "loss": 0.458,
      "step": 13651
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.1257450706382666,
      "learning_rate": 6.74153355845697e-08,
      "loss": 0.5102,
      "step": 13652
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.53512351534746,
      "learning_rate": 6.723117729519279e-08,
      "loss": 0.4223,
      "step": 13653
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.5365775524164004,
      "learning_rate": 6.7047269179768e-08,
      "loss": 0.4075,
      "step": 13654
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.2698177348044135,
      "learning_rate": 6.686361124762397e-08,
      "loss": 0.4759,
      "step": 13655
    },
    {
      "epoch": 0.95,
      "grad_norm": 3.154518018467964,
      "learning_rate": 6.668020350807381e-08,
      "loss": 0.4933,
      "step": 13656
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.8679205222764943,
      "learning_rate": 6.649704597042061e-08,
      "loss": 0.5146,
      "step": 13657
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.8255774227093378,
      "learning_rate": 6.631413864395308e-08,
      "loss": 0.4412,
      "step": 13658
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.0189929526490804,
      "learning_rate": 6.613148153794824e-08,
      "loss": 0.4527,
      "step": 13659
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.5543143582207046,
      "learning_rate": 6.594907466166866e-08,
      "loss": 0.3818,
      "step": 13660
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.208501953466928,
      "learning_rate": 6.576691802436641e-08,
      "loss": 0.5245,
      "step": 13661
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.4016396734619043,
      "learning_rate": 6.558501163527964e-08,
      "loss": 0.4415,
      "step": 13662
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.0815390756013747,
      "learning_rate": 6.540335550363319e-08,
      "loss": 0.4751,
      "step": 13663
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.8909086809910123,
      "learning_rate": 6.522194963864136e-08,
      "loss": 0.4519,
      "step": 13664
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.674252163174209,
      "learning_rate": 6.504079404950403e-08,
      "loss": 0.4421,
      "step": 13665
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.3369296150578918,
      "learning_rate": 6.485988874540882e-08,
      "loss": 0.4756,
      "step": 13666
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.157611985023371,
      "learning_rate": 6.467923373553009e-08,
      "loss": 0.4814,
      "step": 13667
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.3941438753685453,
      "learning_rate": 6.449882902903104e-08,
      "loss": 0.4888,
      "step": 13668
    },
    {
      "epoch": 0.95,
      "grad_norm": 5.0016950342782796,
      "learning_rate": 6.431867463506047e-08,
      "loss": 0.4722,
      "step": 13669
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.8099877365434354,
      "learning_rate": 6.413877056275552e-08,
      "loss": 0.4803,
      "step": 13670
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.9394138413722424,
      "learning_rate": 6.395911682124056e-08,
      "loss": 0.4835,
      "step": 13671
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.8710050564096443,
      "learning_rate": 6.377971341962607e-08,
      "loss": 0.4957,
      "step": 13672
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.7513008463441575,
      "learning_rate": 6.360056036701257e-08,
      "loss": 0.5042,
      "step": 13673
    },
    {
      "epoch": 0.95,
      "grad_norm": 3.499822665227289,
      "learning_rate": 6.342165767248443e-08,
      "loss": 0.4628,
      "step": 13674
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.8538620583080974,
      "learning_rate": 6.324300534511551e-08,
      "loss": 0.5149,
      "step": 13675
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.9404204600161106,
      "learning_rate": 6.306460339396636e-08,
      "loss": 0.4484,
      "step": 13676
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.529807738471612,
      "learning_rate": 6.288645182808583e-08,
      "loss": 0.4203,
      "step": 13677
    },
    {
      "epoch": 0.95,
      "grad_norm": 3.1673018990593285,
      "learning_rate": 6.270855065650839e-08,
      "loss": 0.5146,
      "step": 13678
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.6649787403990195,
      "learning_rate": 6.253089988825678e-08,
      "loss": 0.4776,
      "step": 13679
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.8205325095812623,
      "learning_rate": 6.235349953234049e-08,
      "loss": 0.4467,
      "step": 13680
    },
    {
      "epoch": 0.95,
      "grad_norm": 3.0750834606176465,
      "learning_rate": 6.217634959775787e-08,
      "loss": 0.4777,
      "step": 13681
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.925699120990635,
      "learning_rate": 6.199945009349173e-08,
      "loss": 0.5517,
      "step": 13682
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.5362811095647175,
      "learning_rate": 6.18228010285149e-08,
      "loss": 0.3943,
      "step": 13683
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.956410628730072,
      "learning_rate": 6.164640241178632e-08,
      "loss": 0.4829,
      "step": 13684
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.0648096399665197,
      "learning_rate": 6.147025425225217e-08,
      "loss": 0.5048,
      "step": 13685
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.027305172145719,
      "learning_rate": 6.129435655884641e-08,
      "loss": 0.4791,
      "step": 13686
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.5283036565867967,
      "learning_rate": 6.111870934048969e-08,
      "loss": 0.4938,
      "step": 13687
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.9360281442418228,
      "learning_rate": 6.094331260609043e-08,
      "loss": 0.4756,
      "step": 13688
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.988477292523183,
      "learning_rate": 6.076816636454375e-08,
      "loss": 0.471,
      "step": 13689
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.3417268692868696,
      "learning_rate": 6.059327062473309e-08,
      "loss": 0.5489,
      "step": 13690
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.8851939685130785,
      "learning_rate": 6.041862539552857e-08,
      "loss": 0.534,
      "step": 13691
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.5023767066467695,
      "learning_rate": 6.0244230685787e-08,
      "loss": 0.5093,
      "step": 13692
    },
    {
      "epoch": 0.95,
      "grad_norm": 3.109851316648017,
      "learning_rate": 6.007008650435408e-08,
      "loss": 0.4893,
      "step": 13693
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.7398139493219804,
      "learning_rate": 5.989619286006054e-08,
      "loss": 0.5176,
      "step": 13694
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.1110581988314547,
      "learning_rate": 5.972254976172653e-08,
      "loss": 0.5128,
      "step": 13695
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.7764230022659149,
      "learning_rate": 5.95491572181589e-08,
      "loss": 0.4424,
      "step": 13696
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.766452126945811,
      "learning_rate": 5.937601523815117e-08,
      "loss": 0.4816,
      "step": 13697
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.9354022218969207,
      "learning_rate": 5.920312383048466e-08,
      "loss": 0.519,
      "step": 13698
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.4220356636235336,
      "learning_rate": 5.903048300392733e-08,
      "loss": 0.458,
      "step": 13699
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.733842521220961,
      "learning_rate": 5.8858092767236084e-08,
      "loss": 0.461,
      "step": 13700
    },
    {
      "epoch": 0.95,
      "grad_norm": 7.300362219393718,
      "learning_rate": 5.868595312915282e-08,
      "loss": 0.4569,
      "step": 13701
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.375884129222525,
      "learning_rate": 5.8514064098408874e-08,
      "loss": 0.5063,
      "step": 13702
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.867631513991045,
      "learning_rate": 5.8342425683720615e-08,
      "loss": 0.4387,
      "step": 13703
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.8653206555328146,
      "learning_rate": 5.817103789379497e-08,
      "loss": 0.4679,
      "step": 13704
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.919916483151854,
      "learning_rate": 5.79999007373222e-08,
      "loss": 0.4644,
      "step": 13705
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.9128348427319246,
      "learning_rate": 5.7829014222982594e-08,
      "loss": 0.5146,
      "step": 13706
    },
    {
      "epoch": 0.95,
      "grad_norm": 3.1361103134146298,
      "learning_rate": 5.7658378359443104e-08,
      "loss": 0.4783,
      "step": 13707
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.137114863932657,
      "learning_rate": 5.748799315535791e-08,
      "loss": 0.4851,
      "step": 13708
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.7442669181045196,
      "learning_rate": 5.7317858619367893e-08,
      "loss": 0.5136,
      "step": 13709
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.0193374026657556,
      "learning_rate": 5.7147974760102255e-08,
      "loss": 0.5191,
      "step": 13710
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.947798193352242,
      "learning_rate": 5.697834158617632e-08,
      "loss": 0.5407,
      "step": 13711
    },
    {
      "epoch": 0.95,
      "grad_norm": 4.084684531556272,
      "learning_rate": 5.6808959106194327e-08,
      "loss": 0.4451,
      "step": 13712
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.351322692329457,
      "learning_rate": 5.663982732874551e-08,
      "loss": 0.4769,
      "step": 13713
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.7637130620570598,
      "learning_rate": 5.647094626240912e-08,
      "loss": 0.4653,
      "step": 13714
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.7803039339653344,
      "learning_rate": 5.630231591574886e-08,
      "loss": 0.4383,
      "step": 13715
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.089660318227293,
      "learning_rate": 5.613393629731789e-08,
      "loss": 0.4807,
      "step": 13716
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.69806269769468,
      "learning_rate": 5.596580741565605e-08,
      "loss": 0.4783,
      "step": 13717
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.748524112824661,
      "learning_rate": 5.579792927928984e-08,
      "loss": 0.5006,
      "step": 13718
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.9787941842226937,
      "learning_rate": 5.5630301896733574e-08,
      "loss": 0.4888,
      "step": 13719
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.673357086732656,
      "learning_rate": 5.546292527648878e-08,
      "loss": 0.4767,
      "step": 13720
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.9026681869970612,
      "learning_rate": 5.529579942704477e-08,
      "loss": 0.5157,
      "step": 13721
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.8529545083284367,
      "learning_rate": 5.512892435687645e-08,
      "loss": 0.4556,
      "step": 13722
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.9335042234789883,
      "learning_rate": 5.496230007444814e-08,
      "loss": 0.494,
      "step": 13723
    },
    {
      "epoch": 0.95,
      "grad_norm": 3.099052598807811,
      "learning_rate": 5.479592658820976e-08,
      "loss": 0.473,
      "step": 13724
    },
    {
      "epoch": 0.95,
      "grad_norm": 3.114035509054783,
      "learning_rate": 5.4629803906600665e-08,
      "loss": 0.5287,
      "step": 13725
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.361186302143924,
      "learning_rate": 5.446393203804468e-08,
      "loss": 0.47,
      "step": 13726
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.5501852609031138,
      "learning_rate": 5.4298310990954506e-08,
      "loss": 0.4175,
      "step": 13727
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.9943245911583476,
      "learning_rate": 5.41329407737301e-08,
      "loss": 0.4711,
      "step": 13728
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.855188088094621,
      "learning_rate": 5.396782139475864e-08,
      "loss": 0.4671,
      "step": 13729
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.0902737976725665,
      "learning_rate": 5.380295286241455e-08,
      "loss": 0.4968,
      "step": 13730
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.136978664167229,
      "learning_rate": 5.363833518505834e-08,
      "loss": 0.4718,
      "step": 13731
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.8604468304242463,
      "learning_rate": 5.3473968371040575e-08,
      "loss": 0.4845,
      "step": 13732
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.581727808061144,
      "learning_rate": 5.330985242869569e-08,
      "loss": 0.5148,
      "step": 13733
    },
    {
      "epoch": 0.95,
      "grad_norm": 6.09677115989837,
      "learning_rate": 5.314598736634868e-08,
      "loss": 0.4767,
      "step": 13734
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.100735998982159,
      "learning_rate": 5.298237319230903e-08,
      "loss": 0.4878,
      "step": 13735
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.152449263454003,
      "learning_rate": 5.281900991487565e-08,
      "loss": 0.5021,
      "step": 13736
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.0144690082573407,
      "learning_rate": 5.265589754233302e-08,
      "loss": 0.4774,
      "step": 13737
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.978849060139899,
      "learning_rate": 5.2493036082954526e-08,
      "loss": 0.4963,
      "step": 13738
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.6020760103185547,
      "learning_rate": 5.233042554499857e-08,
      "loss": 0.4431,
      "step": 13739
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.7002140788462516,
      "learning_rate": 5.216806593671353e-08,
      "loss": 0.5506,
      "step": 13740
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.1073603168690576,
      "learning_rate": 5.2005957266333396e-08,
      "loss": 0.4703,
      "step": 13741
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.5511288951509661,
      "learning_rate": 5.1844099542079916e-08,
      "loss": 0.4072,
      "step": 13742
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.7494546778273297,
      "learning_rate": 5.168249277216153e-08,
      "loss": 0.4887,
      "step": 13743
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.8764346663072362,
      "learning_rate": 5.1521136964774457e-08,
      "loss": 0.4787,
      "step": 13744
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.2551056180942908,
      "learning_rate": 5.13600321281027e-08,
      "loss": 0.4786,
      "step": 13745
    },
    {
      "epoch": 0.96,
      "grad_norm": 3.9884370190635083,
      "learning_rate": 5.1199178270316395e-08,
      "loss": 0.4856,
      "step": 13746
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.0051626663659583,
      "learning_rate": 5.103857539957402e-08,
      "loss": 0.5207,
      "step": 13747
    },
    {
      "epoch": 0.96,
      "grad_norm": 3.60998008206763,
      "learning_rate": 5.0878223524020164e-08,
      "loss": 0.5023,
      "step": 13748
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.522629993803199,
      "learning_rate": 5.071812265178833e-08,
      "loss": 0.4648,
      "step": 13749
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.467817288583737,
      "learning_rate": 5.055827279099701e-08,
      "loss": 0.5218,
      "step": 13750
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.2140394058084936,
      "learning_rate": 5.039867394975417e-08,
      "loss": 0.5093,
      "step": 13751
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.3946687421961665,
      "learning_rate": 5.0239326136154454e-08,
      "loss": 0.4993,
      "step": 13752
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.7537348850867214,
      "learning_rate": 5.008022935827861e-08,
      "loss": 0.4929,
      "step": 13753
    },
    {
      "epoch": 0.96,
      "grad_norm": 3.1014370888616747,
      "learning_rate": 4.992138362419574e-08,
      "loss": 0.4905,
      "step": 13754
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.6232463327252202,
      "learning_rate": 4.976278894196218e-08,
      "loss": 0.4759,
      "step": 13755
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.0966601533651783,
      "learning_rate": 4.9604445319621495e-08,
      "loss": 0.482,
      "step": 13756
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.457555841138275,
      "learning_rate": 4.944635276520393e-08,
      "loss": 0.5937,
      "step": 13757
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.8763399528432325,
      "learning_rate": 4.9288511286727513e-08,
      "loss": 0.4388,
      "step": 13758
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.081656122817552,
      "learning_rate": 4.913092089219807e-08,
      "loss": 0.5132,
      "step": 13759
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.149917041793949,
      "learning_rate": 4.897358158960697e-08,
      "loss": 0.4543,
      "step": 13760
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.124403227947179,
      "learning_rate": 4.881649338693506e-08,
      "loss": 0.4695,
      "step": 13761
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.9826765929303949,
      "learning_rate": 4.865965629214819e-08,
      "loss": 0.4898,
      "step": 13762
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.7695886255915008,
      "learning_rate": 4.850307031320223e-08,
      "loss": 0.5417,
      "step": 13763
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.85450115588388,
      "learning_rate": 4.834673545803692e-08,
      "loss": 0.4815,
      "step": 13764
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.0796165809056513,
      "learning_rate": 4.819065173458204e-08,
      "loss": 0.4918,
      "step": 13765
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.7858656829208481,
      "learning_rate": 4.8034819150752924e-08,
      "loss": 0.4365,
      "step": 13766
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.9051804693820455,
      "learning_rate": 4.787923771445435e-08,
      "loss": 0.4769,
      "step": 13767
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.0493572310537678,
      "learning_rate": 4.772390743357558e-08,
      "loss": 0.5009,
      "step": 13768
    },
    {
      "epoch": 0.96,
      "grad_norm": 4.0907259684007355,
      "learning_rate": 4.7568828315995295e-08,
      "loss": 0.5023,
      "step": 13769
    },
    {
      "epoch": 0.96,
      "grad_norm": 3.222812773332188,
      "learning_rate": 4.741400036957777e-08,
      "loss": 0.4997,
      "step": 13770
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.8865918058938531,
      "learning_rate": 4.725942360217561e-08,
      "loss": 0.4928,
      "step": 13771
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.969848463772529,
      "learning_rate": 4.7105098021629213e-08,
      "loss": 0.4584,
      "step": 13772
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.5536351905026671,
      "learning_rate": 4.695102363576454e-08,
      "loss": 0.3963,
      "step": 13773
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.124917740326024,
      "learning_rate": 4.6797200452395886e-08,
      "loss": 0.5162,
      "step": 13774
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.7150546227932855,
      "learning_rate": 4.6643628479325355e-08,
      "loss": 0.4575,
      "step": 13775
    },
    {
      "epoch": 0.96,
      "grad_norm": 3.022178772424611,
      "learning_rate": 4.64903077243406e-08,
      "loss": 0.47,
      "step": 13776
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.5571501885454375,
      "learning_rate": 4.633723819521818e-08,
      "loss": 0.4846,
      "step": 13777
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.396312724659099,
      "learning_rate": 4.618441989972133e-08,
      "loss": 0.4908,
      "step": 13778
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.8137937471519658,
      "learning_rate": 4.603185284560052e-08,
      "loss": 0.4736,
      "step": 13779
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.8721250999309476,
      "learning_rate": 4.5879537040592895e-08,
      "loss": 0.4749,
      "step": 13780
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.9859697067736537,
      "learning_rate": 4.572747249242393e-08,
      "loss": 0.49,
      "step": 13781
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.9652137869091773,
      "learning_rate": 4.55756592088058e-08,
      "loss": 0.4914,
      "step": 13782
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.006563051478821,
      "learning_rate": 4.54240971974379e-08,
      "loss": 0.5009,
      "step": 13783
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.2091070287358643,
      "learning_rate": 4.527278646600686e-08,
      "loss": 0.5305,
      "step": 13784
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.964200539828604,
      "learning_rate": 4.5121727022186533e-08,
      "loss": 0.4897,
      "step": 13785
    },
    {
      "epoch": 0.96,
      "grad_norm": 6.442884116698703,
      "learning_rate": 4.497091887363858e-08,
      "loss": 0.4862,
      "step": 13786
    },
    {
      "epoch": 0.96,
      "grad_norm": 3.397566590371343,
      "learning_rate": 4.482036202801132e-08,
      "loss": 0.471,
      "step": 13787
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.785959426434963,
      "learning_rate": 4.467005649294032e-08,
      "loss": 0.4806,
      "step": 13788
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.1989254159613036,
      "learning_rate": 4.452000227604891e-08,
      "loss": 0.5216,
      "step": 13789
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.6073835342819383,
      "learning_rate": 4.437019938494713e-08,
      "loss": 0.5093,
      "step": 13790
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.2918250233175095,
      "learning_rate": 4.422064782723279e-08,
      "loss": 0.478,
      "step": 13791
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.925844454263688,
      "learning_rate": 4.407134761048981e-08,
      "loss": 0.4771,
      "step": 13792
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.8810203558173435,
      "learning_rate": 4.392229874229159e-08,
      "loss": 0.4732,
      "step": 13793
    },
    {
      "epoch": 0.96,
      "grad_norm": 3.0420545118502518,
      "learning_rate": 4.377350123019597e-08,
      "loss": 0.4886,
      "step": 13794
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.804608565602444,
      "learning_rate": 4.36249550817508e-08,
      "loss": 0.4651,
      "step": 13795
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.3365261216454773,
      "learning_rate": 4.347666030448894e-08,
      "loss": 0.5237,
      "step": 13796
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.1302375094244375,
      "learning_rate": 4.3328616905931595e-08,
      "loss": 0.5292,
      "step": 13797
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.517918423423597,
      "learning_rate": 4.318082489358666e-08,
      "loss": 0.4928,
      "step": 13798
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.03105148777795,
      "learning_rate": 4.30332842749509e-08,
      "loss": 0.5039,
      "step": 13799
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.5184679040545204,
      "learning_rate": 4.2885995057506125e-08,
      "loss": 0.4545,
      "step": 13800
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.031757474972327,
      "learning_rate": 4.27389572487219e-08,
      "loss": 0.4596,
      "step": 13801
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.9769682095279693,
      "learning_rate": 4.2592170856056717e-08,
      "loss": 0.5146,
      "step": 13802
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.828298454776625,
      "learning_rate": 4.2445635886954604e-08,
      "loss": 0.4568,
      "step": 13803
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6190211386789134,
      "learning_rate": 4.229935234884741e-08,
      "loss": 0.4402,
      "step": 13804
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.384423729412696,
      "learning_rate": 4.215332024915364e-08,
      "loss": 0.5041,
      "step": 13805
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.5416184360493496,
      "learning_rate": 4.200753959528015e-08,
      "loss": 0.4044,
      "step": 13806
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.587086796312979,
      "learning_rate": 4.186201039462046e-08,
      "loss": 0.4067,
      "step": 13807
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.4487795084185127,
      "learning_rate": 4.171673265455478e-08,
      "loss": 0.5099,
      "step": 13808
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.2694663702909827,
      "learning_rate": 4.157170638245167e-08,
      "loss": 0.5306,
      "step": 13809
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.3421955801747645,
      "learning_rate": 4.1426931585665796e-08,
      "loss": 0.4938,
      "step": 13810
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.1333075927697496,
      "learning_rate": 4.1282408271540733e-08,
      "loss": 0.4586,
      "step": 13811
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.3738932184249917,
      "learning_rate": 4.1138136447405606e-08,
      "loss": 0.4809,
      "step": 13812
    },
    {
      "epoch": 0.96,
      "grad_norm": 3.345381798525495,
      "learning_rate": 4.09941161205768e-08,
      "loss": 0.4926,
      "step": 13813
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.488839243416935,
      "learning_rate": 4.0850347298359574e-08,
      "loss": 0.5532,
      "step": 13814
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.6939393890517274,
      "learning_rate": 4.070682998804476e-08,
      "loss": 0.5079,
      "step": 13815
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.1016191533757156,
      "learning_rate": 4.056356419691154e-08,
      "loss": 0.5069,
      "step": 13816
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.8004749784071759,
      "learning_rate": 4.042054993222522e-08,
      "loss": 0.4687,
      "step": 13817
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.1621001469189416,
      "learning_rate": 4.027778720123998e-08,
      "loss": 0.5091,
      "step": 13818
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.022217446023545,
      "learning_rate": 4.0135276011195046e-08,
      "loss": 0.4527,
      "step": 13819
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.5358448517346851,
      "learning_rate": 3.9993016369319624e-08,
      "loss": 0.3972,
      "step": 13820
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.9308401544993121,
      "learning_rate": 3.98510082828274e-08,
      "loss": 0.5369,
      "step": 13821
    },
    {
      "epoch": 0.96,
      "grad_norm": 7.20128683701244,
      "learning_rate": 3.970925175892093e-08,
      "loss": 0.4712,
      "step": 13822
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.756512093200008,
      "learning_rate": 3.956774680479003e-08,
      "loss": 0.4476,
      "step": 13823
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.1781036960693867,
      "learning_rate": 3.9426493427611177e-08,
      "loss": 0.4775,
      "step": 13824
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.348906783843824,
      "learning_rate": 3.928549163454754e-08,
      "loss": 0.4507,
      "step": 13825
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.037657336055981,
      "learning_rate": 3.9144741432751155e-08,
      "loss": 0.4485,
      "step": 13826
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.772752247040588,
      "learning_rate": 3.900424282936077e-08,
      "loss": 0.4442,
      "step": 13827
    },
    {
      "epoch": 0.96,
      "grad_norm": 4.3702485606947485,
      "learning_rate": 3.886399583150069e-08,
      "loss": 0.5222,
      "step": 13828
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.5275028128445521,
      "learning_rate": 3.872400044628466e-08,
      "loss": 0.4025,
      "step": 13829
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.8602828017914668,
      "learning_rate": 3.858425668081311e-08,
      "loss": 0.5059,
      "step": 13830
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.5124142881709558,
      "learning_rate": 3.844476454217261e-08,
      "loss": 0.4094,
      "step": 13831
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.8166244209885158,
      "learning_rate": 3.8305524037438035e-08,
      "loss": 0.5092,
      "step": 13832
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.4169031151973144,
      "learning_rate": 3.816653517367097e-08,
      "loss": 0.5243,
      "step": 13833
    },
    {
      "epoch": 0.96,
      "grad_norm": 4.620101899857132,
      "learning_rate": 3.8027797957920776e-08,
      "loss": 0.5192,
      "step": 13834
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.055928494998573,
      "learning_rate": 3.7889312397224044e-08,
      "loss": 0.4657,
      "step": 13835
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.5379613830732858,
      "learning_rate": 3.775107849860404e-08,
      "loss": 0.4051,
      "step": 13836
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.092014958747119,
      "learning_rate": 3.7613096269071283e-08,
      "loss": 0.518,
      "step": 13837
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.8222636841160411,
      "learning_rate": 3.747536571562405e-08,
      "loss": 0.4613,
      "step": 13838
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.388670752206488,
      "learning_rate": 3.7337886845247306e-08,
      "loss": 0.4761,
      "step": 13839
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.9532878575231674,
      "learning_rate": 3.720065966491382e-08,
      "loss": 0.4835,
      "step": 13840
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.1205157335734754,
      "learning_rate": 3.706368418158302e-08,
      "loss": 0.4851,
      "step": 13841
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.5410527980253058,
      "learning_rate": 3.6926960402202674e-08,
      "loss": 0.425,
      "step": 13842
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.987742532558946,
      "learning_rate": 3.6790488333705574e-08,
      "loss": 0.5014,
      "step": 13843
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.1707124481369187,
      "learning_rate": 3.6654267983014526e-08,
      "loss": 0.4971,
      "step": 13844
    },
    {
      "epoch": 0.96,
      "grad_norm": 10.514566481119978,
      "learning_rate": 3.651829935703732e-08,
      "loss": 0.4617,
      "step": 13845
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.9270884201932759,
      "learning_rate": 3.638258246267012e-08,
      "loss": 0.4778,
      "step": 13846
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.2018391515633806,
      "learning_rate": 3.624711730679575e-08,
      "loss": 0.539,
      "step": 13847
    },
    {
      "epoch": 0.96,
      "grad_norm": 3.4368655062122406,
      "learning_rate": 3.6111903896285384e-08,
      "loss": 0.4982,
      "step": 13848
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.9214534810290669,
      "learning_rate": 3.597694223799575e-08,
      "loss": 0.4888,
      "step": 13849
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.187532006461896,
      "learning_rate": 3.584223233877193e-08,
      "loss": 0.4863,
      "step": 13850
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.5501058874966094,
      "learning_rate": 3.5707774205446245e-08,
      "loss": 0.4152,
      "step": 13851
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.0250249020182953,
      "learning_rate": 3.557356784483712e-08,
      "loss": 0.4559,
      "step": 13852
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.8207501784749542,
      "learning_rate": 3.5439613263751896e-08,
      "loss": 0.4964,
      "step": 13853
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.5615575588297169,
      "learning_rate": 3.530591046898457e-08,
      "loss": 0.4071,
      "step": 13854
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.366397760023142,
      "learning_rate": 3.517245946731529e-08,
      "loss": 0.4416,
      "step": 13855
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.1690443185075963,
      "learning_rate": 3.503926026551252e-08,
      "loss": 0.4694,
      "step": 13856
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.00364111552151,
      "learning_rate": 3.4906312870331973e-08,
      "loss": 0.4725,
      "step": 13857
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.9080523128209437,
      "learning_rate": 3.477361728851602e-08,
      "loss": 0.5041,
      "step": 13858
    },
    {
      "epoch": 0.96,
      "grad_norm": 5.844592492556843,
      "learning_rate": 3.4641173526794855e-08,
      "loss": 0.489,
      "step": 13859
    },
    {
      "epoch": 0.96,
      "grad_norm": 3.928095833839439,
      "learning_rate": 3.450898159188476e-08,
      "loss": 0.5002,
      "step": 13860
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.8147086207101744,
      "learning_rate": 3.4377041490490926e-08,
      "loss": 0.4732,
      "step": 13861
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.7705911561814593,
      "learning_rate": 3.424535322930522e-08,
      "loss": 0.4497,
      "step": 13862
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.1982690888042393,
      "learning_rate": 3.4113916815005086e-08,
      "loss": 0.4753,
      "step": 13863
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.8240228172055786,
      "learning_rate": 3.3982732254257964e-08,
      "loss": 0.5338,
      "step": 13864
    },
    {
      "epoch": 0.96,
      "grad_norm": 4.018827829359993,
      "learning_rate": 3.385179955371631e-08,
      "loss": 0.4748,
      "step": 13865
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.6638073371032263,
      "learning_rate": 3.372111872002093e-08,
      "loss": 0.4823,
      "step": 13866
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.776334328694715,
      "learning_rate": 3.359068975979929e-08,
      "loss": 0.4223,
      "step": 13867
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.7491433066724955,
      "learning_rate": 3.3460512679666656e-08,
      "loss": 0.4315,
      "step": 13868
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.0268751861904772,
      "learning_rate": 3.333058748622442e-08,
      "loss": 0.4676,
      "step": 13869
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.9261771822999876,
      "learning_rate": 3.3200914186062863e-08,
      "loss": 0.4802,
      "step": 13870
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.9975029063310212,
      "learning_rate": 3.307149278575839e-08,
      "loss": 0.4813,
      "step": 13871
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.575297843264923,
      "learning_rate": 3.294232329187408e-08,
      "loss": 0.4913,
      "step": 13872
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.4751191071444536,
      "learning_rate": 3.2813405710962475e-08,
      "loss": 0.5243,
      "step": 13873
    },
    {
      "epoch": 0.96,
      "grad_norm": 4.7857975986298955,
      "learning_rate": 3.2684740049560574e-08,
      "loss": 0.4388,
      "step": 13874
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.8874886707240663,
      "learning_rate": 3.2556326314194254e-08,
      "loss": 0.4901,
      "step": 13875
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.312478975136424,
      "learning_rate": 3.2428164511376095e-08,
      "loss": 0.4743,
      "step": 13876
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.0994337894012105,
      "learning_rate": 3.2300254647606444e-08,
      "loss": 0.5114,
      "step": 13877
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.3005858187889783,
      "learning_rate": 3.217259672937234e-08,
      "loss": 0.4323,
      "step": 13878
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.9345471893426769,
      "learning_rate": 3.2045190763148046e-08,
      "loss": 0.4331,
      "step": 13879
    },
    {
      "epoch": 0.97,
      "grad_norm": 5.467367940180725,
      "learning_rate": 3.1918036755395066e-08,
      "loss": 0.4431,
      "step": 13880
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.653063922884279,
      "learning_rate": 3.179113471256212e-08,
      "loss": 0.4814,
      "step": 13881
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.082487801072569,
      "learning_rate": 3.166448464108629e-08,
      "loss": 0.4985,
      "step": 13882
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.8576379848555753,
      "learning_rate": 3.15380865473891e-08,
      "loss": 0.4712,
      "step": 13883
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.7858711992020506,
      "learning_rate": 3.1411940437882646e-08,
      "loss": 0.4452,
      "step": 13884
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.9562466020331009,
      "learning_rate": 3.1286046318964035e-08,
      "loss": 0.4787,
      "step": 13885
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.494200432647048,
      "learning_rate": 3.1160404197018155e-08,
      "loss": 0.4422,
      "step": 13886
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.0479567220228043,
      "learning_rate": 3.1035014078417136e-08,
      "loss": 0.513,
      "step": 13887
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.9108511095776202,
      "learning_rate": 3.090987596952033e-08,
      "loss": 0.4641,
      "step": 13888
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.1000906103212253,
      "learning_rate": 3.0784989876674886e-08,
      "loss": 0.5275,
      "step": 13889
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.5337730579346471,
      "learning_rate": 3.066035580621407e-08,
      "loss": 0.382,
      "step": 13890
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.0177931689722,
      "learning_rate": 3.053597376445894e-08,
      "loss": 0.505,
      "step": 13891
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.2134027556261233,
      "learning_rate": 3.041184375771777e-08,
      "loss": 0.4685,
      "step": 13892
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.7616858782465354,
      "learning_rate": 3.02879657922861e-08,
      "loss": 0.4743,
      "step": 13893
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.2728695167670323,
      "learning_rate": 3.016433987444667e-08,
      "loss": 0.4778,
      "step": 13894
    },
    {
      "epoch": 0.97,
      "grad_norm": 4.623893529215813,
      "learning_rate": 3.0040966010469466e-08,
      "loss": 0.4877,
      "step": 13895
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.5806451041300477,
      "learning_rate": 2.991784420661115e-08,
      "loss": 0.396,
      "step": 13896
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.254650818554195,
      "learning_rate": 2.9794974469116722e-08,
      "loss": 0.5324,
      "step": 13897
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.6475224010072336,
      "learning_rate": 2.9672356804216762e-08,
      "loss": 0.4784,
      "step": 13898
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.9099108026538638,
      "learning_rate": 2.954999121813129e-08,
      "loss": 0.4645,
      "step": 13899
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.6388611263896493,
      "learning_rate": 2.9427877717065344e-08,
      "loss": 0.4738,
      "step": 13900
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.8337603816429169,
      "learning_rate": 2.9306016307212858e-08,
      "loss": 0.4556,
      "step": 13901
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.8174295508517884,
      "learning_rate": 2.9184406994753335e-08,
      "loss": 0.524,
      "step": 13902
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.8605170280797678,
      "learning_rate": 2.9063049785855168e-08,
      "loss": 0.4907,
      "step": 13903
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.4550381323952855,
      "learning_rate": 2.8941944686672885e-08,
      "loss": 0.4754,
      "step": 13904
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.370929044112402,
      "learning_rate": 2.8821091703348237e-08,
      "loss": 0.4566,
      "step": 13905
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.309085980438204,
      "learning_rate": 2.8700490842011875e-08,
      "loss": 0.4824,
      "step": 13906
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.9080128654909436,
      "learning_rate": 2.8580142108778354e-08,
      "loss": 0.5034,
      "step": 13907
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.5954965298104957,
      "learning_rate": 2.8460045509752232e-08,
      "loss": 0.445,
      "step": 13908
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.2060575247929237,
      "learning_rate": 2.834020105102475e-08,
      "loss": 0.5081,
      "step": 13909
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.22424110723839,
      "learning_rate": 2.8220608738673828e-08,
      "loss": 0.5012,
      "step": 13910
    },
    {
      "epoch": 0.97,
      "grad_norm": 5.777318092085041,
      "learning_rate": 2.8101268578764607e-08,
      "loss": 0.4787,
      "step": 13911
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.5985115429512955,
      "learning_rate": 2.7982180577349472e-08,
      "loss": 0.4101,
      "step": 13912
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.529326178991141,
      "learning_rate": 2.786334474046859e-08,
      "loss": 0.5195,
      "step": 13913
    },
    {
      "epoch": 0.97,
      "grad_norm": 11.078471680851772,
      "learning_rate": 2.774476107414881e-08,
      "loss": 0.5521,
      "step": 13914
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.8637422853408023,
      "learning_rate": 2.76264295844042e-08,
      "loss": 0.4887,
      "step": 13915
    },
    {
      "epoch": 0.97,
      "grad_norm": 8.611625507906894,
      "learning_rate": 2.7508350277236084e-08,
      "loss": 0.5388,
      "step": 13916
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.855766129274354,
      "learning_rate": 2.7390523158633552e-08,
      "loss": 0.4624,
      "step": 13917
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.088357494510018,
      "learning_rate": 2.7272948234571827e-08,
      "loss": 0.4975,
      "step": 13918
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.9701236979575096,
      "learning_rate": 2.7155625511013916e-08,
      "loss": 0.4608,
      "step": 13919
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.3317381154232018,
      "learning_rate": 2.7038554993910616e-08,
      "loss": 0.4739,
      "step": 13920
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.314881494998285,
      "learning_rate": 2.692173668919884e-08,
      "loss": 0.4786,
      "step": 13921
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.5429655356705446,
      "learning_rate": 2.6805170602803297e-08,
      "loss": 0.4117,
      "step": 13922
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.0873393989357965,
      "learning_rate": 2.6688856740636482e-08,
      "loss": 0.5017,
      "step": 13923
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.5659509549921294,
      "learning_rate": 2.657279510859645e-08,
      "loss": 0.4079,
      "step": 13924
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.9142029169717327,
      "learning_rate": 2.645698571257016e-08,
      "loss": 0.4489,
      "step": 13925
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.9263883991940687,
      "learning_rate": 2.6341428558430692e-08,
      "loss": 0.4791,
      "step": 13926
    },
    {
      "epoch": 0.97,
      "grad_norm": 3.1668595800474026,
      "learning_rate": 2.622612365203947e-08,
      "loss": 0.4867,
      "step": 13927
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.9096618861036334,
      "learning_rate": 2.6111070999242925e-08,
      "loss": 0.4803,
      "step": 13928
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.6962768995191446,
      "learning_rate": 2.5996270605877506e-08,
      "loss": 0.5037,
      "step": 13929
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.076961819353328,
      "learning_rate": 2.5881722477765215e-08,
      "loss": 0.4682,
      "step": 13930
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.116723280786538,
      "learning_rate": 2.5767426620715298e-08,
      "loss": 0.4771,
      "step": 13931
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.6336539619116102,
      "learning_rate": 2.5653383040524228e-08,
      "loss": 0.4275,
      "step": 13932
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.2198531711113323,
      "learning_rate": 2.553959174297682e-08,
      "loss": 0.4644,
      "step": 13933
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.925410410637813,
      "learning_rate": 2.5426052733843464e-08,
      "loss": 0.4977,
      "step": 13934
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.842600720484411,
      "learning_rate": 2.5312766018882328e-08,
      "loss": 0.4487,
      "step": 13935
    },
    {
      "epoch": 0.97,
      "grad_norm": 3.231718234621853,
      "learning_rate": 2.5199731603839373e-08,
      "loss": 0.4837,
      "step": 13936
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.7299036231385876,
      "learning_rate": 2.5086949494447233e-08,
      "loss": 0.521,
      "step": 13937
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.125839325235682,
      "learning_rate": 2.4974419696426334e-08,
      "loss": 0.4747,
      "step": 13938
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.0729208927576166,
      "learning_rate": 2.486214221548322e-08,
      "loss": 0.5023,
      "step": 13939
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.265683085391619,
      "learning_rate": 2.475011705731223e-08,
      "loss": 0.4491,
      "step": 13940
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.5114694078537527,
      "learning_rate": 2.4638344227594923e-08,
      "loss": 0.4065,
      "step": 13941
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.9410041657759294,
      "learning_rate": 2.4526823732000104e-08,
      "loss": 0.4363,
      "step": 13942
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.8858199050168443,
      "learning_rate": 2.4415555576184357e-08,
      "loss": 0.4984,
      "step": 13943
    },
    {
      "epoch": 0.97,
      "grad_norm": 4.563345702107299,
      "learning_rate": 2.4304539765789835e-08,
      "loss": 0.5017,
      "step": 13944
    },
    {
      "epoch": 0.97,
      "grad_norm": 3.210459441226682,
      "learning_rate": 2.4193776306447593e-08,
      "loss": 0.4528,
      "step": 13945
    },
    {
      "epoch": 0.97,
      "grad_norm": 7.40552789664249,
      "learning_rate": 2.4083265203774796e-08,
      "loss": 0.5233,
      "step": 13946
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.920113925792606,
      "learning_rate": 2.3973006463376412e-08,
      "loss": 0.4831,
      "step": 13947
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.531892610259291,
      "learning_rate": 2.386300009084408e-08,
      "loss": 0.505,
      "step": 13948
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.1304788008484388,
      "learning_rate": 2.3753246091757776e-08,
      "loss": 0.4725,
      "step": 13949
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.38648040892944,
      "learning_rate": 2.364374447168305e-08,
      "loss": 0.5118,
      "step": 13950
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.4469936673769626,
      "learning_rate": 2.3534495236173237e-08,
      "loss": 0.492,
      "step": 13951
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.1508458259106464,
      "learning_rate": 2.3425498390770573e-08,
      "loss": 0.4628,
      "step": 13952
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.8121584506736208,
      "learning_rate": 2.3316753941001747e-08,
      "loss": 0.4612,
      "step": 13953
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.8236907826119295,
      "learning_rate": 2.3208261892382346e-08,
      "loss": 0.4831,
      "step": 13954
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.7227764743716227,
      "learning_rate": 2.310002225041408e-08,
      "loss": 0.4838,
      "step": 13955
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.5279300548552042,
      "learning_rate": 2.2992035020587556e-08,
      "loss": 0.4074,
      "step": 13956
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.536295350176646,
      "learning_rate": 2.2884300208378395e-08,
      "loss": 0.5044,
      "step": 13957
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.5455722923822707,
      "learning_rate": 2.277681781925223e-08,
      "loss": 0.4036,
      "step": 13958
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.563764026105084,
      "learning_rate": 2.266958785865858e-08,
      "loss": 0.497,
      "step": 13959
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.1165183746504606,
      "learning_rate": 2.256261033203644e-08,
      "loss": 0.4753,
      "step": 13960
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.073135899125162,
      "learning_rate": 2.245588524481146e-08,
      "loss": 0.5075,
      "step": 13961
    },
    {
      "epoch": 0.97,
      "grad_norm": 3.17155969222805,
      "learning_rate": 2.234941260239598e-08,
      "loss": 0.4453,
      "step": 13962
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.137643696765424,
      "learning_rate": 2.224319241019013e-08,
      "loss": 0.4532,
      "step": 13963
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.6438938898059439,
      "learning_rate": 2.213722467358126e-08,
      "loss": 0.4403,
      "step": 13964
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.9076763458286077,
      "learning_rate": 2.203150939794396e-08,
      "loss": 0.5,
      "step": 13965
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.2481564505368126,
      "learning_rate": 2.192604658863895e-08,
      "loss": 0.4409,
      "step": 13966
    },
    {
      "epoch": 0.97,
      "grad_norm": 3.039019087681444,
      "learning_rate": 2.182083625101583e-08,
      "loss": 0.4552,
      "step": 13967
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.7159510753037086,
      "learning_rate": 2.1715878390409782e-08,
      "loss": 0.4567,
      "step": 13968
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.9143978879292614,
      "learning_rate": 2.1611173012144328e-08,
      "loss": 0.4283,
      "step": 13969
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.760670258571182,
      "learning_rate": 2.1506720121529656e-08,
      "loss": 0.4651,
      "step": 13970
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.8403697937655537,
      "learning_rate": 2.1402519723863202e-08,
      "loss": 0.4917,
      "step": 13971
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.1430989093416377,
      "learning_rate": 2.129857182443018e-08,
      "loss": 0.497,
      "step": 13972
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.0200065714480515,
      "learning_rate": 2.119487642850193e-08,
      "loss": 0.47,
      "step": 13973
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.9285762517058147,
      "learning_rate": 2.109143354133758e-08,
      "loss": 0.4706,
      "step": 13974
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.5228921104051514,
      "learning_rate": 2.0988243168183488e-08,
      "loss": 0.4616,
      "step": 13975
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.1072443759692012,
      "learning_rate": 2.088530531427324e-08,
      "loss": 0.4967,
      "step": 13976
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.3555214805816576,
      "learning_rate": 2.0782619984827667e-08,
      "loss": 0.4828,
      "step": 13977
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.8294239441318696,
      "learning_rate": 2.0680187185054266e-08,
      "loss": 0.5176,
      "step": 13978
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.8627363458839068,
      "learning_rate": 2.057800692014833e-08,
      "loss": 0.4726,
      "step": 13979
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.00339140744804,
      "learning_rate": 2.047607919529182e-08,
      "loss": 0.4924,
      "step": 13980
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.0757995904320268,
      "learning_rate": 2.0374404015654493e-08,
      "loss": 0.5601,
      "step": 13981
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.5969343839119134,
      "learning_rate": 2.0272981386393332e-08,
      "loss": 0.4067,
      "step": 13982
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.027731499239556,
      "learning_rate": 2.0171811312650892e-08,
      "loss": 0.5412,
      "step": 13983
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.415743856868178,
      "learning_rate": 2.0070893799559732e-08,
      "loss": 0.4831,
      "step": 13984
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.8279031753679793,
      "learning_rate": 1.9970228852236872e-08,
      "loss": 0.4662,
      "step": 13985
    },
    {
      "epoch": 0.97,
      "grad_norm": 3.9839335681354995,
      "learning_rate": 1.986981647578823e-08,
      "loss": 0.5022,
      "step": 13986
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.1661412005434424,
      "learning_rate": 1.976965667530639e-08,
      "loss": 0.4807,
      "step": 13987
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.120461534343492,
      "learning_rate": 1.966974945587119e-08,
      "loss": 0.4504,
      "step": 13988
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.2032591896309883,
      "learning_rate": 1.9570094822549678e-08,
      "loss": 0.5414,
      "step": 13989
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.5041641940751624,
      "learning_rate": 1.9470692780395595e-08,
      "loss": 0.4631,
      "step": 13990
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.2789871745595516,
      "learning_rate": 1.937154333445046e-08,
      "loss": 0.5021,
      "step": 13991
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.0275130138260375,
      "learning_rate": 1.927264648974303e-08,
      "loss": 0.4429,
      "step": 13992
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.3808400768546596,
      "learning_rate": 1.9174002251288736e-08,
      "loss": 0.4646,
      "step": 13993
    },
    {
      "epoch": 0.97,
      "grad_norm": 3.0368925028270817,
      "learning_rate": 1.9075610624090246e-08,
      "loss": 0.4871,
      "step": 13994
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.9560732665986909,
      "learning_rate": 1.8977471613138566e-08,
      "loss": 0.4323,
      "step": 13995
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.3997513078476698,
      "learning_rate": 1.8879585223410268e-08,
      "loss": 0.4921,
      "step": 13996
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.5152081529503245,
      "learning_rate": 1.8781951459870274e-08,
      "loss": 0.427,
      "step": 13997
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.145695329302222,
      "learning_rate": 1.868457032746962e-08,
      "loss": 0.4452,
      "step": 13998
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.11135482224385,
      "learning_rate": 1.858744183114769e-08,
      "loss": 0.446,
      "step": 13999
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.315198467902543,
      "learning_rate": 1.8490565975830544e-08,
      "loss": 0.492,
      "step": 14000
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.9229393911026085,
      "learning_rate": 1.8393942766430917e-08,
      "loss": 0.4851,
      "step": 14001
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.002975521128648,
      "learning_rate": 1.829757220784989e-08,
      "loss": 0.5201,
      "step": 14002
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.8170268690898295,
      "learning_rate": 1.8201454304974664e-08,
      "loss": 0.4947,
      "step": 14003
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.5471299640872527,
      "learning_rate": 1.8105589062679675e-08,
      "loss": 0.3864,
      "step": 14004
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.1008919365115775,
      "learning_rate": 1.8009976485827697e-08,
      "loss": 0.4755,
      "step": 14005
    },
    {
      "epoch": 0.97,
      "grad_norm": 3.1198342340630925,
      "learning_rate": 1.7914616579267074e-08,
      "loss": 0.4491,
      "step": 14006
    },
    {
      "epoch": 0.97,
      "grad_norm": 4.164883206992448,
      "learning_rate": 1.781950934783505e-08,
      "loss": 0.4864,
      "step": 14007
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.4121147123221496,
      "learning_rate": 1.7724654796354434e-08,
      "loss": 0.4588,
      "step": 14008
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.1946407233488605,
      "learning_rate": 1.7630052929636378e-08,
      "loss": 0.4279,
      "step": 14009
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.0974893013955787,
      "learning_rate": 1.753570375247815e-08,
      "loss": 0.4691,
      "step": 14010
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.8994380134898161,
      "learning_rate": 1.7441607269665928e-08,
      "loss": 0.4519,
      "step": 14011
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.7375760548985406,
      "learning_rate": 1.734776348597089e-08,
      "loss": 0.4696,
      "step": 14012
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.631822952014056,
      "learning_rate": 1.7254172406152568e-08,
      "loss": 0.4843,
      "step": 14013
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.854296226075303,
      "learning_rate": 1.7160834034958275e-08,
      "loss": 0.4513,
      "step": 14014
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.7317741935430262,
      "learning_rate": 1.7067748377121442e-08,
      "loss": 0.471,
      "step": 14015
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.604395019554728,
      "learning_rate": 1.697491543736385e-08,
      "loss": 0.4192,
      "step": 14016
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.0943905350572396,
      "learning_rate": 1.6882335220391732e-08,
      "loss": 0.4803,
      "step": 14017
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.906925508285717,
      "learning_rate": 1.6790007730902446e-08,
      "loss": 0.449,
      "step": 14018
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.9474254110299936,
      "learning_rate": 1.6697932973577247e-08,
      "loss": 0.4868,
      "step": 14019
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.03134717583955,
      "learning_rate": 1.660611095308684e-08,
      "loss": 0.4735,
      "step": 14020
    },
    {
      "epoch": 0.97,
      "grad_norm": 3.2791577942959123,
      "learning_rate": 1.6514541674087502e-08,
      "loss": 0.4751,
      "step": 14021
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.9025172069449667,
      "learning_rate": 1.6423225141223854e-08,
      "loss": 0.498,
      "step": 14022
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.1182968978641754,
      "learning_rate": 1.6332161359126076e-08,
      "loss": 0.4966,
      "step": 14023
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.5522398122009076,
      "learning_rate": 1.6241350332414363e-08,
      "loss": 0.5249,
      "step": 14024
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.7764957979104259,
      "learning_rate": 1.615079206569281e-08,
      "loss": 0.4545,
      "step": 14025
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.9965064562109984,
      "learning_rate": 1.606048656355441e-08,
      "loss": 0.5107,
      "step": 14026
    },
    {
      "epoch": 0.98,
      "grad_norm": 3.358954727476209,
      "learning_rate": 1.59704338305805e-08,
      "loss": 0.4756,
      "step": 14027
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.8390103075040818,
      "learning_rate": 1.588063387133687e-08,
      "loss": 0.4878,
      "step": 14028
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.2219057963287123,
      "learning_rate": 1.579108669037821e-08,
      "loss": 0.4995,
      "step": 14029
    },
    {
      "epoch": 0.98,
      "grad_norm": 3.066414278225929,
      "learning_rate": 1.570179229224589e-08,
      "loss": 0.4717,
      "step": 14030
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.9920058835937733,
      "learning_rate": 1.5612750681469613e-08,
      "loss": 0.4722,
      "step": 14031
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.1987234072144646,
      "learning_rate": 1.552396186256411e-08,
      "loss": 0.5031,
      "step": 14032
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.9728718197017194,
      "learning_rate": 1.5435425840032993e-08,
      "loss": 0.4867,
      "step": 14033
    },
    {
      "epoch": 0.98,
      "grad_norm": 3.8803062774028283,
      "learning_rate": 1.534714261836656e-08,
      "loss": 0.4682,
      "step": 14034
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.8141471605149528,
      "learning_rate": 1.5259112202041793e-08,
      "loss": 0.4142,
      "step": 14035
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.042818239340266,
      "learning_rate": 1.5171334595524e-08,
      "loss": 0.4332,
      "step": 14036
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.10190382770704,
      "learning_rate": 1.508380980326518e-08,
      "loss": 0.4659,
      "step": 14037
    },
    {
      "epoch": 0.98,
      "grad_norm": 7.10155561489954,
      "learning_rate": 1.4996537829702895e-08,
      "loss": 0.486,
      "step": 14038
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.8553170587433876,
      "learning_rate": 1.4909518679264712e-08,
      "loss": 0.5021,
      "step": 14039
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.9405501549400697,
      "learning_rate": 1.4822752356363212e-08,
      "loss": 0.4209,
      "step": 14040
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.011240661233979,
      "learning_rate": 1.4736238865398766e-08,
      "loss": 0.4865,
      "step": 14041
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.9138239982885572,
      "learning_rate": 1.464997821075953e-08,
      "loss": 0.4602,
      "step": 14042
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.5939563695286109,
      "learning_rate": 1.4563970396820337e-08,
      "loss": 0.4336,
      "step": 14043
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.6139599313991846,
      "learning_rate": 1.4478215427943254e-08,
      "loss": 0.412,
      "step": 14044
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.319379175776456,
      "learning_rate": 1.4392713308477579e-08,
      "loss": 0.4915,
      "step": 14045
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.385652233132952,
      "learning_rate": 1.4307464042758734e-08,
      "loss": 0.4662,
      "step": 14046
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.9423440444877458,
      "learning_rate": 1.4222467635111592e-08,
      "loss": 0.4675,
      "step": 14047
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.5789558899207848,
      "learning_rate": 1.4137724089846593e-08,
      "loss": 0.4153,
      "step": 14048
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.9805664607284943,
      "learning_rate": 1.4053233411260858e-08,
      "loss": 0.4924,
      "step": 14049
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.990988741754849,
      "learning_rate": 1.3968995603639846e-08,
      "loss": 0.4563,
      "step": 14050
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.5277445630156463,
      "learning_rate": 1.388501067125625e-08,
      "loss": 0.5214,
      "step": 14051
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.143491621218235,
      "learning_rate": 1.380127861836944e-08,
      "loss": 0.4839,
      "step": 14052
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.6234402837617319,
      "learning_rate": 1.3717799449225467e-08,
      "loss": 0.4823,
      "step": 14053
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.0302276964047894,
      "learning_rate": 1.3634573168058717e-08,
      "loss": 0.4638,
      "step": 14054
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.354961351531787,
      "learning_rate": 1.3551599779089707e-08,
      "loss": 0.5164,
      "step": 14055
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.1170309881693163,
      "learning_rate": 1.3468879286527292e-08,
      "loss": 0.4494,
      "step": 14056
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.087834580603084,
      "learning_rate": 1.3386411694565894e-08,
      "loss": 0.4671,
      "step": 14057
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.5478716573577496,
      "learning_rate": 1.3304197007388276e-08,
      "loss": 0.4342,
      "step": 14058
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.8894719240964002,
      "learning_rate": 1.3222235229164438e-08,
      "loss": 0.5122,
      "step": 14059
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.5750699590428603,
      "learning_rate": 1.3140526364051054e-08,
      "loss": 0.4991,
      "step": 14060
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.4670793181386306,
      "learning_rate": 1.3059070416192033e-08,
      "loss": 0.4441,
      "step": 14061
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.7510392233352006,
      "learning_rate": 1.2977867389718512e-08,
      "loss": 0.5113,
      "step": 14062
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.564116596666406,
      "learning_rate": 1.2896917288748868e-08,
      "loss": 0.4947,
      "step": 14063
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.5869841092047696,
      "learning_rate": 1.28162201173887e-08,
      "loss": 0.4238,
      "step": 14064
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.3834705351768144,
      "learning_rate": 1.273577587973085e-08,
      "loss": 0.5509,
      "step": 14065
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.9712926943548414,
      "learning_rate": 1.265558457985483e-08,
      "loss": 0.487,
      "step": 14066
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.8341124854765245,
      "learning_rate": 1.2575646221828497e-08,
      "loss": 0.5078,
      "step": 14067
    },
    {
      "epoch": 0.98,
      "grad_norm": 3.3363665775036675,
      "learning_rate": 1.2495960809704722e-08,
      "loss": 0.4545,
      "step": 14068
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.7817236083644112,
      "learning_rate": 1.2416528347525824e-08,
      "loss": 0.4728,
      "step": 14069
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.6857664791281586,
      "learning_rate": 1.233734883932025e-08,
      "loss": 0.4815,
      "step": 14070
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.4743109979183275,
      "learning_rate": 1.2258422289103677e-08,
      "loss": 0.4792,
      "step": 14071
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.9689992152152855,
      "learning_rate": 1.2179748700879013e-08,
      "loss": 0.4899,
      "step": 14072
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.5015571047855878,
      "learning_rate": 1.2101328078635843e-08,
      "loss": 0.4069,
      "step": 14073
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.797724931665869,
      "learning_rate": 1.2023160426352098e-08,
      "loss": 0.4875,
      "step": 14074
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.7575776932937166,
      "learning_rate": 1.1945245747991829e-08,
      "loss": 0.5079,
      "step": 14075
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.8423043261857006,
      "learning_rate": 1.1867584047506876e-08,
      "loss": 0.4535,
      "step": 14076
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.4684648787913637,
      "learning_rate": 1.179017532883575e-08,
      "loss": 0.4701,
      "step": 14077
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.800472362366389,
      "learning_rate": 1.1713019595904207e-08,
      "loss": 0.4953,
      "step": 14078
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.1254424523270115,
      "learning_rate": 1.1636116852625778e-08,
      "loss": 0.4785,
      "step": 14079
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.877664773974729,
      "learning_rate": 1.1559467102900679e-08,
      "loss": 0.4807,
      "step": 14080
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.571371301729443,
      "learning_rate": 1.1483070350615799e-08,
      "loss": 0.4511,
      "step": 14081
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.070348888141033,
      "learning_rate": 1.1406926599646373e-08,
      "loss": 0.4793,
      "step": 14082
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.242230025590987,
      "learning_rate": 1.1331035853853756e-08,
      "loss": 0.5211,
      "step": 14083
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.170127681783372,
      "learning_rate": 1.1255398117087091e-08,
      "loss": 0.5402,
      "step": 14084
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.1139280714970075,
      "learning_rate": 1.1180013393182198e-08,
      "loss": 0.4506,
      "step": 14085
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.319153615150426,
      "learning_rate": 1.1104881685962687e-08,
      "loss": 0.4835,
      "step": 14086
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.939228407400637,
      "learning_rate": 1.1030002999238843e-08,
      "loss": 0.4564,
      "step": 14087
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.5334853134447797,
      "learning_rate": 1.0955377336808181e-08,
      "loss": 0.4717,
      "step": 14088
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.9883932445580679,
      "learning_rate": 1.0881004702455456e-08,
      "loss": 0.4772,
      "step": 14089
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.5461981631729117,
      "learning_rate": 1.0806885099953202e-08,
      "loss": 0.4153,
      "step": 14090
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.415100951654032,
      "learning_rate": 1.0733018533059526e-08,
      "loss": 0.5129,
      "step": 14091
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.017099263497199,
      "learning_rate": 1.0659405005521429e-08,
      "loss": 0.4796,
      "step": 14092
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.840390679934449,
      "learning_rate": 1.0586044521072036e-08,
      "loss": 0.4838,
      "step": 14093
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.781481065541729,
      "learning_rate": 1.0512937083432262e-08,
      "loss": 0.5118,
      "step": 14094
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.8994676690236107,
      "learning_rate": 1.044008269630914e-08,
      "loss": 0.5001,
      "step": 14095
    },
    {
      "epoch": 0.98,
      "grad_norm": 5.284843814846358,
      "learning_rate": 1.0367481363398602e-08,
      "loss": 0.4714,
      "step": 14096
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.9154669697432796,
      "learning_rate": 1.0295133088382147e-08,
      "loss": 0.502,
      "step": 14097
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.098893103406532,
      "learning_rate": 1.0223037874929064e-08,
      "loss": 0.4497,
      "step": 14098
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.5771348525400124,
      "learning_rate": 1.0151195726695873e-08,
      "loss": 0.4697,
      "step": 14099
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.3586552870223327,
      "learning_rate": 1.0079606647326323e-08,
      "loss": 0.4841,
      "step": 14100
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.5605762729396415,
      "learning_rate": 1.0008270640450845e-08,
      "loss": 0.4144,
      "step": 14101
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.6148059876789098,
      "learning_rate": 9.937187709688212e-09,
      "loss": 0.42,
      "step": 14102
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.1759033474732505,
      "learning_rate": 9.866357858642206e-09,
      "loss": 0.4465,
      "step": 14103
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.9830388227229703,
      "learning_rate": 9.795781090906064e-09,
      "loss": 0.4722,
      "step": 14104
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.3244490534306017,
      "learning_rate": 9.725457410058592e-09,
      "loss": 0.5097,
      "step": 14105
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.0468445091051795,
      "learning_rate": 9.655386819666934e-09,
      "loss": 0.4485,
      "step": 14106
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.397055260536752,
      "learning_rate": 9.585569323284915e-09,
      "loss": 0.4894,
      "step": 14107
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.249243469197698,
      "learning_rate": 9.516004924452482e-09,
      "loss": 0.5114,
      "step": 14108
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.9015128487679915,
      "learning_rate": 9.446693626698477e-09,
      "loss": 0.4559,
      "step": 14109
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.0282040375488877,
      "learning_rate": 9.377635433538423e-09,
      "loss": 0.4568,
      "step": 14110
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.044476189539541,
      "learning_rate": 9.308830348473963e-09,
      "loss": 0.5034,
      "step": 14111
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.9753113619528737,
      "learning_rate": 9.240278374995637e-09,
      "loss": 0.5237,
      "step": 14112
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.513998998610625,
      "learning_rate": 9.171979516579e-09,
      "loss": 0.4088,
      "step": 14113
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.1178033028827175,
      "learning_rate": 9.1039337766885e-09,
      "loss": 0.4504,
      "step": 14114
    },
    {
      "epoch": 0.98,
      "grad_norm": 8.10395477745984,
      "learning_rate": 9.03614115877527e-09,
      "loss": 0.4879,
      "step": 14115
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.5626124817584264,
      "learning_rate": 8.968601666277666e-09,
      "loss": 0.4226,
      "step": 14116
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.12495935555065,
      "learning_rate": 8.901315302621283e-09,
      "loss": 0.4734,
      "step": 14117
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.008214315342323,
      "learning_rate": 8.834282071217282e-09,
      "loss": 0.5228,
      "step": 14118
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.8654142515196321,
      "learning_rate": 8.767501975467384e-09,
      "loss": 0.482,
      "step": 14119
    },
    {
      "epoch": 0.98,
      "grad_norm": 4.309741941984642,
      "learning_rate": 8.700975018756663e-09,
      "loss": 0.4911,
      "step": 14120
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.0018935376674865,
      "learning_rate": 8.634701204460194e-09,
      "loss": 0.4657,
      "step": 14121
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.3762629708058802,
      "learning_rate": 8.568680535939177e-09,
      "loss": 0.4901,
      "step": 14122
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.6257992941240202,
      "learning_rate": 8.502913016541492e-09,
      "loss": 0.4619,
      "step": 14123
    },
    {
      "epoch": 0.98,
      "grad_norm": 5.6902017331563,
      "learning_rate": 8.437398649602247e-09,
      "loss": 0.5092,
      "step": 14124
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.278368922759033,
      "learning_rate": 8.372137438445449e-09,
      "loss": 0.5306,
      "step": 14125
    },
    {
      "epoch": 0.98,
      "grad_norm": 3.8015293281777827,
      "learning_rate": 8.30712938638012e-09,
      "loss": 0.5009,
      "step": 14126
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.390186454197045,
      "learning_rate": 8.242374496703065e-09,
      "loss": 0.429,
      "step": 14127
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.433937018465972,
      "learning_rate": 8.17787277269888e-09,
      "loss": 0.4693,
      "step": 14128
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.444746220768027,
      "learning_rate": 8.113624217638283e-09,
      "loss": 0.4842,
      "step": 14129
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.9401944111945424,
      "learning_rate": 8.049628834780887e-09,
      "loss": 0.5256,
      "step": 14130
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.6243980314399196,
      "learning_rate": 7.98588662737132e-09,
      "loss": 0.4412,
      "step": 14131
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.891343553864461,
      "learning_rate": 7.922397598642551e-09,
      "loss": 0.4692,
      "step": 14132
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.7385902070589783,
      "learning_rate": 7.859161751814782e-09,
      "loss": 0.4664,
      "step": 14133
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.1557196276189194,
      "learning_rate": 7.796179090094891e-09,
      "loss": 0.4746,
      "step": 14134
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.779914220541829,
      "learning_rate": 7.733449616677546e-09,
      "loss": 0.4648,
      "step": 14135
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.096185117411589,
      "learning_rate": 7.670973334743537e-09,
      "loss": 0.4823,
      "step": 14136
    },
    {
      "epoch": 0.98,
      "grad_norm": 3.369598378332578,
      "learning_rate": 7.608750247462548e-09,
      "loss": 0.4415,
      "step": 14137
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.9692395992310796,
      "learning_rate": 7.546780357988725e-09,
      "loss": 0.4818,
      "step": 14138
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.3904203912087953,
      "learning_rate": 7.485063669466219e-09,
      "loss": 0.4588,
      "step": 14139
    },
    {
      "epoch": 0.98,
      "grad_norm": 4.3362080831814485,
      "learning_rate": 7.423600185024749e-09,
      "loss": 0.4641,
      "step": 14140
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.8208544542200538,
      "learning_rate": 7.362389907781819e-09,
      "loss": 0.4934,
      "step": 14141
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.9337939061478346,
      "learning_rate": 7.301432840841061e-09,
      "loss": 0.498,
      "step": 14142
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.0298221571223363,
      "learning_rate": 7.2407289872949986e-09,
      "loss": 0.4908,
      "step": 14143
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.09639752364039,
      "learning_rate": 7.180278350221726e-09,
      "loss": 0.4917,
      "step": 14144
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.765980394222194,
      "learning_rate": 7.120080932687123e-09,
      "loss": 0.51,
      "step": 14145
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.8656273363198748,
      "learning_rate": 7.06013673774375e-09,
      "loss": 0.4945,
      "step": 14146
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.8861489858317948,
      "learning_rate": 7.000445768433062e-09,
      "loss": 0.5789,
      "step": 14147
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.7741090305322684,
      "learning_rate": 6.941008027781526e-09,
      "loss": 0.4831,
      "step": 14148
    },
    {
      "epoch": 0.98,
      "grad_norm": 5.229930900262437,
      "learning_rate": 6.8818235188033985e-09,
      "loss": 0.5318,
      "step": 14149
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.8454488637561273,
      "learning_rate": 6.822892244500723e-09,
      "loss": 0.4723,
      "step": 14150
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.136104684291245,
      "learning_rate": 6.7642142078627734e-09,
      "loss": 0.4332,
      "step": 14151
    },
    {
      "epoch": 0.98,
      "grad_norm": 3.7064146338466313,
      "learning_rate": 6.705789411864394e-09,
      "loss": 0.4678,
      "step": 14152
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.7784998232684954,
      "learning_rate": 6.64761785946988e-09,
      "loss": 0.4594,
      "step": 14153
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.8645945551739314,
      "learning_rate": 6.589699553628537e-09,
      "loss": 0.4501,
      "step": 14154
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.1110212923190437,
      "learning_rate": 6.532034497278017e-09,
      "loss": 0.5012,
      "step": 14155
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.273419544946167,
      "learning_rate": 6.4746226933432026e-09,
      "loss": 0.4783,
      "step": 14156
    },
    {
      "epoch": 0.98,
      "grad_norm": 3.536759289213627,
      "learning_rate": 6.417464144736208e-09,
      "loss": 0.5259,
      "step": 14157
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.7374719669897811,
      "learning_rate": 6.3605588543547145e-09,
      "loss": 0.4398,
      "step": 14158
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.1981849942521556,
      "learning_rate": 6.303906825085859e-09,
      "loss": 0.5144,
      "step": 14159
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.5811290206812563,
      "learning_rate": 6.247508059802343e-09,
      "loss": 0.4757,
      "step": 14160
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.8922169765048487,
      "learning_rate": 6.1913625613646555e-09,
      "loss": 0.5014,
      "step": 14161
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.2512193883314295,
      "learning_rate": 6.135470332620519e-09,
      "loss": 0.4843,
      "step": 14162
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.6361861369446924,
      "learning_rate": 6.079831376404333e-09,
      "loss": 0.4609,
      "step": 14163
    },
    {
      "epoch": 0.98,
      "grad_norm": 7.34346432982271,
      "learning_rate": 6.024445695537728e-09,
      "loss": 0.463,
      "step": 14164
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.258975175397056,
      "learning_rate": 5.969313292830126e-09,
      "loss": 0.4401,
      "step": 14165
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.9229427724581636,
      "learning_rate": 5.914434171077066e-09,
      "loss": 0.4855,
      "step": 14166
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.1297919347268905,
      "learning_rate": 5.859808333062988e-09,
      "loss": 0.5194,
      "step": 14167
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.041143796337603,
      "learning_rate": 5.8054357815567895e-09,
      "loss": 0.4787,
      "step": 14168
    },
    {
      "epoch": 0.99,
      "grad_norm": 3.058095174502787,
      "learning_rate": 5.7513165193173735e-09,
      "loss": 0.4885,
      "step": 14169
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.110472585866208,
      "learning_rate": 5.6974505490886564e-09,
      "loss": 0.4441,
      "step": 14170
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.1841614121494137,
      "learning_rate": 5.643837873603453e-09,
      "loss": 0.5241,
      "step": 14171
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.0460777472391687,
      "learning_rate": 5.590478495580143e-09,
      "loss": 0.5005,
      "step": 14172
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.109854292975818,
      "learning_rate": 5.5373724177243404e-09,
      "loss": 0.4991,
      "step": 14173
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.5740318878054287,
      "learning_rate": 5.484519642731112e-09,
      "loss": 0.4077,
      "step": 14174
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.7645359124342481,
      "learning_rate": 5.4319201732794255e-09,
      "loss": 0.4646,
      "step": 14175
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.1256587596519267,
      "learning_rate": 5.379574012037703e-09,
      "loss": 0.4713,
      "step": 14176
    },
    {
      "epoch": 0.99,
      "grad_norm": 3.1370242846790775,
      "learning_rate": 5.327481161660486e-09,
      "loss": 0.5003,
      "step": 14177
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.3184889349017714,
      "learning_rate": 5.275641624789551e-09,
      "loss": 0.4767,
      "step": 14178
    },
    {
      "epoch": 0.99,
      "grad_norm": 4.598924998752417,
      "learning_rate": 5.224055404055018e-09,
      "loss": 0.5135,
      "step": 14179
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.835852590218568,
      "learning_rate": 5.172722502072014e-09,
      "loss": 0.4587,
      "step": 14180
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.7064645737792388,
      "learning_rate": 5.1216429214445695e-09,
      "loss": 0.4985,
      "step": 14181
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.275151082730035,
      "learning_rate": 5.0708166647628345e-09,
      "loss": 0.4424,
      "step": 14182
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.582846809609345,
      "learning_rate": 5.0202437346053015e-09,
      "loss": 0.4241,
      "step": 14183
    },
    {
      "epoch": 0.99,
      "grad_norm": 3.1575041224836125,
      "learning_rate": 4.969924133536585e-09,
      "loss": 0.4601,
      "step": 14184
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.5661723648516314,
      "learning_rate": 4.9198578641079795e-09,
      "loss": 0.4179,
      "step": 14185
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.7986404898105062,
      "learning_rate": 4.870044928859674e-09,
      "loss": 0.4977,
      "step": 14186
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.7786767437739681,
      "learning_rate": 4.820485330317981e-09,
      "loss": 0.42,
      "step": 14187
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.4353794551438166,
      "learning_rate": 4.7711790709953355e-09,
      "loss": 0.4928,
      "step": 14188
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.308943230196365,
      "learning_rate": 4.722126153393625e-09,
      "loss": 0.4798,
      "step": 14189
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.9998127929791938,
      "learning_rate": 4.673326579999749e-09,
      "loss": 0.5016,
      "step": 14190
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.8915485616503231,
      "learning_rate": 4.624780353288949e-09,
      "loss": 0.5049,
      "step": 14191
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.5448498859068739,
      "learning_rate": 4.576487475724256e-09,
      "loss": 0.4265,
      "step": 14192
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.6659602790336163,
      "learning_rate": 4.528447949753157e-09,
      "loss": 0.4907,
      "step": 14193
    },
    {
      "epoch": 0.99,
      "grad_norm": 4.7975361057864845,
      "learning_rate": 4.480661777813699e-09,
      "loss": 0.4923,
      "step": 14194
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.4028218039481026,
      "learning_rate": 4.433128962328392e-09,
      "loss": 0.5506,
      "step": 14195
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.816047659793625,
      "learning_rate": 4.385849505708084e-09,
      "loss": 0.4487,
      "step": 14196
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.5675966128502585,
      "learning_rate": 4.338823410351412e-09,
      "loss": 0.405,
      "step": 14197
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.8260705878638328,
      "learning_rate": 4.292050678642579e-09,
      "loss": 0.4923,
      "step": 14198
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.0334810856099734,
      "learning_rate": 4.245531312953577e-09,
      "loss": 0.5864,
      "step": 14199
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.8670233319557195,
      "learning_rate": 4.19926531564474e-09,
      "loss": 0.5196,
      "step": 14200
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.241139785271466,
      "learning_rate": 4.153252689061415e-09,
      "loss": 0.5005,
      "step": 14201
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.0463530759759276,
      "learning_rate": 4.1074934355384015e-09,
      "loss": 0.5166,
      "step": 14202
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.766998819589427,
      "learning_rate": 4.061987557394953e-09,
      "loss": 0.4571,
      "step": 14203
    },
    {
      "epoch": 0.99,
      "grad_norm": 3.1607455038745598,
      "learning_rate": 4.016735056940335e-09,
      "loss": 0.4734,
      "step": 14204
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.0978933452023636,
      "learning_rate": 3.971735936469378e-09,
      "loss": 0.4816,
      "step": 14205
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.8378571307123543,
      "learning_rate": 3.926990198263037e-09,
      "loss": 0.4976,
      "step": 14206
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.5458682124136427,
      "learning_rate": 3.88249784459227e-09,
      "loss": 0.4576,
      "step": 14207
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.8710926094629619,
      "learning_rate": 3.838258877713053e-09,
      "loss": 0.4291,
      "step": 14208
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.8438586730133262,
      "learning_rate": 3.794273299868589e-09,
      "loss": 0.5062,
      "step": 14209
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.012526344998129,
      "learning_rate": 3.750541113289874e-09,
      "loss": 0.503,
      "step": 14210
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.0730384024040824,
      "learning_rate": 3.7070623201951317e-09,
      "loss": 0.463,
      "step": 14211
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.2267419410803497,
      "learning_rate": 3.663836922789821e-09,
      "loss": 0.4677,
      "step": 14212
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.0081805791682696,
      "learning_rate": 3.620864923264966e-09,
      "loss": 0.4564,
      "step": 14213
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.5490865717032993,
      "learning_rate": 3.578146323801046e-09,
      "loss": 0.4417,
      "step": 14214
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.335235405992196,
      "learning_rate": 3.535681126564661e-09,
      "loss": 0.4873,
      "step": 14215
    },
    {
      "epoch": 0.99,
      "grad_norm": 3.0829210775720326,
      "learning_rate": 3.4934693337085324e-09,
      "loss": 0.4062,
      "step": 14216
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.231137021307855,
      "learning_rate": 3.4515109473742815e-09,
      "loss": 0.4662,
      "step": 14217
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.900444713982614,
      "learning_rate": 3.40980596968965e-09,
      "loss": 0.5443,
      "step": 14218
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.4476066512410926,
      "learning_rate": 3.3683544027701687e-09,
      "loss": 0.4669,
      "step": 14219
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.20283085068477,
      "learning_rate": 3.327156248717489e-09,
      "loss": 0.4583,
      "step": 14220
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.1582115329892226,
      "learning_rate": 3.286211509621606e-09,
      "loss": 0.4636,
      "step": 14221
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.8830453008620875,
      "learning_rate": 3.2455201875586372e-09,
      "loss": 0.4835,
      "step": 14222
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.5526649993982298,
      "learning_rate": 3.2050822845924866e-09,
      "loss": 0.4194,
      "step": 14223
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.087737372652989,
      "learning_rate": 3.1648978027737366e-09,
      "loss": 0.4913,
      "step": 14224
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.7917640457612336,
      "learning_rate": 3.1249667441413113e-09,
      "loss": 0.4564,
      "step": 14225
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.494940302939473,
      "learning_rate": 3.0852891107197023e-09,
      "loss": 0.4522,
      "step": 14226
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.6337432857469318,
      "learning_rate": 3.0458649045211897e-09,
      "loss": 0.4628,
      "step": 14227
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.816666001864302,
      "learning_rate": 3.0066941275458396e-09,
      "loss": 0.4721,
      "step": 14228
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.6700234109321441,
      "learning_rate": 2.9677767817792858e-09,
      "loss": 0.4649,
      "step": 14229
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.330560361373057,
      "learning_rate": 2.92911286919606e-09,
      "loss": 0.4956,
      "step": 14230
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.9112743313213312,
      "learning_rate": 2.8907023917568167e-09,
      "loss": 0.4722,
      "step": 14231
    },
    {
      "epoch": 0.99,
      "grad_norm": 7.143179969004018,
      "learning_rate": 2.8525453514099966e-09,
      "loss": 0.495,
      "step": 14232
    },
    {
      "epoch": 0.99,
      "grad_norm": 4.391419911143628,
      "learning_rate": 2.8146417500901634e-09,
      "loss": 0.4947,
      "step": 14233
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.7887383656884468,
      "learning_rate": 2.7769915897196687e-09,
      "loss": 0.4616,
      "step": 14234
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.8950012204063689,
      "learning_rate": 2.739594872208651e-09,
      "loss": 0.4822,
      "step": 14235
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.4202385143971954,
      "learning_rate": 2.7024515994528155e-09,
      "loss": 0.474,
      "step": 14236
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.0036682190552946,
      "learning_rate": 2.6655617733373217e-09,
      "loss": 0.471,
      "step": 14237
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.056786176422827,
      "learning_rate": 2.628925395731785e-09,
      "loss": 0.4594,
      "step": 14238
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.1624114106898737,
      "learning_rate": 2.5925424684947185e-09,
      "loss": 0.4829,
      "step": 14239
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.903090748333092,
      "learning_rate": 2.5564129934718683e-09,
      "loss": 0.466,
      "step": 14240
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.703394614674071,
      "learning_rate": 2.520536972494547e-09,
      "loss": 0.4572,
      "step": 14241
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.442546704891507,
      "learning_rate": 2.484914407383521e-09,
      "loss": 0.4768,
      "step": 14242
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.069692623538015,
      "learning_rate": 2.4495452999440117e-09,
      "loss": 0.4827,
      "step": 14243
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.5459749582271813,
      "learning_rate": 2.4144296519712506e-09,
      "loss": 0.4597,
      "step": 14244
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.1108317667413345,
      "learning_rate": 2.3795674652454804e-09,
      "loss": 0.4313,
      "step": 14245
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.131812501873397,
      "learning_rate": 2.344958741534731e-09,
      "loss": 0.4607,
      "step": 14246
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.069483250031368,
      "learning_rate": 2.3106034825942647e-09,
      "loss": 0.4909,
      "step": 14247
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.9048080090740491,
      "learning_rate": 2.2765016901665772e-09,
      "loss": 0.4711,
      "step": 14248
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.1390294301424215,
      "learning_rate": 2.2426533659813955e-09,
      "loss": 0.468,
      "step": 14249
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.9236427473230986,
      "learning_rate": 2.2090585117551242e-09,
      "loss": 0.4964,
      "step": 14250
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.238750608072335,
      "learning_rate": 2.1757171291919565e-09,
      "loss": 0.4588,
      "step": 14251
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.3009376619114033,
      "learning_rate": 2.1426292199822064e-09,
      "loss": 0.5315,
      "step": 14252
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.9987053127702357,
      "learning_rate": 2.109794785804531e-09,
      "loss": 0.502,
      "step": 14253
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.6953915020949901,
      "learning_rate": 2.07721382832371e-09,
      "loss": 0.4346,
      "step": 14254
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.415224451468328,
      "learning_rate": 2.044886349192865e-09,
      "loss": 0.5058,
      "step": 14255
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.9605692613701362,
      "learning_rate": 2.0128123500506856e-09,
      "loss": 0.4624,
      "step": 14256
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.1185024781357367,
      "learning_rate": 1.980991832524759e-09,
      "loss": 0.4913,
      "step": 14257
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.9984118421173171,
      "learning_rate": 1.9494247982282386e-09,
      "loss": 0.4375,
      "step": 14258
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.9167020242120567,
      "learning_rate": 1.918111248762067e-09,
      "loss": 0.4767,
      "step": 14259
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.1455367967078036,
      "learning_rate": 1.887051185714972e-09,
      "loss": 0.4568,
      "step": 14260
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.3770620290912854,
      "learning_rate": 1.856244610661806e-09,
      "loss": 0.4956,
      "step": 14261
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.6096738562422471,
      "learning_rate": 1.8256915251646524e-09,
      "loss": 0.4278,
      "step": 14262
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.280570002977956,
      "learning_rate": 1.7953919307739375e-09,
      "loss": 0.4832,
      "step": 14263
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.0780611027517275,
      "learning_rate": 1.7653458290256554e-09,
      "loss": 0.4562,
      "step": 14264
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.782827281175043,
      "learning_rate": 1.7355532214435867e-09,
      "loss": 0.4635,
      "step": 14265
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.201781400511783,
      "learning_rate": 1.7060141095393002e-09,
      "loss": 0.5003,
      "step": 14266
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.7493145707811355,
      "learning_rate": 1.6767284948104868e-09,
      "loss": 0.4955,
      "step": 14267
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.3576835021513585,
      "learning_rate": 1.6476963787426247e-09,
      "loss": 0.4859,
      "step": 14268
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.413526921512876,
      "learning_rate": 1.6189177628078702e-09,
      "loss": 0.5193,
      "step": 14269
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.9055304978665537,
      "learning_rate": 1.5903926484661658e-09,
      "loss": 0.4493,
      "step": 14270
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.3299510822550475,
      "learning_rate": 1.5621210371641327e-09,
      "loss": 0.5342,
      "step": 14271
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.028283838124816,
      "learning_rate": 1.5341029303350685e-09,
      "loss": 0.4869,
      "step": 14272
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.5320402822457315,
      "learning_rate": 1.506338329400614e-09,
      "loss": 0.4985,
      "step": 14273
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.5459606374222852,
      "learning_rate": 1.4788272357685318e-09,
      "loss": 0.4244,
      "step": 14274
    },
    {
      "epoch": 0.99,
      "grad_norm": 3.2733206245905246,
      "learning_rate": 1.4515696508343724e-09,
      "loss": 0.4767,
      "step": 14275
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.1146580851297325,
      "learning_rate": 1.4245655759803633e-09,
      "loss": 0.4196,
      "step": 14276
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.5239055922796421,
      "learning_rate": 1.3978150125759649e-09,
      "loss": 0.4011,
      "step": 14277
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.8163230014375231,
      "learning_rate": 1.3713179619778693e-09,
      "loss": 0.4858,
      "step": 14278
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.0877648638311306,
      "learning_rate": 1.345074425530557e-09,
      "loss": 0.4709,
      "step": 14279
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.9955168581999025,
      "learning_rate": 1.319084404564075e-09,
      "loss": 0.4604,
      "step": 14280
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.1692936512400594,
      "learning_rate": 1.293347900397368e-09,
      "loss": 0.5023,
      "step": 14281
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.0871025302338273,
      "learning_rate": 1.2678649143349485e-09,
      "loss": 0.5242,
      "step": 14282
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.5050734957849077,
      "learning_rate": 1.242635447669671e-09,
      "loss": 0.4703,
      "step": 14283
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.04164706594104,
      "learning_rate": 1.2176595016810677e-09,
      "loss": 0.5119,
      "step": 14284
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.599397582390867,
      "learning_rate": 1.1929370776359028e-09,
      "loss": 0.422,
      "step": 14285
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.492013179023007,
      "learning_rate": 1.1684681767881734e-09,
      "loss": 0.4764,
      "step": 14286
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.362425189961181,
      "learning_rate": 1.1442528003779985e-09,
      "loss": 0.5149,
      "step": 14287
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.4661554162209445,
      "learning_rate": 1.120290949634395e-09,
      "loss": 0.4326,
      "step": 14288
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.8475564873784898,
      "learning_rate": 1.096582625772502e-09,
      "loss": 0.4646,
      "step": 14289
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.045378919708485,
      "learning_rate": 1.0731278299946912e-09,
      "loss": 0.5178,
      "step": 14290
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.1387546479813633,
      "learning_rate": 1.0499265634900114e-09,
      "loss": 0.4567,
      "step": 14291
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.5473374763259465,
      "learning_rate": 1.026978827435854e-09,
      "loss": 0.4138,
      "step": 14292
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.9503099987644905,
      "learning_rate": 1.0042846229957327e-09,
      "loss": 0.4975,
      "step": 14293
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.196598429594015,
      "learning_rate": 9.818439513203937e-10,
      "loss": 0.5228,
      "step": 14294
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.198111112203179,
      "learning_rate": 9.596568135483708e-10,
      "loss": 0.5091,
      "step": 14295
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.8341167222191985,
      "learning_rate": 9.3772321080432e-10,
      "loss": 0.4535,
      "step": 14296
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.3117043813168237,
      "learning_rate": 9.160431442017947e-10,
      "loss": 0.476,
      "step": 14297
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.7698474431923668,
      "learning_rate": 8.946166148388058e-10,
      "loss": 0.494,
      "step": 14298
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.047200922410421,
      "learning_rate": 8.734436238033716e-10,
      "loss": 0.4841,
      "step": 14299
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.445060945264323,
      "learning_rate": 8.52524172169078e-10,
      "loss": 0.4654,
      "step": 14300
    },
    {
      "epoch": 0.99,
      "grad_norm": 1.7685725512240036,
      "learning_rate": 8.318582609961878e-10,
      "loss": 0.4792,
      "step": 14301
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.3525812719365056,
      "learning_rate": 8.114458913333068e-10,
      "loss": 0.4672,
      "step": 14302
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.923439588104493,
      "learning_rate": 7.912870642151627e-10,
      "loss": 0.4753,
      "step": 14303
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.222173217044683,
      "learning_rate": 7.713817806648261e-10,
      "loss": 0.4533,
      "step": 14304
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.0071074043179284,
      "learning_rate": 7.517300416920448e-10,
      "loss": 0.5078,
      "step": 14305
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.0071878251902713,
      "learning_rate": 7.323318482926888e-10,
      "loss": 0.513,
      "step": 14306
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.058286467003224,
      "learning_rate": 7.131872014509711e-10,
      "loss": 0.4732,
      "step": 14307
    },
    {
      "epoch": 0.99,
      "grad_norm": 3.0696954560952263,
      "learning_rate": 6.942961021377815e-10,
      "loss": 0.499,
      "step": 14308
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.0661437412083465,
      "learning_rate": 6.756585513112423e-10,
      "loss": 0.5042,
      "step": 14309
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.425430285165446,
      "learning_rate": 6.572745499161537e-10,
      "loss": 0.5217,
      "step": 14310
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.8683706879605544,
      "learning_rate": 6.391440988856578e-10,
      "loss": 0.5283,
      "step": 14311
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.3681526961862494,
      "learning_rate": 6.212671991390195e-10,
      "loss": 0.515,
      "step": 14312
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.219786331098513,
      "learning_rate": 6.036438515827358e-10,
      "loss": 0.4498,
      "step": 14313
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.880188582378392,
      "learning_rate": 5.862740571105363e-10,
      "loss": 0.4784,
      "step": 14314
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.321282021303836,
      "learning_rate": 5.69157816603938e-10,
      "loss": 0.5032,
      "step": 14315
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.610593109422984,
      "learning_rate": 5.522951309300251e-10,
      "loss": 0.4961,
      "step": 14316
    },
    {
      "epoch": 1.0,
      "grad_norm": 4.251463937009357,
      "learning_rate": 5.356860009447795e-10,
      "loss": 0.4889,
      "step": 14317
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.1508543565835616,
      "learning_rate": 5.193304274903054e-10,
      "loss": 0.4427,
      "step": 14318
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.17819798583691,
      "learning_rate": 5.032284113959395e-10,
      "loss": 0.4761,
      "step": 14319
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.7846419851139943,
      "learning_rate": 4.87379953478806e-10,
      "loss": 0.4471,
      "step": 14320
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.7007577365613298,
      "learning_rate": 4.717850545427061e-10,
      "loss": 0.4327,
      "step": 14321
    },
    {
      "epoch": 1.0,
      "grad_norm": 5.485936440129364,
      "learning_rate": 4.5644371537756363e-10,
      "loss": 0.4701,
      "step": 14322
    },
    {
      "epoch": 1.0,
      "grad_norm": 3.8982976806501393,
      "learning_rate": 4.4135593676275513e-10,
      "loss": 0.47,
      "step": 14323
    },
    {
      "epoch": 1.0,
      "grad_norm": 3.040504023823693,
      "learning_rate": 4.2652171946266916e-10,
      "loss": 0.4834,
      "step": 14324
    },
    {
      "epoch": 1.0,
      "grad_norm": 3.8256563646873722,
      "learning_rate": 4.119410642294819e-10,
      "loss": 0.4595,
      "step": 14325
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.8033620168575477,
      "learning_rate": 3.97613971803712e-10,
      "loss": 0.4917,
      "step": 14326
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.4189375568202856,
      "learning_rate": 3.835404429108902e-10,
      "loss": 0.4527,
      "step": 14327
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.333783979045412,
      "learning_rate": 3.697204782654451e-10,
      "loss": 0.4756,
      "step": 14328
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.1185264840273015,
      "learning_rate": 3.5615407856792737e-10,
      "loss": 0.5335,
      "step": 14329
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.6386891296273112,
      "learning_rate": 3.428412445066753e-10,
      "loss": 0.4503,
      "step": 14330
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.556008083638156,
      "learning_rate": 3.297819767561494e-10,
      "loss": 0.4844,
      "step": 14331
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.7997181557144861,
      "learning_rate": 3.1697627597970794e-10,
      "loss": 0.4539,
      "step": 14332
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.1162927696201734,
      "learning_rate": 3.044241428262762e-10,
      "loss": 0.525,
      "step": 14333
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.5544882925319732,
      "learning_rate": 2.921255779325671e-10,
      "loss": 0.4059,
      "step": 14334
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.0758664023987428,
      "learning_rate": 2.80080581921971e-10,
      "loss": 0.4589,
      "step": 14335
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.8636315803409054,
      "learning_rate": 2.6828915540566547e-10,
      "loss": 0.4932,
      "step": 14336
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.3417455101316387,
      "learning_rate": 2.5675129898206086e-10,
      "loss": 0.5088,
      "step": 14337
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.5091565050017874,
      "learning_rate": 2.4546701323568954e-10,
      "loss": 0.5286,
      "step": 14338
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.5982690701263277,
      "learning_rate": 2.344362987388715e-10,
      "loss": 0.43,
      "step": 14339
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.8631552545888628,
      "learning_rate": 2.2365915605171428e-10,
      "loss": 0.4818,
      "step": 14340
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.2507101256405933,
      "learning_rate": 2.1313558571989245e-10,
      "loss": 0.5031,
      "step": 14341
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.139158597507658,
      "learning_rate": 2.0286558827797842e-10,
      "loss": 0.4869,
      "step": 14342
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.961453262951981,
      "learning_rate": 1.9284916424611166e-10,
      "loss": 0.4346,
      "step": 14343
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.1409296851938024,
      "learning_rate": 1.8308631413277434e-10,
      "loss": 0.5003,
      "step": 14344
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.013991663398004,
      "learning_rate": 1.735770384331259e-10,
      "loss": 0.4704,
      "step": 14345
    },
    {
      "epoch": 1.0,
      "grad_norm": 3.780062097555915,
      "learning_rate": 1.6432133762900315e-10,
      "loss": 0.4402,
      "step": 14346
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.656905642432731,
      "learning_rate": 1.5531921219058554e-10,
      "loss": 0.5,
      "step": 14347
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.2343128245135246,
      "learning_rate": 1.4657066257361964e-10,
      "loss": 0.5246,
      "step": 14348
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.1534731014442827,
      "learning_rate": 1.380756892221946e-10,
      "loss": 0.4944,
      "step": 14349
    },
    {
      "epoch": 1.0,
      "grad_norm": 3.109327826809733,
      "learning_rate": 1.2983429256707703e-10,
      "loss": 0.5118,
      "step": 14350
    },
    {
      "epoch": 1.0,
      "grad_norm": 14.217031798805776,
      "learning_rate": 1.2184647302626585e-10,
      "loss": 0.5318,
      "step": 14351
    },
    {
      "epoch": 1.0,
      "grad_norm": 3.217200760594452,
      "learning_rate": 1.1411223100443735e-10,
      "loss": 0.4643,
      "step": 14352
    },
    {
      "epoch": 1.0,
      "grad_norm": 3.265936111087422,
      "learning_rate": 1.0663156689461051e-10,
      "loss": 0.4113,
      "step": 14353
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.5662635733248679,
      "learning_rate": 9.940448107592649e-11,
      "loss": 0.4071,
      "step": 14354
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.4980839863076296,
      "learning_rate": 9.243097391475886e-11,
      "loss": 0.46,
      "step": 14355
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.5522676125064699,
      "learning_rate": 8.571104576471367e-11,
      "loss": 0.3939,
      "step": 14356
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.5295575589678094,
      "learning_rate": 7.924469696718451e-11,
      "loss": 0.4813,
      "step": 14357
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.281882974210711,
      "learning_rate": 7.303192784913205e-11,
      "loss": 0.458,
      "step": 14358
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.3024168841311177,
      "learning_rate": 6.707273872641474e-11,
      "loss": 0.5084,
      "step": 14359
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.6657958658027077,
      "learning_rate": 6.136712990156834e-11,
      "loss": 0.4674,
      "step": 14360
    },
    {
      "epoch": 1.0,
      "grad_norm": 4.60150775090122,
      "learning_rate": 5.5915101662695756e-11,
      "loss": 0.4864,
      "step": 14361
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.5674944966250934,
      "learning_rate": 5.071665428735273e-11,
      "loss": 0.5305,
      "step": 14362
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.5404700317408277,
      "learning_rate": 4.577178803866211e-11,
      "loss": 0.4033,
      "step": 14363
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.9124411654256932,
      "learning_rate": 4.108050316808942e-11,
      "loss": 0.467,
      "step": 14364
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.5842230207527405,
      "learning_rate": 3.664279991266728e-11,
      "loss": 0.4426,
      "step": 14365
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.2705955345370894,
      "learning_rate": 3.245867849832607e-11,
      "loss": 0.5105,
      "step": 14366
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.4350082329458895,
      "learning_rate": 2.8528139136563272e-11,
      "loss": 0.4771,
      "step": 14367
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.3344665653129897,
      "learning_rate": 2.4851182027219035e-11,
      "loss": 0.5175,
      "step": 14368
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.394773322627041,
      "learning_rate": 2.1427807356255715e-11,
      "loss": 0.4683,
      "step": 14369
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.0139128433442504,
      "learning_rate": 1.8258015297978327e-11,
      "loss": 0.5265,
      "step": 14370
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.8428226825066305,
      "learning_rate": 1.5341806012258986e-11,
      "loss": 0.5004,
      "step": 14371
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.62824503701479,
      "learning_rate": 1.2679179647867578e-11,
      "loss": 0.5336,
      "step": 14372
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.881215035978883,
      "learning_rate": 1.0270136339696202e-11,
      "loss": 0.4474,
      "step": 14373
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.5856946790919731,
      "learning_rate": 8.114676209314276e-12,
      "loss": 0.3824,
      "step": 14374
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.0381289769375353,
      "learning_rate": 6.2127993666338815e-12,
      "loss": 0.4507,
      "step": 14375
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.2324035850343447,
      "learning_rate": 4.564505907689309e-12,
      "loss": 0.4622,
      "step": 14376
    },
    {
      "epoch": 1.0,
      "grad_norm": 9.271179666671824,
      "learning_rate": 3.16979591685751e-12,
      "loss": 0.4793,
      "step": 14377
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.2753617378033595,
      "learning_rate": 2.028669464082533e-12,
      "loss": 0.4643,
      "step": 14378
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.9123281013144544,
      "learning_rate": 1.141126607095977e-12,
      "loss": 0.4902,
      "step": 14379
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.3821361132363066,
      "learning_rate": 5.071673919720965e-13,
      "loss": 0.4561,
      "step": 14380
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.538326918939366,
      "learning_rate": 1.2679184979713655e-13,
      "loss": 0.4095,
      "step": 14381
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.214372272375645,
      "learning_rate": 0.0,
      "loss": 0.4327,
      "step": 14382
    },
    {
      "epoch": 1.0,
      "step": 14382,
      "total_flos": 1.1849613938786304e+16,
      "train_loss": 0.5078163075067457,
      "train_runtime": 262491.3206,
      "train_samples_per_second": 14.026,
      "train_steps_per_second": 0.055
    }
  ],
  "logging_steps": 1.0,
  "max_steps": 14382,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "total_flos": 1.1849613938786304e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
